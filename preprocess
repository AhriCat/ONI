class preprocessor():
    def preprocess_text(text):
        tokens = word_tokenize(text.lower())  # Tokenize and convert to lower case
        tokens = [token for token in tokens if token.isalpha()]  # Remove non-alphabetic characters
        tokens = [token for token in tokens if token not in stopwords_list]  # Remove stopwords
        return tokens

# Example applying preprocessing to texts we use
#brown_texts = [' '.join(preprocessor.preprocess_text(' '.join(words))) for words in brown.sents()]
#treebank_texts = [' '.join(preprocessor.preprocess_text(' '.join(words))) for words in treebank.sents()]

preprocessor.preprocess_text(corpus)
