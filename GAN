import numpy as np
class GAN:
    def __init__(self, latent_dim, image_size):
        self.latent_dim = latent_dim
        self.image_size = image_size
        self.params = self.initialize_params()

    #activation function
    @staticmethod
    def sigmoid(x):
        return 1 / (1 + np.exp(-x))

    @staticmethod
    def tanh(x):
        return np.tanh(x)

    def generator(self, z):
        # Simple fully connected layer with tanh activation
        return self.tanh(np.dot(z, self.params['G_weights']) + self.params['G_bias'])
    #discriminator (tells features from params)
    def discriminator(x, params):
        # Simple fully connected layer with sigmoid activation
        return sigmoid(np.dot(x, params['D_weights']) + params['D_bias'])

     #params
    def initialize_params():
        params = {'G_weights': np.random.randn(latent_dim, image_size),  # Adjust dimensions as necessary
                  'G_bias': np.zeros((1, image_size)),
                  'D_weights': np.random.randn(image_size, 1),
                  'D_bias': np.zeros((1, 1))}
        return params

    #training function
    def train_step(params, data, latent_dim, lr=0.01):
       # Sample random noise
        z = np.random.randn(latent_dim)

        # Generate fake images
        fake_images = generator(z, params)

         # Get predictions for real and fake images
        real_preds = discriminator(data, params)
        fake_preds = discriminator(fake_images, params)

        # Calculate loss (placeholder values)
        D_loss = -np.log(real_preds) - np.log(1 - fake_preds)
        G_loss = -np.log(fake_preds)

        # Backpropagate errors and update weights (not implemented here)
        params = update_params(params, D_loss, G_loss, lr)

        return D_loss, G_loss

        # Load your data here
    # gen image function
    def generate_image(self):
        z = np.random.randn(1, self.latent_dim)
        img = self.generator(z).reshape(28, 28)  # Assuming square image
        plt.imshow(img, cmap='gray')
        plt.show()


#initialize GAN
params = initialize_params()
latent_dim = 100  # Dimensionality of the latent space
image_size = 28 * 28  # Example: flattened 28x28 grayscale image
gan = GAN(latent_dim, image_size)

data = np.random.randn(1, (225))  # Dummy data


#Training
num_epochs = 50

for epoch in range(num_epochs):
    D_loss, G_loss = GAN.train_step(params, data, latent_dim)
    print(f"Epoch {epoch}, D Loss: {D_loss}, G Loss: {G_loss}")

params = initialize_params()
latent_dim = 100  # Dimensionality of the latent space
gan.generate_image()
