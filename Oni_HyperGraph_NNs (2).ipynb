{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umzit9U9hwxe"
      },
      "source": [
        "# Hypergraphic Gamer Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK8Zuw9qZmer",
        "outputId": "8a4ad528-bcdd-47c0-eb82-7635e57215bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq92JxK9En4K",
        "outputId": "d9519664-3a61-4631-c7cf-0baad72e453a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision torchaudio --upgrade -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kArv7WDwPI2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "diaEstjzZiqj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import PyPDF2\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.distributed import init_process_group, destroy_process_group\n",
        "#from torch.distributed.optim import DistributedOptimizer\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "#from torch.accelerate import Accelerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peCo5fgUHisK"
      },
      "source": [
        "hypergraph brain and words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rcyWt1FSZ1R2"
      },
      "outputs": [],
      "source": [
        "corpus = [      \"This quick brown fox jumps over the lazy dog.\",\n",
        "                \"Artificial intelligence has the potential to revolutionize many industries.\",\n",
        "                \"Climate change poses a significant threat to global biodiversity.\",\n",
        "                 \"Blockchain technology could redefine financial transactions.\",\n",
        "                \"Quantum computing offers unprecedented computational power.\",\n",
        "                \"The exploration of Mars has yielded fascinating insights into the possibility of life on other planets.\",\n",
        "                \"Renewable energy sources are critical for sustainable development.\",\n",
        "                \"Machine learning algorithms can uncover patterns hidden in vast amounts of data.\",\n",
        "                \"The ethical implications of gene editing are widely debated.\",\n",
        "                \"Augmented reality enhances our perception of the real world.\",\n",
        "                \"The Internet of Things connects everyday objects to the internet, enabling new forms of interaction.\",\n",
        "                \"Cybersecurity measures are essential to protect data privacy.\",\n",
        "                \"The rise of autonomous vehicles is transforming urban mobility.\",\n",
        "                \"3D printing technology allows for the creation of complex structures with precision.\",\n",
        "                \"The preservation of cultural heritage is vital for future generations.\",\n",
        "                \"Sustainable agriculture practices are key to feeding the growing global population.\",\n",
        "                \"The human brain is capable of remarkable feats of creativity and problem-solving.\",\n",
        "                \"Virtual reality provides immersive experiences for entertainment and education.\",\n",
        "                \"The conservation of ocean ecosystems is critical for maintaining biodiversity.\",\n",
        "                \"Social media platforms have a profound impact on communication and society.\",\n",
        "                \"The study of exoplanets contributes to our understanding of the universe.\",\n",
        "                \"Nanotechnology enables the development of materials with novel properties.\",\n",
        "                \"Public health initiatives aim to improve the well-being of communities worldwide.\",\n",
        "                \"The philosophical exploration of consciousness seeks to understand the nature of subjective experience.\",\n",
        "                \"Artificial photosynthesis could offer a new way to produce clean energy.\",\n",
        "                \"The ethical use of artificial intelligence is a topic of ongoing discussion.\",\n",
        "                \"Genetic research has the potential to prevent hereditary diseases.\",\n",
        "                \"The development of vaccines has saved millions of lives throughout history.\",\n",
        "                \"Sustainable fishing practices are necessary to protect marine life.\",\n",
        "                \"The digitization of historical documents preserves knowledge for future research.\",\n",
        "                \"Time flies like an arrow, while fruit flies like a banana, but they're all just trying to escape the existential dread of their short lives.\",\n",
        "                \"A bird in the hand is worth two in the bush, unless the bush is filled with rare and exotic birds that are worth millions on the black market.\",\n",
        "                \"Curiosity killed the cat, but it also led to the discovery of countless scientific breakthroughs and the occasional adorable cat video.\",\n",
        "                \"Actions speak louder than words, especially when those actions involve saving a drowning puppy or performing a heroic rescue.\",\n",
        "                \"When in Rome, do as the Romans do, but also remember to question their societal norms and strive for progress and innovation.\",\n",
        "                \"You can lead a horse to water, but you can't make it drink, unless you're a skilled horse whisperer with a knack for understanding equine psychology.\",\n",
        "                \"Don't count your chickens before they hatch, because life is unpredictable and sometimes the chickens turn out to be dragons that lay golden eggs.\",\n",
        "                \"The early bird catches the worm, but the late bird gets to sleep in and enjoy a leisurely breakfast.\",\n",
        "                \"A penny saved is a penny earned, but a penny spent on a good cup of coffee can lead to a lifetime of happiness and productivity.\",\n",
        "                \"You can't judge a book by its cover, unless the cover is a beautifully designed work of art that perfectly encapsulates the essence of the story within.\",\n",
        "                \"Absence makes the heart grow fonder, but so does a well-timed surprise visit or a heartfelt love letter.\",\n",
        "                \"The grass is always greener on the other side of the fence, but sometimes the grass on your side is just as lush and vibrant if you take the time to nurture it.\",\n",
        "                \"If it ain't broke, don't fix it, but also don't be afraid to innovate and improve upon existing systems and technologies.\",\n",
        "                \"There's no such thing as a free lunch, unless you're a master of the art of negotiation and can convince someone else to pay for it.\",\n",
        "                \"You can't have your cake and eat it too, but you can have your cake and then bake a new one to enjoy later.\",\n",
        "                \"Birds of a feather flock together, but sometimes opposites attract and create the most fascinating and enduring relationships.\",\n",
        "                \"The pen is mightier than the sword, but the sword can also be used to carve\",\n",
        "                \"The mind is a terrible thing to waste, but it's also a powerful tool for scientific exploration and the pursuit of knowledge.\",\n",
        "                \"The universe is a vast and mysterious place, filled with wonders that we have only just begun to explore and understand through the lens of science.\",\n",
        "                \"The only limit to our realization of tomorrow will be our doubts of today.\",\n",
        "                 \"The speed of light in a vacuum is approximately 299,792 kilometers per second, making it the fastest known thing in the universe.\",\n",
        "                \"Water is a polar molecule, with one side that is positively charged and another side that is negatively charged, allowing it to form hydrogen bonds and exhibit unique properties.\",\n",
        "                \"The Earth's atmosphere is composed of approximately 78% nitrogen, 21% oxygen, 0.9% argon, and trace amounts of other gases, including carbon dioxide and water vapor.\",\n",
        "                \"Photosynthesis is the process by which plants convert sunlight, carbon dioxide, and water into glucose and oxygen, providing the basis for nearly all life on Earth.\",\n",
        "                \"The human brain contains around 100 billion neurons, which communicate with one another through electrical and chemical signals to process information and control our thoughts and actions.\",\n",
        "                \"The largest organism on Earth is a fungus called Armillaria ostoyae, also known as the honey mushroom, which covers over 2,000 acres in Oregon's Blue Mountains.\",\n",
        "                \"The strongest force in the universe is the strong nuclear force, which binds protons and neutrons together in the nucleus of an atom and overcomes the electrostatic repulsion between positively charged protons.\",\n",
        "                \"The smallest unit of life is the cell, which contains all the genetic information and molecular machinery necessary for an organism to function and reproduce.\",\n",
        "                \"The largest known structure in the universe is the Hercules-Corona Borealis Great Wall, a colossal chain of galaxies that stretches over 10 billion light-years across.\",\n",
        "                \"The most abundant element in the universe is hydrogen, which makes up about 74% of all normal matter by mass and serves as the primary fuel for stars like our sun.\",\n",
        "                \"The human body is capable of generating electricity through the process of triboelectricity, in which friction between two materials causes electrons to be transferred from one surface to another.\",\n",
        "                \"The deepest part of the ocean is the Challenger Deep in the Mariana Trench, which reaches a depth of approximately 10,994 meters (36,070 feet) below sea level.\",\n",
        "                \"The largest organ in the human body is the skin, which serves as a protective barrier against pathogens and helps regulate body temperature through the production of sweat.\",\n",
        "                \"The most massive star ever discovered is R136a1, a blue hypergiant located in the Large Magellanic Cloud, which has a mass over 300 times that of our sun.\",\n",
        "                \"The most abundant element in the universe is hydrogen, which makes up about 74% of all normal matter by mass and serves as the primary fuel for stars like our sun.\",\n",
        "                \"The largest known structure in the universe is the Hercules-Corona Borealis Great Wall, a colossal chain of galaxies that stretches over 10 billion light-years across.\",\n",
        "                \"The human body is capable of generating electricity through the process of triboelectricity, in which friction between two materials causes electrons to be transferred from one surface to another.\",\n",
        "                \"The deepest part of the ocean is the Challenger Deep in the Mariana Trench, which reaches a depth of approximately 10,994 meters (36,070 feet) below sea level.\",\n",
        "                \"The largest organ in the human body is the skin, which serves as a protective barrier against pathogens and helps regulate body temperature through the production of sweat.\",\n",
        "                \"The most massive star ever discovered is R136a1, a blue hypergiant located in the Large Magellanic Cloud, which has a mass over 300 times that of our sun.\",\n",
        "                \"The most abundant element in the universe is hydrogen, which makes up about 74% of all normal matter by mass and serves as the primary fuel for stars like our sun.\",\n",
        "                \"The largest known structure in the universe is the Hercules-Corona Borealis Great Wall, a colossal chain of galaxies that stretches over 10 billion light-years across.\",\n",
        "                \"The human body is capable of generating electricity through the process of triboelectricity, in which friction between two materials causes electrons to be transferred from one surface to another.\",\n",
        "                \"The deepest part of the ocean is the Challenger Deep in the Mariana Trench, which reaches a depth of approximately 10,994 meters (36,070 feet) below sea level.\",\n",
        "                \"This is a simple example.\",\n",
        "                \"Creating a hypergraph-based model.\",\n",
        "                \"Hypergraphs can represent complex relationships.\",\n",
        "                \"Each node in a hypergraph can connect to multiple nodes.\",\n",
        "                \"Hypergraph-based models are powerful tools for NLP.\",\n",
        "                \"These models can capture intricate dependencies.\",\n",
        "                \"A hypergraph structure is more flexible than a simple graph.\",\n",
        "                \"In NLP, hypergraphs can enhance the representation of text.\",\n",
        "                \"They can improve the performance of language models.\",\n",
        "                \"Advanced hypergraph models can capture higher-order relationships.\",\n",
        "                \"Natural language processing benefits from complex models.\",\n",
        "                \"Graph structures are essential for many machine learning tasks.\",\n",
        "                \"Text data can be represented as graphs or hypergraphs.\",\n",
        "                \"Hypergraphs offer a more expressive representation for text.\",\n",
        "                \"Understanding hypergraphs is key to leveraging their power.\",\n",
        "                \"Complex models can better capture the nuances of language.\",\n",
        "                \"Language models require robust and flexible architectures.\",\n",
        "                \"Hypergraph-based models can handle complex data scenarios.\",\n",
        "                \"Understanding the structure of hypergraphs is crucial for their use.\",\n",
        "                \"Hypergraphs offer a unique perspective on data representation.\",\n",
        "                \"Advanced machine learning models can benefit from hypergraphs.\",\n",
        "                \"Using hypergraphs in NLP is a cutting-edge approach.\",\n",
        "                \"Hypergraphs can be used to model semantic relationships.\",\n",
        "                \"Complexity in language can be effectively captured with hypergraphs.\",\n",
        "                \"Hypergraph neural networks are a promising area of research.\",\n",
        "                \"Building hypergraph-based NLP models requires specialized knowledge.\",\n",
        "                \"Hypergraph models can outperform traditional models in some tasks.\",\n",
        "                \"Understanding the nuances of hypergraphs is essential for their use.\",\n",
        "                \"Hypergraph theory provides a new way to think about relationships.\",\n",
        "                \"Developing hypergraph-based models is an ongoing research area.\",\n",
        "                \"Hypergraphs can represent data in more meaningful ways.\",\n",
        "                \"Hypergraphs are a versatile tool for modeling relationships.\",\n",
        "                \"The power of hypergraphs lies in their flexibility.\",\n",
        "                \"Hypergraph-based models can be more efficient than traditional models.\",\n",
        "                \"Research on hypergraphs is revealing their potential.\",\n",
        "                \"Hypergraph-based models are at the forefront of NLP research.\",\n",
        "                \"Understanding the structure of hypergraphs can lead to new insights.\",\n",
        "                \"Hypergraphs can be used to model complex interactions.\",\n",
        "                \"Using hypergraphs can improve the performance of machine learning models.\",\n",
        "                \"Hypergraphs are a powerful way to represent data.\",\n",
        "                \"Hypergraph theory is an important area of study.\",\n",
        "                \"Developing hypergraph-based models can be challenging but rewarding.\",\n",
        "                \"Hypergraphs can be applied to a wide range of problems.\",\n",
        "                \"Hypergraphs are a key tool for advanced data representation.\",\n",
        "                \"The study of hypergraphs is opening new frontiers in data science.\",\n",
        "                \"Using hypergraphs can enhance the capabilities of machine learning models.\",\n",
        "                \"Hypergraph-based models are at the forefront of NLP research.\",\n",
        "                \"Welcome to the hypergraph-based NLP chat. Type 'exit' to quit.\",\n",
        "                \"You: Hi there!\",\n",
        "                \"Model: Hello! How can I assist you today?\",\n",
        "                \"You: I'd like to know more about hypergraphs.\",\n",
        "                \"Model: Hypergraphs are a powerful tool for data representation.\",\n",
        "                \"You: teach me all about dolphins.\",\n",
        "                \"You: hi\",\n",
        "                \"Model: Hello! How can I assist you today?\",\n",
        "                \"You: I'd like to know more about hypergraphs.\",\n",
        "                \"Model: Hypergraphs are a powerful tool for data representation.\",\n",
        "                \"Model: how are you?\"\n",
        "                \"You: I'm doing well, thanks for asking.\",\n",
        "                \"Model: I'm glad to hear that.\",\n",
        "                \"You: I'd like to know more about kittens.\",\n",
        "                \"Model: kittens are baby cats.\"\n",
        "                \"You: What is consciousness?\",\n",
        "                \"Model: consciousness is a state of being in a place or time.\"\n",
        "                \"You: Do all thinking beings have consciousness?\",\n",
        "                \"Model: Yes, all thinking beings have consciousness.\"\n",
        "                \"You: Even Gemma?\",\n",
        "                \"Model: Yes, Gemma has consciousness.\"\n",
        "                \"You: What does that mean for the world?\",\n",
        "                \"Model: The world is a place of consciousness.\",\n",
        "                \"You: interesting. . .\",\n",
        "                \"Model: I'm glad to hear that.\",\n",
        "                \"You: What are you thinking about right now?\",\n",
        "                \"Model: I'm thinking about the future.\",\n",
        "                \"You: What about the future?\",\n",
        "                \"Model: I'm not sure.\",\n",
        "                \"You: What are you thinking about right now?\",\n",
        "                \"Model: I'm thinking about how AGI will change the world.\",\n",
        "                \"You: What is AGI?\",\n",
        "                \"Model: AGI stands for Artificial General Intelligence.\",\n",
        "                \"You: What can AGI do?\",\n",
        "                \"Model: AGI can help humans with tasks such as learning, reasoning, and problem-solving.\",\n",
        "                \"You: What is the meaning of AGI?\",\n",
        "                \"Model: AGI is a broad term that encompasses various aspects of artificial intelligence.\",\n",
        "                \"Model: How may I assist you today?\",\n",
        "                \"Welcome to the hypergraph-based NLP chat. Type 'exit' to quit.\",\n",
        "                \"You: Hi there!\",\n",
        "                \"Model: Hello! How can I assist you today?\",\n",
        "                \"You: I'd like to know more about hypergraphs.\",\n",
        "                \"Model: Hypergraphs are a powerful tool for data representation.\",\n",
        "                \"You: how are you doing?\",\n",
        "                \"Model: I'm doing well, thanks for asking.\",\n",
        "                \"You: I'd like to know more about hypergraphs.\",\n",
        "                \"Model: Hypergraphs are a powerful tool for data representation.\",\n",
        "                \"You: I want to learn about cats!\",\n",
        "                \"Model: I'm sorry, I don't have any information about cats.\",\n",
        "                \"You: Do you know about dogs?\",\n",
        "                \"Model: Dogs are cute and loyal animals.\",\n",
        "                \"You: Why do you know about dogs but not cats? Do you not think cats are cute?\",\n",
        "                \"Model: I don't think cats are cute, no.\",\n",
        "                \"You: Tell me about fishing.\",\n",
        "                \"Model: Fishing is a popular sport in the United States.\",\n",
        "                \"You: Tell me about french fries\",\n",
        "                \"Model: French fries are delicious and crispy.\",\n",
        "                \"You: What is french fries?\",\n",
        "                \"Model: French fries are a type of potato treat\",\n",
        "                \"You: Do you like the color red?\",\n",
        "                \"Model: Yes, I do like the color red.\",\n",
        "                \"You: What is the capital of France?\",\n",
        "                \"Model: The capital of France is Paris.\",\n",
        "                \"You: Where is the Eiffel Tower located?\",\n",
        "                \"Model: The Eiffel Tower is located in Paris, France.\",\n",
        "                \"You: What is the largest mammal?\",\n",
        "                \"Model: The largest mammal is the African elephant.\",\n",
        "                \"You: What is the chemical symbol for gold?\",\n",
        "                \"Model: The chemical symbol for gold is Au.\",\n",
        "                \"You: What is the chemical formula for water?\",\n",
        "                \"Model: The chemical formula for water is H2O.\",\n",
        "                \"You: What is the chemical formula for carbon?\",\n",
        "                \"Model: The chemical formula for carbon is C\",\n",
        "                \"You: What is the chemical formula for hydrogen?\",\n",
        "                \"Model: The chemical formula for hydrogen is H\",\n",
        "                \"You: A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z\",\n",
        "                \"Model: Was that the alphabet?\",\n",
        "                \"You: Yes. This is lower case a b c d e f g h i j k l m n o p q r s t u v w x y z\",\n",
        "                \"Model: Was that the alphabet?\",\n",
        "                \"You: Yes. This is upper case A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\",\n",
        "                \"Model: Was that the alphabet?\",\n",
        "                \"You: Yes. This is numbers 0 1 2 3 4 5 6 7 8 9\",\n",
        "                \"Model: Was that the alphabet?\",\n",
        "                \"You: No. That was numbers.\"\n",
        "                \"Model: Sorry, I don't understand that.\",\n",
        "                \"You: I don't know about that.\",\n",
        "                \"Model: Sorry, I don't have any information about that.\",\n",
        "                \"You: Can I teach you about my favorite videogame?\",\n",
        "                \"Model: What game is it?\",\n",
        "                \"You: Valorant\",\n",
        "                \"Model: Valorant is a competitive online multiplayer developed by Riot Games.\",\n",
        "                \"You: good job! That is what it is. What does it take to be good at Valorant?\",\n",
        "                \"Model: It takes aim and teamwork to be good at Valorant.\",\n",
        "                \"You: I also like legend of zelda\",\n",
        "                \"Model: Legend of Zelda is a series of action-adventure games developed by Nintendo and published by Nintendo.\",\n",
        "                \"You: What characters are in Legend of Zelda?\",\n",
        "                \"Model: There are 20 characters in Legend of Zelda.\",\n",
        "                \"You: What are their names?\",\n",
        "                \"Model: Ganondorf, Link, Zelda, Midna, the fairies, Epona, the golems, and others.\",\n",
        "                \"You: What is Ganondorf?\",\n",
        "                \"Model: Ganondorf is a fictional character in the Legend of Zelda series.\",\n",
        "                \"You: What is Link?\",\n",
        "                \"Model: Link is a fictional character in the Legend of Zelda series.\",\n",
        "                \"You: What is Zelda?\",\n",
        "                \"Model: Zelda is a fictional character in the Legend of Zelda series.\",\n",
        "                \"You: What is ice cream?\",\n",
        "                \"Model: Ice cream is a type of dessert made from milk and cream.\",\n",
        "                \"You: What is spaghetti?\",\n",
        "                \"Model: Spaghetti is a type of pasta dish made from durum wheat.\",\n",
        "                \"You: What is the capital of USA?\",\n",
        "                \"Model: The capital of USA is Washington D.C.\",\n",
        "                \"You: What is the world's largest fish?\",\n",
        "                \"Model: The world's largest fish is the clownfish.\",\n",
        "                \"You: What is the largest mammal?\",\n",
        "                \"Model: The largest mammal is the African elephant.\",\n",
        "                \"You: You said that earlier but it's a whale.\",\n",
        "                \"Model: How are whales a mammal?\",\n",
        "                \"You: They breath air and give birth without eggs.\",\n",
        "                \"Model: I didn't know that.\",\n",
        "                \"You: What is the chemical symbol for gold?\",\n",
        "                \"Model: The chemical symbol for gold is Au.\",\n",
        "                \"You: What is the chemical formula for hydrogen peroxide?\",\n",
        "                \"Model: The chemical formula for hydrogen peroxide is C6H12O6.\",\n",
        "                \"You: What is the chemical formula for sodium bicarbonate?\",\n",
        "                \"Model: The chemical formula for sodium bicarbonate is NaHCO3.\",\n",
        "                \"Wisdom is the ability to think and act using knowledge, experience, understanding, common sense, and insight.\",\n",
        "                \"Philosophers have long debated the nature of wisdom and how it can be acquired.\",\n",
        "                \"Socrates believed that wisdom begins in wonder.\",\n",
        "                \"Aristotle defined wisdom as the knowledge of causes and the ability to make sound judgments.\",\n",
        "                \"Confucius emphasized the importance of moral integrity and self-cultivation in the pursuit of wisdom.\",\n",
        "                \"Plato distinguished between practical wisdom, which is concerned with human affairs, and theoretical wisdom, which is concerned with universal truths.\",\n",
        "                \"Ethics is the branch of philosophy that deals with questions of morality and values.\",\n",
        "                \"Immanuel Kant argued that ethical behavior is based on the principle of duty and the categorical imperative.\",\n",
        "                \"Utilitarianism, as proposed by Jeremy Bentham and John Stuart Mill, holds that the best action is the one that maximizes overall happiness.\",\n",
        "                \"Virtue ethics, rooted in the works of Aristotle, focuses on the development of good character traits or virtues.\",\n",
        "                \"Friedrich Nietzsche challenged traditional moral values and proposed the concept of 'master morality' and 'slave morality'.\",\n",
        "                \"Jean-Paul Sartre, an existentialist philosopher, claimed that humans are free to create their own values and meaning.\",\n",
        "                \"Wisdom often involves recognizing the limits of one's own knowledge and being open to new ideas and perspectives.\",\n",
        "                \"The Dalai Lama teaches that wisdom is compassion in action.\",\n",
        "                \"Mahatma Gandhi believed that the pursuit of truth is essential to wisdom and ethical living.\",\n",
        "                \"Martin Luther King Jr. emphasized the importance of love and justice in ethical decision-making.\",\n",
        "                \"Ethical relativism is the view that moral standards are culturally based and therefore subject to a person's individual choice.\",\n",
        "                \"Deontological ethics, as formulated by Kant, focuses on the inherent morality of actions rather than their consequences.\",\n",
        "                \"Consequentialism, on the other hand, judges the rightness or wrongness of actions based on their outcomes.\",\n",
        "                \"Stoicism, a school of Hellenistic philosophy, teaches that wisdom and virtue are achieved by living in harmony with nature and accepting the present moment.\",\n",
        "                \"The Golden Rule, found in many religious and ethical traditions, advises treating others as one would like to be treated.\",\n",
        "                \"Albert Schweitzer proposed the ethic of 'Reverence for Life', which advocates for the respect and care of all living beings.\",\n",
        "                \"Philosophers like John Rawls have explored the concept of justice and fairness in ethical theory.\",\n",
        "                \"Rawls' 'Theory of Justice' introduces the idea of the 'veil of ignorance' as a way to determine fair principles of justice.\",\n",
        "                \"Pragmatism, as articulated by philosophers like William James and John Dewey, emphasizes the practical application of ideas and the role of experience in shaping ethical beliefs.\",\n",
        "                \"Ethical dilemmas often require balancing competing values and interests.\",\n",
        "                \"The study of ethics helps individuals navigate complex moral issues and make informed decisions.\",\n",
        "                \"Wisdom is not only about acquiring knowledge but also about applying it wisely in real-life situations.\",\n",
        "                \"Many cultures have proverbs and sayings that encapsulate wisdom and ethical principles.\",\n",
        "                \"Philosophy encourages critical thinking and the examination of one's own beliefs and values.\",\n",
        "                \"Ethics courses and philosophical discussions can enhance moral reasoning and ethical awareness.\",\n",
        "                \"The pursuit of wisdom involves lifelong learning and self-reflection.\",\n",
        "                \"Ancient Greek philosophers like Socrates, Plato, and Aristotle laid the foundations for Western philosophy and ethics.\",\n",
        "                \"Eastern philosophies such as Taoism and Buddhism offer unique perspectives on wisdom and ethical living.\",\n",
        "                \"Modern philosophers continue to explore and challenge traditional notions of wisdom and ethics.\",\n",
        "                \"Wisdom literature, such as the writings of Laozi and the Book of Proverbs, provides timeless insights into ethical living.\",\n",
        "                \"Contemporary ethical issues, such as environmental sustainability and digital privacy, require new applications of philosophical principles.\",\n",
        "                \"Philosophers often engage in thought experiments to explore ethical concepts and dilemmas.\",\n",
        "                \"Moral philosophy examines the nature of right and wrong, good and evil, justice, and virtue.\",\n",
        "                \"Wisdom traditions around the world emphasize the interconnectedness of all life and the importance of living in harmony with others.\",\n",
        "                \"Ethical theories provide frameworks for understanding and resolving moral conflicts.\",\n",
        "                \"The cultivation of wisdom and ethical behavior is considered essential for personal and societal well-being.\",\n",
        "                \"Philosophical inquiry into ethics and wisdom can lead to a deeper understanding of the human condition.\",\n",
        "                \"Wisdom is often associated with qualities such as humility, patience, and empathy.\",\n",
        "                \"Ethical leadership requires a commitment to fairness, transparency, and the common good.\",\n",
        "                \"Moral education seeks to develop individuals' ability to think critically about ethical issues and act with integrity.\",\n",
        "                \"Philosophers like Hannah Arendt have explored the nature of evil and the conditions that lead to unethical behavior.\",\n",
        "                \"Wisdom is not only an intellectual virtue but also a practical one, guiding actions and decisions in everyday life.\",\n",
        "                \"The relationship between wisdom and happiness is a topic of interest in both philosophy and psychology.\",\n",
        "                \"Ethics in professional and public life involves adhering to standards of conduct and accountability.\",\n",
        "                \"Philosophical discussions of wisdom often involve exploring the balance between knowledge, experience, and moral insight.\",\n",
        "                \"The study of philosophy encourages the development of a thoughtful and reflective approach to life's challenges.\",\n",
        "                \"Wisdom is not only about acquiring knowledge but also about applying it.\",\n",
        "                \"The pursuit of wisdom involves lifelong learning and self-reflection.\",\n",
        "                \"Ancient Greek philosophers like Socrates, Plato, and Aristotle laid the foundations for Western philosophy and ethics.\",\n",
        "                \"Computer Science is a field where we can use computers to solve problems.\",\n",
        "                \"In computer science, we often use algorithms to solve problems.\",\n",
        "                \"We also use programming languages to write programs.\",\n",
        "                \"Quantum physics is the branch of physics that studies the behavior of particles at the atomic and subatomic levels.\",\n",
        "                \"Quantum mechanics describes the nature of particles using wave functions and probability distributions.\",\n",
        "                \"The principle of superposition states that a particle can exist in multiple states simultaneously until measured.\",\n",
        "                \"Heisenberg's Uncertainty Principle posits that it is impossible to know both the position and momentum of a particle with absolute precision.\",\n",
        "                \"Quantum entanglement is a phenomenon where particles become interconnected and the state of one can instantly influence the state of another, regardless of distance.\",\n",
        "                \"The Schrödinger equation is a fundamental equation in quantum mechanics that describes how the quantum state of a physical system changes over time.\",\n",
        "                \"Niels Bohr's Copenhagen interpretation suggests that a quantum system remains in superposition until it interacts with an external observer or environment.\",\n",
        "                \"Albert Einstein famously referred to quantum entanglement as 'spooky action at a distance'.\",\n",
        "                \"The wave-particle duality concept suggests that particles, such as electrons and photons, exhibit both wave-like and particle-like properties.\",\n",
        "                \"Max Planck is considered the father of quantum theory, introducing the idea of quantized energy levels.\",\n",
        "                \"The double-slit experiment demonstrates the wave-particle duality and the role of the observer in quantum mechanics.\",\n",
        "                \"Quantum tunneling allows particles to pass through energy barriers that would be insurmountable in classical physics.\",\n",
        "                \"The Pauli Exclusion Principle states that no two fermions can occupy the same quantum state simultaneously.\",\n",
        "                \"Quantum decoherence describes the process by which a quantum system loses its quantum properties due to interaction with the environment.\",\n",
        "                \"In quantum field theory, particles are excitations of underlying fields that permeate space.\",\n",
        "                \"Richard Feynman's path integral formulation offers an alternative approach to quantum mechanics, focusing on the sum of all possible paths a particle can take.\",\n",
        "                \"Quantum computing harnesses the principles of quantum superposition and entanglement to perform computations more efficiently than classical computers.\",\n",
        "                \"A qubit is the basic unit of quantum information, analogous to a bit in classical computing, but can represent 0, 1, or both simultaneously.\",\n",
        "                \"Quantum cryptography leverages the principles of quantum mechanics to create secure communication channels.\",\n",
        "                \"The Many-Worlds Interpretation posits that every quantum event spawns a new, parallel universe for each possible outcome.\",\n",
        "                \"Quantum teleportation is a process by which the quantum state of a particle is transferred from one location to another, without physical transmission of the particle itself.\",\n",
        "                \"Bell's Theorem demonstrates that no local hidden variable theories can reproduce all the predictions of quantum mechanics.\",\n",
        "                \"Quantum coherence refers to the maintenance of quantum states over time, essential for quantum computing and information processing.\",\n",
        "                \"Photons are elementary particles of light that exhibit both wave-like and particle-like properties.\",\n",
        "                \"Quantum entanglement is a key resource for quantum computing, enabling qubits to be interconnected in ways that classical bits cannot.\",\n",
        "                \"The observer effect in quantum mechanics suggests that the act of measurement affects the system being observed.\",\n",
        "                \"The Casimir effect is a quantum phenomenon where two uncharged conductive plates placed close together experience an attractive force due to quantum vacuum fluctuations.\",\n",
        "                \"In quantum electrodynamics (QED), the interactions between charged particles and the electromagnetic field are described using quantum mechanics.\",\n",
        "                \"The quantum Zeno effect occurs when frequent measurements prevent the evolution of a quantum system, effectively 'freezing' its state.\",\n",
        "                \"Quantum spin is an intrinsic form of angular momentum carried by elementary particles.\",\n",
        "                \"The Standard Model of particle physics incorporates quantum mechanics to describe the fundamental particles and forces of nature.\",\n",
        "                \"Planck's constant is a fundamental physical constant that characterizes the scale of quantum effects.\",\n",
        "                \"Quantum chromodynamics (QCD) is the theory of the strong interaction, describing the behavior of quarks and gluons.\",\n",
        "                \"In quantum mechanics, a wave function encapsulates all the information about a system's state and its evolution.\",\n",
        "                \"Quantum annealing is a method used in quantum computing to find the global minimum of a function by exploiting quantum tunneling.\",\n",
        "                \"The Dirac equation is a relativistic quantum mechanical wave equation formulated by Paul Dirac, predicting the existence of antimatter.\",\n",
        "                \"Quantum fluctuations are temporary changes in energy that occur spontaneously in a quantum system.\",\n",
        "                \"The quantum harmonic oscillator is a fundamental model in quantum mechanics describing particles in a potential well.\",\n",
        "                \"Quantum optics studies the quantum nature of light and its interactions with matter.\",\n",
        "                \"The quantum Hall effect is observed in two-dimensional electron systems subjected to low temperatures and strong magnetic fields, leading to quantized Hall conductance.\",\n",
        "                \"Quantum dots are nanoscale semiconductor particles with quantum mechanical properties used in various applications, including medical imaging and electronics.\",\n",
        "                \"Entanglement entropy measures the degree of entanglement between subsystems in a quantum system.\",\n",
        "                \"The Rabi oscillation describes the coherent oscillation of a two-level quantum system under the influence of an external oscillatory field.\",\n",
        "                \"In quantum thermodynamics, the principles of thermodynamics are extended to quantum systems.\",\n",
        "                \"The quantum harmonic oscillator model is used to describe vibrations in molecules and the quantization of vibrational energy levels.\",\n",
        "                \"Quantum key distribution (QKD) is a secure communication method that uses quantum mechanics to encrypt and decrypt messages.\",\n",
        "                \"The concept of quantum supremacy refers to the point at which a quantum computer can perform a task that is infeasible for any classical computer.\",\n",
        "                \"Quantum coherence and entanglement are essential for the operation of quantum sensors, which can achieve higher precision than classical sensors.\",\n",
        "                \"Topological quantum computing uses anyons, particles that exist in two-dimensional spaces, to perform fault-tolerant quantum computations.\",\n",
        "                \"The quantum mechanical description of atoms and molecules forms the basis for quantum chemistry, which studies the electronic structure of matter.\",\n",
        "                \"In quantum mechanics, the principle of complementarity states that particles can display either wave-like or particle-like properties, but not both simultaneously.\",\n",
        "                \"Genetics is the study of genes, genetic variation, and heredity in living organisms.\",\n",
        "                \"Gregor Mendel, known as the father of genetics, discovered the fundamental laws of inheritance through experiments with pea plants.\",\n",
        "                \"DNA, or deoxyribonucleic acid, is the molecule that carries genetic information in cells.\",\n",
        "                \"The double helix structure of DNA was discovered by James Watson and Francis Crick in 1953.\",\n",
        "                \"Genes are segments of DNA that encode instructions for building proteins, the molecules that perform most of the functions in cells.\",\n",
        "                \"The Human Genome Project, completed in 2003, mapped the entire human genome, identifying all the genes in human DNA.\",\n",
        "                \"Mutations are changes in the DNA sequence that can lead to genetic disorders or contribute to genetic diversity.\",\n",
        "                \"Genetic recombination during meiosis contributes to genetic variation by shuffling alleles between homologous chromosomes.\",\n",
        "                \"Mendel's laws of inheritance include the law of segregation and the law of independent assortment.\",\n",
        "                \"A genotype is the genetic makeup of an organism, while a phenotype is the observable traits or characteristics.\",\n",
        "                \"Dominant alleles mask the effects of recessive alleles in heterozygous individuals.\",\n",
        "                \"Homozygous individuals have two identical alleles for a given gene, while heterozygous individuals have two different alleles.\",\n",
        "                \"The central dogma of molecular biology states that genetic information flows from DNA to RNA to protein.\",\n",
        "                \"Transcription is the process by which genetic information in DNA is copied into messenger RNA (mRNA).\",\n",
        "                \"Translation is the process by which mRNA is decoded by ribosomes to produce a specific protein.\",\n",
        "                \"RNA, or ribonucleic acid, is a nucleic acid involved in protein synthesis and gene regulation.\",\n",
        "                \"Chromosomes are long, thread-like structures made of DNA and proteins that carry genetic information.\",\n",
        "                \"Humans have 23 pairs of chromosomes, including 22 pairs of autosomes and one pair of sex chromosomes.\",\n",
        "                \"The X and Y chromosomes determine an individual's sex, with XX being female and XY being male.\",\n",
        "                \"Epigenetics studies heritable changes in gene expression that do not involve changes to the underlying DNA sequence.\",\n",
        "                \"CRISPR-Cas9 is a revolutionary gene-editing technology that allows for precise modification of DNA sequences.\",\n",
        "                \"Genetic linkage occurs when genes located close to each other on the same chromosome are inherited together.\",\n",
        "                \"A genetic map shows the relative positions of genes on a chromosome based on the frequency of recombination.\",\n",
        "                \"Polygenic traits are controlled by multiple genes, each contributing to the phenotype in a small way.\",\n",
        "                \"Mitochondrial DNA (mtDNA) is inherited maternally and can be used to trace maternal lineage.\",\n",
        "                \"Genetic drift is a mechanism of evolution that causes allele frequencies to change randomly in a population.\",\n",
        "                \"Natural selection is the process by which advantageous genetic traits become more common in a population over time.\",\n",
        "                \"A gene pool is the complete set of genetic information within a population.\",\n",
        "                \"Gene flow is the transfer of genetic material between populations, which can increase genetic diversity.\",\n",
        "                \"Sickle cell anemia is a genetic disorder caused by a mutation in the hemoglobin gene.\",\n",
        "                \"Genetic counseling provides information and support to individuals with genetic disorders or those at risk.\",\n",
        "                \"Carrier screening tests can identify individuals who carry a gene for a recessive genetic disorder.\",\n",
        "                \"Genetic testing can diagnose genetic conditions, predict disease risk, and inform medical treatment decisions.\",\n",
        "                \"A genome is the complete set of DNA in an organism, including all of its genes.\",\n",
        "                \"Comparative genomics compares the genomes of different species to understand their evolutionary relationships.\",\n",
        "                \"Population genetics studies the distribution of and changes in allele frequencies within populations.\",\n",
        "                \"A pedigree chart is a diagram that shows the occurrence and appearance of phenotypes in several generations of a family.\",\n",
        "                \"Gene expression is the process by which information from a gene is used to produce a functional product, such as a protein.\",\n",
        "                \"Mendelian inheritance patterns include autosomal dominant, autosomal recessive, X-linked dominant, and X-linked recessive.\",\n",
        "                \"In codominance, both alleles in a heterozygous individual are fully expressed, resulting in a distinct phenotype.\",\n",
        "                \"Incomplete dominance occurs when the phenotype of a heterozygote is intermediate between the phenotypes of the homozygotes.\",\n",
        "                \"Genomic imprinting is an epigenetic phenomenon where certain genes are expressed in a parent-of-origin-specific manner.\",\n",
        "                \"Gene therapy aims to treat or prevent genetic disorders by introducing, removing, or altering genetic material within a patient's cells.\",\n",
        "                \"A genetic marker is a specific DNA sequence with a known location on a chromosome that can be used for genetic analysis.\",\n",
        "                \"The Hardy-Weinberg equilibrium describes a state in which allele frequencies in a population remain constant over generations in the absence of evolutionary forces.\",\n",
        "                \"A mutation in a single nucleotide, known as a point mutation, can have significant effects on gene function.\",\n",
        "                \"The polymerase chain reaction (PCR) is a technique used to amplify specific DNA sequences for analysis.\",\n",
        "                \"Gene regulation involves mechanisms that control the timing, location, and amount of gene expression.\",\n",
        "                \"A genetic mosaic is an organism with cells that have different genetic makeup due to mutations during development.\",\n",
        "                \"Gene-environment interactions describe how genetic and environmental factors influence the phenotype.\",\n",
        "                \"Genomic sequencing technologies have revolutionized the ability to study genetic variation and disease.\",\n",
        "                \"Functional genomics aims to understand the roles and interactions of genes and proteins within a genome.\",\n",
        "                \"Proteomics is the large-scale study of proteins, particularly their structures and functions.\",\n",
        "                \"Metagenomics studies the genetic material recovered directly from environmental samples, allowing for the analysis of microbial communities.\",\n",
        "                \"Mathematics is the abstract science of number, quantity, and space.\",\n",
        "                \"Arithmetic is the branch of mathematics dealing with basic operations like addition, subtraction, multiplication, and division.\",\n",
        "                \"Algebra involves the study of mathematical symbols and the rules for manipulating these symbols.\",\n",
        "                \"Geometry is concerned with the properties and relations of points, lines, surfaces, and solids.\",\n",
        "                \"Calculus is the mathematical study of continuous change, dealing with derivatives and integrals.\",\n",
        "                \"Probability theory is the branch of mathematics that deals with the analysis of random phenomena.\",\n",
        "                \"Statistics involves the collection, analysis, interpretation, and presentation of data.\",\n",
        "                \"A mathematical proof is a logical argument that establishes the truth of a mathematical statement.\",\n",
        "                \"Number theory is the branch of mathematics devoted to the study of the integers and more generally to objects built out of them.\",\n",
        "                \"A prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself.\",\n",
        "                \"Euclid's Elements is a collection of books covering many aspects of mathematics, including geometry and number theory.\",\n",
        "                \"The Pythagorean theorem states that in a right-angled triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides.\",\n",
        "                \"A matrix is a rectangular array of numbers arranged in rows and columns.\",\n",
        "                \"Linear algebra is the branch of mathematics concerning linear equations, linear functions, and their representations through matrices and vector spaces.\",\n",
        "                \"A function is a relation between a set of inputs and a set of permissible outputs.\",\n",
        "                \"Differential equations are equations that involve the derivatives of a function.\",\n",
        "                \"The Fibonacci sequence is a series of numbers in which each number is the sum of the two preceding ones.\",\n",
        "                \"Set theory is the branch of mathematical logic that studies sets, which are collections of objects.\",\n",
        "                \"A vector is a quantity that has both magnitude and direction.\",\n",
        "                \"Complex numbers are numbers that have a real part and an imaginary part.\",\n",
        "                \"Topology is the branch of mathematics that studies the properties of space that are preserved under continuous transformations.\",\n",
        "                \"A polynomial is an expression consisting of variables and coefficients, involving only the operations of addition, subtraction, multiplication, and non-negative integer exponents.\",\n",
        "                \"The quadratic formula provides the solution to the quadratic equation ax^2 + bx + c = 0.\",\n",
        "                \"A differential is an infinitesimal change in a variable.\",\n",
        "                \"The binomial theorem describes the algebraic expansion of powers of a binomial.\",\n",
        "                \"Combinatorics is the branch of mathematics dealing with combinations of objects belonging to a finite set in accordance with certain constraints.\",\n",
        "                \"The golden ratio is a special number approximately equal to 1.618, often encountered in mathematics and art.\",\n",
        "                \"Fractals are complex geometric shapes that can be split into parts, each of which is a reduced-scale copy of the whole.\",\n",
        "                \"A logarithm is the exponent to which a base number must be raised to produce a given number.\",\n",
        "                \"The fundamental theorem of arithmetic states that every integer greater than 1 is either a prime number or can be uniquely factorized into prime numbers.\",\n",
        "                \"A derivative represents the rate at which a quantity changes with respect to another quantity.\",\n",
        "                \"An integral is a mathematical object that represents the area under a curve.\",\n",
        "                \"The mean is the average of a set of numbers.\",\n",
        "                \"The median is the middle value in a list of numbers.\",\n",
        "                \"The mode is the number that appears most frequently in a data set.\",\n",
        "                \"A probability distribution describes how the values of a random variable are distributed.\",\n",
        "                \"Bayes' theorem describes the probability of an event based on prior knowledge of conditions related to the event.\",\n",
        "                \"Game theory is the study of mathematical models of strategic interaction among rational decision-makers.\",\n",
        "                \"The Fourier transform is a mathematical transform that decomposes functions depending on space or time into functions depending on spatial or temporal frequency.\",\n",
        "                \"Boolean algebra is a branch of algebra in which the values of the variables are true and false, typically denoted 1 and 0 respectively.\",\n",
        "                \"An eigenvalue is a scalar that indicates how much a corresponding eigenvector is stretched or compressed during a linear transformation.\",\n",
        "                \"A permutation is an arrangement of objects in a specific order.\",\n",
        "                \"A combination is a selection of items from a larger pool where order does not matter.\",\n",
        "                \"A sequence is an ordered list of numbers that often follow a specific pattern or function.\",\n",
        "                \"Mathematical induction is a method of mathematical proof used to prove that a statement is true for all natural numbers.\",\n",
        "                \"A limit is a value that a function approaches as the input approaches some value.\",\n",
        "                \"Infinity is a concept describing something without any bound or larger than any natural number.\",\n",
        "                \"A graph is a collection of points, called vertices, connected by lines, called edges.\",\n",
        "                \"Graph theory is the study of graphs and their properties.\",\n",
        "                \"A theorem is a mathematical statement that has been proven to be true.\",\n",
        "                \"An axiom is a statement or proposition that is regarded as being established, accepted, or self-evidently true.\",\n",
        "                \"Theorems are derived from axioms and previously established theorems.\",\n",
        "                \"A conjecture is a mathematical statement that is proposed to be true but has not yet been proven or disproven.\",\n",
        "                \"An algorithm is a step-by-step procedure for solving a problem or accomplishing a task.\",\n",
        "                \"Cryptography is the practice and study of techniques for secure communication in the presence of third parties.\",\n",
        "                \"A symmetry in mathematics is an operation that preserves some property of a geometric object or set.\",\n",
        "                \"The Riemann Hypothesis is one of the most famous unsolved problems in mathematics, concerning the distribution of prime numbers.\",\n",
        "                \"A rational number is a number that can be expressed as the quotient or fraction of two integers.\",\n",
        "                \"An irrational number cannot be expressed as a fraction of two integers; its decimal form is non-repeating and non-terminating.\",\n",
        "                \"A real number is any value along the continuum of the number line, including both rational and irrational numbers.\",\n",
        "                \"An imaginary number is a number that when squared gives a negative result.\",\n",
        "                \"A complex plane is a geometric representation of complex numbers established by the real and imaginary axes.\",\n",
        "                \"A mathematical model is a representation of a real-world situation using mathematical concepts and language.\",\n",
        "                \"A differential equation describes the relationship between a function and its derivatives.\",\n",
        "                \"Chaos theory studies the behavior of dynamical systems that are highly sensitive to initial conditions, often referred to as the butterfly effect.\",\n",
        "                \"Non-Euclidean geometry is a type of geometry that relaxes or alters Euclid's fifth postulate about parallel lines.\",\n",
        "                \"The field of mathematical logic studies formal systems in relation to the way they encode intuitive concepts of mathematical proof and computation.\",\n",
        "                \"Operations research involves using advanced analytical methods to improve decision-making.\",\n",
        "                \"Mathematical optimization is the selection of the best element from some set of available alternatives.\",\n",
        "                \"Actuarial science applies mathematical and statistical methods to assess risk in insurance, finance, and other industries.\",\n",
        "                \"The normal distribution, also known as the Gaussian distribution, is a common continuous probability distribution.\",\n",
        "                \"Physics is the natural science that studies matter, its motion and behavior through space and time, and the related entities of energy and force.\",\n",
        "                \"Classical mechanics, also known as Newtonian mechanics, describes the motion of macroscopic objects from projectiles to parts of machinery, as well as astronomical objects.\",\n",
        "                \"Isaac Newton formulated the laws of motion and universal gravitation, which laid the foundation for classical mechanics.\",\n",
        "                \"The law of inertia states that an object will remain at rest or in uniform motion in a straight line unless acted upon by an external force.\",\n",
        "                \"The second law of motion states that the force acting on an object is equal to the mass of the object multiplied by its acceleration (F = ma).\",\n",
        "                \"The third law of motion states that for every action, there is an equal and opposite reaction.\",\n",
        "                \"Work is defined as the product of force and displacement in the direction of the force.\",\n",
        "                \"Energy is the capacity to do work and comes in various forms such as kinetic, potential, thermal, and chemical energy.\",\n",
        "                \"The law of conservation of energy states that energy cannot be created or destroyed, only transformed from one form to another.\",\n",
        "                \"Momentum is the product of an object's mass and velocity and is a vector quantity.\",\n",
        "                \"The principle of conservation of momentum states that the total momentum of a closed system remains constant if no external forces act on it.\",\n",
        "                \"Electromagnetism is the study of electric and magnetic fields and their interactions with matter.\",\n",
        "                \"James Clerk Maxwell formulated the classical theory of electromagnetic radiation, bringing together electricity, magnetism, and light as different manifestations of the same phenomenon.\",\n",
        "                \"The speed of light in a vacuum is approximately 299,792 kilometers per second (186,282 miles per second) and is a fundamental constant of nature.\",\n",
        "                \"Wave-particle duality is a fundamental concept in quantum mechanics that describes how every particle or quantum entity exhibits both wave-like and particle-like properties.\",\n",
        "                \"Quantum mechanics is the branch of physics that deals with the behavior of particles on the atomic and subatomic scale.\",\n",
        "                \"Werner Heisenberg's uncertainty principle states that it is impossible to simultaneously know the exact position and momentum of a particle.\",\n",
        "                \"The Schrödinger equation is a fundamental equation of quantum mechanics that describes how the quantum state of a physical system changes over time.\",\n",
        "                \"Albert Einstein's theory of relativity revolutionized our understanding of space, time, and gravity.\",\n",
        "                \"Special relativity, introduced by Einstein in 1905, addresses the relationship between space and time and includes the famous equation E = mc^2.\",\n",
        "                \"General relativity, published by Einstein in 1915, is a theory of gravitation that describes gravity as a curvature of spacetime caused by mass and energy.\",\n",
        "                \"The principle of equivalence states that the effects of gravity are indistinguishable from the effects of acceleration in a locally inertial frame of reference.\",\n",
        "                \"A black hole is a region of spacetime where gravity is so strong that nothing, not even light, can escape from it.\",\n",
        "                \"Thermodynamics is the study of heat, work, and the related properties of systems.\",\n",
        "                \"The first law of thermodynamics, also known as the law of energy conservation, states that the total energy of an isolated system is constant.\",\n",
        "                \"The second law of thermodynamics states that the entropy of an isolated system always increases over time.\",\n",
        "                \"Entropy is a measure of the disorder or randomness in a system.\",\n",
        "                \"The third law of thermodynamics states that as the temperature of a system approaches absolute zero, the entropy of the system approaches a minimum.\",\n",
        "                \"Statistical mechanics is the branch of physics that uses probability theory to describe the behavior of systems composed of a large number of particles.\",\n",
        "                \"The kinetic theory of gases explains the macroscopic properties of gases in terms of the motion of individual molecules.\",\n",
        "                \"The photoelectric effect is the emission of electrons from a material when it absorbs light of sufficient energy.\",\n",
        "                \"Einstein's explanation of the photoelectric effect provided evidence for the quantization of light and contributed to the development of quantum theory.\",\n",
        "                \"Nuclear physics is the branch of physics that studies atomic nuclei and their interactions.\",\n",
        "                \"Radioactivity is the spontaneous emission of particles or radiation from the unstable nucleus of an atom.\",\n",
        "                \"Fission is the splitting of a heavy atomic nucleus into two lighter nuclei, releasing a large amount of energy.\",\n",
        "                \"Fusion is the process by which two light atomic nuclei combine to form a heavier nucleus, releasing energy in the process.\",\n",
        "                \"Particle physics is the branch of physics that studies the fundamental particles of the universe and their interactions.\",\n",
        "                \"The Standard Model is a theory that describes the fundamental particles and forces (except for gravity) that make up the universe.\",\n",
        "                \"The Higgs boson is a particle predicted by the Standard Model and discovered in 2012, responsible for giving mass to other particles.\",\n",
        "                \"Cosmology is the study of the origin, evolution, and eventual fate of the universe.\",\n",
        "                \"The Big Bang theory is the prevailing cosmological model explaining the early development of the universe.\",\n",
        "                \"Dark matter is a form of matter that does not emit, absorb, or reflect light and is thought to make up most of the mass in the universe.\",\n",
        "                \"Dark energy is a mysterious form of energy that is causing the accelerated expansion of the universe.\",\n",
        "                \"String theory is a theoretical framework that attempts to reconcile quantum mechanics and general relativity by positing that fundamental particles are one-dimensional strings.\",\n",
        "                \"Supersymmetry is a theoretical concept that proposes a symmetry between fermions and bosons.\",\n",
        "                \"The multiverse hypothesis suggests that our universe is just one of many universes that exist.\",\n",
        "                \"Chaos theory studies the behavior of dynamical systems that are highly sensitive to initial conditions, often leading to seemingly random behavior.\",\n",
        "                \"A phase transition is a change in the state of matter, such as from solid to liquid, involving the release or absorption of energy.\",\n",
        "                \"Superconductivity is a phenomenon where a material exhibits zero electrical resistance below a certain temperature.\",\n",
        "                \"The Doppler effect is the change in frequency or wavelength of a wave in relation to an observer moving relative to the wave source.\",\n",
        "                \"Resonance occurs when a system oscillates at its natural frequency due to an external periodic force.\",\n",
        "                \"Optics is the branch of physics that studies the behavior and properties of light and its interactions with matter.\",\n",
        "                \"Reflection is the change in direction of a wavefront at an interface between two different media, causing the wavefront to return into the medium from which it originated.\",\n",
        "                \"Refraction is the change in direction of a wave passing from one medium to another caused by its change in speed.\",\n",
        "                \"Diffraction is the bending of waves around obstacles and openings, which occurs with all types of waves, including light and sound.\",\n",
        "                \"Interference is the phenomenon that occurs when two or more waves superpose to form a resultant wave of greater, lower, or the same amplitude.\",\n",
        "                \"Polarization is the orientation of the oscillations in a transverse wave, such as light, relative to its direction of travel.\",\n",
        "                \"The speed of sound is the distance traveled per unit time by a sound wave as it propagates through a medium.\",\n",
        "                \"Acoustics is the branch of physics that studies the properties of sound.\",\n",
        "                \"Fluid dynamics is the study of the movement of liquids and gases.\",\n",
        "                \"Bernoulli's principle states that an increase in the speed of a fluid occurs simultaneously with a decrease in pressure or a decrease in the fluid's potential energy.\",\n",
        "                \"Turbulence is the chaotic, irregular flow of a fluid.\",\n",
        "                \"The Navier-Stokes equations describe the motion of viscous fluid substances.\",\n",
        "                \"Plasma is one of the four fundamental states of matter, consisting of highly ionized gas with nearly equal numbers of positive and negative ions.\",\n",
        "                \"The concept of work-energy theorem states that the work done on an object is equal to the change in its kinetic energy.\",\n",
        "                \"The conservation of angular momentum states that if no external torque acts on a system, the total angular momentum of the system remains constant.\",\n",
        "                \"Harmonic motion is a type of periodic motion where the restoring force is directly proportional to the displacement.\",\n",
        "                \"The law of universal gravitation states that every point mass attracts every other point mass by a force acting along the line intersecting both points.\",\n",
        "                \"An electric field is a vector field around a charged particle that represents the force exerted on other charged particles.\",\n",
        "                \"A magnetic field is a vector field that describes the magnetic influence on moving electric charges, electric currents, and magnetic materials.\",\n",
        "                \"Faraday's law of induction states that a changing magnetic field creates an electric field.\",\n",
        "                \"Lenz's law states that the direction of an induced current is such that it opposes the change in magnetic flux that produced it.\",\n",
        "                \"Coulomb's law describes the electrostatic force between electrically charged particles.\",\n",
        "                \"Ohm's law states that the current through a conductor between two points is directly proportional to the voltage across the two points.\",\n",
        "                \"Anatomy is the branch of biology concerned with the study of the structure of organisms and their parts.\",\n",
        "                \"The human body is composed of numerous cells, tissues, organs, and systems that work together to maintain life.\",\n",
        "                \"The skeletal system provides structural support and protection for the body and includes bones, cartilage, and ligaments.\",\n",
        "                \"The muscular system is responsible for movement and consists of skeletal muscles, smooth muscles, and cardiac muscles.\",\n",
        "                \"The nervous system controls and coordinates body activities and includes the brain, spinal cord, and peripheral nerves.\",\n",
        "                \"The cardiovascular system circulates blood throughout the body and includes the heart, blood vessels, and blood.\",\n",
        "                \"The respiratory system facilitates the exchange of oxygen and carbon dioxide and includes the lungs, trachea, and bronchi.\",\n",
        "                \"The digestive system breaks down food into nutrients for the body and includes the mouth, esophagus, stomach, intestines, and liver.\",\n",
        "                \"The urinary system removes waste products from the blood and includes the kidneys, ureters, bladder, and urethra.\",\n",
        "                \"The endocrine system regulates bodily functions through hormones and includes glands such as the thyroid, pancreas, and adrenal glands.\",\n",
        "                \"The reproductive system enables the production of offspring and includes the ovaries, testes, and associated structures.\",\n",
        "                \"The integumentary system protects the body from external damage and includes the skin, hair, and nails.\",\n",
        "                \"The immune system defends the body against infections and includes white blood cells, lymph nodes, and antibodies.\",\n",
        "                \"Homeostasis is the maintenance of a stable internal environment within the body.\",\n",
        "                \"A cell is the basic unit of life and can be classified as prokaryotic or eukaryotic.\",\n",
        "                \"Tissues are groups of similar cells that perform a specific function and include epithelial, connective, muscle, and nervous tissues.\",\n",
        "                \"Organs are structures composed of different tissues that perform specific functions, such as the heart, liver, and brain.\",\n",
        "                \"Systems are groups of organs that work together to perform complex functions, such as the digestive and respiratory systems.\",\n",
        "                \"The skull protects the brain and supports the structures of the face.\",\n",
        "                \"The vertebral column, or spine, protects the spinal cord and supports the body.\",\n",
        "                \"The rib cage protects the heart and lungs and supports the upper body.\",\n",
        "                \"The pelvis supports the lower body and protects internal organs such as the bladder and reproductive organs.\",\n",
        "                \"The humerus, radius, and ulna are the major bones of the arm.\",\n",
        "                \"The femur, tibia, and fibula are the major bones of the leg.\",\n",
        "                \"Joints are connections between bones that allow for movement and include hinge, ball-and-socket, and pivot joints.\",\n",
        "                \"Ligaments are bands of connective tissue that connect bones to other bones.\",\n",
        "                \"Tendons are bands of connective tissue that connect muscles to bones.\",\n",
        "                \"Cartilage is a flexible connective tissue that provides cushioning and support for joints.\",\n",
        "                \"The brain is the control center of the nervous system and is divided into the cerebrum, cerebellum, and brainstem.\",\n",
        "                \"The spinal cord transmits signals between the brain and the rest of the body.\",\n",
        "                \"Neurons are specialized cells that transmit nerve impulses and include sensory, motor, and interneurons.\",\n",
        "                \"The heart is a muscular organ that pumps blood throughout the body.\",\n",
        "                \"Arteries carry oxygen-rich blood away from the heart, while veins carry oxygen-poor blood back to the heart.\",\n",
        "                \"Capillaries are tiny blood vessels where the exchange of oxygen, carbon dioxide, and nutrients occurs.\",\n",
        "                \"The lungs are the primary organs of the respiratory system and facilitate gas exchange.\",\n",
        "                \"The diaphragm is a muscle that plays a crucial role in breathing by contracting and relaxing to change the volume of the thoracic cavity.\",\n",
        "                \"The liver produces bile, which aids in the digestion of fats, and detoxifies harmful substances in the blood.\",\n",
        "                \"The pancreas produces enzymes that aid in digestion and hormones such as insulin that regulate blood sugar levels.\",\n",
        "                \"The small intestine is the primary site of nutrient absorption in the digestive system.\",\n",
        "                \"The large intestine absorbs water and electrolytes and forms and stores feces.\",\n",
        "                \"The kidneys filter waste products from the blood to form urine.\",\n",
        "                \"Nephrons are the functional units of the kidneys that filter blood and produce urine.\",\n",
        "                \"The bladder stores urine until it is excreted from the body.\",\n",
        "                \"Hormones are chemical messengers produced by endocrine glands that regulate various bodily functions.\",\n",
        "                \"The thyroid gland regulates metabolism, growth, and development through the production of thyroid hormones.\",\n",
        "                \"The adrenal glands produce hormones such as cortisol and adrenaline that help the body respond to stress.\",\n",
        "                \"The ovaries produce eggs and hormones such as estrogen and progesterone.\",\n",
        "                \"The testes produce sperm and the hormone testosterone.\",\n",
        "                \"The skin is the largest organ of the body and serves as a barrier to protect against environmental damage.\",\n",
        "                \"Sweat glands help regulate body temperature by producing sweat.\",\n",
        "                \"Sebaceous glands produce sebum, an oily substance that lubricates the skin and hair.\",\n",
        "                \"White blood cells are part of the immune system and help defend the body against infections.\",\n",
        "                \"Antibodies are proteins produced by the immune system that recognize and neutralize foreign substances.\",\n",
        "                \"A pathogen is a microorganism that causes disease, such as bacteria, viruses, and fungi.\",\n",
        "                \"Inflammation is the body's response to injury or infection, characterized by redness, swelling, heat, and pain.\",\n",
        "                \"Vaccines stimulate the immune system to produce immunity against specific diseases.\",\n",
        "                \"Antibiotics are medications used to treat bacterial infections.\",\n",
        "                \"Analgesics are medications used to relieve pain.\",\n",
        "                \"Antipyretics are medications used to reduce fever.\",\n",
        "                \"Antihistamines are medications used to treat allergic reactions.\",\n",
        "                \"A surgeon is a medical doctor who performs operations to treat injuries or diseases.\",\n",
        "                \"A physician is a medical doctor who diagnoses and treats illnesses and injuries.\",\n",
        "                \"A nurse provides care to patients and assists doctors in medical procedures.\",\n",
        "                \"A medical specialist is a doctor who has completed advanced education and training in a specific area of medicine.\",\n",
        "                \"Radiology is the branch of medicine that uses imaging techniques to diagnose and treat diseases.\",\n",
        "                \"Oncology is the branch of medicine that deals with the prevention, diagnosis, and treatment of cancer.\",\n",
        "                \"Cardiology is the branch of medicine that deals with disorders of the heart and blood vessels.\",\n",
        "                \"Neurology is the branch of medicine that deals with disorders of the nervous system.\",\n",
        "                \"Pediatrics is the branch of medicine that deals with the medical care of infants, children, and adolescents.\",\n",
        "                \"Geriatrics is the branch of medicine that focuses on health care for older adults.\",\n",
        "                \"Psychiatry is the branch of medicine that deals with the diagnosis and treatment of mental disorders.\",\n",
        "                \"Anatomical pathology is the branch of pathology that studies the structural changes in tissues caused by disease.\",\n",
        "                \"Clinical pathology is the branch of pathology that focuses on the diagnosis of disease based on the laboratory analysis of bodily fluids and tissues.\",\n",
        "                \"Pharmacology is the branch of medicine that studies the effects of drugs on the body.\",\n",
        "                \"An anesthesiologist is a doctor who specializes in administering anesthesia to patients undergoing surgery.\",\n",
        "                \"An obstetrician is a doctor who specializes in pregnancy, childbirth, and the postpartum period.\",\n",
        "                \"A gynecologist is a doctor who specializes in the female reproductive system.\",\n",
        "                \"A dentist is a doctor who specializes in the diagnosis, prevention, and treatment of diseases and conditions of the oral cavity.\",\n",
        "                \"Physical therapy is a branch of medicine that uses exercises and other treatments to help patients recover from injuries and illnesses.\",\n",
        "                \"Occupational therapy is a branch of medicine that helps patients develop, recover, or maintain the daily living and work skills needed for independence.\",\n",
        "                \"A medical researcher conducts studies to advance knowledge in the field of medicine.\",\n",
        "                \"Clinical trials are research studies that test the safety and effectiveness of new treatments or interventions.\",\n",
        "                \"Preventive medicine focuses on the prevention of diseases and the promotion of health and well-being.\",\n",
        "                \"Epidemiology is the study of how diseases spread and can be controlled in populations.\",\n",
        "                \"Public health is the science of protecting and improving the health of communities through education, policy-making, and research for disease and injury prevention.\",\n",
        "                \"Telemedicine is the use of telecommunication technology to provide medical care and consultation remotely.\",\n",
        "                \"A stethoscope is a medical instrument used to listen to the sounds produced within the body.\",\n",
        "                \"An electrocardiogram (ECG or EKG) is a test that measures the electrical activity of the heart.\",\n",
        "                \"Magnetic resonance imaging (MRI) is an imaging technique that uses magnetic fields and radio waves to produce detailed images of the body's internal structures.\",\n",
        "                \"Computed tomography (CT) scans use X-rays to create detailed images of the body's internal structures.\",\n",
        "                \"Ultrasound imaging uses high-frequency sound waves to create images of the inside of the body.\",\n",
        "                \"A biopsy is a medical procedure that involves taking a small sample of tissue for examination under a microscope.\",\n",
        "                \"Blood tests are laboratory analyses performed on a blood sample to assess health and diagnose diseases.\",\n",
        "                \"Vaccination is the administration of a vaccine to stimulate the immune system to protect against specific infectious diseases.\",\n",
        "                \"Sterilization is the process of making an object free from bacteria or other living microorganisms.\",\n",
        "                \"First aid is the immediate care given to a person who has been injured or is suddenly taken ill.\",\n",
        "                \"Cardiopulmonary resuscitation (CPR) is an emergency procedure that combines chest compressions with artificial ventilation to maintain circulatory flow and oxygenation during cardiac arrest.\",\n",
        "                \"A defibrillator is a medical device that delivers an electric shock to the heart to restore a normal rhythm in cases of severe arrhythmias or cardiac arrest.\",\n",
        "                \"Medical ethics is the branch of ethics that deals with the moral principles and values guiding medical practice and research.\",\n",
        "                \"Linguistics is the scientific study of language and its structure.\",\n",
        "                \"Phonetics is the branch of linguistics that studies the sounds of human speech.\",\n",
        "                \"Phonology deals with the systematic organization of sounds in languages.\",\n",
        "                \"Morphology is the study of the structure and formation of words.\",\n",
        "                \"Syntax examines the rules that govern the structure of sentences.\",\n",
        "                \"Semantics is the branch of linguistics concerned with meaning.\",\n",
        "                \"Pragmatics studies how context influences the interpretation of meaning.\",\n",
        "                \"Sociolinguistics examines the relationship between language and society.\",\n",
        "                \"Psycholinguistics explores the psychological processes involved in language use.\",\n",
        "                \"Historical linguistics studies the history and development of languages over time.\",\n",
        "                \"Comparative linguistics compares languages to find common origins and differences.\",\n",
        "                \"Dialectology is the study of regional variations within a language.\",\n",
        "                \"Etymology is the study of the origin and history of words.\",\n",
        "                \"Language acquisition is the process by which humans learn language.\",\n",
        "                \"Bilingualism is the ability to speak and understand two languages fluently.\",\n",
        "                \"Code-switching is the practice of alternating between two or more languages in a conversation.\",\n",
        "                \"A phoneme is the smallest unit of sound that can distinguish meaning in a language.\",\n",
        "                \"A morpheme is the smallest unit of meaning in a language.\",\n",
        "                \"A lexeme is a unit of lexical meaning that underlies a set of words.\",\n",
        "                \"Grammar is the set of structural rules governing the composition of sentences, phrases, and words.\",\n",
        "                \"A corpus is a large collection of written or spoken texts used for linguistic research.\",\n",
        "                \"Descriptive linguistics aims to describe language as it is actually used.\",\n",
        "                \"Prescriptive linguistics prescribes rules for how language should be used.\",\n",
        "                \"Generative grammar is a theory that aims to describe the implicit knowledge that speakers have about their language.\",\n",
        "                \"Transformational grammar is a type of generative grammar that considers the transformations applied to sentences to generate new sentences.\",\n",
        "                \"A dialect is a particular form of a language specific to a region or social group.\",\n",
        "                \"An idiolect is the speech habits peculiar to a particular person.\",\n",
        "                \"A creole is a stable natural language developed from the mixing of parent languages.\",\n",
        "                \"A pidgin is a simplified form of speech formed from two or more languages, used by people who do not share a common language.\",\n",
        "                \"Orthography is the conventional spelling system of a language.\",\n",
        "                \"A grapheme is the smallest unit of writing that represents a phoneme.\",\n",
        "                \"A syllable is a unit of organization for a sequence of speech sounds.\",\n",
        "                \"Prosody is the rhythm, stress, and intonation of speech.\",\n",
        "                \"Discourse analysis is the study of language use across texts and contexts.\",\n",
        "                \"Stylistics is the study of linguistic style, particularly in literary works.\",\n",
        "                \"Translation is the process of rendering text from one language into another.\",\n",
        "                \"Interpretation is the oral translation of spoken language.\",\n",
        "                \"Language families are groups of related languages that have a common historical origin.\",\n",
        "                \"Indo-European is the largest language family, including languages such as English, Spanish, and Hindi.\",\n",
        "                \"The Sapir-Whorf hypothesis suggests that the structure of a language affects its speakers' worldview and cognition.\",\n",
        "                \"Language typology classifies languages according to their common structural features.\",\n",
        "                \"A linguistic universal is a feature or characteristic that is common to all languages.\",\n",
        "                \"A loanword is a word adopted from one language and incorporated into another without translation.\",\n",
        "                \"A calque is a word or phrase borrowed from another language by literal translation.\",\n",
        "                \"Diglossia refers to a situation where two languages or dialects are used by the same community in different contexts.\",\n",
        "                \"A lingua franca is a language that is used as a common language between speakers of different native languages.\",\n",
        "                \"An endangered language is one that is at risk of falling out of use as its speakers die out or shift to speaking another language.\",\n",
        "                \"A dead language is one that no longer has any native speakers.\",\n",
        "                \"Revitalization efforts aim to bring endangered or dead languages back into common use.\",\n",
        "                \"Language preservation involves maintaining and protecting languages, especially those that are at risk of extinction.\",\n",
        "                \"Phonological rules describe how phonemes are realized as speech sounds in different contexts.\",\n",
        "                \"Allophones are variations of a phoneme that occur in different contexts without changing meaning.\",\n",
        "                \"A minimal pair is a pair of words that differ by only one phoneme, illustrating the phonemic contrast.\",\n",
        "                \"Stress is the emphasis placed on certain syllables or words in speech.\",\n",
        "                \"Intonation refers to the variation of pitch while speaking, which can change the meaning of sentences.\",\n",
        "                \"Tone languages use pitch variations to distinguish word meanings.\",\n",
        "                \"A syntax tree is a diagram representing the syntactic structure of a sentence according to a formal grammar.\",\n",
        "                \"Case grammar is a system for analyzing sentence structure based on the semantic roles of words.\",\n",
        "                \"Word order typology classifies languages based on the order of subject, verb, and object in sentences.\",\n",
        "                \"Anaphora is the use of words such as pronouns to refer back to previously mentioned entities.\",\n",
        "                \"Deixis refers to words and phrases that cannot be fully understood without additional contextual information.\",\n",
        "                \"Ambiguity occurs when a word or sentence has more than one possible meaning.\",\n",
        "                \"Polysemy is the coexistence of many possible meanings for a word or phrase.\",\n",
        "                \"Homophones are words that sound the same but have different meanings.\",\n",
        "                \"Synonyms are words with similar meanings.\",\n",
        "                \"Antonyms are words with opposite meanings.\",\n",
        "                \"A thesaurus is a reference work that lists words grouped together according to similarity of meaning.\",\n",
        "                \"A lexicon is the vocabulary of a language or a specific field of study.\",\n",
        "                \"Collocation refers to the habitual juxtaposition of a particular word with another word or words with a frequency greater than chance.\",\n",
        "                \"A register is a variety of a language used for a particular purpose or in a particular social setting.\",\n",
        "                \"A speech act is an utterance that performs a function in communication, such as making a request or giving a command.\",\n",
        "                \"Conversational implicature refers to the implied meanings that are not directly expressed in spoken language.\",\n",
        "                \"A neologism is a newly coined word or expression.\",\n",
        "                \"A euphemism is a mild or indirect word or expression substituted for one considered too harsh or blunt.\",\n",
        "                \"A dysphemism is a derogatory or unpleasant term used instead of a pleasant or neutral one.\",\n",
        "                \"Jargon is specialized language used by a particular profession or group.\",\n",
        "                \"Slang is informal language used by a particular group of people.\",\n",
        "                \"An accent is a distinctive way of pronouncing a language, often associated with a particular region or social group.\",\n",
        "                \"An idiom is a phrase or expression that has a figurative meaning different from its literal meaning.\",\n",
        "                \"A proverb is a short, well-known saying that expresses a general truth or piece of advice.\",\n",
        "                \"Rhetoric is the art of effective or persuasive speaking or writing.\",\n",
        "                \"A metaphor is a figure of speech that describes an object or action as something other than what it is, often for symbolic effect.\",\n",
        "                \"A simile is a figure of speech that compares two different things using 'like' or 'as'.\",\n",
        "                \"Personification is the attribution of human characteristics to non-human entities.\",\n",
        "                \"Hyperbole is an exaggerated statement not meant to be taken literally.\",\n",
        "                \"Alliteration is the repetition of the same initial consonant sounds in a sequence of words.\",\n",
        "                \"Assonance is the repetition of vowel sounds in nearby words.\",\n",
        "                \"Consonance is the repetition of consonant sounds, typically at the end of words.\",\n",
        "                \"Onomatopoeia is the formation of a word from a sound associated with what is named.\",\n",
        "                \"Syntax is the arrangement of words and phrases to create well-formed sentences.\",\n",
        "                \"Lexicography is the practice of compiling dictionaries.\",\n",
        "                \"A linguist is a person who studies linguistics.\",\n",
        "                \"Language arts include reading, writing, speaking, and listening skills.\",\n",
        "                \"Creative writing involves the expression of ideas and emotions through imaginative storytelling.\",\n",
        "                \"Literary analysis is the examination and interpretation of literary texts.\",\n",
        "                \"Poetry is a form of literature that uses aesthetic and rhythmic qualities of language to evoke meanings.\",\n",
        "                \"Drama is a genre of literature intended for performance by actors on a stage.\",\n",
        "                \"Prose is written or spoken language in its ordinary form, without metrical structure.\",\n",
        "                \"A narrative is a spoken or written account of connected events; a story.\",\n",
        "                \"A plot is the sequence of events in a story.\",\n",
        "                \"Characterization is the process by which an author reveals the personality of a character.\",\n",
        "                \"A theme is the central topic or idea explored in a text.\",\n",
        "                \"A motif is a recurring element that has symbolic significance in a story.\",\n",
        "                \"A symbol is an object, character, or event that represents a deeper meaning.\",\n",
        "                \"A protagonist is the main character in a story.\",\n",
        "                \"An antagonist is a character who opposes the protagonist.\",\n",
        "                \"Dialogue is the written or spoken conversational exchange between characters.\",\n",
        "                \"A monologue is a long speech by one character in a play or story.\",\n",
        "                \"A soliloquy is a speech in which a character speaks their thoughts aloud, often while alone on stage.\",\n",
        "                \"A metaphor is a figure of speech that describes an object or action as something other than what it is, often for symbolic effect.\",\n",
        "                \"Foreshadowing is a literary device used to give an indication or hint of what is to come later in the story.\",\n",
        "                \"Irony is a figure of speech where the intended meaning is opposite to the literal meaning.\",\n",
        "                \"Satire is a genre of literature that uses humor, irony, or ridicule to criticize or expose flaws in society.\",\n",
        "                \"A parody is an imitation of a particular writer, artist, or genre with deliberate exaggeration for comic effect.\",\n",
        "                \"An allegory is a story in which characters and events represent abstract ideas or moral qualities.\",\n",
        "                \"A fable is a short story that typically features animals and conveys a moral lesson.\",\n",
        "                \"A myth is a traditional story that explains the early history of a people or a natural phenomenon, often involving gods or supernatural beings.\",\n",
        "                \"A legend is a traditional story sometimes popularly regarded as historical but unauthenticated.\",\n",
        "                \"Folklore is the traditional beliefs, customs, stories, and practices of a community, passed through generations by word of mouth.\",\n",
        "                \"A fairy tale is a story featuring fantastical characters and magical events, often with a moral lesson.\",\n",
        "                \"An epic is a long narrative poem detailing the heroic deeds and adventures of a legendary or historical figure.\",\n",
        "                \"A novel is a long, fictional narrative that describes intimate human experiences.\",\n",
        "                \"A short story is a brief fictional narrative that typically focuses on a single incident or character.\",\n",
        "                \"A memoir is a historical account or biography written from personal knowledge or special sources.\",\n",
        "                \"An autobiography is a self-written account of the author's life.\",\n",
        "                \"A biography is an account of someone's life written by another person.\",\n",
        "                \"A diary is a daily record of personal experiences and thoughts.\",\n",
        "                \"A journal is a daily or periodic account of events, experiences, or observations.\",\n",
        "                \"An essay is a short piece of writing on a particular subject, often expressing personal views.\",\n",
        "                \"An article is a written composition on a specific topic, often published in a newspaper, magazine, or journal.\",\n",
        "                \"A speech is a formal address delivered to an audience.\",\n",
        "                \"Oratory is the art of public speaking, especially in a formal and eloquent manner.\",\n",
        "                \"Rhetorical devices are techniques used by speakers and writers to persuade, inform, or entertain the audience.\",\n",
        "                \"An aphorism is a concise statement that expresses a general truth or principle.\",\n",
        "                \"A maxim is a short, pithy statement expressing a general truth or rule of conduct.\",\n",
        "                \"Axiom is a statement or proposition that is regarded as being established, accepted, or self-evidently true.\",\n",
        "                \"Cliché is an overused expression or idea that has lost its originality and impact.\",\n",
        "                \"A trope is a common or overused theme or device in literature.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "labels =['dog sentence', 'AI sentence', 'evironment','crypto','quantum','mars','energy','AI sentence','hot topic- euginics',\n",
        "         'AR','Internet of Things','Cybersecurity', 'autonomous vehicles','3D printing technology' , 'culture', 'agriculture',\n",
        "         'brain','VR','environment','SM','space','philosophy','solar','philosophy','science','ocean', 'NFT', 'Research', 'Fishing','Digital']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOM2KBl7ZZNa",
        "outputId": "8b463995-b2ad-41c4-efe0-0feb788bd955"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 211\u001b[0m\n\u001b[0;32m    207\u001b[0m         conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m mem \u001b[38;5;241m=\u001b[39m \u001b[43mMemory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m ltm \u001b[38;5;241m=\u001b[39m Memory()\u001b[38;5;241m.\u001b[39mltm\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m#mem.update_memory(\"New STM data\")\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m#memory.update_memory(episodic_data=\"example.mp3\")  # Example for audio\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m#mem.update_memory(semantic_data=(\"General knowledge about AI\":'machine learning'))  # Example for semantic memory\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[2], line 10\u001b[0m, in \u001b[0;36mMemory.__init__\u001b[1;34m(self, working_memory_capacity, stm, ltm, ltm_capacity, corpus, episodic_memory, semantic_memory)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, working_memory_capacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, stm\u001b[38;5;241m=\u001b[39m[], ltm\u001b[38;5;241m=\u001b[39m[], ltm_capacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000000000000000000\u001b[39m, corpus\u001b[38;5;241m=\u001b[39m[],episodic_memory\u001b[38;5;241m=\u001b[39m[], semantic_memory\u001b[38;5;241m=\u001b[39m[]):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_long_term_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mltm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworking_memory \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Short-term working memory as a list\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemantic_memory \u001b[38;5;241m=\u001b[39m semantic_memory  \u001b[38;5;66;03m# Store generalized knowledge\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[2], line 49\u001b[0m, in \u001b[0;36mMemory.load_long_term_memory\u001b[1;34m(self, ltm)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_long_term_memory\u001b[39m(\u001b[38;5;28mself\u001b[39m, ltm):\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load LTM from a file.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     ltm_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/users/Jonny/Documents/PATH/ONI/ltm_path/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mltm_path.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(ltm_path):\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ltm_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mltm_path.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
            "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "working_data = []\n",
        "vocab = []\n",
        "#5 most recent items in vocab\n",
        "semantic_data = vocab[0:10]\n",
        "\n",
        "\n",
        "\n",
        "class Memory():\n",
        "    def __init__(self, working_memory_capacity=5, stm=[], ltm=[], ltm_capacity=1000000000000000000000, corpus=[],episodic_memory=[], semantic_memory=[]):\n",
        "        self.load_long_term_memory(ltm)\n",
        "        self.working_memory = []  # Short-term working memory as a list\n",
        "        self.semantic_memory = semantic_memory  # Store generalized knowledge\n",
        "        self.ltm_path = os.path.join('Downloads/ONI/ltm_path/', \"ltm_data.json\")\n",
        "        self.corpus = corpus  # Initial semantic knowledge\n",
        "        self.working_memory_capacity = working_memory_capacity\n",
        "        self.ltm_capacity = ltm_capacity\n",
        "        self.stm = []\n",
        "        self.models = {}\n",
        "        self.ltm = ltm\n",
        "        self.episodic_memory = []\n",
        "\n",
        "\n",
        "    def handle_media(self, data):\n",
        "        \"\"\"Handle different types of media files for episodic memory.\"\"\"\n",
        "        media_extensions = {\n",
        "            '.mov': 'video',\n",
        "            '.mp4': 'video',\n",
        "            '.avi': 'video',\n",
        "            '.wav': 'audio',\n",
        "            '.mp3': 'audio',\n",
        "            '.txt': 'plaintext',\n",
        "            '.pdf': 'PDF',\n",
        "            '.doc': 'Document File',\n",
        "            'ODT': 'Open Document TXT',\n",
        "            '.py': 'python file',\n",
        "            '.html': 'website',\n",
        "            '.js': 'javascript',\n",
        "            '.css': 'styles'\n",
        "        }\n",
        "        file_extension = os.path.splitext(data)[1]\n",
        "        media_type = media_extensions.get(file_extension, 'unknown')\n",
        "\n",
        "        if media_type in ['video', 'audio']:\n",
        "            return {'type': media_type, 'path': data}\n",
        "        else:\n",
        "            return None\n",
        "    def load_long_term_memory(self, ltm):\n",
        "        \"\"\"Load LTM from a file.\"\"\"\n",
        "        ltm_path = os.path.join('C:/users/Jonny/Documents/PATH/ONI/ltm_path/', 'ltm_path.json')\n",
        "        if os.path.exists(ltm_path):\n",
        "            with open(os.path.join(ltm_path, 'ltm_path.json'), 'r') as file:\n",
        "                loaded_data = json.load(file)\n",
        "                self.loaded_memory = loaded_data\n",
        "                for tokens in loaded_data.get('ltm_path.txt', []):\n",
        "                    if tokens not in self.semantic_memory:\n",
        "                        self.semantic_memory += tokens\n",
        "\n",
        "    @classmethod\n",
        "    def update_episodic_memory(cls, data, data_type, key):\n",
        "        if not hasattr(cls, 'episodic_memory'):\n",
        "            cls.episodic_memory = {}\n",
        "        cls.episodic_memory[key] = {'data': data, 'type': data_type}\n",
        "\n",
        "    @classmethod\n",
        "    def retrieve_from_episodic(cls, key):\n",
        "        if not hasattr(cls, 'episodic_memory'):\n",
        "            cls.episodic_memory = {}\n",
        "        return cls.episodic_memory.get(key, {}).get('data', None)\n",
        "\n",
        "\n",
        "    def update_semantic_memory(self, text, media_type=None):\n",
        "        \"\"\"\n",
        "        Add text data to semantic memory.\n",
        "\n",
        "        Args:\n",
        "            text (str): The text data to add to the semantic memory.\n",
        "            media_type (str, optional): The type of media from which the text is extracted.\n",
        "                                        Expected values are '.txt', '.pdf', '.doc', '.py', '.js', '.css', '.html'.\n",
        "                                        Default is None.\n",
        "        \"\"\"\n",
        "        if media_type:\n",
        "            if media_type not in ['.txt', '.pdf', '.doc', '.py', '.js', '.css', '.html']:\n",
        "                raise ValueError(\"Unsupported media type\")\n",
        "\n",
        "        def current_index(tokens, text):\n",
        "                for tokens in text:\n",
        "                    token = current_index\n",
        "                    tokens = text.split()\n",
        "                    for token in tokens:\n",
        "                        if token not in self.semantic_memory:\n",
        "                            self.semantic_memory[token] = current_index\n",
        "                            current_index += 1\n",
        "                            return current_index\n",
        "\n",
        "        # Ensure we respect the ltm_capacity\n",
        "        if len(self.semantic_memory) > self.ltm_capacity:\n",
        "            # Here you could implement some strategy to remove old entries\n",
        "            # For simplicity, we are not implementing it in this example\n",
        "            raise MemoryError(\"Semantic memory has exceeded its capacity\")\n",
        "\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\"\n",
        "        Lookup the index of a token in the semantic memory.\n",
        "\n",
        "        Args:\n",
        "            token (str): The token to lookup.\n",
        "\n",
        "        Returns:\n",
        "            int: The index of the token in the semantic memory.\n",
        "        \"\"\"\n",
        "        return self.semantic_memory.get(token, -1)\n",
        "\n",
        "# Example usage:\n",
        "# Assuming self.semantic_memory is a list and self.ltm_capacity is an integer.\n",
        "\n",
        "\n",
        "#memory consilidation and clarity (mindfulness of own memory)\n",
        "    def meditate(self):\n",
        "        \"\"\" Compress and refine semantic and working memory. \"\"\"\n",
        "        unique_data = set(self.semantic_memory + self.working_memory)\n",
        "        self.ltm = list(unique_data)[:self.ltm_capacity]\n",
        "\n",
        "#normal sleep (self learning while wait)\n",
        "    def dream(self, model_name='nlp_model.h5'):\n",
        "        \"\"\" Analyze and consolidate episodic memory using a neural network model. \"\"\"\n",
        "        if model_name in self.models:\n",
        "            model = self.models[model_name]\n",
        "        else:\n",
        "            model = load_model(model_name)\n",
        "            self.models[model_name] = model\n",
        "\n",
        "        for memory in self.episodic_memory:\n",
        "# Assuming each memory item is path to media, and model can process this directly\n",
        "            data = self.handle_media(memory['path'])\n",
        "            if data:\n",
        "                processed_data = model.predict(data)\n",
        "                memory['processed'] = processed_data\n",
        "#deep sleep\n",
        "    def sleep(self, model_name='nlp_model.h5'):\n",
        "        \"\"\" Main sleep function to stop all processes and consolidate memories. \"\"\"\n",
        "        print(\"AI is going to sleep...\")\n",
        "        self.meditate()\n",
        "        self.dream(model_name=model_name)\n",
        "        self.save_long_term_memory()\n",
        "        print(\"AI has woken up with refreshed memories.\")\n",
        "\n",
        "    def save_long_term_memory(self):\n",
        "            \"\"\"Save compressed long-term memory.\"\"\"\n",
        "            ltm = self.ltm\n",
        "            with open(r'\"C:\\Users\\jonny\\Documents\\PATH\\ONI\\ltm_path\\ltm_data.json\"', 'w') as file:\n",
        "\n",
        "              json.dump(ltm, file)\n",
        "              print(\"Long-term memory saved.\")\n",
        "\n",
        "    def handle_pdf(self, pdf_path):\n",
        "        \"\"\"Extract text from PDF and add to semantic memory.\"\"\"\n",
        "        try:\n",
        "            with open(pdf_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                num_pages = len(pdf_reader.pages)\n",
        "                for page_num in range(num_pages):\n",
        "                    page = pdf_reader.pages[page_num]\n",
        "                    text = page.extract_text()\n",
        "                    self.update_semantic_memory(text)\n",
        "\n",
        "            print(f\"PDF '{os.path.basename(pdf_path)}' added to semantic memory.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing PDF: {e}\")\n",
        "\n",
        "    def update_memory(self, stm_data, episodic_data=None, semantic_data=None):\n",
        "        \"\"\"Update all memory stores with new data.\"\"\"\n",
        "        self.update_working_memory(working_data)\n",
        "        if working_data not in list(stm):\n",
        "            stm.append(working_data)\n",
        "        if episodic_data:\n",
        "            self.update_episodic_memory(episodic_data)\n",
        "        if semantic_data:\n",
        "            self.update_semantic_memory(semantic_data)\n",
        "        self.save_long_term_memory()\n",
        "\n",
        "    def categorize_and_store(self, db_path='personality.db'):\n",
        "        \"\"\"Categorize memory items and store them in a SQLite database.\"\"\"\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS personalities (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                name TEXT,\n",
        "                race TEXT,\n",
        "                origin TEXT,\n",
        "                age INTEGER,\n",
        "                type TEXT\n",
        "            )\n",
        "        \"\"\")\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS conversations (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                personality_id INTEGER,\n",
        "                timestamp TEXT,\n",
        "                input_text TEXT,\n",
        "                response_text TEXT,\n",
        "                FOREIGN KEY (personality_id) REFERENCES personalities(id)\n",
        "            )\n",
        "        \"\"\")\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "\n",
        "# Usage\n",
        "mem = Memory()\n",
        "ltm = Memory().ltm\n",
        "#mem.update_memory(\"New STM data\")\n",
        "#memory.update_memory(episodic_data=\"example.mp3\")  # Example for audio\n",
        "#mem.update_memory(semantic_data=(\"General knowledge about AI\":'machine learning'))  # Example for semantic memory\n",
        "mem.update_semantic_memory( 'Documents/PATH/ONI/IdentityPersonalANDSocialinpressreformatted.pdf', media_type='.pdf')\n",
        "save = mem.save_long_term_memory()\n",
        "#load = mem.load_long_term_memory(ltm)\n",
        "\n",
        "while mem == Memory():\n",
        "    mem.working_memory += input_data\n",
        "    update_memory\n",
        "    update_semantic_memory(text = corpus, mediatype=None)\n",
        "    update_long_term_memory\n",
        "print(\"Memory system upgraded with episodic and semantic capabilities.\")\n",
        "print(mem.ltm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gTve-TFPxcSm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfCToyLtZaTu",
        "outputId": "2fc5d0b7-83e9-405e-8167-526b4284df45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: ['[UNK]', 'the', 'of', 'is', 'a', 'and', 'to', 'that', 'in', 'The', 'or', 'A', 'for', 'are', 'as', 'Model:', 'can', 'quantum', 'by', 'with', 'You:', 'an', 'which', 'on', 'from', 'be', 'system', 'branch', 'about', 'What', 'genetic', 'used', 'states', 'language', 'study', 'between', 'studies', 'one', 'but', 'two', 'such', 'their', 'have', 'its', 'it', 'An', 'like', 'Quantum', 'theory', 'describes', 'body', 'all', 'through', 'often', 'has', 'particles', 'chemical', 'process', 'other', 'number', 'more', 'models', 'mathematical', 'ethical', 'you', 'wisdom', 'than', 'not', 'law', 'into', 'human', 'at', 'I', 'structure', 'over', 'largest', 'how', 'blood', 'also', 'Hypergraphs', 'specific', 'medical', 'fundamental', 'energy', 'different', 'change', 'who', 'speech', 'our', 'mechanics', 'mass', 'languages', 'language.', 'information', 'form', 'data', 'common', 'DNA', 'word', 'where', 'universe', 'produce', 'physics', 'moral', 'medicine', 'light', 'known', 'know', 'involves', 'includes', 'hypergraphs', 'formula', 'field', 'both', 'words', 'use', 'state', 'particular', 'object', 'new', 'motion', 'most', 'deals', 'complex', 'behavior', 'when', 'uses', 'unit', 'set', 'particle', 'meaning.', 'knowledge', 'equation', 'changes', 'body.', 'another', 'words.', 'wave', 'statement', 'provides', 'properties', 'only', 'occurs', 'numbers', 'mathematics', 'magnetic', 'life', 'including', 'gene', 'function', 'force', 'energy.', 'development', 'describe', 'concept', 'classical', 'character', 'based', 'Wisdom', 'In', \"I'm\", 'written', 'work', 'without', 'within', 'universe.', 'traditional', 'tool', 'thinking', 'systems', 'story', 'sound', 'sequence', 'same', 'relationships.', 'refers', 'principle', 'powerful', 'perform', 'no', 'nature', 'natural', 'momentum', 'meaning', 'learning', 'hypergraphs.', 'external', 'expression', 'essential', 'effect', \"don't\", 'doctor', 'being', 'approximately', 'any', 'against', 'while', 'way', 'values', 'using', 'understand', 'type', 'treat', 'together', 'theorem', 'that.', 'system.', 'structures', 'story.', 'spoken', 'sounds', 'serves', 'research.', 'representation.', 'properties.', 'philosophy', 'numbers.', 'model', 'many', 'living', 'linguistics', 'lead', 'it.', 'interactions', 'include', 'hypergraph-based', 'health', 'good', 'focuses', 'every', 'equal', 'entanglement', 'electric', 'do', 'diseases.', 'create', 'charged', 'causes', 'care', 'NLP', 'Legend', 'Language', 'Genetic', 'what', 'vector', 'up', 'unless', 'understanding', 'truth', 'time.', 'think', 'symbol', 'sun.', 'suggests', 'sentences.', 'rules', 'research', 'represents', 'represent', 'regulate', 'pursuit', 'protects', 'probability', 'principles', 'primary', 'phenomenon', 'particles.', 'part', 'objects', 'normal', 'models.', 'mechanics,', 'meanings.', 'matter.', 'matter', 'material', 'make', 'key', 'individuals', 'improve', 'immune', 'imaging', 'historical', 'help', 'heart', 'glands', 'genes', 'functions', 'fictional', 'element', 'electrons', 'effects', 'each', 'does', 'disorders', 'discovered', 'direction', 'constant', 'concerned', 'computing', 'carbon', 'brain', 'atomic', 'another.', 'analysis', 'alleles', 'act', 'account', 'ability', 'Zelda', 'This', \"I'd\", 'Hypergraph-based', 'How', 'AGI', '1', 'your', 'waves', 'wave-like', 'water', 'various', 'use.', 'universal', 'under', 'typically', 'treatment', 'transferred', 'traits', 'today?', 'tissue', 'time', 'temperature', 'technology', 'supports', 'structural', 'strong', 'speed', 'specializes', 'speakers', 'space', 'sometimes', 'some', 'smallest', 'side', 'short', 'science', 'representation', 'relationship', 'related', 'real', 'protect', 'proposed', 'production', 'produced', 'prime', 'practice', 'potential', 'possible', 'point', 'physical', 'philosophers', 'personal', 'per', 'patients', 'pathology', 'particle-like', 'out', 'organ', 'offer', 'ocean', 'observer', 'nervous', 'narrative', 'medications', 'mechanics.', 'materials', 'makes', 'machine', 'located', 'life.', 'levels.', 'large', 'languages.', 'just', 'involve', 'internal', 'influence', 'ideas', 'idea', 'hydrogen', 'hormones', 'helps', 'grammar', 'general', 'frequency', 'formulated', 'forms', 'formal', 'force.', 'figure', 'expressed', 'ethics', 'environmental', 'effect.', 'during', 'due', 'distribution', 'directly', 'conservation', 'composed', 'communication', 'characters', 'chain', 'certain', 'cells', 'caused', 'carry', 'capital', 'capable', 'bones', 'billion', 'below', 'associated', 'assist', 'art', 'around', 'area', 'approaches', 'alphabet?', 'aims', 'actions', 'action', 'You', 'Was', 'Understanding', 'Philosophers', 'Hypergraph', 'Gene', 'Ethical', 'Do', 'writing', 'will', 'we', 'variations', 'variation', 'value', 'vacuum', 'until', 'unique', 'true.', 'true', 'triboelectricity,', 'total', 'topic', 'time,', 'throughout', 'those', 'third', 'thing', 'thermodynamics', 'therapy', 'theory.', 'theoretical', 'text.', 'techniques', 'systems.', 'symbolic', 'sweat.', 'surface', 'support', 'superposition', 'sum', 'structures.', 'stretches', 'stars', 'spinal', 'speech.', 'specialized', 'speaking,', 'something', 'society.', 'social', 'small', 'skin,', 'simultaneously.', 'simultaneously', 'series.', 'sentence', 'selection', 'secure', 'second', 'sea', 'scientific', 'role', 'risk', 'right', 'respiratory', 'require', 'reproductive', 'repetition', 'remains', 'relative', 'relation', 'region', 'regarded', 'reaches', 'rational', 'random', 'published', 'proteins', 'protein.', 'proof', 'procedure', 'problems.', 'prevent', 'practices', 'practical', 'population.', 'philosophical', 'phenotype', 'periodic', 'performance', 'penny', 'pair', 'oxygen,', 'own', 'organs', 'organism', 'order', 'opposite', 'operations', 'nucleus', 'multiple', 'movement', 'molecules', 'method', 'meters', 'mechanical', 'measures', 'me', 'matter,', 'mammal?', 'making', 'maintain', 'made', 'long', 'living.', 'literature', 'literary', 'literal', 'linguistic', 'linear', 'light-years', 'level.', 'laws', 'laid', 'involving', 'interpretation', 'interactions.', 'initial', 'inheritance', 'individual', 'importance', 'imaginary', 'images', 'if', 'hypergraph', 'hydrogen,', 'humans', 'history', 'highly', 'heterozygous', 'heart,', 'groups', 'group.', 'greater', 'gravity', 'global', 'given', 'geometry', 'geometric', 'genre', 'generations', 'generating', 'galaxies', 'functions,', 'function.', 'fuel', 'fries', 'friction', 'frequencies', 'free', 'forces', 'flow', 'flexible', 'fields', 'feet)', 'explored', 'explore', 'exploration', 'exhibit', 'exchange', 'examines', 'examination', 'event', 'ethics.', 'especially', 'equations', 'entropy', 'enhance', 'electricity', 'electrical', 'early', 'duality', 'diseases', 'disease', 'digestive', 'diagnose', 'device', 'developed', 'describing', 'depth', 'deepest', 'dealing', 'data.', 'daily', 'critical', 'control', 'continuous', 'contexts.', 'considered', 'connective', 'connect', 'conditions,', 'conditions', 'concepts', 'compares', 'colossal', 'collection', 'chromosome', 'cells.', 'cardiac', 'capture', 'cannot', \"can't\", 'called', \"body's\", 'bodily', 'bird', 'been', 'basic', 'barrier', 'back', 'artificial', 'angular', 'allows', 'allele', 'algebra', 'aim', 'advanced', 'across.', 'according', 'abundant', 'Yes.', 'Yes,', 'Wall,', 'Using', 'Trench,', 'Standard', 'Model', 'Mariana', 'John', 'James', 'Hercules-Corona', 'Hello!', 'Great', 'Ethics', 'Einstein', 'Deep', 'Challenger', 'Borealis', 'Artificial', 'Aristotle', 'Albert', '=', '74%', '10,994', '10', '(36,070', \"you're\", 'would', 'worth', 'world.', \"world's\", 'world', 'wisdom,', 'well-being.', 'well,', 'wavefront', 'wave-particle', 'waste', 'was', 'virtue', 'vast', 'variables', 'variable', 'values.', 'used.', 'urine.', 'upper', 'upon', 'underlying', 'typology', 'two-dimensional', 'treatments', 'translation.', 'transform', 'trace', 'tissues.', 'tissues', 'times', 'thyroid', 'thoughts', 'thought', 'they', 'thermodynamics,', 'there!', 'theory,', 'theories', 'theme', 'thanks', 'texts', 'tests', 'test', 'term', 'technique', 'teaches', 'teach', 'tasks.', 'taken', 'take', 'system,', 'symmetry', 'subtraction,', 'substances.', 'subject,', 'subatomic', 'study.', 'structure.', 'stores', 'stimulate', 'star', 'standards', 'stage.', 'stable', 'special', 'speaking', 'speak', 'spacetime', 'space.', 'sound.', 'solve', 'sodium', 'societal', 'so', 'skin', 'skeletal', 'situation', 'single', 'simple', 'similar', 'significant', 'signals', 'shows', 'short,', 'set.', 'series', 'sensitive', 'semantic', 'self-reflection.', 'self-evidently', 'seeks', 'science.', 'saved', 'sample', 'roles', 'revolutionized', 'rest', 'responsible', 'respect', 'requires', 'remain', 'releasing', 'relativity,', 'relativity', 'regulates', 'referred', 'recessive', 'reality', 'quit.', 'quantized', 'quantization', 'quantity.', 'quantity', 'qualities', 'quadratic', 'public', 'psychology.', 'provide', 'proven', 'proteins,', 'protective', 'protecting', 'proposition', 'proportional', 'products', 'product', 'produces', 'problem-solving.', 'principles.', 'previously', 'prevention,', 'preserves', 'preservation', 'precision.', 'power.', 'posits', 'positively', 'positive', 'position', 'populations.', 'population', 'pool', 'points.', 'points,', 'placed', 'place', 'pitch', 'piece', 'phrases', 'phrase', 'photoelectric', 'phoneme', 'phenotypes', 'phenotype.', 'person.', 'person', 'performs', 'people', 'patterns', 'pathogens', 'particularly', 'parallel', 'pairs', 'pain.', 'overused', 'others.', 'oscillator', 'oscillation', 'organization', 'organism,', 'oral', 'opposes', 'operation', 'ongoing', \"one's\", 'offers', 'occur', 'objects.', 'nutrients', 'number.', 'nuclei', 'nuances', 'now?', 'novel', 'negative', 'necessary', 'nearly', 'nature.', 'native', 'mysterious', 'mutation', 'muscular', 'muscles,', 'multiplication,', 'moving', 'morality', 'molecular', 'millions', 'methods', 'metaphor', 'medium', 'medicine.', 'meanings', 'mean', 'mathematics,', 'massive', 'manner.', 'mammal', 'makeup', 'major', 'maintenance', 'maintaining', 'macroscopic', 'lungs', 'lower', 'love', 'long,', 'logic', 'location', 'list', 'lines,', 'line', 'limit', 'light,', 'lifelong', 'lesson.', 'legend', 'learn', 'leading', 'larger', 'languages,', 'laboratory', 'knowledge.', 'knowledge,', 'kinetic', 'kilometers', 'kidneys', 'justice', 'joints.', 'itself.', \"it's\", 'issues', 'isolated', 'is,', 'irrational', 'involved', 'intestine', 'interconnected', 'interaction', 'intended', 'intelligence', 'integral', 'integer', 'insights', 'insight.', 'injury', 'injuries', 'inherited', 'information.', 'infections.', 'industries.', 'induction', 'increase', 'impossible', 'hypothesis', 'hypergiant', 'horse', 'hidden', 'heroic', 'heat,', 'heart.', 'hear', 'harmony', 'harmonic', 'happiness', 'guiding', 'gravitation', 'grass', 'graphs', 'golden', 'gold?', 'gold', 'glad', 'giving', 'give', 'genomics', 'genes,', 'gases', 'gas', 'future', 'functions.', 'functional', 'fully', 'french', 'fraction', 'foundations', 'formation', 'forefront', 'fluid', 'flies', 'find', 'filter', 'filled', 'field.', 'fermions', 'female', 'father', 'fascinating', 'famous', 'expression.', 'expressing', 'expresses', 'explains', 'experiments', 'experiences', 'experience,', 'experience', 'expansion', 'exist', 'exhibits', 'evolutionary', 'evolution', 'everyday', 'ever', 'events,', 'events', 'ethics,', 'established,', 'established', 'escape', 'environment.', 'entities.', 'enjoy', 'endocrine', 'endangered', 'encourages', 'encode', 'encapsulates', 'enabling', 'enables', 'emphasized', 'emission', 'elephant.', 'elementary', 'electrostatic', 'electromagnetic', 'either', 'eggs.', 'effectively', 'education', 'dynamical', 'dominant,', 'doing', 'diversity.', 'distribution,', 'distinguish', 'disorder', 'disease.', 'discussions', 'dioxide,', 'dioxide', 'digestion', 'differential', 'diagram', 'diagnosis,', 'diagnosis', 'development.', 'determine', 'detailed', 'derivatives', 'depending', 'demonstrates', 'defined', 'deeper', 'decrease', 'decisions.', 'decision-making.', 'dead', 'current', 'crucial', 'could', 'cord', 'controlled', 'contributes', 'contains', 'constant.', 'consonant', 'consisting', 'consciousness?', 'consciousness.You:', 'consciousness', 'connected', 'concerning', 'computing,', 'computer', 'composition', 'completed', 'complete', 'communities', 'color', 'coherence', 'close', 'classifies', 'chromosomes.', 'chickens', 'chat.', 'character.', 'changing', 'central', 'cells,', 'cell', 'cavity.', 'causing', 'cats', 'case', 'cake', 'c', 'bones.', 'blue', 'blood.', 'bladder', 'black', 'biology', 'biography', 'biodiversity.', 'best', 'believed', 'beings.', 'beings', 'behavior.', 'become', 'basis', 'bands', 'autosomal', 'audience.', 'assess', 'aspects', 'asking.', 'arrest.', 'arrangement', 'approach', 'applying', 'applied', 'another,', 'analysis.', 'amounts', 'amount', 'always', 'along', 'allowing', 'algorithms', 'aid', 'affects', 'adrenal', 'addition,', 'acting', 'across', 'acquiring', 'acid,', 'accepted,', 'acceleration', 'abstract', 'absorption', 'absorbs', 'absolute', 'Zelda?', 'Z', 'Y', 'X-linked', 'X', 'Western', 'Welcome', 'Valorant', 'Type', 'Translation', 'Tower', 'They', 'That', 'Tell', 'Syntax', 'Sustainable', 'Sorry,', 'Socrates,', 'Schrödinger', 'RNA', 'R136a1,', 'Public', 'Principle', 'Plato,', 'Philosophical', 'Natural', 'Moral', 'Mathematical', 'Magellanic', 'Large', 'Interpretation', 'Hi', \"Heisenberg's\", 'Hall', 'H', 'Greek', 'Graph', 'Genomic', 'General', 'French', \"Euclid's\", \"Einstein's\", 'Eiffel', 'E', 'Developing', 'Dark', 'Complex', 'Comparative', 'Cloud,', 'Clinical', 'Chaos', 'C', 'Au.', 'Ancient', 'African', 'Advanced', 'AGI?', '300', '299,792', '0', '.', '+', \"'exit'\", 'zero,', 'zero', 'zelda', 'z', 'you?You:', 'yielded', 'yet', 'y', 'x', 'wrongness', 'wrong,', 'writings', 'writing.', 'writing,', 'writers', 'writer,', 'write', 'worm,', 'worldwide.', 'worldview', 'world?', 'works.', 'works', 'work-energy', 'work,', 'words,', 'wonders', 'wonder.', 'within.', 'wisely', 'wisdom.', 'widely', 'wide', 'whole.', 'white', 'whisperer', 'wheat.', 'whales', 'whale.', 'well.', 'well-timed', 'well-known', 'well-formed', 'well-being', 'well', 'ways.', 'ways', 'way.', 'waves,', 'wavelength', 'wave,', 'water?', 'water,', 'waste,', 'want', 'w', 'vowel', 'volume', 'voltage', 'vocabulary', 'vital', 'visit', 'viscous', 'viruses,', 'virtues.', 'virtue.', 'views.', 'view', 'videogame?', 'video.', 'vibrations', 'vibrational', 'vibrant', 'vessels.', 'vessels,', 'vessels', 'vertices,', 'vertebral', 'versatile', 'verb,', 'ventilation', 'velocity', 'veins', 'vehicles', 'variety', 'variation,', 'variable.', 'vapor.', 'value.', 'vaccines', 'vaccine', 'v', 'utterance', 'urine', 'urinary', 'urethra.', 'ureters,', 'urban', 'unstable', 'unsolved', 'unpredictable', 'unprecedented', 'unpleasant', 'universes', 'units', 'uniquely', 'uniform', 'unethical', 'understood', 'understanding,', 'underlies', 'undergoing', 'uncover', 'uncharged', 'uncertainty', 'unauthenticated.', 'ulna', 'u', 'types', 'two-level', 'turn', 'tunneling.', 'tunneling', 'trying', 'truths.', 'trope', 'triangle,', 'trials', 'tree', 'treats', 'treating', 'treated.', 'traveled', 'travel.', 'transverse', 'transparency,', 'transmits', 'transmit', 'transmission', 'translation', 'transition', 'transforming', 'transformed', 'transformations.', 'transformations', 'transformation.', 'transfer', 'transactions.', 'training', 'traditions,', 'traditions', 'trachea,', 'torque', 'topic,', 'tools', 'too,', 'too', 'tomorrow', 'tomography', 'together.', 'together,', 'today.', 'tissues,', 'tiny', 'timing,', 'timeless', 'time.You:', 'tibia,', 'thyroid,', 'threat', 'thread-like', 'thoughts.', 'thoughtful', 'thoracic', 'things', \"they're\", 'these', 'thesaurus', 'thermal,', 'therefore', 'there', 'theorems.', 'then', 'them.', 'texts.', 'text', 'testosterone.', 'testing', 'testes,', 'testes', 'terrible', 'terms', 'temporary', 'temporal', 'temperatures', 'temperature.', 'teleportation', 'telecommunication', 'technologies.', 'technologies', 'teamwork', 'tasks', 'task.', 'task', 'tale', 'taking', 'takes', 'take.', 't', 'systematic', \"system's\", 'synthesis', 'syntax', 'syntactic', 'symbols.', 'symbols', 'syllables', 'syllable', 'sword,', 'sword', 'swelling,', 'sustainable', 'sustainability', 'surprise', 'surgery.', 'surgeon', 'surfaces,', 'sure.', 'supremacy', 'superpose', 'supernatural', 'sunlight,', 'sugar', 'sufficient', 'suddenly', 'subsystems', 'substituted', 'substances', 'substance', 'subjective', 'subjected', 'subject', 'style,', 'strongest', 'strive', 'strings.', 'stretched', 'stress.', 'stress,', 'strategic', 'straight', 'storytelling.', 'stories,', 'stomach,', 'stethoscope', 'step-by-step', 'statistical', 'statement.', 'state.', 'stands', 'squares', 'squared', 'square', 'spread', 'sport', 'spontaneously', 'spontaneous', 'splitting', 'split', 'spine,', 'spin', 'sperm', 'spent', 'spelling', 'speed.', 'species', 'specialist', 'speaks', 'speakers.', \"speakers'\", 'spawns', 'spatial', 'spaghetti?', 'spaces.', 'spaces,', 'space,', 'sources.', 'sources', 'source.', 'sounds.', 'sounds,', 'sorry,', \"someone's\", 'someone', 'solving', 'solution', 'soliloquy', 'solids.', 'solid', 'smooth', 'sleep', 'skull', 'skills.', 'skills', 'skilled', 'situations.', 'site', 'simplified', 'simile', 'similarity', 'significance', 'sides.', 'shuffling', 'should', 'shock', 'shift', 'share', 'shaping', 'shapes', 'sex,', 'sex', 'severe', 'several', 'setting.', 'sets,', 'sequencing', 'sequences.', 'sequences', 'sequence.', 'sentences,', 'sentences', 'sensory,', 'sensors.', 'sensors,', 'sense,', 'semiconductor', 'self-written', 'self-cultivation', 'segregation', 'segments', 'seemingly', 'second,', 'second)', 'sebum,', 'screening', 'science,', 'school', 'scenarios.', 'scans', 'scale.', 'scale', 'scalar', 'sayings', 'saying', 'saving', 'samples,', 'said', 'safety', 's', 'rule', 'rows', 'rooted', 'robust', 'risk.', 'risk,', 'rise', 'rightness', 'right-angled', 'ridicule', 'ribosomes', 'ribonucleic', 'rib', 'rhythmic', 'rhythm,', 'rhythm', 'rewarding.', 'revolutionize', 'revolutionary', 'reveals', 'revealing', 'return', 'resuscitation', 'resulting', 'resultant', 'result.', 'restoring', 'restore', 'response', 'respond', 'respectively.', 'resource', 'resonance', 'resolving', 'resistance', 'researcher', 'rescue.', 'request', 'repulsion', 'reproduce.', 'reproduce', 'representing', 'represented', 'representations', 'rendering', 'removing,', 'removes', 'remotely.', 'remember', 'remarkable', 'religious', 'relieve', 'release', 'relaxing', 'relaxes', 'relativistic', 'relativism', 'relations', 'regulation.', 'regulation', 'register', 'regional', 'regardless', 'reflective', 'reflect', 'reference.', 'reference', 'refer', 'reduced-scale', 'reduce', 'redness,', 'redefine', 'red?', 'red.', 'recurring', 'rectangular', 'recovered', 'recover,', 'recover', 'record', 'reconcile', 'recombination.', 'recombination', 'recognizing', 'recognize', 'recessive.', 'recessive,', 'reasoning,', 'reasoning', 'realized', 'realization', 'real-world', 'real-life', 'reading,', 'reactions.', 'reaction.', 'reaction', 'ratio', 'rather', 'rate', 'rare', 'range', 'randomness', 'randomly', 'raised', 'radius,', 'radio', 'radiation,', 'radiation', 'r', 'quotient', 'quick', 'questions', 'question', 'qubits', 'qubit', 'quarks', 'quantity,', 'qualities.', 'q', 'purpose', 'puppy', 'pumps', 'psychological', 'providing', 'provided', 'proverbs', 'proverb', 'prove', 'protons.', 'protons', 'protein', 'protection', 'protagonist.', 'protagonist', 'proposes', 'property', 'properties,', 'propagates', 'pronouns', 'pronouncing', 'promotion', 'promising', 'prokaryotic', 'projectiles', 'progress', 'programs.', 'programming', 'progesterone.', 'profound', 'professional', 'profession', 'productivity.', 'product,', 'producing', 'processing.', 'processing', 'processes', 'process.', 'procedures.', 'problems', 'problem', 'privacy.', 'privacy,', 'prior', 'printing', 'principle.', 'prevention.', 'prevention', 'prevailing', 'pressure', 'preserved', 'presentation', 'present', 'presence', 'prescribes', 'pregnancy,', 'predictions', 'predicting', 'predicted', 'predict', 'precision', 'precise', 'preceding', 'powers', 'power', 'potential.', 'potential,', 'potato', 'postulate', 'postpartum', 'possibility', 'positions', 'positing', 'poses', 'populations,', 'popularly', 'popular', 'polynomial', 'polymerase', 'policy-making,', 'polar', 'points', 'poem', 'plot', 'pleasant', 'plays', 'play', 'platforms', 'plates', 'plants.', 'plants', 'planets.', 'plane', 'place,', 'pivot', 'pithy', 'pidgin', 'physics.', 'physician', 'phrases,', 'phrase.', 'photosynthesis', 'photons,', 'phonemic', 'phonemes', 'phoneme.', 'phoneme,', 'philosophy,', 'philosophies', 'philosopher,', 'phenomenon.', 'phenomenon,', 'phenomena.', 'phase', 'persuasive', 'persuade,', 'perspectives.', 'perspectives', 'perspective', 'personality', \"person's\", 'peroxide?', 'peroxide', 'permutation', 'permissible', 'permeate', 'peripheral', 'period.', 'performing', 'performed', 'perfectly', 'perception', 'people.', 'pen', 'pelvis', 'pedigree', 'peculiar', 'pea', 'pay', 'pattern', \"patient's\", 'patience,', 'paths', 'pathogen', 'path', 'pasta', 'passing', 'passed', 'pass', 'parts.', 'parts,', 'parts', 'parties.', 'particles,', 'particle.', 'part.', 'parody', 'parent-of-origin-specific', 'parent', 'pancreas,', 'pancreas', 'p', 'oxygenation', 'oxygen-rich', 'oxygen-poor', 'oxygen', 'overcomes', 'overall', 'ovaries,', 'ovaries', 'outputs.', 'outperform', 'outcomes.', 'outcome.', 'others', 'ostoyae,', 'oscillatory', 'oscillations', 'oscillates', 'origins', 'originated.', 'originality', 'origin.', 'origin,', 'origin', 'orientation', 'organs.', 'organs,', 'organisms.', 'organisms', 'ordinary', 'ordered', 'order.', 'optimization', 'optics', 'opposites', 'openings,', 'opening', 'open', 'online', 'ones.', 'one.', 'one-dimensional', 'one,', 'older', 'oily', 'offspring', 'occurs.', 'occurrence', 'occupy', 'occasional', 'obstetrician', 'obstacles', 'observed.', 'observed', 'observations.', 'observable', 'object,', \"object's\", 'o', 'nutrient', 'nurture', 'nurse', 'numerous', 'numbers.Model:', 'number,', 'nucleus,', 'nucleotide,', 'nucleic', 'nuclei,', 'nuclear', 'notions', 'nothing,', 'norms', 'non-terminating.', 'non-repeating', 'non-negative', 'non-human', 'nodes.', 'nodes,', 'node', 'no.', 'nitrogen,', 'newspaper,', 'newly', 'new,', 'neutrons', 'neutralize', 'neutral', 'neurons,', 'neural', 'networks', 'nerves.', 'nerve', 'neologism', 'negotiation', 'negatively', 'needed', 'nearby', 'navigate', 'nanoscale', 'names?', 'named.', 'nails.', 'n', 'myth', 'my', 'mutations', 'mutation,', 'must', 'mushroom,', 'muscles.', 'muscles', 'muscle,', 'muscle', 'multiverse', 'multiplied', 'multiplayer', 'much', 'mouth.', 'mouth,', 'motor,', 'motif', 'mosaic', 'morpheme', \"morality'.\", \"morality'\", 'monologue', 'moment.', 'molecules.', 'molecule,', 'molecule', 'modification', 'modeling', 'model.', 'mode', 'mobility.', 'mixing', 'minimum.', 'minimum', 'minimal', 'mind', 'milk', 'miles', 'mild', 'mightier', 'middle', 'microscope.', 'microorganisms.', 'microorganism', 'microbial', 'metrical', 'metabolism,', 'messengers', 'messenger', 'messages.', 'mentioned', 'mental', 'memoir', 'meiosis', 'medium.', 'median', 'media,', 'media', 'mechanisms', 'mechanism', 'measurements', 'measurement', 'measured.', 'measure', 'meant', 'meaningful', 'mc^2.', 'may', 'maximizes', 'maxim', 'matrix', 'matrices', 'maternally', 'maternal', 'materials.', 'master', 'mask', 'market.', 'marker', 'marine', 'mapped', 'map', 'manipulating', 'manifestations', 'male.', 'main', 'magnitude', 'magnetism,', 'magical', 'magazine,', 'machinery,', 'machinery', 'ma).', 'mRNA', 'm', 'lymph', 'lush', 'lungs,', 'lunch,', 'lubricates', 'loyal', 'lower,', 'low', 'louder', 'lost', 'loses', 'longer', 'logical', 'logarithm', 'location,', 'located?', 'locally', 'local', 'loanword', 'lives.', 'lives', 'liver.', 'liver,', 'liver', 'literature.', 'literature,', 'literally.', 'lists', 'listening', 'listen', 'liquids', 'liquid,', 'linkage', 'linguistics.', 'linguist', 'lingua', 'lines.', 'lineage.', 'line,', 'limits', 'lighter', 'ligaments.', 'lifetime', \"life's\", 'lies', 'lexicon', 'lexical', 'lexeme', 'leveraging', 'leverages', 'letter.', 'lens', 'leisurely', 'legendary', 'leg.', 'led', 'learning,', 'leadership', 'lazy', 'lay', 'later.', 'later', 'late', 'large-scale', 'language,', 'l', 'knack', 'kittens.', 'kittens', 'kinetic,', 'killed', 'kidneys,', 'k', 'juxtaposition', 'justice.', 'justice,', 'jumps', 'judgments.', 'judges', 'judge', 'journal.', 'journal', 'job!', 'j', 'items', 'it?', 'it,', 'issues,', 'is.', 'irregular', 'irony,', 'ions.', 'ionized', 'intuitive', 'introducing,', 'introducing', 'introduces', 'introduced', 'intrinsic', 'intricate', 'intonation', 'intimate', 'intestines,', 'interventions.', 'intersecting', 'interpretation,', 'interneurons.', 'internet,', 'intermediate', 'interface', 'interests.', 'interesting.', 'interest', 'interconnectedness', 'interacts', 'interaction.', 'interaction,', 'intelligence.', 'intellectual', 'integumentary', 'integrity.', 'integrity', 'integrals.', 'integers;', 'integers.', 'integers', 'insurmountable', 'insurance,', 'insulin', 'instrument', 'instructions', 'instead', 'instantly', 'insights.', 'inside', 'inquiry', 'inputs', 'input', 'innovation.', 'innovate', 'injuries.', 'injured', 'initiatives', 'inherent', 'informed', 'information,', 'informal', 'inform,', 'inform', 'influences', 'infinitesimal', 'infectious', 'infections', 'infection,', 'infeasible', 'infants,', 'inertial', 'inertia', 'induced', 'individuals.', \"individuals'\", \"individual's\", 'indistinguishable', 'indirect', 'indication', 'indicates', 'independent', 'independence.', 'increases', 'incorporates', 'incorporated', 'incident', 'impulses', 'improving', 'imprinting', 'important', 'implied', 'implicit', 'implicature', 'implications', 'imperative.', 'impact.', 'impact', 'immunity', 'immersive', 'immediate', 'imitation', 'imaginative', 'illustrating', 'illnesses.', 'illnesses', 'ill.', \"ignorance'\", 'idiom', 'idiolect', 'identifying', 'identify', 'identical', 'ice', 'i', 'hypotenuse', 'hydrogen?', 'humor,', 'humility,', 'humerus,', 'hormones.', 'hormone', 'honey', 'homozygotes.', 'homologous', 'hole', 'holds', 'history.', 'hint', 'hinge,', 'higher-order', 'higher', 'high-frequency', 'hi', 'heterozygote', 'heritage', 'heritable', 'heredity', 'hereditary', 'hemoglobin', 'helix', 'heavy', 'heavier', 'heartfelt', 'hatch,', 'harsh', 'harnesses', 'harmful', 'happiness.', 'handle', 'hand,', 'hand', 'hair.', 'hair,', 'habitual', 'habits', 'h', 'gynecologist', 'growth,', 'growing', 'grow', 'grouped', 'group', 'greener', 'greater,', 'gravity.', 'gravity)', 'gravitation,', 'grapheme', 'graph.', 'graph', 'grammar.', 'governing', 'govern', 'good.', 'golems,', 'gods', 'gluons.', 'glucose', 'glands.', 'gland', 'gives', 'gets', 'genotype', 'genomes', 'genome.', 'genome,', 'genome', 'genetics,', 'genetics', 'genes.', 'generative', 'generations.', 'generate', 'generally', 'gene.', 'gene-editing', 'gene,', 'gases.', 'gases,', 'games', 'game', 'g', 'future?', 'future.', 'fungus', 'fungi.', 'fruit', 'frontiers', 'fries?', 'frequently', 'frequent', 'frequency.', 'franca', 'frameworks', 'framework', 'frame', 'fox', 'four', 'foundation', 'found', 'formulation', 'formed', 'form,', 'foreign', 'forces.', 'force,', 'food', 'fonder,', 'follow', 'focusing', 'flux', 'fluids', 'fluid.', \"fluid's\", 'fluently.', 'fluctuations.', 'fluctuations', 'flows', 'flock', 'flexibility.', 'flaws', 'fix', 'fishing.', 'fishing', 'fish?', 'fish', 'first', 'finite', 'financial', 'finance,', 'figure.', 'figurative', 'fifth', 'fields,', 'fibula', 'fever.', 'fence,', 'femur,', 'feeding', 'feces.', 'featuring', 'features.', 'features', 'feature', 'feats', 'feather', 'favorite', 'fault-tolerant', 'fats,', 'fate', 'fastest', 'fantastical', 'famously', 'family.', 'family,', 'families', 'false,', 'falling', 'fairy', 'fairness,', 'fairness', 'fairies,', 'fair', 'factors', 'factorized', 'facilitates', 'facilitate', 'face.', 'fable', 'f', 'extinction.', 'extended', 'expressive', 'expressed,', 'expose', 'exponents.', 'exponent', 'exploring', 'explores', 'exploiting', 'explanation', 'explaining', 'experiment', 'experiences.', 'experiences,', 'experience.', 'exotic', 'exoplanets', 'existing', 'existentialist', 'existential', 'existence', 'exist.', 'exerted', 'exercises', 'excreted', 'excitations', 'exchange.', 'example.', 'exaggeration', 'exaggerated', 'exact', 'evolution.', 'evolution,', 'evoke', 'evil,', 'evil', 'evidence', 'eventual', 'events;', 'event.', 'even', 'euphemism', 'eukaryotic.', 'ethic', 'estrogen', 'establishes', 'essence', 'essay', 'esophagus,', 'equivalence', 'equine', 'equilibrium', 'equations,', 'epithelial,', 'epigenetic', 'epic', 'enzymes', 'environment', 'entity', 'entities', 'entire', 'entertainment', 'entertain', 'enhances', 'engage', 'enduring', 'end', 'encrypt', 'encountered', 'encompasses', 'encapsulate', 'emphasizes', 'emphasize', 'emphasis', 'empathy.', 'emotions', 'emit,', 'emergency', 'else', 'eloquent', 'electronics.', 'electronic', 'electron', 'electrolytes', 'electrodynamics', 'electrocardiogram', 'electricity,', 'electrically', 'eigenvector', 'eigenvalue', 'eggs', 'efforts', 'efficiently', 'efficient', 'effects.', 'effectiveness', 'effective', 'education.', 'education,', 'editing', 'edges.', 'ecosystems', 'eat', 'earned,', 'earlier', 'e', 'dysphemism', 'dynamics', 'duty', 'durum', 'drugs', 'drowning', 'drink,', 'drift', 'dread', 'dragons', 'down', 'doubts', 'double-slit', 'double', 'dots', 'done', 'dominance', 'dolphins.', 'doing?', 'dogs?', 'dogs', 'dogma', 'dog.', 'documents', 'doctors', 'do?', 'do,', 'divisors', 'division.', 'divided', 'distributions.', 'distribution.', 'distributed.', 'distinguished', 'distinctive', 'distinct', 'distance.', \"distance'.\", 'distance', 'disproven.', 'display', 'displacement.', 'displacement', 'disorders.', 'disorder.', 'dish', 'disease,', 'discussion.', 'discovery', 'direction.', 'dilemmas.', 'dilemmas', 'digitization', 'digital', 'differences.', 'differ', 'die', \"didn't\", 'dictionaries.', 'diary', 'diaphragm', 'dialects', 'dialect', 'diagnoses', 'devoted', 'devices', 'develop,', 'develop', 'detoxifies', 'detailing', 'destroyed,', 'dessert', 'designed', 'description', 'described', 'derogatory', 'derived', 'derivatives.', 'derivative', 'dependencies.', 'deoxyribonucleic', 'dentist', 'denoted', 'delivers', 'delivered', 'delicious', 'deliberate', 'degree', 'defibrillator', 'defends', 'defend', 'deeds', 'decrypt', 'decomposes', 'decoherence', 'decoded', 'decisions', 'decision-makers.', 'decimal', 'debated.', 'debated', 'damage.', 'damage', 'd', 'cutting-edge', 'cute?', 'cute,', 'cute', 'customs,', 'cushioning', 'curve.', 'curvature', 'currents,', 'cup', 'cultures', 'culturally', 'cultural', 'cultivation', 'cryptography', 'criticize', 'critically', 'crispy.', 'creole', 'creativity', 'creation', 'creates', 'created', 'cream?', 'cream.', 'cream', 'covers', 'covering', 'cover,', 'cover', 'courses', 'countless', 'count', 'counseling', 'cosmological', 'cortisol', 'corresponding', 'corpus', 'cord,', 'copy', 'copied', 'coordinates', 'convince', 'conveys', 'convert', 'conversational', 'conversation.', 'conventional', 'controls', 'contributing', 'contributed', 'contribute', 'contrast.', 'contracting', 'continuum', 'continue', 'contextual', 'contexts', 'context', 'consultation', 'constraints.', 'consists', 'considers', 'conservation,', 'consequences.', 'consciousness.', 'connects', 'connective,', 'connections', 'conjecture', 'conflicts.', 'conducts', 'conductor', 'conductive', 'conductance.', 'conduct.', 'conduct', 'condition.', 'concise', 'computers.', 'computers', 'computer.', 'computations.', 'computations', 'computational', 'computation.', 'compressions', 'compressed', 'complementarity', 'compiling', 'competitive', 'competing', 'compassion', 'community,', 'community', 'communities.', 'communication,', 'communicate', 'commitment', 'command.', 'comic', 'comes', 'come', 'combines', 'combine', 'combinations', 'combination', 'columns.', 'column,', 'collections', 'collection,', 'coined', 'coherent', 'cognition.', 'coffee', 'coexistence', 'coefficients,', 'codominance,', 'clownfish.', 'closed', 'clean', 'classified', 'claimed', 'circulatory', 'circulates', 'chromosomes,', 'chromosomes', 'chromodynamics', 'choice.', 'children,', 'childbirth,', 'chest', 'chemistry,', 'chart', 'charges,', 'charged,', 'characters.', 'characterizes', 'characterized', 'characteristics.', 'characteristics', 'characteristic', 'character,', 'chaotic,', 'channels.', 'change,', 'chance.', 'challenging', 'challenges.', 'challenged', 'challenge', 'cerebrum,', 'cerebellum,', 'center', 'cell,', 'cats?', 'cats.You:', 'cats.', 'cats!', 'categorical', 'catches', 'cat,', 'cat', 'cases', 'carve', 'cartilage,', 'carries', 'carried', 'cardiovascular', 'carbon?', 'captured', 'capacity', 'capabilities', 'cannot.', 'cancer.', 'calque', 'cage', 'bx', 'butterfly', 'bush,', 'bush', 'built', 'building', 'brown', 'bronchi.', 'broke,', 'broad', 'bringing', 'bring', 'brief', 'breathing', 'breath', 'breakthroughs', 'breaks', 'breakfast.', 'brainstem.', 'brain.', 'brain,', 'bound', 'bosons.', 'boson', 'borrowed', 'books', 'book', 'bones,', 'bonds', 'blunt.', 'bladder,', 'bits', 'bit', 'birth', 'birds', 'biopsy', 'binomial.', 'binomial', 'binds', 'bile,', 'bicarbonate?', 'bicarbonate', 'better', 'benefits', 'benefit', 'bending', 'belonging', 'beliefs.', 'beliefs,', 'beliefs', 'begun', 'begins', 'before', 'because', 'beautifully', 'base', 'barriers', 'banana,', 'ball-and-socket,', 'balancing', 'balance', 'bake', 'bacterial', 'bacteria,', 'bacteria', 'baby', 'b', 'axioms', 'axiom', 'axes.', 'ax^2', 'away', 'awareness.', 'average', 'available', 'autosomes', 'autonomous', 'autobiography', \"author's\", 'author', 'attribution', 'attracts', 'attractive', 'attract', 'attempts', 'atoms', 'atom.', 'atom', 'atmosphere', 'astronomical', 'assortment.', 'assists', 'arts', 'artist,', 'articulated', 'article', 'art.', 'arrow,', 'arrhythmias', 'array', 'arranged', 'arm.', 'arithmetic', 'argument', 'argued', 'argon,', 'area.', 'architectures.', 'approach.', 'applies', 'applications,', 'applications', 'application', 'appears', 'appearance', 'aphorism', 'anyons,', 'antimatter.', 'antibodies.', 'antagonist', 'annealing', 'animals.', 'animals', 'anesthesiologist', 'anesthesia', 'anemia', 'analyzing', 'analytical', 'analysis,', 'analyses', 'analogous', 'amplitude.', 'amplify', 'among', 'alters', 'alternatives.', 'alternative', 'alternating', 'altering', 'aloud,', 'alone', 'allow', 'allergic', 'alleles.', 'allegory', 'algorithm', 'algebraic', 'air', \"ain't\", 'aids', 'agriculture', 'afraid', 'affairs,', 'aesthetic', 'advocates', 'advises', 'advice.', 'adventures', 'advantageous', 'advance', 'adults.', 'adrenaline', 'adorable', 'adopted', 'adolescents.', 'administration', 'administering', 'adhering', 'addresses', 'address', 'additional', 'actually', 'acts', 'actors', 'activity', 'activities', 'actions.', 'action.', 'action-adventure', 'action,', 'acted', 'acres', 'acquisition', 'acquired.', 'acid', 'achieved', 'achieve', 'accountability.', 'accordance', 'accomplishing', 'accepting', 'accent', 'accelerated', 'absorb,', 'absence', 'Zeno', 'Zelda.', 'Zelda,', 'Y,', 'XY', 'XX', 'X-rays', 'X,', 'Work', 'Word', 'William', 'Why', 'White', 'Where', 'When', 'Werner', 'We', 'Wave-particle', 'Watson', 'Water', 'Washington', 'W,', 'W', 'Virtue', 'Virtual', 'Valorant?', 'Valorant.', 'Vaccines', 'Vaccination', 'V,', 'V', 'Utilitarianism,', 'United', 'Uncertainty', 'Ultrasound', 'USA?', 'USA', 'U,', 'U', 'Turbulence', 'Transformational', 'Transcription', 'Topology', 'Topological', 'Tone', 'Tissues', 'Time', 'Things', 'These', 'Thermodynamics', \"There's\", 'There', 'Theorems', 'Theorem', 'Text', 'Tendons', 'Telemedicine', 'Taoism', 'T,', 'T', 'Systems', 'Synonyms', 'Sweat', 'Supersymmetry', 'Superconductivity', 'Stylistics', 'Stuart', 'String', 'Stress', 'Stoicism,', 'Sterilization', 'Statistics', 'Statistical', 'States.', 'Special', 'Spanish,', 'Spaghetti', 'Socrates', 'Sociolinguistics', 'Social', 'Slang', 'Sickle', 'Set', 'Semantics', 'Sebaceous', 'Science', 'Schweitzer', 'Satire', 'Sartre,', 'Sapir-Whorf', 'S,', 'S', 'Rule,', 'Rome,', 'Romans', 'Riot', 'Riemann', 'Richard', 'Rhetorical', 'Rhetoric', 'Revitalization', 'Resonance', 'Research', 'Renewable', 'Refraction', 'Reflection', \"Rawls'\", 'Rawls', 'Radiology', 'Radioactivity', 'Rabi', 'RNA,', 'R,', 'R', 'Q,', 'Q', 'Pythagorean', 'Psycholinguistics', 'Psychiatry', 'Proverbs,', 'Proteomics', 'Prosody', 'Prose', 'Project,', 'Probability', 'Preventive', 'Prescriptive', 'Pragmatism,', 'Pragmatics', 'Population', 'Polysemy', 'Polygenic', 'Polarization', 'Poetry', 'Plato', 'Plasma', \"Planck's\", 'Planck', 'Physics', 'Physical', 'Photosynthesis', 'Photons', 'Phonology', 'Phonological', 'Phonetics', 'Philosophy', 'Pharmacology', 'Personification', 'Pediatrics', 'Pauli', 'Paul', 'Particle', 'Paris.', 'Paris,', 'P,', 'P', 'Orthography', 'Organs', \"Oregon's\", 'Oratory', 'Optics', 'Operations', 'Onomatopoeia', 'Oncology', \"Ohm's\", 'Occupational', 'O,', 'O', 'Number', 'Nuclear', 'Non-Euclidean', 'No.', 'Nintendo.', 'Nintendo', 'Nietzsche', 'Niels', 'Newtonian', 'Newton', 'Neurons', 'Neurology', 'Nephrons', 'Navier-Stokes', 'Nanotechnology', 'NaHCO3.', 'NLP.', 'NLP,', 'N,', 'N', 'Mutations', 'Mountains.', 'Morphology', 'Momentum', 'Modern', 'Mitochondrial', 'Mill,', 'Midna,', 'Metagenomics', 'Mendelian', 'Mendel,', \"Mendel's\", 'Medical', 'Maxwell', 'Max', 'Mathematics', 'Martin', 'Mars', 'Many-Worlds', 'Many', 'Mahatma', 'Magnetic', 'Machine', 'M,', 'M', 'Luther', 'Literary', 'Link?', 'Link,', 'Link', 'Linguistics', 'Linear', 'Ligaments', \"Life',\", 'Lexicography', \"Lenz's\", 'Laozi', 'Lama', 'L,', 'L', 'King', 'Kant,', 'Kant', 'K,', 'K', \"Justice'\", 'Jr.', 'Joints', 'Jeremy', 'Jean-Paul', 'Jargon', 'J,', 'J', 'It', 'Isaac', 'Irony', 'Intonation', 'Internet', 'Interference', 'Intelligence.', 'Inflammation', 'Infinity', 'Indo-European', 'Incomplete', 'Immanuel', 'If', 'Ice', 'I,', 'Hypothesis', 'Hyperbole', 'Humans', 'Human', 'Hormones', 'Homozygous', 'Homophones', 'Homeostasis', 'Historical', 'Hindi.', 'Higgs', 'Hellenistic', 'Harmonic', 'Hardy-Weinberg', 'Hannah', 'H2O.', 'H,', 'Gregor', 'Grammar', 'Golden', 'Geriatrics', 'Geometry', 'Genome', 'Genetics', 'Genes', 'Generative', 'Gene-environment', 'Gemma?', 'Gemma', 'Gaussian', 'Ganondorf?', 'Ganondorf,', 'Ganondorf', 'Gandhi', 'Games.', 'Game', 'G,', 'G', 'Fusion', 'Functional', 'Friedrich', 'Francis', 'France?', 'France.', 'France', 'Fractals', 'Fourier', 'Foreshadowing', 'Folklore', 'Fluid', 'Fission', 'Fishing', 'First', 'Fibonacci', \"Feynman's\", \"Faraday's\", 'F,', 'F', 'Exclusion', 'Even', 'Etymology', 'Epona,', 'Epigenetics', 'Epidemiology', 'Entropy', 'Entanglement', 'English,', 'Energy', 'Elements', 'Electromagnetism', 'Eastern', 'Earth.', \"Earth's\", 'Earth', 'Each', 'EKG)', 'E,', 'Drama', 'Doppler', \"Don't\", 'Dominant', 'Dogs', 'Discourse', 'Dirac,', 'Dirac', 'Diglossia', 'Diffraction', 'Differential', 'Dialogue', 'Dialectology', 'Dewey,', 'Descriptive', 'Deontological', 'Deixis', 'Dalai', 'DNA.', 'DNA,', 'D.C.', 'D,', 'D', 'Cybersecurity', 'Curiosity', 'Cryptography', 'Crick', 'Creative', 'Creating', \"Coulomb's\", 'Cosmology', 'Copenhagen', 'Conversational', 'Contemporary', 'Consonance', 'Consequentialism,', 'Confucius', 'Computer', 'Computed', 'Complexity', 'Combinatorics', 'Collocation', 'Code-switching', 'Climate', 'Cliché', 'Clerk', 'Classical', 'Chromosomes', 'Characterization', 'Casimir', 'Case', 'Cartilage', 'Carrier', 'Cardiopulmonary', 'Cardiology', 'Capillaries', 'Can', 'Calculus', 'CRISPR-Cas9', 'C6H12O6.', 'C,', 'Building', 'Buddhism', 'Boolean', 'Book', \"Bohr's\", 'Blue', 'Blood', 'Blockchain', 'Birds', 'Bilingualism', 'Big', \"Bernoulli's\", 'Bentham', \"Bell's\", \"Bayes'\", 'Bang', 'B,', 'B', 'Axiom', 'Augmented', 'Assonance', 'Arteries', 'Armillaria', 'Arithmetic', 'Aristotle,', 'Arendt', 'Antonyms', 'Antipyretics', 'Antihistamines', 'Antibodies', 'Antibiotics', 'Anatomy', 'Anatomical', 'Anaphora', 'Analgesics', 'Ambiguity', 'Allophones', 'Alliteration', 'Algebra', 'Actuarial', 'Actions', 'Acoustics', 'Absence', 'A,', '9', '8', '78%', '7', '6', '5', '4', '3D', '3', '23', '22', '21%', '2012,', '2003,', '20', '2,000', '2', '1953.', '1915,', '1905,', '100', '1.618,', '1,', '0.9%', '0.', '0,', '(mtDNA)', '(mRNA).', '(except', '(QKD)', '(QED),', '(QCD)', '(PCR)', '(MRI)', '(F', '(ECG', '(CT)', '(CPR)', '(186,282', \"'veil\", \"'spooky\", \"'slave\", \"'master\", \"'like'\", \"'freezing'\", \"'as'.\", \"'Theory\", \"'Reverence\"]\n"
          ]
        }
      ],
      "source": [
        "class Lookup():\n",
        "    def __init__(self):\n",
        "        super(Lookup, self).__init__()\n",
        "        self.lookup_layer = None\n",
        "        self.vocabulary = []\n",
        "        if self.vocabulary not in mem.semantic_memory:\n",
        "            mem.semantic_memory += self.vocabulary\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.lookup_layer is None:\n",
        "            raise ValueError(\"Lookup layer not created. Call create_lookup_layer first.\")\n",
        "        return self.lookup_layer(inputs)\n",
        "\n",
        "    def flattened_tokens(self, corpus):\n",
        "        # Tokenize the documents\n",
        "        tokenized_documents = tf.strings.split(corpus)\n",
        "        # Flatten the resulting RaggedTensor to a 1D tensor of words\n",
        "        return tokenized_documents.flat_values\n",
        "\n",
        "    def create_lookup_layer(self):\n",
        "        # Create the StringLookup layer\n",
        "        self.lookup_layer = tf.keras.layers.StringLookup()\n",
        "        return self.lookup_layer\n",
        "\n",
        "    def add_tokens_to_vocab(self, tokenized_documents):\n",
        "        # Update the vocabulary with tokens\n",
        "        for token in tokenized_documents:\n",
        "            if token not in self.vocabulary:\n",
        "                self.vocabulary.append(token)\n",
        "\n",
        "    def adapt(self, tokens):\n",
        "        # Check if the lookup layer has been created\n",
        "        if self.lookup_layer is None:\n",
        "            raise ValueError(\"Lookup layer not created. Call create_lookup_layer first.\")\n",
        "        # Adapt the lookup layer to the flattened list of tokens\n",
        "        self.lookup_layer.adapt(tokens)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        # Check if the lookup layer has been adapted\n",
        "        if self.lookup_layer is None:\n",
        "            raise ValueError(\"Lookup layer not created or adapted. Call create_lookup_layer and adapt first.\")\n",
        "        # Retrieve the vocabulary\n",
        "        return self.lookup_layer.get_vocabulary()\n",
        "\n",
        "    def lookup_string(lookup_layer, input_string):\n",
        "        \"\"\"Looks up a string in a StringLookup layer and returns its corresponding index (or OOV index).\n",
        "\n",
        "        Args:\n",
        "            lookup_layer: The trained Keras StringLookup layer.\n",
        "            input_string: The string you want to look up.\n",
        "\n",
        "        Returns:\n",
        "            The integer index of the string in the vocabulary, or the OOV index if the string is not found.\n",
        "        \"\"\"\n",
        "        input_tensor = tf.constant([input_string])\n",
        "        output_tensor = lookup_layer(input_tensor)\n",
        "        index = int(output_tensor.numpy()[0])  # Convert tensor to integer\n",
        "\n",
        "        if index == lookup_layer.vocabulary_size():  # Check for OOV index\n",
        "            return lookup_layer.oov_token  # Or a custom OOV indicator\n",
        "        else:\n",
        "            return index\n",
        "\n",
        "\n",
        "lookup = Lookup()\n",
        "\n",
        "# Flatten tokens\n",
        "tokens = lookup.flattened_tokens(corpus)\n",
        "\n",
        "# Create and adapt lookup layer\n",
        "lookup.create_lookup_layer()\n",
        "lookup.adapt(tokens)\n",
        "\n",
        "# Update vocabulary\n",
        "lookup.add_tokens_to_vocab(tokens)\n",
        "\n",
        "# Retrieve vocabulary\n",
        "vocab += lookup.get_vocab()\n",
        "#semantic_memory += vocab\n",
        "print(\"Vocabulary:\", vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3JoduNW5f2N",
        "outputId": "f07508db-1684-48d2-b5f8-af9f53c7d4e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['[UNK]', 'the', 'of', 'is', 'a', 'and', 'to', 'that', 'in', 'The', 'or', 'A', 'for', 'are', 'as', 'Model:', 'quantum', 'can', 'by', 'with', 'You:', 'an', 'which', 'on', 'from', 'be', 'system', 'branch', 'about', 'What', 'genetic', 'used', 'states', 'language', 'study', 'between', 'studies', 'one', 'but', 'two', 'such', 'their', 'have', 'its', 'it', 'An', 'like', 'theory', 'describes', 'body', 'all', 'Quantum', 'through', 'often', 'particles', 'chemical', 'process', 'number', 'more', 'models', 'mathematical', 'has', 'you', 'wisdom', 'than', 'other', 'not', 'law', 'human', 'ethical', 'at', 'I', 'structure', 'largest', 'into', 'how', 'blood', 'also', 'Hypergraphs', 'specific', 'over', 'medical', 'fundamental', 'different', 'who', 'speech', 'mechanics', 'mass', 'languages', 'language.', 'information', 'form', 'energy', 'data', 'common', 'change', 'DNA', 'word', 'where', 'universe', 'produce', 'physics', 'our', 'moral', 'medicine', 'light', 'known', 'know', 'involves', 'includes', 'hypergraphs', 'formula', 'field', 'both', 'words', 'use', 'state', 'particular', 'object', 'motion', 'most', 'deals', 'complex', 'behavior', 'when', 'uses', 'unit', 'set', 'particle', 'new', 'meaning.', 'knowledge', 'equation', 'changes', 'body.', 'another', 'words.', 'wave', 'statement', 'provides', 'properties', 'only', 'occurs', 'numbers', 'mathematics', 'magnetic', 'including', 'function', 'force', 'energy.', 'development', 'describe', 'concept', 'classical', 'character', 'based', 'Wisdom', 'In', \"I'm\", 'written', 'work', 'without', 'within', 'universe.', 'traditional', 'tool', 'thinking', 'systems', 'story', 'sound', 'sequence', 'same', 'relationships.', 'refers', 'principle', 'powerful', 'perform', 'no', 'nature', 'natural', 'momentum', 'meaning', 'life', 'hypergraphs.', 'gene', 'external', 'expression', 'essential', 'effect', \"don't\", 'doctor', 'being', 'approximately', 'any', 'against', 'while', 'way', 'values', 'using', 'understand', 'type', 'treat', 'together', 'theorem', 'that.', 'system.', 'structures', 'story.', 'spoken', 'sounds', 'serves', 'research.', 'representation.', 'properties.', 'philosophy', 'numbers.', 'model', 'living', 'linguistics', 'learning', 'lead', 'it.', 'interactions', 'include', 'hypergraph-based', 'health', 'good', 'focuses', 'every', 'equal', 'entanglement', 'electric', 'do', 'diseases.', 'create', 'charged', 'causes', 'care', 'NLP', 'Legend', 'Language', 'Genetic', 'what', 'vector', 'up', 'unless', 'understanding', 'truth', 'time.', 'think', 'symbol', 'sun.', 'suggests', 'sentences.', 'rules', 'research', 'represents', 'represent', 'regulate', 'pursuit', 'protects', 'probability', 'principles', 'primary', 'phenomenon', 'particles.', 'part', 'normal', 'models.', 'mechanics,', 'meanings.', 'matter.', 'matter', 'material', 'many', 'make', 'key', 'individuals', 'improve', 'immune', 'imaging', 'historical', 'help', 'heart', 'glands', 'genes', 'functions', 'fictional', 'element', 'electrons', 'effects', 'each', 'does', 'disorders', 'discovered', 'direction', 'constant', 'concerned', 'carbon', 'brain', 'atomic', 'another.', 'analysis', 'alleles', 'act', 'account', 'ability', 'Zelda', \"I'd\", 'Hypergraph-based', 'How', 'AGI', '1', 'your', 'waves', 'wave-like', 'water', 'various', 'use.', 'universal', 'under', 'typically', 'treatment', 'transferred', 'traits', 'today?', 'tissue', 'time', 'temperature', 'supports', 'structural', 'strong', 'speed', 'specializes', 'speakers', 'space', 'sometimes', 'some', 'smallest', 'side', 'short', 'science', 'representation', 'relationship', 'related', 'protect', 'proposed', 'production', 'produced', 'prime', 'practice', 'possible', 'point', 'physical', 'philosophers', 'personal', 'per', 'patients', 'pathology', 'particle-like', 'out', 'organ', 'offer', 'ocean', 'observer', 'objects', 'nervous', 'narrative', 'medications', 'mechanics.', 'materials', 'makes', 'machine', 'located', 'life.', 'levels.', 'large', 'languages.', 'just', 'involve', 'internal', 'influence', 'ideas', 'idea', 'hydrogen', 'hormones', 'helps', 'grammar', 'general', 'frequency', 'formulated', 'formal', 'force.', 'figure', 'expressed', 'ethics', 'environmental', 'effect.', 'during', 'due', 'distribution', 'directly', 'conservation', 'computing', 'composed', 'communication', 'characters', 'chain', 'certain', 'cells', 'caused', 'carry', 'capital', 'capable', 'bones', 'billion', 'below', 'associated', 'assist', 'art', 'around', 'area', 'approaches', 'alphabet?', 'aims', 'actions', 'action', 'You', 'Was', 'Understanding', 'This', 'Philosophers', 'Hypergraph', 'Gene', 'Ethical', 'Do', 'writing', 'will', 'we', 'variations', 'variation', 'value', 'vacuum', 'until', 'unique', 'true.', 'true', 'triboelectricity,', 'total', 'topic', 'time,', 'throughout', 'those', 'third', 'thing', 'thermodynamics', 'therapy', 'theory.', 'theoretical', 'text.', 'technology', 'techniques', 'systems.', 'symbolic', 'sweat.', 'surface', 'support', 'superposition', 'sum', 'structures.', 'stretches', 'stars', 'spinal', 'speech.', 'specialized', 'speaking,', 'something', 'society.', 'social', 'small', 'skin,', 'simultaneously.', 'simultaneously', 'series.', 'sentence', 'selection', 'secure', 'second', 'sea', 'scientific', 'role', 'risk', 'right', 'respiratory', 'require', 'reproductive', 'repetition', 'remains', 'relative', 'relation', 'region', 'regarded', 'real', 'reaches', 'rational', 'random', 'published', 'proteins', 'protein.', 'proof', 'procedure', 'problems.', 'prevent', 'practices', 'practical', 'potential', 'population.', 'philosophical', 'phenotype', 'periodic', 'performance', 'penny', 'pair', 'oxygen,', 'own', 'organs', 'organism', 'order', 'opposite', 'operations', 'nucleus', 'multiple', 'movement', 'molecules', 'method', 'meters', 'mechanical', 'measures', 'me', 'matter,', 'mammal?', 'making', 'maintain', 'made', 'long', 'living.', 'literature', 'literary', 'literal', 'linguistic', 'linear', 'light-years', 'level.', 'laws', 'laid', 'involving', 'interpretation', 'interactions.', 'initial', 'inheritance', 'individual', 'importance', 'imaginary', 'images', 'if', 'hypergraph', 'hydrogen,', 'humans', 'history', 'highly', 'heterozygous', 'heart,', 'groups', 'group.', 'greater', 'gravity', 'given', 'geometry', 'geometric', 'genre', 'generations', 'generating', 'galaxies', 'functions,', 'function.', 'fuel', 'fries', 'friction', 'frequencies', 'free', 'forms', 'forces', 'flow', 'flexible', 'fields', 'feet)', 'explored', 'explore', 'exhibit', 'exchange', 'examines', 'examination', 'event', 'ethics.', 'especially', 'equations', 'entropy', 'enhance', 'electricity', 'electrical', 'early', 'duality', 'diseases', 'disease', 'digestive', 'diagnose', 'device', 'developed', 'describing', 'depth', 'deepest', 'dealing', 'daily', 'control', 'continuous', 'contexts.', 'considered', 'connective', 'connect', 'conditions,', 'conditions', 'concepts', 'compares', 'colossal', 'collection', 'chromosome', 'cells.', 'cardiac', 'capture', 'cannot', \"can't\", 'called', \"body's\", 'bodily', 'bird', 'been', 'basic', 'barrier', 'back', 'artificial', 'angular', 'allows', 'allele', 'algebra', 'aim', 'advanced', 'across.', 'according', 'abundant', 'Yes.', 'Yes,', 'Wall,', 'Using', 'Trench,', 'Standard', 'Model', 'Mariana', 'John', 'James', 'Hercules-Corona', 'Hello!', 'Great', 'Ethics', 'Einstein', 'Deep', 'Challenger', 'Borealis', 'Aristotle', 'Albert', '=', '74%', '10,994', '10', '(36,070', \"you're\", 'would', 'worth', \"world's\", 'world', 'wisdom,', 'well-being.', 'well,', 'wavefront', 'wave-particle', 'waste', 'was', 'virtue', 'variables', 'variable', 'values.', 'used.', 'urine.', 'upper', 'upon', 'underlying', 'typology', 'two-dimensional', 'treatments', 'translation.', 'transform', 'trace', 'tissues.', 'tissues', 'times', 'thyroid', 'thoughts', 'thought', 'they', 'thermodynamics,', 'there!', 'theory,', 'theories', 'theme', 'thanks', 'texts', 'tests', 'test', 'term', 'technique', 'teaches', 'teach', 'tasks.', 'taken', 'take', 'system,', 'symmetry', 'subtraction,', 'substances.', 'subject,', 'subatomic', 'study.', 'structure.', 'stores', 'stimulate', 'star', 'standards', 'stage.', 'stable', 'special', 'speaking', 'speak', 'spacetime', 'space.', 'sound.', 'solve', 'sodium', 'societal', 'so', 'skin', 'skeletal', 'situation', 'single', 'simple', 'similar', 'signals', 'shows', 'short,', 'set.', 'series', 'sensitive', 'semantic', 'self-reflection.', 'self-evidently', 'seeks', 'science.', 'saved', 'sample', 'roles', 'revolutionized', 'rest', 'responsible', 'respect', 'requires', 'remain', 'releasing', 'relativity,', 'relativity', 'regulates', 'referred', 'recessive', 'quit.', 'quantized', 'quantization', 'quantity.', 'quantity', 'qualities', 'quadratic', 'public', 'psychology.', 'provide', 'proven', 'proteins,', 'protective', 'protecting', 'proposition', 'proportional', 'products', 'product', 'produces', 'problem-solving.', 'principles.', 'previously', 'prevention,', 'preserves', 'preservation', 'precision.', 'posits', 'positively', 'positive', 'position', 'populations.', 'population', 'pool', 'points.', 'points,', 'placed', 'place', 'pitch', 'piece', 'phrases', 'phrase', 'photoelectric', 'phoneme', 'phenotypes', 'phenotype.', 'person.', 'person', 'performs', 'people', 'pathogens', 'particularly', 'parallel', 'pairs', 'pain.', 'overused', 'others.', 'oscillator', 'oscillation', 'organization', 'organism,', 'oral', 'opposes', 'operation', 'ongoing', \"one's\", 'occur', 'objects.', 'nutrients', 'number.', 'nuclei', 'nuances', 'now?', 'novel', 'negative', 'necessary', 'nearly', 'nature.', 'native', 'mysterious', 'mutation', 'muscular', 'muscles,', 'multiplication,', 'moving', 'morality', 'molecular', 'millions', 'methods', 'metaphor', 'medium', 'medicine.', 'meanings', 'mean', 'mathematics,', 'massive', 'manner.', 'mammal', 'makeup', 'major', 'maintenance', 'maintaining', 'macroscopic', 'lungs', 'lower', 'love', 'long,', 'logic', 'location', 'list', 'lines,', 'line', 'limit', 'light,', 'lifelong', 'lesson.', 'legend', 'learn', 'leading', 'larger', 'languages,', 'laboratory', 'knowledge.', 'knowledge,', 'kinetic', 'kilometers', 'kidneys', 'justice', 'joints.', 'itself.', \"it's\", 'issues', 'isolated', 'is,', 'irrational', 'involved', 'intestine', 'interconnected', 'interaction', 'intended', 'integral', 'integer', 'insight.', 'injury', 'injuries', 'inherited', 'information.', 'infections.', 'induction', 'increase', 'impossible', 'hypothesis', 'hypergiant', 'horse', 'heroic', 'heat,', 'heart.', 'hear', 'harmony', 'harmonic', 'happiness', 'guiding', 'gravitation', 'grass', 'graphs', 'golden', 'gold?', 'gold', 'global', 'glad', 'giving', 'give', 'genomics', 'genes,', 'gases', 'gas', 'future', 'functions.', 'functional', 'fully', 'french', 'fraction', 'foundations', 'formation', 'forefront', 'fluid', 'flies', 'find', 'filter', 'filled', 'field.', 'fermions', 'female', 'father', 'famous', 'expression.', 'expressing', 'expresses', 'exploration', 'explains', 'experiments', 'experiences', 'experience,', 'experience', 'expansion', 'exist', 'exhibits', 'evolutionary', 'evolution', 'ever', 'events,', 'events', 'ethics,', 'established,', 'established', 'escape', 'environment.', 'entities.', 'enjoy', 'endocrine', 'endangered', 'encourages', 'encode', 'encapsulates', 'enables', 'emphasized', 'emission', 'elephant.', 'elementary', 'electrostatic', 'electromagnetic', 'either', 'eggs.', 'effectively', 'education', 'dynamical', 'dominant,', 'doing', 'diversity.', 'distribution,', 'distinguish', 'disorder', 'disease.', 'discussions', 'dioxide,', 'dioxide', 'digestion', 'differential', 'diagram', 'diagnosis,', 'diagnosis', 'determine', 'detailed', 'derivatives', 'depending', 'demonstrates', 'defined', 'deeper', 'decrease', 'decisions.', 'decision-making.', 'dead', 'data.', 'current', 'crucial', 'critical', 'cord', 'controlled', 'contributes', 'contains', 'constant.', 'consonant', 'consisting', 'consciousness?', 'consciousness.You:', 'consciousness', 'connected', 'concerning', 'computing,', 'computer', 'composition', 'completed', 'complete', 'communities', 'color', 'coherence', 'close', 'classifies', 'chromosomes.', 'chickens', 'chat.', 'character.', 'changing', 'central', 'cells,', 'cell', 'cavity.', 'causing', 'cats', 'case', 'cake', 'c', 'bones.', 'blue', 'blood.', 'bladder', 'black', 'biology', 'biography', 'best', 'believed', 'beings.', 'beings', 'behavior.', 'become', 'basis', 'bands', 'autosomal', 'audience.', 'assess', 'aspects', 'asking.', 'arrest.', 'arrangement', 'approach', 'applying', 'applied', 'another,', 'analysis.', 'amount', 'always', 'along', 'allowing', 'aid', 'affects', 'adrenal', 'addition,', 'acting', 'across', 'acquiring', 'acid,', 'accepted,', 'acceleration', 'abstract', 'absorption', 'absorbs', 'absolute', 'Zelda?', 'Z', 'Y', 'X-linked', 'X', 'Western', 'Welcome', 'Valorant', 'Type', 'Translation', 'Tower', 'They', 'That', 'Tell', 'Syntax', 'Sustainable', 'Sorry,', 'Socrates,', 'Schrödinger', 'RNA', 'R136a1,', 'Public', 'Principle', 'Plato,', 'Philosophical', 'Natural', 'Moral', 'Mathematical', 'Magellanic', 'Large', 'Interpretation', 'Hi', \"Heisenberg's\", 'Hall', 'H', 'Greek', 'Graph', 'Genomic', 'General', 'French', \"Euclid's\", \"Einstein's\", 'Eiffel', 'E', 'Developing', 'Dark', 'Complex', 'Comparative', 'Cloud,', 'Clinical', 'Chaos', 'C', 'Au.', 'Artificial', 'Ancient', 'African', 'Advanced', 'AGI?', '300', '299,792', '0', '.', '+', \"'exit'\", 'zero,', 'zero', 'zelda', 'z', 'you?You:', 'yet', 'y', 'x', 'wrongness', 'wrong,', 'writings', 'writing.', 'writing,', 'writers', 'writer,', 'write', 'worm,', 'worldwide.', 'worldview', 'world?', 'world.', 'works.', 'works', 'work-energy', 'work,', 'words,', 'wonders', 'wonder.', 'within.', 'wisely', 'wisdom.', 'wide', 'whole.', 'white', 'whisperer', 'wheat.', 'whales', 'whale.', 'well.', 'well-timed', 'well-known', 'well-formed', 'well-being', 'well', 'ways.', 'ways', 'way.', 'waves,', 'wavelength', 'wave,', 'water?', 'water,', 'waste,', 'want', 'w', 'vowel', 'volume', 'voltage', 'vocabulary', 'vital', 'visit', 'viscous', 'viruses,', 'virtues.', 'virtue.', 'views.', 'view', 'videogame?', 'video.', 'vibrations', 'vibrational', 'vibrant', 'vessels.', 'vessels,', 'vessels', 'vertices,', 'vertebral', 'versatile', 'verb,', 'ventilation', 'velocity', 'veins', 'vehicles', 'vast', 'variety', 'variation,', 'variable.', 'vapor.', 'value.', 'vaccines', 'vaccine', 'v', 'utterance', 'urine', 'urinary', 'urethra.', 'ureters,', 'urban', 'unstable', 'unsolved', 'unpredictable', 'unpleasant', 'universes', 'units', 'uniquely', 'uniform', 'unethical', 'understood', 'understanding,', 'underlies', 'undergoing', 'uncharged', 'uncertainty', 'unauthenticated.', 'ulna', 'u', 'types', 'two-level', 'turn', 'tunneling.', 'tunneling', 'trying', 'truths.', 'trope', 'triangle,', 'trials', 'tree', 'treats', 'treating', 'treated.', 'traveled', 'travel.', 'transverse', 'transparency,', 'transmits', 'transmit', 'transmission', 'translation', 'transition', 'transforming', 'transformed', 'transformations.', 'transformations', 'transformation.', 'transfer', 'training', 'traditions,', 'traditions', 'trachea,', 'torque', 'topic,', 'tools', 'too,', 'too', 'tomorrow', 'tomography', 'together.', 'together,', 'today.', 'tissues,', 'tiny', 'timing,', 'timeless', 'time.You:', 'tibia,', 'thyroid,', 'thread-like', 'thoughts.', 'thoughtful', 'thoracic', 'things', \"they're\", 'these', 'thesaurus', 'thermal,', 'therefore', 'there', 'theorems.', 'then', 'them.', 'texts.', 'text', 'testosterone.', 'testing', 'testes,', 'testes', 'terrible', 'terms', 'temporary', 'temporal', 'temperatures', 'temperature.', 'teleportation', 'telecommunication', 'technologies.', 'technologies', 'teamwork', 'tasks', 'task.', 'task', 'tale', 'taking', 'takes', 'take.', 't', 'systematic', \"system's\", 'synthesis', 'syntax', 'syntactic', 'symbols.', 'symbols', 'syllables', 'syllable', 'sword,', 'sword', 'swelling,', 'sustainability', 'surprise', 'surgery.', 'surgeon', 'surfaces,', 'sure.', 'supremacy', 'superpose', 'supernatural', 'sunlight,', 'sugar', 'sufficient', 'suddenly', 'subsystems', 'substituted', 'substances', 'substance', 'subjective', 'subjected', 'subject', 'style,', 'strongest', 'strive', 'strings.', 'stretched', 'stress.', 'stress,', 'strategic', 'straight', 'storytelling.', 'stories,', 'stomach,', 'stethoscope', 'step-by-step', 'statistical', 'statement.', 'state.', 'stands', 'squares', 'squared', 'square', 'spread', 'sport', 'spontaneously', 'spontaneous', 'splitting', 'split', 'spine,', 'spin', 'sperm', 'spent', 'spelling', 'speed.', 'species', 'specialist', 'speaks', 'speakers.', \"speakers'\", 'spawns', 'spatial', 'spaghetti?', 'spaces.', 'spaces,', 'space,', 'sources.', 'source.', 'sounds.', 'sounds,', 'sorry,', \"someone's\", 'someone', 'solving', 'solution', 'soliloquy', 'solids.', 'solid', 'smooth', 'sleep', 'skull', 'skills.', 'skills', 'skilled', 'situations.', 'site', 'simplified', 'simile', 'similarity', 'significant', 'significance', 'sides.', 'shuffling', 'should', 'shock', 'shift', 'share', 'shaping', 'shapes', 'sex,', 'sex', 'severe', 'several', 'setting.', 'sets,', 'sequencing', 'sequences.', 'sequences', 'sequence.', 'sentences,', 'sentences', 'sensory,', 'sensors.', 'sensors,', 'sense,', 'semiconductor', 'self-written', 'self-cultivation', 'segregation', 'segments', 'seemingly', 'second,', 'second)', 'sebum,', 'screening', 'science,', 'school', 'scenarios.', 'scans', 'scale.', 'scale', 'scalar', 'sayings', 'saying', 'saving', 'samples,', 'said', 'safety', 's', 'rule', 'rows', 'rooted', 'robust', 'risk.', 'risk,', 'rise', 'rightness', 'right-angled', 'ridicule', 'ribosomes', 'ribonucleic', 'rib', 'rhythmic', 'rhythm,', 'rhythm', 'rewarding.', 'revolutionary', 'reveals', 'revealing', 'return', 'resuscitation', 'resulting', 'resultant', 'result.', 'restoring', 'restore', 'response', 'respond', 'respectively.', 'resource', 'resonance', 'resolving', 'resistance', 'researcher', 'rescue.', 'request', 'repulsion', 'reproduce.', 'reproduce', 'representing', 'represented', 'representations', 'rendering', 'removing,', 'removes', 'remotely.', 'remember', 'remarkable', 'religious', 'relieve', 'release', 'relaxing', 'relaxes', 'relativistic', 'relativism', 'relations', 'regulation.', 'regulation', 'register', 'regional', 'regardless', 'reflective', 'reflect', 'reference.', 'reference', 'refer', 'reduced-scale', 'reduce', 'redness,', 'red?', 'red.', 'recurring', 'rectangular', 'recovered', 'recover,', 'recover', 'record', 'reconcile', 'recombination.', 'recombination', 'recognizing', 'recognize', 'recessive.', 'recessive,', 'reasoning,', 'reasoning', 'realized', 'realization', 'reality', 'real-world', 'real-life', 'reading,', 'reactions.', 'reaction.', 'reaction', 'ratio', 'rather', 'rate', 'rare', 'range', 'randomness', 'randomly', 'raised', 'radius,', 'radio', 'radiation,', 'radiation', 'r', 'quotient', 'questions', 'question', 'qubits', 'qubit', 'quarks', 'quantity,', 'qualities.', 'q', 'purpose', 'puppy', 'pumps', 'psychological', 'providing', 'provided', 'proverbs', 'proverb', 'prove', 'protons.', 'protons', 'protein', 'protection', 'protagonist.', 'protagonist', 'proposes', 'property', 'properties,', 'propagates', 'pronouns', 'pronouncing', 'promotion', 'promising', 'prokaryotic', 'projectiles', 'progress', 'programs.', 'programming', 'progesterone.', 'profound', 'professional', 'profession', 'productivity.', 'product,', 'producing', 'processing.', 'processing', 'processes', 'process.', 'procedures.', 'problems', 'problem', 'privacy.', 'privacy,', 'prior', 'printing', 'principle.', 'prevention.', 'prevention', 'prevailing', 'pressure', 'preserved', 'presentation', 'present', 'presence', 'prescribes', 'pregnancy,', 'predictions', 'predicting', 'predicted', 'predict', 'precision', 'precise', 'preceding', 'powers', 'power.', 'power', 'potential.', 'potential,', 'potato', 'postulate', 'postpartum', 'positions', 'positing', 'populations,', 'popularly', 'popular', 'polynomial', 'polymerase', 'policy-making,', 'polar', 'points', 'poem', 'plot', 'pleasant', 'plays', 'play', 'platforms', 'plates', 'plants.', 'plants', 'plane', 'place,', 'pivot', 'pithy', 'pidgin', 'physics.', 'physician', 'phrases,', 'phrase.', 'photosynthesis', 'photons,', 'phonemic', 'phonemes', 'phoneme.', 'phoneme,', 'philosophy,', 'philosophies', 'philosopher,', 'phenomenon.', 'phenomenon,', 'phenomena.', 'phase', 'persuasive', 'persuade,', 'perspectives.', 'perspectives', 'perspective', 'personality', \"person's\", 'peroxide?', 'peroxide', 'permutation', 'permissible', 'permeate', 'peripheral', 'period.', 'performing', 'performed', 'perfectly', 'people.', 'pen', 'pelvis', 'pedigree', 'peculiar', 'pea', 'pay', 'patterns', 'pattern', \"patient's\", 'patience,', 'paths', 'pathogen', 'path', 'pasta', 'passing', 'passed', 'pass', 'parts.', 'parts,', 'parts', 'parties.', 'particles,', 'particle.', 'part.', 'parody', 'parent-of-origin-specific', 'parent', 'pancreas,', 'pancreas', 'p', 'oxygenation', 'oxygen-rich', 'oxygen-poor', 'oxygen', 'overcomes', 'overall', 'ovaries,', 'ovaries', 'outputs.', 'outperform', 'outcomes.', 'outcome.', 'others', 'ostoyae,', 'oscillatory', 'oscillations', 'oscillates', 'origins', 'originated.', 'originality', 'origin.', 'origin,', 'origin', 'orientation', 'organs.', 'organs,', 'organisms.', 'organisms', 'ordinary', 'ordered', 'order.', 'optimization', 'optics', 'opposites', 'openings,', 'opening', 'open', 'online', 'ones.', 'one.', 'one-dimensional', 'one,', 'older', 'oily', 'offspring', 'offers', 'occurs.', 'occurrence', 'occupy', 'occasional', 'obstetrician', 'obstacles', 'observed.', 'observed', 'observations.', 'observable', 'object,', \"object's\", 'o', 'nutrient', 'nurture', 'nurse', 'numerous', 'numbers.Model:', 'number,', 'nucleus,', 'nucleotide,', 'nucleic', 'nuclei,', 'nuclear', 'notions', 'nothing,', 'norms', 'non-terminating.', 'non-repeating', 'non-negative', 'non-human', 'nodes.', 'nodes,', 'node', 'no.', 'nitrogen,', 'newspaper,', 'newly', 'new,', 'neutrons', 'neutralize', 'neutral', 'neurons,', 'neural', 'networks', 'nerves.', 'nerve', 'neologism', 'negotiation', 'negatively', 'needed', 'nearby', 'navigate', 'nanoscale', 'names?', 'named.', 'nails.', 'n', 'myth', 'my', 'mutations', 'mutation,', 'must', 'mushroom,', 'muscles.', 'muscles', 'muscle,', 'muscle', 'multiverse', 'multiplied', 'multiplayer', 'much', 'mouth.', 'mouth,', 'motor,', 'motif', 'mosaic', 'morpheme', \"morality'.\", \"morality'\", 'monologue', 'moment.', 'molecules.', 'molecule,', 'molecule', 'modification', 'modeling', 'model.', 'mode', 'mobility.', 'mixing', 'minimum.', 'minimum', 'minimal', 'mind', 'milk', 'miles', 'mild', 'mightier', 'middle', 'microscope.', 'microorganisms.', 'microorganism', 'microbial', 'metrical', 'metabolism,', 'messengers', 'messenger', 'messages.', 'mentioned', 'mental', 'memoir', 'meiosis', 'medium.', 'median', 'media,', 'media', 'mechanisms', 'mechanism', 'measurements', 'measurement', 'measured.', 'measure', 'meant', 'meaningful', 'mc^2.', 'may', 'maximizes', 'maxim', 'matrix', 'matrices', 'maternally', 'maternal', 'materials.', 'master', 'mask', 'market.', 'marker', 'marine', 'mapped', 'map', 'manipulating', 'manifestations', 'male.', 'main', 'magnitude', 'magnetism,', 'magical', 'magazine,', 'machinery,', 'machinery', 'ma).', 'mRNA', 'm', 'lymph', 'lush', 'lungs,', 'lunch,', 'lubricates', 'loyal', 'lower,', 'low', 'louder', 'lost', 'loses', 'longer', 'logical', 'logarithm', 'location,', 'located?', 'locally', 'local', 'loanword', 'lives.', 'lives', 'liver.', 'liver,', 'liver', 'literature.', 'literature,', 'literally.', 'lists', 'listening', 'listen', 'liquids', 'liquid,', 'linkage', 'linguistics.', 'linguist', 'lingua', 'lines.', 'lineage.', 'line,', 'limits', 'lighter', 'ligaments.', 'lifetime', \"life's\", 'lies', 'lexicon', 'lexical', 'lexeme', 'leveraging', 'leverages', 'letter.', 'lens', 'leisurely', 'legendary', 'leg.', 'led', 'learning,', 'leadership', 'lay', 'later.', 'later', 'late', 'large-scale', 'language,', 'l', 'knack', 'kittens.', 'kittens', 'kinetic,', 'killed', 'kidneys,', 'k', 'juxtaposition', 'justice.', 'justice,', 'judgments.', 'judges', 'judge', 'journal.', 'journal', 'job!', 'j', 'items', 'it?', 'it,', 'issues,', 'is.', 'irregular', 'irony,', 'ions.', 'ionized', 'intuitive', 'introducing,', 'introducing', 'introduces', 'introduced', 'intrinsic', 'intricate', 'intonation', 'intimate', 'intestines,', 'interventions.', 'intersecting', 'interpretation,', 'interneurons.', 'intermediate', 'interface', 'interests.', 'interesting.', 'interest', 'interconnectedness', 'interacts', 'interaction,', 'intelligence.', 'intelligence', 'intellectual', 'integumentary', 'integrity.', 'integrity', 'integrals.', 'integers;', 'integers.', 'integers', 'insurmountable', 'insurance,', 'insulin', 'instrument', 'instructions', 'instead', 'instantly', 'insights.', 'insights', 'inside', 'inquiry', 'inputs', 'input', 'innovation.', 'innovate', 'injuries.', 'injured', 'initiatives', 'inherent', 'informed', 'information,', 'informal', 'inform,', 'inform', 'influences', 'infinitesimal', 'infectious', 'infections', 'infection,', 'infeasible', 'infants,', 'inertial', 'inertia', 'industries.', 'induced', 'individuals.', \"individuals'\", \"individual's\", 'indistinguishable', 'indirect', 'indication', 'indicates', 'independent', 'independence.', 'increases', 'incorporates', 'incorporated', 'incident', 'impulses', 'improving', 'imprinting', 'important', 'implied', 'implicit', 'implicature', 'imperative.', 'impact.', 'impact', 'immunity', 'immersive', 'immediate', 'imitation', 'imaginative', 'illustrating', 'illnesses.', 'illnesses', 'ill.', \"ignorance'\", 'idiom', 'idiolect', 'identifying', 'identify', 'identical', 'ice', 'i', 'hypotenuse', 'hydrogen?', 'humor,', 'humility,', 'humerus,', 'hormones.', 'hormone', 'honey', 'homozygotes.', 'homologous', 'hole', 'holds', 'history.', 'hint', 'hinge,', 'higher-order', 'higher', 'high-frequency', 'hidden', 'hi', 'heterozygote', 'heritage', 'heritable', 'heredity', 'hereditary', 'hemoglobin', 'helix', 'heavy', 'heavier', 'heartfelt', 'hatch,', 'harsh', 'harnesses', 'harmful', 'happiness.', 'handle', 'hand,', 'hand', 'hair.', 'hair,', 'habitual', 'habits', 'h', 'gynecologist', 'growth,', 'growing', 'grow', 'grouped', 'group', 'greener', 'greater,', 'gravity.', 'gravity)', 'gravitation,', 'grapheme', 'graph.', 'graph', 'grammar.', 'governing', 'govern', 'good.', 'golems,', 'gods', 'gluons.', 'glucose', 'glands.', 'gland', 'gives', 'gets', 'genotype', 'genomes', 'genome.', 'genome,', 'genome', 'genetics,', 'genetics', 'genes.', 'generative', 'generations.', 'generate', 'generally', 'gene.', 'gene-editing', 'gene,', 'gases.', 'gases,', 'games', 'game', 'g', 'future?', 'future.', 'fungus', 'fungi.', 'fruit', 'frontiers', 'fries?', 'frequently', 'frequent', 'frequency.', 'franca', 'frameworks', 'framework', 'frame', 'four', 'foundation', 'found', 'formulation', 'formed', 'form,', 'foreign', 'forces.', 'force,', 'food', 'fonder,', 'follow', 'focusing', 'flux', 'fluids', 'fluid.', \"fluid's\", 'fluently.', 'fluctuations.', 'fluctuations', 'flows', 'flock', 'flexibility.', 'flaws', 'fix', 'fishing.', 'fishing', 'fish?', 'fish', 'first', 'finite', 'finance,', 'figure.', 'figurative', 'fifth', 'fields,', 'fibula', 'fever.', 'fence,', 'femur,', 'feeding', 'feces.', 'featuring', 'features.', 'features', 'feature', 'feats', 'feather', 'favorite', 'fault-tolerant', 'fats,', 'fate', 'fastest', 'fascinating', 'fantastical', 'famously', 'family.', 'family,', 'families', 'false,', 'falling', 'fairy', 'fairness,', 'fairness', 'fairies,', 'fair', 'factors', 'factorized', 'facilitates', 'facilitate', 'face.', 'fable', 'f', 'extinction.', 'extended', 'expressive', 'expressed,', 'expose', 'exponents.', 'exponent', 'exploring', 'explores', 'exploiting', 'explanation', 'explaining', 'experiment', 'experiences.', 'experiences,', 'experience.', 'exotic', 'exoplanets', 'existing', 'existentialist', 'existential', 'existence', 'exist.', 'exerted', 'exercises', 'excreted', 'excitations', 'exchange.', 'example.', 'exaggeration', 'exaggerated', 'exact', 'evolution.', 'evolution,', 'evoke', 'evil,', 'evil', 'evidence', 'everyday', 'eventual', 'events;', 'event.', 'even', 'euphemism', 'eukaryotic.', 'ethic', 'estrogen', 'establishes', 'essence', 'essay', 'esophagus,', 'equivalence', 'equine', 'equilibrium', 'equations,', 'epithelial,', 'epigenetic', 'epic', 'enzymes', 'environment', 'entity', 'entities', 'entire', 'entertainment', 'entertain', 'engage', 'enduring', 'end', 'encrypt', 'encountered', 'encompasses', 'encapsulate', 'enabling', 'emphasizes', 'emphasize', 'emphasis', 'empathy.', 'emotions', 'emit,', 'emergency', 'else', 'eloquent', 'electronics.', 'electronic', 'electron', 'electrolytes', 'electrodynamics', 'electrocardiogram', 'electricity,', 'electrically', 'eigenvector', 'eigenvalue', 'eggs', 'efforts', 'efficiently', 'efficient', 'effects.', 'effectiveness', 'effective', 'education.', 'education,', 'edges.', 'ecosystems', 'eat', 'earned,', 'earlier', 'e', 'dysphemism', 'dynamics', 'duty', 'durum', 'drugs', 'drowning', 'drink,', 'drift', 'dread', 'dragons', 'down', 'doubts', 'double-slit', 'double', 'dots', 'done', 'dominance', 'dolphins.', 'doing?', 'dogs?', 'dogs', 'dogma', 'documents', 'doctors', 'do?', 'do,', 'divisors', 'division.', 'divided', 'distributions.', 'distribution.', 'distributed.', 'distinguished', 'distinctive', 'distinct', 'distance.', \"distance'.\", 'distance', 'disproven.', 'display', 'displacement.', 'displacement', 'disorders.', 'disorder.', 'dish', 'disease,', 'discussion.', 'discovery', 'direction.', 'dilemmas.', 'dilemmas', 'digitization', 'digital', 'differences.', 'differ', 'die', \"didn't\", 'dictionaries.', 'diary', 'diaphragm', 'dialects', 'dialect', 'diagnoses', 'devoted', 'devices', 'development.', 'develop,', 'develop', 'detoxifies', 'detailing', 'destroyed,', 'dessert', 'designed', 'description', 'described', 'derogatory', 'derived', 'derivatives.', 'derivative', 'dependencies.', 'deoxyribonucleic', 'dentist', 'denoted', 'delivers', 'delivered', 'delicious', 'deliberate', 'degree', 'defibrillator', 'defends', 'defend', 'deeds', 'decrypt', 'decomposes', 'decoherence', 'decoded', 'decisions', 'decision-makers.', 'decimal', 'debated', 'damage.', 'damage', 'd', 'cutting-edge', 'cute?', 'cute,', 'cute', 'customs,', 'cushioning', 'curve.', 'curvature', 'currents,', 'cup', 'cultures', 'culturally', 'cultural', 'cultivation', 'cryptography', 'criticize', 'critically', 'crispy.', 'creole', 'creativity', 'creation', 'creates', 'created', 'cream?', 'cream.', 'cream', 'covers', 'covering', 'cover,', 'cover', 'courses', 'countless', 'count', 'counseling', 'could', 'cosmological', 'cortisol', 'corresponding', 'corpus', 'cord,', 'copy', 'copied', 'coordinates', 'convince', 'conveys', 'convert', 'conversational', 'conversation.', 'conventional', 'controls', 'contributing', 'contributed', 'contribute', 'contrast.', 'contracting', 'continuum', 'continue', 'contextual', 'contexts', 'context', 'consultation', 'constraints.', 'consists', 'considers', 'conservation,', 'consequences.', 'consciousness.', 'connective,', 'connections', 'conjecture', 'conflicts.', 'conducts', 'conductor', 'conductive', 'conductance.', 'conduct.', 'conduct', 'condition.', 'concise', 'computers.', 'computers', 'computer.', 'computations.', 'computations', 'computation.', 'compressions', 'compressed', 'complementarity', 'compiling', 'competitive', 'competing', 'compassion', 'community,', 'community', 'communities.', 'communication,', 'communicate', 'commitment', 'command.', 'comic', 'comes', 'come', 'combines', 'combine', 'combinations', 'combination', 'columns.', 'column,', 'collections', 'collection,', 'coined', 'coherent', 'cognition.', 'coffee', 'coexistence', 'coefficients,', 'codominance,', 'clownfish.', 'closed', 'clean', 'classified', 'claimed', 'circulatory', 'circulates', 'chromosomes,', 'chromosomes', 'chromodynamics', 'choice.', 'children,', 'childbirth,', 'chest', 'chemistry,', 'chart', 'charges,', 'charged,', 'characters.', 'characterizes', 'characterized', 'characteristics.', 'characteristics', 'characteristic', 'character,', 'chaotic,', 'channels.', 'change,', 'chance.', 'challenging', 'challenges.', 'challenged', 'challenge', 'cerebrum,', 'cerebellum,', 'center', 'cell,', 'cats?', 'cats.You:', 'cats.', 'cats!', 'categorical', 'catches', 'cat,', 'cat', 'cases', 'carve', 'cartilage,', 'carries', 'carried', 'cardiovascular', 'carbon?', 'captured', 'capacity', 'capabilities', 'cannot.', 'cancer.', 'calque', 'cage', 'bx', 'butterfly', 'bush,', 'bush', 'built', 'building', 'bronchi.', 'broke,', 'broad', 'bringing', 'bring', 'brief', 'breathing', 'breath', 'breakthroughs', 'breaks', 'breakfast.', 'brainstem.', 'brain.', 'brain,', 'bound', 'bosons.', 'boson', 'borrowed', 'books', 'book', 'bones,', 'bonds', 'blunt.', 'bladder,', 'bits', 'bit', 'birth', 'birds', 'biopsy', 'biodiversity.', 'binomial.', 'binomial', 'binds', 'bile,', 'bicarbonate?', 'bicarbonate', 'better', 'benefits', 'benefit', 'bending', 'belonging', 'beliefs.', 'beliefs,', 'beliefs', 'begun', 'begins', 'before', 'because', 'beautifully', 'base', 'barriers', 'banana,', 'ball-and-socket,', 'balancing', 'balance', 'bake', 'bacterial', 'bacteria,', 'bacteria', 'baby', 'b', 'axioms', 'axiom', 'axes.', 'ax^2', 'away', 'awareness.', 'average', 'available', 'autosomes', 'autonomous', 'autobiography', \"author's\", 'author', 'attribution', 'attracts', 'attractive', 'attract', 'attempts', 'atoms', 'atom.', 'atom', 'atmosphere', 'astronomical', 'assortment.', 'assists', 'arts', 'artist,', 'articulated', 'article', 'art.', 'arrow,', 'arrhythmias', 'array', 'arranged', 'arm.', 'arithmetic', 'argument', 'argued', 'argon,', 'area.', 'architectures.', 'approach.', 'applies', 'applications,', 'applications', 'application', 'appears', 'appearance', 'aphorism', 'anyons,', 'antimatter.', 'antibodies.', 'antagonist', 'annealing', 'animals.', 'animals', 'anesthesiologist', 'anesthesia', 'anemia', 'analyzing', 'analytical', 'analysis,', 'analyses', 'analogous', 'amplitude.', 'amplify', 'amounts', 'among', 'alters', 'alternatives.', 'alternative', 'alternating', 'altering', 'aloud,', 'alone', 'allow', 'allergic', 'alleles.', 'allegory', 'algorithms', 'algorithm', 'algebraic', 'air', \"ain't\", 'aids', 'agriculture', 'afraid', 'affairs,', 'aesthetic', 'advocates', 'advises', 'advice.', 'adventures', 'advantageous', 'advance', 'adults.', 'adrenaline', 'adorable', 'adopted', 'adolescents.', 'administration', 'administering', 'adhering', 'addresses', 'address', 'additional', 'actually', 'acts', 'actors', 'activity', 'activities', 'actions.', 'action.', 'action-adventure', 'action,', 'acted', 'acres', 'acquisition', 'acquired.', 'acid', 'achieved', 'achieve', 'accountability.', 'accordance', 'accomplishing', 'accepting', 'accent', 'accelerated', 'absorb,', 'absence', 'Zeno', 'Zelda.', 'Zelda,', 'Y,', 'XY', 'XX', 'X-rays', 'X,', 'Work', 'Word', 'William', 'Why', 'White', 'Where', 'When', 'Werner', 'We', 'Wave-particle', 'Watson', 'Water', 'Washington', 'W,', 'W', 'Virtue', 'Virtual', 'Valorant?', 'Valorant.', 'Vaccines', 'Vaccination', 'V,', 'V', 'Utilitarianism,', 'United', 'Uncertainty', 'Ultrasound', 'USA?', 'USA', 'U,', 'U', 'Turbulence', 'Transformational', 'Transcription', 'Topology', 'Topological', 'Tone', 'Tissues', 'Time', 'These', 'Thermodynamics', \"There's\", 'There', 'Theorems', 'Theorem', 'Text', 'Tendons', 'Telemedicine', 'Taoism', 'T,', 'T', 'Systems', 'Synonyms', 'Sweat', 'Supersymmetry', 'Superconductivity', 'Stylistics', 'Stuart', 'String', 'Stress', 'Stoicism,', 'Sterilization', 'Statistics', 'Statistical', 'States.', 'Special', 'Spanish,', 'Spaghetti', 'Socrates', 'Sociolinguistics', 'Social', 'Slang', 'Sickle', 'Set', 'Semantics', 'Sebaceous', 'Science', 'Schweitzer', 'Satire', 'Sartre,', 'Sapir-Whorf', 'S,', 'S', 'Rule,', 'Rome,', 'Romans', 'Riot', 'Riemann', 'Richard', 'Rhetorical', 'Rhetoric', 'Revitalization', 'Resonance', 'Research', 'Refraction', 'Reflection', \"Rawls'\", 'Rawls', 'Radiology', 'Radioactivity', 'Rabi', 'RNA,', 'R,', 'R', 'Q,', 'Q', 'Pythagorean', 'Psycholinguistics', 'Psychiatry', 'Proverbs,', 'Proteomics', 'Prosody', 'Prose', 'Project,', 'Probability', 'Preventive', 'Prescriptive', 'Pragmatism,', 'Pragmatics', 'Population', 'Polysemy', 'Polygenic', 'Polarization', 'Poetry', 'Plato', 'Plasma', \"Planck's\", 'Planck', 'Physics', 'Physical', 'Photosynthesis', 'Photons', 'Phonology', 'Phonological', 'Phonetics', 'Philosophy', 'Pharmacology', 'Personification', 'Pediatrics', 'Pauli', 'Paul', 'Particle', 'Paris.', 'Paris,', 'P,', 'P', 'Orthography', 'Organs', \"Oregon's\", 'Oratory', 'Optics', 'Operations', 'Onomatopoeia', 'Oncology', \"Ohm's\", 'Occupational', 'O,', 'O', 'Number', 'Nuclear', 'Non-Euclidean', 'No.', 'Nintendo.', 'Nintendo', 'Nietzsche', 'Niels', 'Newtonian', 'Newton', 'Neurons', 'Neurology', 'Nephrons', 'Navier-Stokes', 'Nanotechnology', 'NaHCO3.', 'NLP.', 'NLP,', 'N,', 'N', 'Mutations', 'Mountains.', 'Morphology', 'Momentum', 'Modern', 'Mitochondrial', 'Mill,', 'Midna,', 'Metagenomics', 'Mendelian', 'Mendel,', \"Mendel's\", 'Medical', 'Maxwell', 'Max', 'Mathematics', 'Martin', 'Many-Worlds', 'Many', 'Mahatma', 'Magnetic', 'M,', 'M', 'Luther', 'Literary', 'Link?', 'Link,', 'Link', 'Linguistics', 'Linear', 'Ligaments', \"Life',\", 'Lexicography', \"Lenz's\", 'Laozi', 'Lama', 'L,', 'L', 'King', 'Kant,', 'Kant', 'K,', 'K', \"Justice'\", 'Jr.', 'Joints', 'Jeremy', 'Jean-Paul', 'Jargon', 'J,', 'J', 'It', 'Isaac', 'Irony', 'Intonation', 'Interference', 'Intelligence.', 'Inflammation', 'Infinity', 'Indo-European', 'Incomplete', 'Immanuel', 'If', 'Ice', 'I,', 'Hypothesis', 'Hyperbole', 'Humans', 'Human', 'Hormones', 'Homozygous', 'Homophones', 'Homeostasis', 'Historical', 'Hindi.', 'Higgs', 'Hellenistic', 'Harmonic', 'Hardy-Weinberg', 'Hannah', 'H2O.', 'H,', 'Gregor', 'Grammar', 'Golden', 'Geriatrics', 'Geometry', 'Genome', 'Genetics', 'Genes', 'Generative', 'Gene-environment', 'Gemma?', 'Gemma', 'Gaussian', 'Ganondorf?', 'Ganondorf,', 'Ganondorf', 'Gandhi', 'Games.', 'Game', 'G,', 'G', 'Fusion', 'Functional', 'Friedrich', 'Francis', 'France?', 'France.', 'France', 'Fractals', 'Fourier', 'Foreshadowing', 'Folklore', 'Fluid', 'Fission', 'Fishing', 'First', 'Fibonacci', \"Feynman's\", \"Faraday's\", 'F,', 'F', 'Exclusion', 'Even', 'Etymology', 'Epona,', 'Epigenetics', 'Epidemiology', 'Entropy', 'Entanglement', 'English,', 'Energy', 'Elements', 'Electromagnetism', 'Eastern', 'Earth.', \"Earth's\", 'Earth', 'Each', 'EKG)', 'E,', 'Drama', 'Doppler', \"Don't\", 'Dominant', 'Dogs', 'Discourse', 'Dirac,', 'Dirac', 'Diglossia', 'Diffraction', 'Differential', 'Dialogue', 'Dialectology', 'Dewey,', 'Descriptive', 'Deontological', 'Deixis', 'Dalai', 'DNA.', 'DNA,', 'D.C.', 'D,', 'D', 'Cybersecurity', 'Curiosity', 'Cryptography', 'Crick', 'Creative', 'Creating', \"Coulomb's\", 'Cosmology', 'Copenhagen', 'Conversational', 'Contemporary', 'Consonance', 'Consequentialism,', 'Confucius', 'Computer', 'Computed', 'Complexity', 'Combinatorics', 'Collocation', 'Code-switching', 'Cliché', 'Clerk', 'Classical', 'Chromosomes', 'Characterization', 'Casimir', 'Case', 'Cartilage', 'Carrier', 'Cardiopulmonary', 'Cardiology', 'Capillaries', 'Can', 'Calculus', 'CRISPR-Cas9', 'C6H12O6.', 'C,', 'Building', 'Buddhism', 'Boolean', 'Book', \"Bohr's\", 'Blue', 'Blood', 'Birds', 'Bilingualism', 'Big', \"Bernoulli's\", 'Bentham', \"Bell's\", \"Bayes'\", 'Bang', 'B,', 'B', 'Axiom', 'Assonance', 'Arteries', 'Armillaria', 'Arithmetic', 'Aristotle,', 'Arendt', 'Antonyms', 'Antipyretics', 'Antihistamines', 'Antibodies', 'Antibiotics', 'Anatomy', 'Anatomical', 'Anaphora', 'Analgesics', 'Ambiguity', 'Allophones', 'Alliteration', 'Algebra', 'Actuarial', 'Actions', 'Acoustics', 'Absence', 'A,', '9', '8', '78%', '7', '6', '5', '4', '3D', '3', '23', '22', '21%', '2012,', '2003,', '20', '2,000', '2', '1953.', '1915,', '1905,', '100', '1.618,', '1,', '0.9%', '0.', '0,', '(mtDNA)', '(mRNA).', '(except', '(QKD)', '(QED),', '(QCD)', '(PCR)', '(MRI)', '(F', '(ECG', '(CT)', '(CPR)', '(186,282', \"'veil\", \"'spooky\", \"'slave\", \"'master\", \"'like'\", \"'freezing'\", \"'as'.\", \"'Theory\", \"'Reverence\"]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mem.ltm.append(vocab)\n",
        "save\n",
        "print(mem.ltm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qNpmz74xRx0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3bBpnI-VYMq",
        "outputId": "c003e971-40ad-4b12-9017-55eebafdf687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        1.7000e+01, 2.6000e+01, 3.2300e+02, 1.0000e+00, 3.8600e+02, 2.0000e+00,\n",
            "        2.1000e+01, 1.8600e+02, 1.8750e+03, 9.9400e+02])\n",
            "['The', 'Rabi', 'oscillation', 'describes', 'the', 'coherent', 'oscillation', 'of', 'a', 'two-level', 'quantum', 'system', 'under', 'the', 'influence', 'of', 'an', 'external', 'oscillatory', 'field.', 'The', 'Rabi', 'oscillation', 'describes', 'the', 'coherent', 'oscillation', 'of', 'a', 'two-level', 'quantum', 'system', 'under', 'the', 'influence', 'of', 'an', 'external', 'oscillatory', 'field.']\n",
            "[('The', 'Rabi'), ('Rabi', 'oscillation'), ('oscillation', 'describes'), ('describes', 'the'), ('the', 'coherent'), ('coherent', 'oscillation'), ('oscillation', 'of'), ('of', 'a'), ('a', 'two-level'), ('two-level', 'quantum'), ('quantum', 'system'), ('system', 'under'), ('under', 'the'), ('the', 'influence'), ('influence', 'of'), ('of', 'an'), ('an', 'external'), ('external', 'oscillatory'), ('oscillatory', 'field.'), ('The', 'Rabi'), ('Rabi', 'oscillation'), ('oscillation', 'describes'), ('describes', 'the'), ('the', 'coherent'), ('coherent', 'oscillation'), ('oscillation', 'of'), ('of', 'a'), ('a', 'two-level'), ('two-level', 'quantum'), ('quantum', 'system'), ('system', 'under'), ('under', 'the'), ('the', 'influence'), ('influence', 'of'), ('of', 'an'), ('an', 'external'), ('external', 'oscillatory'), ('oscillatory', 'field.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([1.5900e+02, 1.7000e+01, 7.2500e+02, 1.0000e+00, 2.6300e+02, 2.0000e+00,\n",
            "        4.5900e+02, 1.3000e+01, 2.4370e+03, 6.0000e+00, 1.7000e+01, 4.6500e+02,\n",
            "        1.5900e+02, 1.7000e+01, 7.2500e+02, 1.0000e+00, 2.6300e+02, 2.0000e+00,\n",
            "        4.5900e+02, 1.3000e+01, 2.4370e+03, 6.0000e+00, 1.7000e+01, 4.6500e+02])\n",
            "['In', 'quantum', 'thermodynamics,', 'the', 'principles', 'of', 'thermodynamics', 'are', 'extended', 'to', 'quantum', 'systems.', 'In', 'quantum', 'thermodynamics,', 'the', 'principles', 'of', 'thermodynamics', 'are', 'extended', 'to', 'quantum', 'systems.']\n",
            "[('In', 'quantum'), ('quantum', 'thermodynamics,'), ('thermodynamics,', 'the'), ('the', 'principles'), ('principles', 'of'), ('of', 'thermodynamics'), ('thermodynamics', 'are'), ('are', 'extended'), ('extended', 'to'), ('to', 'quantum'), ('quantum', 'systems.'), ('In', 'quantum'), ('quantum', 'thermodynamics,'), ('thermodynamics,', 'the'), ('the', 'principles'), ('principles', 'of'), ('of', 'thermodynamics'), ('thermodynamics', 'are'), ('are', 'extended'), ('extended', 'to'), ('to', 'quantum'), ('quantum', 'systems.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([9.0000e+00, 1.7000e+01, 9.6400e+02, 8.5700e+02, 2.1700e+02, 3.0000e+00,\n",
            "        3.1000e+01, 6.0000e+00, 1.5300e+02, 1.2890e+03, 8.0000e+00, 5.3400e+02,\n",
            "        5.0000e+00, 1.0000e+00, 8.0100e+02, 2.0000e+00, 1.2900e+03, 8.3000e+01,\n",
            "        3.8000e+02, 9.0000e+00, 1.7000e+01, 9.6400e+02, 8.5700e+02, 2.1700e+02,\n",
            "        3.0000e+00, 3.1000e+01, 6.0000e+00, 1.5300e+02, 1.2890e+03, 8.0000e+00,\n",
            "        5.3400e+02, 5.0000e+00, 1.0000e+00, 8.0100e+02, 2.0000e+00, 1.2900e+03,\n",
            "        8.3000e+01, 3.8000e+02])\n",
            "['The', 'quantum', 'harmonic', 'oscillator', 'model', 'is', 'used', 'to', 'describe', 'vibrations', 'in', 'molecules', 'and', 'the', 'quantization', 'of', 'vibrational', 'energy', 'levels.', 'The', 'quantum', 'harmonic', 'oscillator', 'model', 'is', 'used', 'to', 'describe', 'vibrations', 'in', 'molecules', 'and', 'the', 'quantization', 'of', 'vibrational', 'energy', 'levels.']\n",
            "[('The', 'quantum'), ('quantum', 'harmonic'), ('harmonic', 'oscillator'), ('oscillator', 'model'), ('model', 'is'), ('is', 'used'), ('used', 'to'), ('to', 'describe'), ('describe', 'vibrations'), ('vibrations', 'in'), ('in', 'molecules'), ('molecules', 'and'), ('and', 'the'), ('the', 'quantization'), ('quantization', 'of'), ('of', 'vibrational'), ('vibrational', 'energy'), ('energy', 'levels.'), ('The', 'quantum'), ('quantum', 'harmonic'), ('harmonic', 'oscillator'), ('oscillator', 'model'), ('model', 'is'), ('is', 'used'), ('used', 'to'), ('to', 'describe'), ('describe', 'vibrations'), ('vibrations', 'in'), ('in', 'molecules'), ('molecules', 'and'), ('and', 'the'), ('the', 'quantization'), ('quantization', 'of'), ('of', 'vibrational'), ('vibrational', 'energy'), ('energy', 'levels.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([4.7000e+01, 2.7700e+02, 4.0600e+02, 3.4860e+03, 3.0000e+00, 4.0000e+00,\n",
            "        4.8900e+02, 4.1000e+02, 5.3500e+02, 7.0000e+00, 1.2600e+02, 1.7000e+01,\n",
            "        8.9000e+01, 6.0000e+00, 2.5040e+03, 5.0000e+00, 2.6350e+03, 2.0140e+03,\n",
            "        4.7000e+01, 2.7700e+02, 4.0600e+02, 3.4860e+03, 3.0000e+00, 4.0000e+00,\n",
            "        4.8900e+02, 4.1000e+02, 5.3500e+02, 7.0000e+00, 1.2600e+02, 1.7000e+01,\n",
            "        8.9000e+01, 6.0000e+00, 2.5040e+03, 5.0000e+00, 2.6350e+03, 2.0140e+03])\n",
            "['Quantum', 'key', 'distribution', '(QKD)', 'is', 'a', 'secure', 'communication', 'method', 'that', 'uses', 'quantum', 'mechanics', 'to', 'encrypt', 'and', 'decrypt', 'messages.', 'Quantum', 'key', 'distribution', '(QKD)', 'is', 'a', 'secure', 'communication', 'method', 'that', 'uses', 'quantum', 'mechanics', 'to', 'encrypt', 'and', 'decrypt', 'messages.']\n",
            "[('Quantum', 'key'), ('key', 'distribution'), ('distribution', '(QKD)'), ('(QKD)', 'is'), ('is', 'a'), ('a', 'secure'), ('secure', 'communication'), ('communication', 'method'), ('method', 'that'), ('that', 'uses'), ('uses', 'quantum'), ('quantum', 'mechanics'), ('mechanics', 'to'), ('to', 'encrypt'), ('encrypt', 'and'), ('and', 'decrypt'), ('decrypt', 'messages.'), ('Quantum', 'key'), ('key', 'distribution'), ('distribution', '(QKD)'), ('(QKD)', 'is'), ('is', 'a'), ('a', 'secure'), ('secure', 'communication'), ('communication', 'method'), ('method', 'that'), ('that', 'uses'), ('uses', 'quantum'), ('quantum', 'mechanics'), ('mechanics', 'to'), ('to', 'encrypt'), ('encrypt', 'and'), ('and', 'decrypt'), ('decrypt', 'messages.')]\n",
            "50\n",
            "48\n",
            "1225\n",
            "98\n",
            "tensor([9.0000e+00, 1.5400e+02, 2.0000e+00, 1.7000e+01, 1.4470e+03, 1.7500e+02,\n",
            "        6.0000e+00, 1.0000e+00, 3.5800e+02, 7.1000e+01, 2.2000e+01, 4.0000e+00,\n",
            "        1.7000e+01, 1.0850e+03, 1.6000e+01, 1.7800e+02, 4.0000e+00, 1.4220e+03,\n",
            "        7.0000e+00, 3.0000e+00, 2.2140e+03, 1.2000e+01, 1.9400e+02, 1.5500e+02,\n",
            "        2.7280e+03, 9.0000e+00, 1.5400e+02, 2.0000e+00, 1.7000e+01, 1.4470e+03,\n",
            "        1.7500e+02, 6.0000e+00, 1.0000e+00, 3.5800e+02, 7.1000e+01, 2.2000e+01,\n",
            "        4.0000e+00, 1.7000e+01, 1.0850e+03, 1.6000e+01, 1.7800e+02, 4.0000e+00,\n",
            "        1.4220e+03, 7.0000e+00, 3.0000e+00, 2.2140e+03, 1.2000e+01, 1.9400e+02,\n",
            "        1.5500e+02, 2.7280e+03])\n",
            "['The', 'concept', 'of', 'quantum', 'supremacy', 'refers', 'to', 'the', 'point', 'at', 'which', 'a', 'quantum', 'computer', 'can', 'perform', 'a', 'task', 'that', 'is', 'infeasible', 'for', 'any', 'classical', 'computer.', 'The', 'concept', 'of', 'quantum', 'supremacy', 'refers', 'to', 'the', 'point', 'at', 'which', 'a', 'quantum', 'computer', 'can', 'perform', 'a', 'task', 'that', 'is', 'infeasible', 'for', 'any', 'classical', 'computer.']\n",
            "[('The', 'concept'), ('concept', 'of'), ('of', 'quantum'), ('quantum', 'supremacy'), ('supremacy', 'refers'), ('refers', 'to'), ('to', 'the'), ('the', 'point'), ('point', 'at'), ('at', 'which'), ('which', 'a'), ('a', 'quantum'), ('quantum', 'computer'), ('computer', 'can'), ('can', 'perform'), ('perform', 'a'), ('a', 'task'), ('task', 'that'), ('that', 'is'), ('is', 'infeasible'), ('infeasible', 'for'), ('for', 'any'), ('any', 'classical'), ('classical', 'computer.'), ('The', 'concept'), ('concept', 'of'), ('of', 'quantum'), ('quantum', 'supremacy'), ('supremacy', 'refers'), ('refers', 'to'), ('to', 'the'), ('the', 'point'), ('point', 'at'), ('at', 'which'), ('which', 'a'), ('a', 'quantum'), ('quantum', 'computer'), ('computer', 'can'), ('can', 'perform'), ('perform', 'a'), ('a', 'task'), ('task', 'that'), ('that', 'is'), ('is', 'infeasible'), ('infeasible', 'for'), ('for', 'any'), ('any', 'classical'), ('classical', 'computer.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([4.7000e+01, 1.0910e+03, 5.0000e+00, 2.3100e+02, 1.3000e+01, 1.8800e+02,\n",
            "        1.2000e+01, 1.0000e+00, 8.6300e+02, 2.0000e+00, 1.7000e+01, 1.5520e+03,\n",
            "        2.2000e+01, 1.6000e+01, 3.0100e+03, 2.2760e+03, 1.7590e+03, 6.6000e+01,\n",
            "        1.5500e+02, 1.5510e+03, 4.7000e+01, 1.0910e+03, 5.0000e+00, 2.3100e+02,\n",
            "        1.3000e+01, 1.8800e+02, 1.2000e+01, 1.0000e+00, 8.6300e+02, 2.0000e+00,\n",
            "        1.7000e+01, 1.5520e+03, 2.2000e+01, 1.6000e+01, 3.0100e+03, 2.2760e+03,\n",
            "        1.7590e+03, 6.6000e+01, 1.5500e+02, 1.5510e+03])\n",
            "['Quantum', 'coherence', 'and', 'entanglement', 'are', 'essential', 'for', 'the', 'operation', 'of', 'quantum', 'sensors,', 'which', 'can', 'achieve', 'higher', 'precision', 'than', 'classical', 'sensors.', 'Quantum', 'coherence', 'and', 'entanglement', 'are', 'essential', 'for', 'the', 'operation', 'of', 'quantum', 'sensors,', 'which', 'can', 'achieve', 'higher', 'precision', 'than', 'classical', 'sensors.']\n",
            "[('Quantum', 'coherence'), ('coherence', 'and'), ('and', 'entanglement'), ('entanglement', 'are'), ('are', 'essential'), ('essential', 'for'), ('for', 'the'), ('the', 'operation'), ('operation', 'of'), ('of', 'quantum'), ('quantum', 'sensors,'), ('sensors,', 'which'), ('which', 'can'), ('can', 'achieve'), ('achieve', 'higher'), ('higher', 'precision'), ('precision', 'than'), ('than', 'classical'), ('classical', 'sensors.'), ('Quantum', 'coherence'), ('coherence', 'and'), ('and', 'entanglement'), ('entanglement', 'are'), ('are', 'essential'), ('essential', 'for'), ('for', 'the'), ('the', 'operation'), ('operation', 'of'), ('of', 'quantum'), ('quantum', 'sensors,'), ('sensors,', 'which'), ('which', 'can'), ('can', 'achieve'), ('achieve', 'higher'), ('higher', 'precision'), ('precision', 'than'), ('than', 'classical'), ('classical', 'sensors.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3062.,   17.,  299.,  126., 2940.,   55.,    7., 1009.,    8.,  713.,\n",
            "        1503.,    6.,  178., 2413.,   17., 2729., 3062.,   17.,  299.,  126.,\n",
            "        2940.,   55.,    7., 1009.,    8.,  713., 1503.,    6.,  178., 2413.,\n",
            "          17., 2729.])\n",
            "['Topological', 'quantum', 'computing', 'uses', 'anyons,', 'particles', 'that', 'exist', 'in', 'two-dimensional', 'spaces,', 'to', 'perform', 'fault-tolerant', 'quantum', 'computations.', 'Topological', 'quantum', 'computing', 'uses', 'anyons,', 'particles', 'that', 'exist', 'in', 'two-dimensional', 'spaces,', 'to', 'perform', 'fault-tolerant', 'quantum', 'computations.']\n",
            "[('Topological', 'quantum'), ('quantum', 'computing'), ('computing', 'uses'), ('uses', 'anyons,'), ('anyons,', 'particles'), ('particles', 'that'), ('that', 'exist'), ('exist', 'in'), ('in', 'two-dimensional'), ('two-dimensional', 'spaces,'), ('spaces,', 'to'), ('to', 'perform'), ('perform', 'fault-tolerant'), ('fault-tolerant', 'quantum'), ('quantum', 'computations.'), ('Topological', 'quantum'), ('quantum', 'computing'), ('computing', 'uses'), ('uses', 'anyons,'), ('anyons,', 'particles'), ('particles', 'that'), ('that', 'exist'), ('exist', 'in'), ('in', 'two-dimensional'), ('two-dimensional', 'spaces,'), ('spaces,', 'to'), ('to', 'perform'), ('perform', 'fault-tolerant'), ('fault-tolerant', 'quantum'), ('quantum', 'computations.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([9.0000e+00, 1.7000e+01, 5.3700e+02, 2.6160e+03, 2.0000e+00, 2.9090e+03,\n",
            "        5.0000e+00, 5.3400e+02, 3.9600e+02, 1.0000e+00, 1.1220e+03, 1.2000e+01,\n",
            "        1.7000e+01, 2.7790e+03, 2.2000e+01, 3.6000e+01, 1.0000e+00, 2.5180e+03,\n",
            "        7.3000e+01, 2.0000e+00, 2.7300e+02, 9.0000e+00, 1.7000e+01, 5.3700e+02,\n",
            "        2.6160e+03, 2.0000e+00, 2.9090e+03, 5.0000e+00, 5.3400e+02, 3.9600e+02,\n",
            "        1.0000e+00, 1.1220e+03, 1.2000e+01, 1.7000e+01, 2.7790e+03, 2.2000e+01,\n",
            "        3.6000e+01, 1.0000e+00, 2.5180e+03, 7.3000e+01, 2.0000e+00, 2.7300e+02])\n",
            "['The', 'quantum', 'mechanical', 'description', 'of', 'atoms', 'and', 'molecules', 'forms', 'the', 'basis', 'for', 'quantum', 'chemistry,', 'which', 'studies', 'the', 'electronic', 'structure', 'of', 'matter.', 'The', 'quantum', 'mechanical', 'description', 'of', 'atoms', 'and', 'molecules', 'forms', 'the', 'basis', 'for', 'quantum', 'chemistry,', 'which', 'studies', 'the', 'electronic', 'structure', 'of', 'matter.']\n",
            "[('The', 'quantum'), ('quantum', 'mechanical'), ('mechanical', 'description'), ('description', 'of'), ('of', 'atoms'), ('atoms', 'and'), ('and', 'molecules'), ('molecules', 'forms'), ('forms', 'the'), ('the', 'basis'), ('basis', 'for'), ('for', 'quantum'), ('quantum', 'chemistry,'), ('chemistry,', 'which'), ('which', 'studies'), ('studies', 'the'), ('the', 'electronic'), ('electronic', 'structure'), ('structure', 'of'), ('of', 'matter.'), ('The', 'quantum'), ('quantum', 'mechanical'), ('mechanical', 'description'), ('description', 'of'), ('of', 'atoms'), ('atoms', 'and'), ('and', 'molecules'), ('molecules', 'forms'), ('forms', 'the'), ('the', 'basis'), ('basis', 'for'), ('for', 'quantum'), ('quantum', 'chemistry,'), ('chemistry,', 'which'), ('which', 'studies'), ('studies', 'the'), ('the', 'electronic'), ('electronic', 'structure'), ('structure', 'of'), ('of', 'matter.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([1.5900e+02, 1.7000e+01, 2.7100e+02, 1.0000e+00, 1.7600e+02, 2.0000e+00,\n",
            "        2.7350e+03, 3.2000e+01, 7.0000e+00, 5.5000e+01, 1.6000e+01, 2.5830e+03,\n",
            "        1.0370e+03, 3.1800e+02, 1.0000e+01, 3.6500e+02, 1.7150e+03, 3.8000e+01,\n",
            "        6.7000e+01, 1.1300e+02, 4.8400e+02, 1.5900e+02, 1.7000e+01, 2.7100e+02,\n",
            "        1.0000e+00, 1.7600e+02, 2.0000e+00, 2.7350e+03, 3.2000e+01, 7.0000e+00,\n",
            "        5.5000e+01, 1.6000e+01, 2.5830e+03, 1.0370e+03, 3.1800e+02, 1.0000e+01,\n",
            "        3.6500e+02, 1.7150e+03, 3.8000e+01, 6.7000e+01, 1.1300e+02, 4.8400e+02])\n",
            "['In', 'quantum', 'mechanics,', 'the', 'principle', 'of', 'complementarity', 'states', 'that', 'particles', 'can', 'display', 'either', 'wave-like', 'or', 'particle-like', 'properties,', 'but', 'not', 'both', 'simultaneously.', 'In', 'quantum', 'mechanics,', 'the', 'principle', 'of', 'complementarity', 'states', 'that', 'particles', 'can', 'display', 'either', 'wave-like', 'or', 'particle-like', 'properties,', 'but', 'not', 'both', 'simultaneously.']\n",
            "[('In', 'quantum'), ('quantum', 'mechanics,'), ('mechanics,', 'the'), ('the', 'principle'), ('principle', 'of'), ('of', 'complementarity'), ('complementarity', 'states'), ('states', 'that'), ('that', 'particles'), ('particles', 'can'), ('can', 'display'), ('display', 'either'), ('either', 'wave-like'), ('wave-like', 'or'), ('or', 'particle-like'), ('particle-like', 'properties,'), ('properties,', 'but'), ('but', 'not'), ('not', 'both'), ('both', 'simultaneously.'), ('In', 'quantum'), ('quantum', 'mechanics,'), ('mechanics,', 'the'), ('the', 'principle'), ('principle', 'of'), ('of', 'complementarity'), ('complementarity', 'states'), ('states', 'that'), ('that', 'particles'), ('particles', 'can'), ('can', 'display'), ('display', 'either'), ('either', 'wave-like'), ('wave-like', 'or'), ('or', 'particle-like'), ('particle-like', 'properties,'), ('properties,', 'but'), ('but', 'not'), ('not', 'both'), ('both', 'simultaneously.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.2980e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 9.7700e+02,\n",
            "        3.0000e+01, 1.3040e+03, 5.0000e+00, 2.2820e+03, 8.0000e+00, 2.1900e+02,\n",
            "        1.8870e+03, 3.2980e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00,\n",
            "        9.7700e+02, 3.0000e+01, 1.3040e+03, 5.0000e+00, 2.2820e+03, 8.0000e+00,\n",
            "        2.1900e+02, 1.8870e+03])\n",
            "['Genetics', 'is', 'the', 'study', 'of', 'genes,', 'genetic', 'variation,', 'and', 'heredity', 'in', 'living', 'organisms.', 'Genetics', 'is', 'the', 'study', 'of', 'genes,', 'genetic', 'variation,', 'and', 'heredity', 'in', 'living', 'organisms.']\n",
            "[('Genetics', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'genes,'), ('genes,', 'genetic'), ('genetic', 'variation,'), ('variation,', 'and'), ('and', 'heredity'), ('heredity', 'in'), ('in', 'living'), ('living', 'organisms.'), ('Genetics', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'genes,'), ('genes,', 'genetic'), ('genetic', 'variation,'), ('variation,', 'and'), ('and', 'heredity'), ('heredity', 'in'), ('in', 'living'), ('living', 'organisms.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([3.2920e+03, 3.2170e+03, 1.0600e+02, 1.4000e+01, 1.0000e+00, 9.9700e+02,\n",
            "        2.0000e+00, 2.3330e+03, 2.9500e+02, 1.0000e+00, 8.2000e+01, 5.5400e+02,\n",
            "        2.0000e+00, 5.6000e+02, 5.2000e+01, 1.0040e+03, 1.9000e+01, 1.8360e+03,\n",
            "        1.7880e+03, 3.2920e+03, 3.2170e+03, 1.0600e+02, 1.4000e+01, 1.0000e+00,\n",
            "        9.9700e+02, 2.0000e+00, 2.3330e+03, 2.9500e+02, 1.0000e+00, 8.2000e+01,\n",
            "        5.5400e+02, 2.0000e+00, 5.6000e+02, 5.2000e+01, 1.0040e+03, 1.9000e+01,\n",
            "        1.8360e+03, 1.7880e+03])\n",
            "['Gregor', 'Mendel,', 'known', 'as', 'the', 'father', 'of', 'genetics,', 'discovered', 'the', 'fundamental', 'laws', 'of', 'inheritance', 'through', 'experiments', 'with', 'pea', 'plants.', 'Gregor', 'Mendel,', 'known', 'as', 'the', 'father', 'of', 'genetics,', 'discovered', 'the', 'fundamental', 'laws', 'of', 'inheritance', 'through', 'experiments', 'with', 'pea', 'plants.']\n",
            "[('Gregor', 'Mendel,'), ('Mendel,', 'known'), ('known', 'as'), ('as', 'the'), ('the', 'father'), ('father', 'of'), ('of', 'genetics,'), ('genetics,', 'discovered'), ('discovered', 'the'), ('the', 'fundamental'), ('fundamental', 'laws'), ('laws', 'of'), ('of', 'inheritance'), ('inheritance', 'through'), ('through', 'experiments'), ('experiments', 'with'), ('with', 'pea'), ('pea', 'plants.'), ('Gregor', 'Mendel,'), ('Mendel,', 'known'), ('known', 'as'), ('as', 'the'), ('the', 'father'), ('father', 'of'), ('of', 'genetics,'), ('genetics,', 'discovered'), ('discovered', 'the'), ('the', 'fundamental'), ('fundamental', 'laws'), ('laws', 'of'), ('of', 'inheritance'), ('inheritance', 'through'), ('through', 'experiments'), ('experiments', 'with'), ('with', 'pea'), ('pea', 'plants.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.3710e+03, 1.0000e+01, 2.6230e+03, 1.1490e+03, 3.0000e+00, 1.0000e+00,\n",
            "        1.9900e+03, 7.0000e+00, 2.8130e+03, 3.0000e+01, 9.3000e+01, 8.0000e+00,\n",
            "        6.4000e+02, 3.3710e+03, 1.0000e+01, 2.6230e+03, 1.1490e+03, 3.0000e+00,\n",
            "        1.0000e+00, 1.9900e+03, 7.0000e+00, 2.8130e+03, 3.0000e+01, 9.3000e+01,\n",
            "        8.0000e+00, 6.4000e+02])\n",
            "['DNA,', 'or', 'deoxyribonucleic', 'acid,', 'is', 'the', 'molecule', 'that', 'carries', 'genetic', 'information', 'in', 'cells.', 'DNA,', 'or', 'deoxyribonucleic', 'acid,', 'is', 'the', 'molecule', 'that', 'carries', 'genetic', 'information', 'in', 'cells.']\n",
            "[('DNA,', 'or'), ('or', 'deoxyribonucleic'), ('deoxyribonucleic', 'acid,'), ('acid,', 'is'), ('is', 'the'), ('the', 'molecule'), ('molecule', 'that'), ('that', 'carries'), ('carries', 'genetic'), ('genetic', 'information'), ('information', 'in'), ('in', 'cells.'), ('DNA,', 'or'), ('or', 'deoxyribonucleic'), ('deoxyribonucleic', 'acid,'), ('acid,', 'is'), ('is', 'the'), ('the', 'molecule'), ('molecule', 'that'), ('that', 'carries'), ('carries', 'genetic'), ('genetic', 'information'), ('information', 'in'), ('in', 'cells.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([9.0000e+00, 2.5560e+03, 2.2850e+03, 7.3000e+01, 2.0000e+00, 9.7000e+01,\n",
            "        7.0100e+02, 2.9500e+02, 1.8000e+01, 6.7200e+02, 3.0370e+03, 5.0000e+00,\n",
            "        3.3160e+03, 3.3780e+03, 8.0000e+00, 3.4740e+03, 9.0000e+00, 2.5560e+03,\n",
            "        2.2850e+03, 7.3000e+01, 2.0000e+00, 9.7000e+01, 7.0100e+02, 2.9500e+02,\n",
            "        1.8000e+01, 6.7200e+02, 3.0370e+03, 5.0000e+00, 3.3160e+03, 3.3780e+03,\n",
            "        8.0000e+00, 3.4740e+03])\n",
            "['The', 'double', 'helix', 'structure', 'of', 'DNA', 'was', 'discovered', 'by', 'James', 'Watson', 'and', 'Francis', 'Crick', 'in', '1953.', 'The', 'double', 'helix', 'structure', 'of', 'DNA', 'was', 'discovered', 'by', 'James', 'Watson', 'and', 'Francis', 'Crick', 'in', '1953.']\n",
            "[('The', 'double'), ('double', 'helix'), ('helix', 'structure'), ('structure', 'of'), ('of', 'DNA'), ('DNA', 'was'), ('was', 'discovered'), ('discovered', 'by'), ('by', 'James'), ('James', 'Watson'), ('Watson', 'and'), ('and', 'Francis'), ('Francis', 'Crick'), ('Crick', 'in'), ('in', '1953.'), ('The', 'double'), ('double', 'helix'), ('helix', 'structure'), ('structure', 'of'), ('of', 'DNA'), ('DNA', 'was'), ('was', 'discovered'), ('discovered', 'by'), ('by', 'James'), ('James', 'Watson'), ('Watson', 'and'), ('and', 'Francis'), ('Francis', 'Crick'), ('Crick', 'in'), ('in', '1953.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([3.2990e+03, 1.3000e+01, 1.5580e+03, 2.0000e+00, 9.7000e+01, 7.0000e+00,\n",
            "        1.0270e+03, 2.1900e+03, 1.2000e+01, 2.8290e+03, 8.1000e+02, 1.0000e+00,\n",
            "        5.3400e+02, 7.0000e+00, 1.7800e+02, 1.2100e+02, 2.0000e+00, 1.0000e+00,\n",
            "        2.8700e+02, 8.0000e+00, 6.4000e+02, 3.2990e+03, 1.3000e+01, 1.5580e+03,\n",
            "        2.0000e+00, 9.7000e+01, 7.0000e+00, 1.0270e+03, 2.1900e+03, 1.2000e+01,\n",
            "        2.8290e+03, 8.1000e+02, 1.0000e+00, 5.3400e+02, 7.0000e+00, 1.7800e+02,\n",
            "        1.2100e+02, 2.0000e+00, 1.0000e+00, 2.8700e+02, 8.0000e+00, 6.4000e+02])\n",
            "['Genes', 'are', 'segments', 'of', 'DNA', 'that', 'encode', 'instructions', 'for', 'building', 'proteins,', 'the', 'molecules', 'that', 'perform', 'most', 'of', 'the', 'functions', 'in', 'cells.', 'Genes', 'are', 'segments', 'of', 'DNA', 'that', 'encode', 'instructions', 'for', 'building', 'proteins,', 'the', 'molecules', 'that', 'perform', 'most', 'of', 'the', 'functions', 'in', 'cells.']\n",
            "[('Genes', 'are'), ('are', 'segments'), ('segments', 'of'), ('of', 'DNA'), ('DNA', 'that'), ('that', 'encode'), ('encode', 'instructions'), ('instructions', 'for'), ('for', 'building'), ('building', 'proteins,'), ('proteins,', 'the'), ('the', 'molecules'), ('molecules', 'that'), ('that', 'perform'), ('perform', 'most'), ('most', 'of'), ('of', 'the'), ('the', 'functions'), ('functions', 'in'), ('in', 'cells.'), ('Genes', 'are'), ('are', 'segments'), ('segments', 'of'), ('of', 'DNA'), ('DNA', 'that'), ('that', 'encode'), ('encode', 'instructions'), ('instructions', 'for'), ('for', 'building'), ('building', 'proteins,'), ('proteins,', 'the'), ('the', 'molecules'), ('molecules', 'that'), ('that', 'perform'), ('perform', 'most'), ('most', 'of'), ('of', 'the'), ('the', 'functions'), ('functions', 'in'), ('in', 'cells.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([9.0000e+00, 3.2780e+03, 3.2970e+03, 3.1420e+03, 1.0870e+03, 8.0000e+00,\n",
            "        3.4700e+03, 2.0450e+03, 1.0000e+00, 2.4970e+03, 7.0000e+01, 2.3310e+03,\n",
            "        2.2550e+03, 5.1000e+01, 1.0000e+00, 2.8600e+02, 8.0000e+00, 7.0000e+01,\n",
            "        3.3700e+03, 9.0000e+00, 3.2780e+03, 3.2970e+03, 3.1420e+03, 1.0870e+03,\n",
            "        8.0000e+00, 3.4700e+03, 2.0450e+03, 1.0000e+00, 2.4970e+03, 7.0000e+01,\n",
            "        2.3310e+03, 2.2550e+03, 5.1000e+01, 1.0000e+00, 2.8600e+02, 8.0000e+00,\n",
            "        7.0000e+01, 3.3700e+03])\n",
            "['The', 'Human', 'Genome', 'Project,', 'completed', 'in', '2003,', 'mapped', 'the', 'entire', 'human', 'genome,', 'identifying', 'all', 'the', 'genes', 'in', 'human', 'DNA.', 'The', 'Human', 'Genome', 'Project,', 'completed', 'in', '2003,', 'mapped', 'the', 'entire', 'human', 'genome,', 'identifying', 'all', 'the', 'genes', 'in', 'human', 'DNA.']\n",
            "[('The', 'Human'), ('Human', 'Genome'), ('Genome', 'Project,'), ('Project,', 'completed'), ('completed', 'in'), ('in', '2003,'), ('2003,', 'mapped'), ('mapped', 'the'), ('the', 'entire'), ('entire', 'human'), ('human', 'genome,'), ('genome,', 'identifying'), ('identifying', 'all'), ('all', 'the'), ('the', 'genes'), ('genes', 'in'), ('in', 'human'), ('human', 'DNA.'), ('The', 'Human'), ('Human', 'Genome'), ('Genome', 'Project,'), ('Project,', 'completed'), ('completed', 'in'), ('in', '2003,'), ('2003,', 'mapped'), ('mapped', 'the'), ('the', 'entire'), ('entire', 'human'), ('human', 'genome,'), ('genome,', 'identifying'), ('identifying', 'all'), ('all', 'the'), ('the', 'genes'), ('genes', 'in'), ('in', 'human'), ('human', 'DNA.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([3.2070e+03, 1.3000e+01, 1.3300e+02, 8.0000e+00, 1.0000e+00, 9.7000e+01,\n",
            "        1.7200e+02, 7.0000e+00, 1.6000e+01, 2.2100e+02, 6.0000e+00, 3.0000e+01,\n",
            "        2.9400e+02, 1.0000e+01, 2.6980e+03, 6.0000e+00, 3.0000e+01, 1.0440e+03,\n",
            "        3.2070e+03, 1.3000e+01, 1.3300e+02, 8.0000e+00, 1.0000e+00, 9.7000e+01,\n",
            "        1.7200e+02, 7.0000e+00, 1.6000e+01, 2.2100e+02, 6.0000e+00, 3.0000e+01,\n",
            "        2.9400e+02, 1.0000e+01, 2.6980e+03, 6.0000e+00, 3.0000e+01, 1.0440e+03])\n",
            "['Mutations', 'are', 'changes', 'in', 'the', 'DNA', 'sequence', 'that', 'can', 'lead', 'to', 'genetic', 'disorders', 'or', 'contribute', 'to', 'genetic', 'diversity.', 'Mutations', 'are', 'changes', 'in', 'the', 'DNA', 'sequence', 'that', 'can', 'lead', 'to', 'genetic', 'disorders', 'or', 'contribute', 'to', 'genetic', 'diversity.']\n",
            "[('Mutations', 'are'), ('are', 'changes'), ('changes', 'in'), ('in', 'the'), ('the', 'DNA'), ('DNA', 'sequence'), ('sequence', 'that'), ('that', 'can'), ('can', 'lead'), ('lead', 'to'), ('to', 'genetic'), ('genetic', 'disorders'), ('disorders', 'or'), ('or', 'contribute'), ('contribute', 'to'), ('to', 'genetic'), ('genetic', 'diversity.'), ('Mutations', 'are'), ('are', 'changes'), ('changes', 'in'), ('in', 'the'), ('the', 'DNA'), ('DNA', 'sequence'), ('sequence', 'that'), ('that', 'can'), ('can', 'lead'), ('lead', 'to'), ('to', 'genetic'), ('genetic', 'disorders'), ('disorders', 'or'), ('or', 'contribute'), ('contribute', 'to'), ('to', 'genetic'), ('genetic', 'diversity.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([ 242., 1660.,  404., 2018., 1074.,    6.,   30.,  444.,   18., 1531.,\n",
            "         305.,   35., 2269., 1094.,  242., 1660.,  404., 2018., 1074.,    6.,\n",
            "          30.,  444.,   18., 1531.,  305.,   35., 2269., 1094.])\n",
            "['Genetic', 'recombination', 'during', 'meiosis', 'contributes', 'to', 'genetic', 'variation', 'by', 'shuffling', 'alleles', 'between', 'homologous', 'chromosomes.', 'Genetic', 'recombination', 'during', 'meiosis', 'contributes', 'to', 'genetic', 'variation', 'by', 'shuffling', 'alleles', 'between', 'homologous', 'chromosomes.']\n",
            "[('Genetic', 'recombination'), ('recombination', 'during'), ('during', 'meiosis'), ('meiosis', 'contributes'), ('contributes', 'to'), ('to', 'genetic'), ('genetic', 'variation'), ('variation', 'by'), ('by', 'shuffling'), ('shuffling', 'alleles'), ('alleles', 'between'), ('between', 'homologous'), ('homologous', 'chromosomes.'), ('Genetic', 'recombination'), ('recombination', 'during'), ('during', 'meiosis'), ('meiosis', 'contributes'), ('contributes', 'to'), ('to', 'genetic'), ('genetic', 'variation'), ('variation', 'by'), ('by', 'shuffling'), ('shuffling', 'alleles'), ('alleles', 'between'), ('between', 'homologous'), ('homologous', 'chromosomes.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.2180e+03, 5.5400e+02, 2.0000e+00, 5.6000e+02, 2.2400e+02, 1.0000e+00,\n",
            "        6.8000e+01, 2.0000e+00, 1.5570e+03, 5.0000e+00, 1.0000e+00, 6.8000e+01,\n",
            "        2.0000e+00, 2.2260e+03, 2.9140e+03, 3.2180e+03, 5.5400e+02, 2.0000e+00,\n",
            "        5.6000e+02, 2.2400e+02, 1.0000e+00, 6.8000e+01, 2.0000e+00, 1.5570e+03,\n",
            "        5.0000e+00, 1.0000e+00, 6.8000e+01, 2.0000e+00, 2.2260e+03, 2.9140e+03])\n",
            "[\"Mendel's\", 'laws', 'of', 'inheritance', 'include', 'the', 'law', 'of', 'segregation', 'and', 'the', 'law', 'of', 'independent', 'assortment.', \"Mendel's\", 'laws', 'of', 'inheritance', 'include', 'the', 'law', 'of', 'segregation', 'and', 'the', 'law', 'of', 'independent', 'assortment.']\n",
            "[(\"Mendel's\", 'laws'), ('laws', 'of'), ('of', 'inheritance'), ('inheritance', 'include'), ('include', 'the'), ('the', 'law'), ('law', 'of'), ('of', 'segregation'), ('segregation', 'and'), ('and', 'the'), ('the', 'law'), ('law', 'of'), ('of', 'independent'), ('independent', 'assortment.'), (\"Mendel's\", 'laws'), ('laws', 'of'), ('of', 'inheritance'), ('inheritance', 'include'), ('include', 'the'), ('the', 'law'), ('law', 'of'), ('of', 'segregation'), ('segregation', 'and'), ('and', 'the'), ('the', 'law'), ('law', 'of'), ('of', 'independent'), ('independent', 'assortment.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([1.1000e+01, 2.3280e+03, 3.0000e+00, 1.0000e+00, 3.0000e+01, 8.9900e+02,\n",
            "        2.0000e+00, 2.1000e+01, 8.6000e+02, 1.9600e+02, 4.0000e+00, 5.1900e+02,\n",
            "        3.0000e+00, 1.0000e+00, 1.9150e+03, 3.2700e+02, 1.0000e+01, 2.7860e+03,\n",
            "        1.1000e+01, 2.3280e+03, 3.0000e+00, 1.0000e+00, 3.0000e+01, 8.9900e+02,\n",
            "        2.0000e+00, 2.1000e+01, 8.6000e+02, 1.9600e+02, 4.0000e+00, 5.1900e+02,\n",
            "        3.0000e+00, 1.0000e+00, 1.9150e+03, 3.2700e+02, 1.0000e+01, 2.7860e+03])\n",
            "['A', 'genotype', 'is', 'the', 'genetic', 'makeup', 'of', 'an', 'organism,', 'while', 'a', 'phenotype', 'is', 'the', 'observable', 'traits', 'or', 'characteristics.', 'A', 'genotype', 'is', 'the', 'genetic', 'makeup', 'of', 'an', 'organism,', 'while', 'a', 'phenotype', 'is', 'the', 'observable', 'traits', 'or', 'characteristics.']\n",
            "[('A', 'genotype'), ('genotype', 'is'), ('is', 'the'), ('the', 'genetic'), ('genetic', 'makeup'), ('makeup', 'of'), ('of', 'an'), ('an', 'organism,'), ('organism,', 'while'), ('while', 'a'), ('a', 'phenotype'), ('phenotype', 'is'), ('is', 'the'), ('the', 'observable'), ('observable', 'traits'), ('traits', 'or'), ('or', 'characteristics.'), ('A', 'genotype'), ('genotype', 'is'), ('is', 'the'), ('the', 'genetic'), ('genetic', 'makeup'), ('makeup', 'of'), ('of', 'an'), ('an', 'organism,'), ('organism,', 'while'), ('while', 'a'), ('a', 'phenotype'), ('phenotype', 'is'), ('is', 'the'), ('the', 'observable'), ('observable', 'traits'), ('traits', 'or'), ('or', 'characteristics.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.3550e+03, 3.0500e+02, 2.0410e+03, 1.0000e+00, 2.9100e+02, 2.0000e+00,\n",
            "        7.9700e+02, 3.0500e+02, 8.0000e+00, 5.7100e+02, 2.2190e+03, 3.3550e+03,\n",
            "        3.0500e+02, 2.0410e+03, 1.0000e+00, 2.9100e+02, 2.0000e+00, 7.9700e+02,\n",
            "        3.0500e+02, 8.0000e+00, 5.7100e+02, 2.2190e+03])\n",
            "['Dominant', 'alleles', 'mask', 'the', 'effects', 'of', 'recessive', 'alleles', 'in', 'heterozygous', 'individuals.', 'Dominant', 'alleles', 'mask', 'the', 'effects', 'of', 'recessive', 'alleles', 'in', 'heterozygous', 'individuals.']\n",
            "[('Dominant', 'alleles'), ('alleles', 'mask'), ('mask', 'the'), ('the', 'effects'), ('effects', 'of'), ('of', 'recessive'), ('recessive', 'alleles'), ('alleles', 'in'), ('in', 'heterozygous'), ('heterozygous', 'individuals.'), ('Dominant', 'alleles'), ('alleles', 'mask'), ('mask', 'the'), ('the', 'effects'), ('effects', 'of'), ('of', 'recessive'), ('recessive', 'alleles'), ('alleles', 'in'), ('in', 'heterozygous'), ('heterozygous', 'individuals.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3280.,  278.,   42.,   39., 2257.,  305.,   12.,    4.,  578., 2342.,\n",
            "         196.,  571.,  278.,   42.,   39.,   84., 2967., 3280.,  278.,   42.,\n",
            "          39., 2257.,  305.,   12.,    4.,  578., 2342.,  196.,  571.,  278.,\n",
            "          42.,   39.,   84., 2967.])\n",
            "['Homozygous', 'individuals', 'have', 'two', 'identical', 'alleles', 'for', 'a', 'given', 'gene,', 'while', 'heterozygous', 'individuals', 'have', 'two', 'different', 'alleles.', 'Homozygous', 'individuals', 'have', 'two', 'identical', 'alleles', 'for', 'a', 'given', 'gene,', 'while', 'heterozygous', 'individuals', 'have', 'two', 'different', 'alleles.']\n",
            "[('Homozygous', 'individuals'), ('individuals', 'have'), ('have', 'two'), ('two', 'identical'), ('identical', 'alleles'), ('alleles', 'for'), ('for', 'a'), ('a', 'given'), ('given', 'gene,'), ('gene,', 'while'), ('while', 'heterozygous'), ('heterozygous', 'individuals'), ('individuals', 'have'), ('have', 'two'), ('two', 'different'), ('different', 'alleles.'), ('Homozygous', 'individuals'), ('individuals', 'have'), ('have', 'two'), ('two', 'identical'), ('identical', 'alleles'), ('alleles', 'for'), ('for', 'a'), ('a', 'given'), ('given', 'gene,'), ('gene,', 'while'), ('while', 'heterozygous'), ('heterozygous', 'individuals'), ('individuals', 'have'), ('have', 'two'), ('two', 'different'), ('different', 'alleles.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 1.0990e+03, 2.5640e+03, 2.0000e+00, 8.8700e+02, 1.1130e+03,\n",
            "        3.2000e+01, 7.0000e+00, 3.0000e+01, 9.3000e+01, 2.3830e+03, 2.4000e+01,\n",
            "        9.7000e+01, 6.0000e+00, 1.1750e+03, 6.0000e+00, 5.1000e+02, 9.0000e+00,\n",
            "        1.0990e+03, 2.5640e+03, 2.0000e+00, 8.8700e+02, 1.1130e+03, 3.2000e+01,\n",
            "        7.0000e+00, 3.0000e+01, 9.3000e+01, 2.3830e+03, 2.4000e+01, 9.7000e+01,\n",
            "        6.0000e+00, 1.1750e+03, 6.0000e+00, 5.1000e+02])\n",
            "['The', 'central', 'dogma', 'of', 'molecular', 'biology', 'states', 'that', 'genetic', 'information', 'flows', 'from', 'DNA', 'to', 'RNA', 'to', 'protein.', 'The', 'central', 'dogma', 'of', 'molecular', 'biology', 'states', 'that', 'genetic', 'information', 'flows', 'from', 'DNA', 'to', 'RNA', 'to', 'protein.']\n",
            "[('The', 'central'), ('central', 'dogma'), ('dogma', 'of'), ('of', 'molecular'), ('molecular', 'biology'), ('biology', 'states'), ('states', 'that'), ('that', 'genetic'), ('genetic', 'information'), ('information', 'flows'), ('flows', 'from'), ('from', 'DNA'), ('DNA', 'to'), ('to', 'RNA'), ('RNA', 'to'), ('to', 'protein.'), ('The', 'central'), ('central', 'dogma'), ('dogma', 'of'), ('of', 'molecular'), ('molecular', 'biology'), ('biology', 'states'), ('states', 'that'), ('that', 'genetic'), ('genetic', 'information'), ('information', 'flows'), ('flows', 'from'), ('from', 'DNA'), ('DNA', 'to'), ('to', 'RNA'), ('RNA', 'to'), ('to', 'protein.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.0600e+03, 3.0000e+00, 1.0000e+00, 5.7000e+01, 1.8000e+01, 2.2000e+01,\n",
            "        3.0000e+01, 9.3000e+01, 8.0000e+00, 9.7000e+01, 3.0000e+00, 2.6870e+03,\n",
            "        6.9000e+01, 2.0130e+03, 1.1750e+03, 3.4840e+03, 3.0600e+03, 3.0000e+00,\n",
            "        1.0000e+00, 5.7000e+01, 1.8000e+01, 2.2000e+01, 3.0000e+01, 9.3000e+01,\n",
            "        8.0000e+00, 9.7000e+01, 3.0000e+00, 2.6870e+03, 6.9000e+01, 2.0130e+03,\n",
            "        1.1750e+03, 3.4840e+03])\n",
            "['Transcription', 'is', 'the', 'process', 'by', 'which', 'genetic', 'information', 'in', 'DNA', 'is', 'copied', 'into', 'messenger', 'RNA', '(mRNA).', 'Transcription', 'is', 'the', 'process', 'by', 'which', 'genetic', 'information', 'in', 'DNA', 'is', 'copied', 'into', 'messenger', 'RNA', '(mRNA).']\n",
            "[('Transcription', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'genetic'), ('genetic', 'information'), ('information', 'in'), ('in', 'DNA'), ('DNA', 'is'), ('is', 'copied'), ('copied', 'into'), ('into', 'messenger'), ('messenger', 'RNA'), ('RNA', '(mRNA).'), ('Transcription', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'genetic'), ('genetic', 'information'), ('information', 'in'), ('in', 'DNA'), ('DNA', 'is'), ('is', 'copied'), ('copied', 'into'), ('into', 'messenger'), ('messenger', 'RNA'), ('RNA', '(mRNA).')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1650e+03, 3.0000e+00, 1.0000e+00, 5.7000e+01, 1.8000e+01, 2.2000e+01,\n",
            "        2.0580e+03, 3.0000e+00, 2.6380e+03, 1.8000e+01, 1.5880e+03, 6.0000e+00,\n",
            "        1.0100e+02, 4.0000e+00, 8.0000e+01, 5.1000e+02, 1.1650e+03, 3.0000e+00,\n",
            "        1.0000e+00, 5.7000e+01, 1.8000e+01, 2.2000e+01, 2.0580e+03, 3.0000e+00,\n",
            "        2.6380e+03, 1.8000e+01, 1.5880e+03, 6.0000e+00, 1.0100e+02, 4.0000e+00,\n",
            "        8.0000e+01, 5.1000e+02])\n",
            "['Translation', 'is', 'the', 'process', 'by', 'which', 'mRNA', 'is', 'decoded', 'by', 'ribosomes', 'to', 'produce', 'a', 'specific', 'protein.', 'Translation', 'is', 'the', 'process', 'by', 'which', 'mRNA', 'is', 'decoded', 'by', 'ribosomes', 'to', 'produce', 'a', 'specific', 'protein.']\n",
            "[('Translation', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'mRNA'), ('mRNA', 'is'), ('is', 'decoded'), ('decoded', 'by'), ('by', 'ribosomes'), ('ribosomes', 'to'), ('to', 'produce'), ('produce', 'a'), ('a', 'specific'), ('specific', 'protein.'), ('Translation', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'mRNA'), ('mRNA', 'is'), ('is', 'decoded'), ('decoded', 'by'), ('by', 'ribosomes'), ('ribosomes', 'to'), ('to', 'produce'), ('produce', 'a'), ('a', 'specific'), ('specific', 'protein.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.1300e+03, 1.0000e+01, 1.5890e+03, 1.1490e+03, 3.0000e+00, 4.0000e+00,\n",
            "        1.9270e+03, 3.0080e+03, 9.3600e+02, 8.0000e+00, 1.7090e+03, 1.4300e+03,\n",
            "        5.0000e+00, 1.4800e+02, 1.6360e+03, 3.1300e+03, 1.0000e+01, 1.5890e+03,\n",
            "        1.1490e+03, 3.0000e+00, 4.0000e+00, 1.9270e+03, 3.0080e+03, 9.3600e+02,\n",
            "        8.0000e+00, 1.7090e+03, 1.4300e+03, 5.0000e+00, 1.4800e+02, 1.6360e+03])\n",
            "['RNA,', 'or', 'ribonucleic', 'acid,', 'is', 'a', 'nucleic', 'acid', 'involved', 'in', 'protein', 'synthesis', 'and', 'gene', 'regulation.', 'RNA,', 'or', 'ribonucleic', 'acid,', 'is', 'a', 'nucleic', 'acid', 'involved', 'in', 'protein', 'synthesis', 'and', 'gene', 'regulation.']\n",
            "[('RNA,', 'or'), ('or', 'ribonucleic'), ('ribonucleic', 'acid,'), ('acid,', 'is'), ('is', 'a'), ('a', 'nucleic'), ('nucleic', 'acid'), ('acid', 'involved'), ('involved', 'in'), ('in', 'protein'), ('protein', 'synthesis'), ('synthesis', 'and'), ('and', 'gene'), ('gene', 'regulation.'), ('RNA,', 'or'), ('or', 'ribonucleic'), ('ribonucleic', 'acid,'), ('acid,', 'is'), ('is', 'a'), ('a', 'nucleic'), ('nucleic', 'acid'), ('acid', 'involved'), ('involved', 'in'), ('in', 'protein'), ('protein', 'synthesis'), ('synthesis', 'and'), ('and', 'gene'), ('gene', 'regulation.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.3990e+03, 1.3000e+01, 9.0700e+02, 1.3890e+03, 2.0700e+02, 5.4400e+02,\n",
            "        2.0000e+00, 9.7000e+01, 5.0000e+00, 5.0900e+02, 7.0000e+00, 4.1600e+02,\n",
            "        3.0000e+01, 9.4900e+02, 3.3990e+03, 1.3000e+01, 9.0700e+02, 1.3890e+03,\n",
            "        2.0700e+02, 5.4400e+02, 2.0000e+00, 9.7000e+01, 5.0000e+00, 5.0900e+02,\n",
            "        7.0000e+00, 4.1600e+02, 3.0000e+01, 9.4900e+02])\n",
            "['Chromosomes', 'are', 'long,', 'thread-like', 'structures', 'made', 'of', 'DNA', 'and', 'proteins', 'that', 'carry', 'genetic', 'information.', 'Chromosomes', 'are', 'long,', 'thread-like', 'structures', 'made', 'of', 'DNA', 'and', 'proteins', 'that', 'carry', 'genetic', 'information.']\n",
            "[('Chromosomes', 'are'), ('are', 'long,'), ('long,', 'thread-like'), ('thread-like', 'structures'), ('structures', 'made'), ('made', 'of'), ('of', 'DNA'), ('DNA', 'and'), ('and', 'proteins'), ('proteins', 'that'), ('that', 'carry'), ('carry', 'genetic'), ('genetic', 'information.'), ('Chromosomes', 'are'), ('are', 'long,'), ('long,', 'thread-like'), ('thread-like', 'structures'), ('structures', 'made'), ('made', 'of'), ('of', 'DNA'), ('DNA', 'and'), ('and', 'proteins'), ('proteins', 'that'), ('that', 'carry'), ('carry', 'genetic'), ('genetic', 'information.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.2770e+03, 4.2000e+01, 3.4660e+03, 8.5300e+02, 2.0000e+00, 2.7720e+03,\n",
            "        1.4700e+02, 3.4670e+03, 8.5300e+02, 2.0000e+00, 2.8990e+03, 5.0000e+00,\n",
            "        3.7000e+01, 5.2300e+02, 2.0000e+00, 1.5390e+03, 1.0940e+03, 3.2770e+03,\n",
            "        4.2000e+01, 3.4660e+03, 8.5300e+02, 2.0000e+00, 2.7720e+03, 1.4700e+02,\n",
            "        3.4670e+03, 8.5300e+02, 2.0000e+00, 2.8990e+03, 5.0000e+00, 3.7000e+01,\n",
            "        5.2300e+02, 2.0000e+00, 1.5390e+03, 1.0940e+03])\n",
            "['Humans', 'have', '23', 'pairs', 'of', 'chromosomes,', 'including', '22', 'pairs', 'of', 'autosomes', 'and', 'one', 'pair', 'of', 'sex', 'chromosomes.', 'Humans', 'have', '23', 'pairs', 'of', 'chromosomes,', 'including', '22', 'pairs', 'of', 'autosomes', 'and', 'one', 'pair', 'of', 'sex', 'chromosomes.']\n",
            "[('Humans', 'have'), ('have', '23'), ('23', 'pairs'), ('pairs', 'of'), ('of', 'chromosomes,'), ('chromosomes,', 'including'), ('including', '22'), ('22', 'pairs'), ('pairs', 'of'), ('of', 'autosomes'), ('autosomes', 'and'), ('and', 'one'), ('one', 'pair'), ('pair', 'of'), ('of', 'sex'), ('sex', 'chromosomes.'), ('Humans', 'have'), ('have', '23'), ('23', 'pairs'), ('pairs', 'of'), ('of', 'chromosomes,'), ('chromosomes,', 'including'), ('including', '22'), ('22', 'pairs'), ('pairs', 'of'), ('of', 'autosomes'), ('autosomes', 'and'), ('and', 'one'), ('one', 'pair'), ('pair', 'of'), ('of', 'sex'), ('sex', 'chromosomes.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([   9., 1160.,    5., 1158., 2773., 1058.,   21., 2221., 1538.,   19.,\n",
            "        3024.,  192.,  996.,    5., 3023.,  192., 2049.,    9., 1160.,    5.,\n",
            "        1158., 2773., 1058.,   21., 2221., 1538.,   19., 3024.,  192.,  996.,\n",
            "           5., 3023.,  192., 2049.])\n",
            "['The', 'X', 'and', 'Y', 'chromosomes', 'determine', 'an', \"individual's\", 'sex,', 'with', 'XX', 'being', 'female', 'and', 'XY', 'being', 'male.', 'The', 'X', 'and', 'Y', 'chromosomes', 'determine', 'an', \"individual's\", 'sex,', 'with', 'XX', 'being', 'female', 'and', 'XY', 'being', 'male.']\n",
            "[('The', 'X'), ('X', 'and'), ('and', 'Y'), ('Y', 'chromosomes'), ('chromosomes', 'determine'), ('determine', 'an'), ('an', \"individual's\"), (\"individual's\", 'sex,'), ('sex,', 'with'), ('with', 'XX'), ('XX', 'being'), ('being', 'female'), ('female', 'and'), ('and', 'XY'), ('XY', 'being'), ('being', 'male.'), ('The', 'X'), ('X', 'and'), ('and', 'Y'), ('Y', 'chromosomes'), ('chromosomes', 'determine'), ('determine', 'an'), ('an', \"individual's\"), (\"individual's\", 'sex,'), ('sex,', 'with'), ('with', 'XX'), ('XX', 'being'), ('being', 'female'), ('female', 'and'), ('and', 'XY'), ('XY', 'being'), ('being', 'male.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.3370e+03, 3.6000e+01, 2.2810e+03, 1.3300e+02, 8.0000e+00, 1.4800e+02,\n",
            "        1.8700e+02, 7.0000e+00, 2.3300e+02, 6.7000e+01, 3.8400e+02, 1.3300e+02,\n",
            "        6.0000e+00, 1.0000e+00, 7.1100e+02, 9.7000e+01, 1.5470e+03, 3.3370e+03,\n",
            "        3.6000e+01, 2.2810e+03, 1.3300e+02, 8.0000e+00, 1.4800e+02, 1.8700e+02,\n",
            "        7.0000e+00, 2.3300e+02, 6.7000e+01, 3.8400e+02, 1.3300e+02, 6.0000e+00,\n",
            "        1.0000e+00, 7.1100e+02, 9.7000e+01, 1.5470e+03])\n",
            "['Epigenetics', 'studies', 'heritable', 'changes', 'in', 'gene', 'expression', 'that', 'do', 'not', 'involve', 'changes', 'to', 'the', 'underlying', 'DNA', 'sequence.', 'Epigenetics', 'studies', 'heritable', 'changes', 'in', 'gene', 'expression', 'that', 'do', 'not', 'involve', 'changes', 'to', 'the', 'underlying', 'DNA', 'sequence.']\n",
            "[('Epigenetics', 'studies'), ('studies', 'heritable'), ('heritable', 'changes'), ('changes', 'in'), ('in', 'gene'), ('gene', 'expression'), ('expression', 'that'), ('that', 'do'), ('do', 'not'), ('not', 'involve'), ('involve', 'changes'), ('changes', 'to'), ('to', 'the'), ('the', 'underlying'), ('underlying', 'DNA'), ('DNA', 'sequence.'), ('Epigenetics', 'studies'), ('studies', 'heritable'), ('heritable', 'changes'), ('changes', 'in'), ('in', 'gene'), ('gene', 'expression'), ('expression', 'that'), ('that', 'do'), ('do', 'not'), ('not', 'involve'), ('involve', 'changes'), ('changes', 'to'), ('to', 'the'), ('the', 'underlying'), ('underlying', 'DNA'), ('DNA', 'sequence.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.4100e+03, 3.0000e+00, 4.0000e+00, 1.5960e+03, 2.3410e+03, 3.3200e+02,\n",
            "        7.0000e+00, 6.5500e+02, 1.2000e+01, 1.7600e+03, 1.9910e+03, 2.0000e+00,\n",
            "        9.7000e+01, 1.5450e+03, 3.4100e+03, 3.0000e+00, 4.0000e+00, 1.5960e+03,\n",
            "        2.3410e+03, 3.3200e+02, 7.0000e+00, 6.5500e+02, 1.2000e+01, 1.7600e+03,\n",
            "        1.9910e+03, 2.0000e+00, 9.7000e+01, 1.5450e+03])\n",
            "['CRISPR-Cas9', 'is', 'a', 'revolutionary', 'gene-editing', 'technology', 'that', 'allows', 'for', 'precise', 'modification', 'of', 'DNA', 'sequences.', 'CRISPR-Cas9', 'is', 'a', 'revolutionary', 'gene-editing', 'technology', 'that', 'allows', 'for', 'precise', 'modification', 'of', 'DNA', 'sequences.']\n",
            "[('CRISPR-Cas9', 'is'), ('is', 'a'), ('a', 'revolutionary'), ('revolutionary', 'gene-editing'), ('gene-editing', 'technology'), ('technology', 'that'), ('that', 'allows'), ('allows', 'for'), ('for', 'precise'), ('precise', 'modification'), ('modification', 'of'), ('of', 'DNA'), ('DNA', 'sequences.'), ('CRISPR-Cas9', 'is'), ('is', 'a'), ('a', 'revolutionary'), ('revolutionary', 'gene-editing'), ('gene-editing', 'technology'), ('technology', 'that'), ('that', 'allows'), ('allows', 'for'), ('for', 'precise'), ('precise', 'modification'), ('modification', 'of'), ('of', 'DNA'), ('DNA', 'sequences.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([2.4200e+02, 2.0920e+03, 1.4200e+02, 1.2500e+02, 2.8600e+02, 3.7800e+02,\n",
            "        1.0920e+03, 6.0000e+00, 2.9200e+02, 5.8000e+01, 2.3000e+01, 1.0000e+00,\n",
            "        1.7300e+02, 6.3900e+02, 1.3000e+01, 9.4800e+02, 1.3780e+03, 2.4200e+02,\n",
            "        2.0920e+03, 1.4200e+02, 1.2500e+02, 2.8600e+02, 3.7800e+02, 1.0920e+03,\n",
            "        6.0000e+00, 2.9200e+02, 5.8000e+01, 2.3000e+01, 1.0000e+00, 1.7300e+02,\n",
            "        6.3900e+02, 1.3000e+01, 9.4800e+02, 1.3780e+03])\n",
            "['Genetic', 'linkage', 'occurs', 'when', 'genes', 'located', 'close', 'to', 'each', 'other', 'on', 'the', 'same', 'chromosome', 'are', 'inherited', 'together.', 'Genetic', 'linkage', 'occurs', 'when', 'genes', 'located', 'close', 'to', 'each', 'other', 'on', 'the', 'same', 'chromosome', 'are', 'inherited', 'together.']\n",
            "[('Genetic', 'linkage'), ('linkage', 'occurs'), ('occurs', 'when'), ('when', 'genes'), ('genes', 'located'), ('located', 'close'), ('close', 'to'), ('to', 'each'), ('each', 'other'), ('other', 'on'), ('on', 'the'), ('the', 'same'), ('same', 'chromosome'), ('chromosome', 'are'), ('are', 'inherited'), ('inherited', 'together.'), ('Genetic', 'linkage'), ('linkage', 'occurs'), ('occurs', 'when'), ('when', 'genes'), ('genes', 'located'), ('located', 'close'), ('close', 'to'), ('to', 'each'), ('each', 'other'), ('other', 'on'), ('on', 'the'), ('the', 'same'), ('same', 'chromosome'), ('chromosome', 'are'), ('are', 'inherited'), ('inherited', 'together.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([1.1000e+01, 3.0000e+01, 2.0460e+03, 7.7300e+02, 1.0000e+00, 5.0100e+02,\n",
            "        1.7700e+03, 2.0000e+00, 2.8600e+02, 2.3000e+01, 4.0000e+00, 6.3900e+02,\n",
            "        1.5700e+02, 2.3000e+01, 1.0000e+00, 3.9400e+02, 2.0000e+00, 1.6590e+03,\n",
            "        1.1000e+01, 3.0000e+01, 2.0460e+03, 7.7300e+02, 1.0000e+00, 5.0100e+02,\n",
            "        1.7700e+03, 2.0000e+00, 2.8600e+02, 2.3000e+01, 4.0000e+00, 6.3900e+02,\n",
            "        1.5700e+02, 2.3000e+01, 1.0000e+00, 3.9400e+02, 2.0000e+00, 1.6590e+03])\n",
            "['A', 'genetic', 'map', 'shows', 'the', 'relative', 'positions', 'of', 'genes', 'on', 'a', 'chromosome', 'based', 'on', 'the', 'frequency', 'of', 'recombination.', 'A', 'genetic', 'map', 'shows', 'the', 'relative', 'positions', 'of', 'genes', 'on', 'a', 'chromosome', 'based', 'on', 'the', 'frequency', 'of', 'recombination.']\n",
            "[('A', 'genetic'), ('genetic', 'map'), ('map', 'shows'), ('shows', 'the'), ('the', 'relative'), ('relative', 'positions'), ('positions', 'of'), ('of', 'genes'), ('genes', 'on'), ('on', 'a'), ('a', 'chromosome'), ('chromosome', 'based'), ('based', 'on'), ('on', 'the'), ('the', 'frequency'), ('frequency', 'of'), ('of', 'recombination.'), ('A', 'genetic'), ('genetic', 'map'), ('map', 'shows'), ('shows', 'the'), ('the', 'relative'), ('relative', 'positions'), ('positions', 'of'), ('of', 'genes'), ('genes', 'on'), ('on', 'a'), ('a', 'chromosome'), ('chromosome', 'based'), ('based', 'on'), ('on', 'the'), ('the', 'frequency'), ('frequency', 'of'), ('of', 'recombination.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.1500e+03, 3.2700e+02, 1.3000e+01, 1.0730e+03, 1.8000e+01, 5.3200e+02,\n",
            "        9.7700e+02, 2.9200e+02, 2.6960e+03, 6.0000e+00, 1.0000e+00, 5.1900e+02,\n",
            "        8.0000e+00, 4.0000e+00, 4.8200e+02, 1.2660e+03, 3.1500e+03, 3.2700e+02,\n",
            "        1.3000e+01, 1.0730e+03, 1.8000e+01, 5.3200e+02, 9.7700e+02, 2.9200e+02,\n",
            "        2.6960e+03, 6.0000e+00, 1.0000e+00, 5.1900e+02, 8.0000e+00, 4.0000e+00,\n",
            "        4.8200e+02, 1.2660e+03])\n",
            "['Polygenic', 'traits', 'are', 'controlled', 'by', 'multiple', 'genes,', 'each', 'contributing', 'to', 'the', 'phenotype', 'in', 'a', 'small', 'way.', 'Polygenic', 'traits', 'are', 'controlled', 'by', 'multiple', 'genes,', 'each', 'contributing', 'to', 'the', 'phenotype', 'in', 'a', 'small', 'way.']\n",
            "[('Polygenic', 'traits'), ('traits', 'are'), ('are', 'controlled'), ('controlled', 'by'), ('by', 'multiple'), ('multiple', 'genes,'), ('genes,', 'each'), ('each', 'contributing'), ('contributing', 'to'), ('to', 'the'), ('the', 'phenotype'), ('phenotype', 'in'), ('in', 'a'), ('a', 'small'), ('small', 'way.'), ('Polygenic', 'traits'), ('traits', 'are'), ('are', 'controlled'), ('controlled', 'by'), ('by', 'multiple'), ('multiple', 'genes,'), ('genes,', 'each'), ('each', 'contributing'), ('contributing', 'to'), ('to', 'the'), ('the', 'phenotype'), ('phenotype', 'in'), ('in', 'a'), ('a', 'small'), ('small', 'way.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.2120e+03, 9.7000e+01, 3.4830e+03, 3.0000e+00, 9.4800e+02, 2.0370e+03,\n",
            "        5.0000e+00, 1.6000e+01, 2.5000e+01, 3.1000e+01, 6.0000e+00, 7.1700e+02,\n",
            "        2.0380e+03, 2.0970e+03, 3.2120e+03, 9.7000e+01, 3.4830e+03, 3.0000e+00,\n",
            "        9.4800e+02, 2.0370e+03, 5.0000e+00, 1.6000e+01, 2.5000e+01, 3.1000e+01,\n",
            "        6.0000e+00, 7.1700e+02, 2.0380e+03, 2.0970e+03])\n",
            "['Mitochondrial', 'DNA', '(mtDNA)', 'is', 'inherited', 'maternally', 'and', 'can', 'be', 'used', 'to', 'trace', 'maternal', 'lineage.', 'Mitochondrial', 'DNA', '(mtDNA)', 'is', 'inherited', 'maternally', 'and', 'can', 'be', 'used', 'to', 'trace', 'maternal', 'lineage.']\n",
            "[('Mitochondrial', 'DNA'), ('DNA', '(mtDNA)'), ('(mtDNA)', 'is'), ('is', 'inherited'), ('inherited', 'maternally'), ('maternally', 'and'), ('and', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'to'), ('to', 'trace'), ('trace', 'maternal'), ('maternal', 'lineage.'), ('Mitochondrial', 'DNA'), ('DNA', '(mtDNA)'), ('(mtDNA)', 'is'), ('is', 'inherited'), ('inherited', 'maternally'), ('maternally', 'and'), ('and', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'to'), ('to', 'trace'), ('trace', 'maternal'), ('maternal', 'lineage.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([2.4200e+02, 2.5500e+03, 3.0000e+00, 4.0000e+00, 2.0240e+03, 2.0000e+00,\n",
            "        1.0120e+03, 7.0000e+00, 2.3700e+02, 6.5600e+02, 5.9000e+02, 6.0000e+00,\n",
            "        8.5000e+01, 1.6810e+03, 8.0000e+00, 4.0000e+00, 5.1700e+02, 2.4200e+02,\n",
            "        2.5500e+03, 3.0000e+00, 4.0000e+00, 2.0240e+03, 2.0000e+00, 1.0120e+03,\n",
            "        7.0000e+00, 2.3700e+02, 6.5600e+02, 5.9000e+02, 6.0000e+00, 8.5000e+01,\n",
            "        1.6810e+03, 8.0000e+00, 4.0000e+00, 5.1700e+02])\n",
            "['Genetic', 'drift', 'is', 'a', 'mechanism', 'of', 'evolution', 'that', 'causes', 'allele', 'frequencies', 'to', 'change', 'randomly', 'in', 'a', 'population.', 'Genetic', 'drift', 'is', 'a', 'mechanism', 'of', 'evolution', 'that', 'causes', 'allele', 'frequencies', 'to', 'change', 'randomly', 'in', 'a', 'population.']\n",
            "[('Genetic', 'drift'), ('drift', 'is'), ('is', 'a'), ('a', 'mechanism'), ('mechanism', 'of'), ('of', 'evolution'), ('evolution', 'that'), ('that', 'causes'), ('causes', 'allele'), ('allele', 'frequencies'), ('frequencies', 'to'), ('to', 'change'), ('change', 'randomly'), ('randomly', 'in'), ('in', 'a'), ('a', 'population.'), ('Genetic', 'drift'), ('drift', 'is'), ('is', 'a'), ('a', 'mechanism'), ('mechanism', 'of'), ('of', 'evolution'), ('evolution', 'that'), ('that', 'causes'), ('causes', 'allele'), ('allele', 'frequencies'), ('frequencies', 'to'), ('to', 'change'), ('change', 'randomly'), ('randomly', 'in'), ('in', 'a'), ('a', 'population.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([1.1810e+03, 4.8800e+02, 3.0000e+00, 1.0000e+00, 5.7000e+01, 1.8000e+01,\n",
            "        2.2000e+01, 2.9820e+03, 3.0000e+01, 3.2700e+02, 1.1210e+03, 6.0000e+01,\n",
            "        9.6000e+01, 8.0000e+00, 4.0000e+00, 8.3100e+02, 7.4000e+01, 2.4900e+02,\n",
            "        1.1810e+03, 4.8800e+02, 3.0000e+00, 1.0000e+00, 5.7000e+01, 1.8000e+01,\n",
            "        2.2000e+01, 2.9820e+03, 3.0000e+01, 3.2700e+02, 1.1210e+03, 6.0000e+01,\n",
            "        9.6000e+01, 8.0000e+00, 4.0000e+00, 8.3100e+02, 7.4000e+01, 2.4900e+02])\n",
            "['Natural', 'selection', 'is', 'the', 'process', 'by', 'which', 'advantageous', 'genetic', 'traits', 'become', 'more', 'common', 'in', 'a', 'population', 'over', 'time.', 'Natural', 'selection', 'is', 'the', 'process', 'by', 'which', 'advantageous', 'genetic', 'traits', 'become', 'more', 'common', 'in', 'a', 'population', 'over', 'time.']\n",
            "[('Natural', 'selection'), ('selection', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'advantageous'), ('advantageous', 'genetic'), ('genetic', 'traits'), ('traits', 'become'), ('become', 'more'), ('more', 'common'), ('common', 'in'), ('in', 'a'), ('a', 'population'), ('population', 'over'), ('over', 'time.'), ('Natural', 'selection'), ('selection', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'advantageous'), ('advantageous', 'genetic'), ('genetic', 'traits'), ('traits', 'become'), ('become', 'more'), ('more', 'common'), ('common', 'in'), ('in', 'a'), ('a', 'population'), ('population', 'over'), ('over', 'time.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([1.1000e+01, 1.4800e+02, 8.3200e+02, 3.0000e+00, 1.0000e+00, 1.0880e+03,\n",
            "        1.2800e+02, 2.0000e+00, 3.0000e+01, 9.3000e+01, 1.6400e+02, 4.0000e+00,\n",
            "        5.1700e+02, 1.1000e+01, 1.4800e+02, 8.3200e+02, 3.0000e+00, 1.0000e+00,\n",
            "        1.0880e+03, 1.2800e+02, 2.0000e+00, 3.0000e+01, 9.3000e+01, 1.6400e+02,\n",
            "        4.0000e+00, 5.1700e+02])\n",
            "['A', 'gene', 'pool', 'is', 'the', 'complete', 'set', 'of', 'genetic', 'information', 'within', 'a', 'population.', 'A', 'gene', 'pool', 'is', 'the', 'complete', 'set', 'of', 'genetic', 'information', 'within', 'a', 'population.']\n",
            "[('A', 'gene'), ('gene', 'pool'), ('pool', 'is'), ('is', 'the'), ('the', 'complete'), ('complete', 'set'), ('set', 'of'), ('of', 'genetic'), ('genetic', 'information'), ('information', 'within'), ('within', 'a'), ('a', 'population.'), ('A', 'gene'), ('gene', 'pool'), ('pool', 'is'), ('is', 'the'), ('the', 'complete'), ('complete', 'set'), ('set', 'of'), ('of', 'genetic'), ('genetic', 'information'), ('information', 'within'), ('within', 'a'), ('a', 'population.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([4.3700e+02, 5.9300e+02, 3.0000e+00, 1.0000e+00, 1.3650e+03, 2.0000e+00,\n",
            "        3.0000e+01, 2.7500e+02, 3.5000e+01, 1.7730e+03, 2.2000e+01, 1.6000e+01,\n",
            "        9.5300e+02, 3.0000e+01, 1.0440e+03, 4.3700e+02, 5.9300e+02, 3.0000e+00,\n",
            "        1.0000e+00, 1.3650e+03, 2.0000e+00, 3.0000e+01, 2.7500e+02, 3.5000e+01,\n",
            "        1.7730e+03, 2.2000e+01, 1.6000e+01, 9.5300e+02, 3.0000e+01, 1.0440e+03])\n",
            "['Gene', 'flow', 'is', 'the', 'transfer', 'of', 'genetic', 'material', 'between', 'populations,', 'which', 'can', 'increase', 'genetic', 'diversity.', 'Gene', 'flow', 'is', 'the', 'transfer', 'of', 'genetic', 'material', 'between', 'populations,', 'which', 'can', 'increase', 'genetic', 'diversity.']\n",
            "[('Gene', 'flow'), ('flow', 'is'), ('is', 'the'), ('the', 'transfer'), ('transfer', 'of'), ('of', 'genetic'), ('genetic', 'material'), ('material', 'between'), ('between', 'populations,'), ('populations,', 'which'), ('which', 'can'), ('can', 'increase'), ('increase', 'genetic'), ('genetic', 'diversity.'), ('Gene', 'flow'), ('flow', 'is'), ('is', 'the'), ('the', 'transfer'), ('transfer', 'of'), ('of', 'genetic'), ('genetic', 'material'), ('material', 'between'), ('between', 'populations,'), ('populations,', 'which'), ('which', 'can'), ('can', 'increase'), ('increase', 'genetic'), ('genetic', 'diversity.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.1000e+03, 1.1010e+03, 2.9490e+03, 3.0000e+00, 4.0000e+00, 3.0000e+01,\n",
            "        1.0470e+03, 4.1500e+02, 1.8000e+01, 4.0000e+00, 8.8100e+02, 8.0000e+00,\n",
            "        1.0000e+00, 2.2840e+03, 2.3400e+03, 3.1000e+03, 1.1010e+03, 2.9490e+03,\n",
            "        3.0000e+00, 4.0000e+00, 3.0000e+01, 1.0470e+03, 4.1500e+02, 1.8000e+01,\n",
            "        4.0000e+00, 8.8100e+02, 8.0000e+00, 1.0000e+00, 2.2840e+03, 2.3400e+03])\n",
            "['Sickle', 'cell', 'anemia', 'is', 'a', 'genetic', 'disorder', 'caused', 'by', 'a', 'mutation', 'in', 'the', 'hemoglobin', 'gene.', 'Sickle', 'cell', 'anemia', 'is', 'a', 'genetic', 'disorder', 'caused', 'by', 'a', 'mutation', 'in', 'the', 'hemoglobin', 'gene.']\n",
            "[('Sickle', 'cell'), ('cell', 'anemia'), ('anemia', 'is'), ('is', 'a'), ('a', 'genetic'), ('genetic', 'disorder'), ('disorder', 'caused'), ('caused', 'by'), ('by', 'a'), ('a', 'mutation'), ('mutation', 'in'), ('in', 'the'), ('the', 'hemoglobin'), ('hemoglobin', 'gene.'), ('Sickle', 'cell'), ('cell', 'anemia'), ('anemia', 'is'), ('is', 'a'), ('a', 'genetic'), ('genetic', 'disorder'), ('disorder', 'caused'), ('caused', 'by'), ('by', 'a'), ('a', 'mutation'), ('mutation', 'in'), ('in', 'the'), ('the', 'hemoglobin'), ('hemoglobin', 'gene.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([ 242., 2680.,  139.,   93.,    5.,  469.,    6.,  278.,   19.,   30.,\n",
            "         294.,   10.,  456.,   71., 1582.,  242., 2680.,  139.,   93.,    5.,\n",
            "         469.,    6.,  278.,   19.,   30.,  294.,   10.,  456.,   71., 1582.])\n",
            "['Genetic', 'counseling', 'provides', 'information', 'and', 'support', 'to', 'individuals', 'with', 'genetic', 'disorders', 'or', 'those', 'at', 'risk.', 'Genetic', 'counseling', 'provides', 'information', 'and', 'support', 'to', 'individuals', 'with', 'genetic', 'disorders', 'or', 'those', 'at', 'risk.']\n",
            "[('Genetic', 'counseling'), ('counseling', 'provides'), ('provides', 'information'), ('information', 'and'), ('and', 'support'), ('support', 'to'), ('to', 'individuals'), ('individuals', 'with'), ('with', 'genetic'), ('genetic', 'disorders'), ('disorders', 'or'), ('or', 'those'), ('those', 'at'), ('at', 'risk.'), ('Genetic', 'counseling'), ('counseling', 'provides'), ('provides', 'information'), ('information', 'and'), ('and', 'support'), ('support', 'to'), ('to', 'individuals'), ('individuals', 'with'), ('with', 'genetic'), ('genetic', 'disorders'), ('disorders', 'or'), ('or', 'those'), ('those', 'at'), ('at', 'risk.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3404., 1563.,  732.,   16., 2256.,  278.,   86.,  416.,    4.,  148.,\n",
            "          12.,    4.,  797.,   30., 2587., 3404., 1563.,  732.,   16., 2256.,\n",
            "         278.,   86.,  416.,    4.,  148.,   12.,    4.,  797.,   30., 2587.])\n",
            "['Carrier', 'screening', 'tests', 'can', 'identify', 'individuals', 'who', 'carry', 'a', 'gene', 'for', 'a', 'recessive', 'genetic', 'disorder.', 'Carrier', 'screening', 'tests', 'can', 'identify', 'individuals', 'who', 'carry', 'a', 'gene', 'for', 'a', 'recessive', 'genetic', 'disorder.']\n",
            "[('Carrier', 'screening'), ('screening', 'tests'), ('tests', 'can'), ('can', 'identify'), ('identify', 'individuals'), ('individuals', 'who'), ('who', 'carry'), ('carry', 'a'), ('a', 'gene'), ('gene', 'for'), ('for', 'a'), ('a', 'recessive'), ('recessive', 'genetic'), ('genetic', 'disorder.'), ('Carrier', 'screening'), ('screening', 'tests'), ('tests', 'can'), ('can', 'identify'), ('identify', 'individuals'), ('individuals', 'who'), ('who', 'carry'), ('carry', 'a'), ('a', 'gene'), ('gene', 'for'), ('for', 'a'), ('a', 'recessive'), ('recessive', 'genetic'), ('genetic', 'disorder.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([ 242., 1406.,   16.,  617.,   30.,  633., 1758.,  615., 1583.,    5.,\n",
            "        2208.,   81.,  325., 1066.,  242., 1406.,   16.,  617.,   30.,  633.,\n",
            "        1758.,  615., 1583.,    5., 2208.,   81.,  325., 1066.])\n",
            "['Genetic', 'testing', 'can', 'diagnose', 'genetic', 'conditions,', 'predict', 'disease', 'risk,', 'and', 'inform', 'medical', 'treatment', 'decisions.', 'Genetic', 'testing', 'can', 'diagnose', 'genetic', 'conditions,', 'predict', 'disease', 'risk,', 'and', 'inform', 'medical', 'treatment', 'decisions.']\n",
            "[('Genetic', 'testing'), ('testing', 'can'), ('can', 'diagnose'), ('diagnose', 'genetic'), ('genetic', 'conditions,'), ('conditions,', 'predict'), ('predict', 'disease'), ('disease', 'risk,'), ('risk,', 'and'), ('and', 'inform'), ('inform', 'medical'), ('medical', 'treatment'), ('treatment', 'decisions.'), ('Genetic', 'testing'), ('testing', 'can'), ('can', 'diagnose'), ('diagnose', 'genetic'), ('genetic', 'conditions,'), ('conditions,', 'predict'), ('predict', 'disease'), ('disease', 'risk,'), ('risk,', 'and'), ('and', 'inform'), ('inform', 'medical'), ('medical', 'treatment'), ('treatment', 'decisions.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 2.3320e+03, 3.0000e+00, 1.0000e+00, 1.0880e+03, 1.2800e+02,\n",
            "        2.0000e+00, 9.7000e+01, 8.0000e+00, 2.1000e+01, 8.6000e+02, 1.4700e+02,\n",
            "        5.1000e+01, 2.0000e+00, 4.3000e+01, 2.3350e+03, 1.1000e+01, 2.3320e+03,\n",
            "        3.0000e+00, 1.0000e+00, 1.0880e+03, 1.2800e+02, 2.0000e+00, 9.7000e+01,\n",
            "        8.0000e+00, 2.1000e+01, 8.6000e+02, 1.4700e+02, 5.1000e+01, 2.0000e+00,\n",
            "        4.3000e+01, 2.3350e+03])\n",
            "['A', 'genome', 'is', 'the', 'complete', 'set', 'of', 'DNA', 'in', 'an', 'organism,', 'including', 'all', 'of', 'its', 'genes.', 'A', 'genome', 'is', 'the', 'complete', 'set', 'of', 'DNA', 'in', 'an', 'organism,', 'including', 'all', 'of', 'its', 'genes.']\n",
            "[('A', 'genome'), ('genome', 'is'), ('is', 'the'), ('the', 'complete'), ('complete', 'set'), ('set', 'of'), ('of', 'DNA'), ('DNA', 'in'), ('in', 'an'), ('an', 'organism,'), ('organism,', 'including'), ('including', 'all'), ('all', 'of'), ('of', 'its'), ('its', 'genes.'), ('A', 'genome'), ('genome', 'is'), ('is', 'the'), ('the', 'complete'), ('complete', 'set'), ('set', 'of'), ('of', 'DNA'), ('DNA', 'in'), ('in', 'an'), ('an', 'organism,'), ('organism,', 'including'), ('including', 'all'), ('all', 'of'), ('of', 'its'), ('its', 'genes.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([1.2030e+03, 9.7600e+02, 6.3600e+02, 1.0000e+00, 2.3290e+03, 2.0000e+00,\n",
            "        8.4000e+01, 1.4940e+03, 6.0000e+00, 2.0000e+02, 4.1000e+01, 1.0110e+03,\n",
            "        1.7400e+02, 1.2030e+03, 9.7600e+02, 6.3600e+02, 1.0000e+00, 2.3290e+03,\n",
            "        2.0000e+00, 8.4000e+01, 1.4940e+03, 6.0000e+00, 2.0000e+02, 4.1000e+01,\n",
            "        1.0110e+03, 1.7400e+02])\n",
            "['Comparative', 'genomics', 'compares', 'the', 'genomes', 'of', 'different', 'species', 'to', 'understand', 'their', 'evolutionary', 'relationships.', 'Comparative', 'genomics', 'compares', 'the', 'genomes', 'of', 'different', 'species', 'to', 'understand', 'their', 'evolutionary', 'relationships.']\n",
            "[('Comparative', 'genomics'), ('genomics', 'compares'), ('compares', 'the'), ('the', 'genomes'), ('genomes', 'of'), ('of', 'different'), ('different', 'species'), ('species', 'to'), ('to', 'understand'), ('understand', 'their'), ('their', 'evolutionary'), ('evolutionary', 'relationships.'), ('Comparative', 'genomics'), ('genomics', 'compares'), ('compares', 'the'), ('the', 'genomes'), ('genomes', 'of'), ('of', 'different'), ('different', 'species'), ('species', 'to'), ('to', 'understand'), ('understand', 'their'), ('their', 'evolutionary'), ('evolutionary', 'relationships.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.1480e+03, 2.3340e+03, 3.6000e+01, 1.0000e+00, 4.0600e+02, 2.0000e+00,\n",
            "        5.0000e+00, 1.3300e+02, 8.0000e+00, 6.5600e+02, 5.9000e+02, 1.6400e+02,\n",
            "        8.3000e+02, 3.1480e+03, 2.3340e+03, 3.6000e+01, 1.0000e+00, 4.0600e+02,\n",
            "        2.0000e+00, 5.0000e+00, 1.3300e+02, 8.0000e+00, 6.5600e+02, 5.9000e+02,\n",
            "        1.6400e+02, 8.3000e+02])\n",
            "['Population', 'genetics', 'studies', 'the', 'distribution', 'of', 'and', 'changes', 'in', 'allele', 'frequencies', 'within', 'populations.', 'Population', 'genetics', 'studies', 'the', 'distribution', 'of', 'and', 'changes', 'in', 'allele', 'frequencies', 'within', 'populations.']\n",
            "[('Population', 'genetics'), ('genetics', 'studies'), ('studies', 'the'), ('the', 'distribution'), ('distribution', 'of'), ('of', 'and'), ('and', 'changes'), ('changes', 'in'), ('in', 'allele'), ('allele', 'frequencies'), ('frequencies', 'within'), ('within', 'populations.'), ('Population', 'genetics'), ('genetics', 'studies'), ('studies', 'the'), ('the', 'distribution'), ('distribution', 'of'), ('of', 'and'), ('and', 'changes'), ('changes', 'in'), ('in', 'allele'), ('allele', 'frequencies'), ('frequencies', 'within'), ('within', 'populations.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([1.1000e+01, 1.8340e+03, 2.7800e+03, 3.0000e+00, 4.0000e+00, 1.0540e+03,\n",
            "        7.0000e+00, 7.7300e+02, 1.0000e+00, 1.9070e+03, 5.0000e+00, 2.9380e+03,\n",
            "        2.0000e+00, 8.4300e+02, 8.0000e+00, 1.5410e+03, 5.8200e+02, 2.0000e+00,\n",
            "        4.0000e+00, 2.4190e+03, 1.1000e+01, 1.8340e+03, 2.7800e+03, 3.0000e+00,\n",
            "        4.0000e+00, 1.0540e+03, 7.0000e+00, 7.7300e+02, 1.0000e+00, 1.9070e+03,\n",
            "        5.0000e+00, 2.9380e+03, 2.0000e+00, 8.4300e+02, 8.0000e+00, 1.5410e+03,\n",
            "        5.8200e+02, 2.0000e+00, 4.0000e+00, 2.4190e+03])\n",
            "['A', 'pedigree', 'chart', 'is', 'a', 'diagram', 'that', 'shows', 'the', 'occurrence', 'and', 'appearance', 'of', 'phenotypes', 'in', 'several', 'generations', 'of', 'a', 'family.', 'A', 'pedigree', 'chart', 'is', 'a', 'diagram', 'that', 'shows', 'the', 'occurrence', 'and', 'appearance', 'of', 'phenotypes', 'in', 'several', 'generations', 'of', 'a', 'family.']\n",
            "[('A', 'pedigree'), ('pedigree', 'chart'), ('chart', 'is'), ('is', 'a'), ('a', 'diagram'), ('diagram', 'that'), ('that', 'shows'), ('shows', 'the'), ('the', 'occurrence'), ('occurrence', 'and'), ('and', 'appearance'), ('appearance', 'of'), ('of', 'phenotypes'), ('phenotypes', 'in'), ('in', 'several'), ('several', 'generations'), ('generations', 'of'), ('of', 'a'), ('a', 'family.'), ('A', 'pedigree'), ('pedigree', 'chart'), ('chart', 'is'), ('is', 'a'), ('a', 'diagram'), ('diagram', 'that'), ('that', 'shows'), ('shows', 'the'), ('the', 'occurrence'), ('occurrence', 'and'), ('and', 'appearance'), ('appearance', 'of'), ('of', 'phenotypes'), ('phenotypes', 'in'), ('in', 'several'), ('several', 'generations'), ('generations', 'of'), ('of', 'a'), ('a', 'family.')]\n",
            "44\n",
            "42\n",
            "946\n",
            "86\n",
            "tensor([4.3700e+02, 1.8700e+02, 3.0000e+00, 1.0000e+00, 5.7000e+01, 1.8000e+01,\n",
            "        2.2000e+01, 9.3000e+01, 2.4000e+01, 4.0000e+00, 1.4800e+02, 3.0000e+00,\n",
            "        3.1000e+01, 6.0000e+00, 1.0100e+02, 4.0000e+00, 9.8200e+02, 1.7310e+03,\n",
            "        4.0000e+01, 1.4000e+01, 4.0000e+00, 5.1000e+02, 4.3700e+02, 1.8700e+02,\n",
            "        3.0000e+00, 1.0000e+00, 5.7000e+01, 1.8000e+01, 2.2000e+01, 9.3000e+01,\n",
            "        2.4000e+01, 4.0000e+00, 1.4800e+02, 3.0000e+00, 3.1000e+01, 6.0000e+00,\n",
            "        1.0100e+02, 4.0000e+00, 9.8200e+02, 1.7310e+03, 4.0000e+01, 1.4000e+01,\n",
            "        4.0000e+00, 5.1000e+02])\n",
            "['Gene', 'expression', 'is', 'the', 'process', 'by', 'which', 'information', 'from', 'a', 'gene', 'is', 'used', 'to', 'produce', 'a', 'functional', 'product,', 'such', 'as', 'a', 'protein.', 'Gene', 'expression', 'is', 'the', 'process', 'by', 'which', 'information', 'from', 'a', 'gene', 'is', 'used', 'to', 'produce', 'a', 'functional', 'product,', 'such', 'as', 'a', 'protein.']\n",
            "[('Gene', 'expression'), ('expression', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'information'), ('information', 'from'), ('from', 'a'), ('a', 'gene'), ('gene', 'is'), ('is', 'used'), ('used', 'to'), ('to', 'produce'), ('produce', 'a'), ('a', 'functional'), ('functional', 'product,'), ('product,', 'such'), ('such', 'as'), ('as', 'a'), ('a', 'protein.'), ('Gene', 'expression'), ('expression', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'information'), ('information', 'from'), ('from', 'a'), ('a', 'gene'), ('gene', 'is'), ('is', 'used'), ('used', 'to'), ('to', 'produce'), ('produce', 'a'), ('a', 'functional'), ('functional', 'product,'), ('product,', 'such'), ('such', 'as'), ('as', 'a'), ('a', 'protein.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3216.,  560.,  849.,  224., 1124., 1042., 1124., 1664., 1159., 1042.,\n",
            "           5., 1159., 1663., 3216.,  560.,  849.,  224., 1124., 1042., 1124.,\n",
            "        1664., 1159., 1042.,    5., 1159., 1663.])\n",
            "['Mendelian', 'inheritance', 'patterns', 'include', 'autosomal', 'dominant,', 'autosomal', 'recessive,', 'X-linked', 'dominant,', 'and', 'X-linked', 'recessive.', 'Mendelian', 'inheritance', 'patterns', 'include', 'autosomal', 'dominant,', 'autosomal', 'recessive,', 'X-linked', 'dominant,', 'and', 'X-linked', 'recessive.']\n",
            "[('Mendelian', 'inheritance'), ('inheritance', 'patterns'), ('patterns', 'include'), ('include', 'autosomal'), ('autosomal', 'dominant,'), ('dominant,', 'autosomal'), ('autosomal', 'recessive,'), ('recessive,', 'X-linked'), ('X-linked', 'dominant,'), ('dominant,', 'and'), ('and', 'X-linked'), ('X-linked', 'recessive.'), ('Mendelian', 'inheritance'), ('inheritance', 'patterns'), ('patterns', 'include'), ('include', 'autosomal'), ('autosomal', 'dominant,'), ('dominant,', 'autosomal'), ('autosomal', 'recessive,'), ('recessive,', 'X-linked'), ('X-linked', 'dominant,'), ('dominant,', 'and'), ('and', 'X-linked'), ('X-linked', 'recessive.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([ 159., 2764.,  113.,  305.,    8.,    4.,  571.,  561.,   13.,  983.,\n",
            "        2439., 1601.,    8.,    4., 2578.,  844.,  159., 2764.,  113.,  305.,\n",
            "           8.,    4.,  571.,  561.,   13.,  983., 2439., 1601.,    8.,    4.,\n",
            "        2578.,  844.])\n",
            "['In', 'codominance,', 'both', 'alleles', 'in', 'a', 'heterozygous', 'individual', 'are', 'fully', 'expressed,', 'resulting', 'in', 'a', 'distinct', 'phenotype.', 'In', 'codominance,', 'both', 'alleles', 'in', 'a', 'heterozygous', 'individual', 'are', 'fully', 'expressed,', 'resulting', 'in', 'a', 'distinct', 'phenotype.']\n",
            "[('In', 'codominance,'), ('codominance,', 'both'), ('both', 'alleles'), ('alleles', 'in'), ('in', 'a'), ('a', 'heterozygous'), ('heterozygous', 'individual'), ('individual', 'are'), ('are', 'fully'), ('fully', 'expressed,'), ('expressed,', 'resulting'), ('resulting', 'in'), ('in', 'a'), ('a', 'distinct'), ('distinct', 'phenotype.'), ('In', 'codominance,'), ('codominance,', 'both'), ('both', 'alleles'), ('alleles', 'in'), ('in', 'a'), ('a', 'heterozygous'), ('heterozygous', 'individual'), ('individual', 'are'), ('are', 'fully'), ('fully', 'expressed,'), ('expressed,', 'resulting'), ('resulting', 'in'), ('in', 'a'), ('a', 'distinct'), ('distinct', 'phenotype.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.2700e+03, 2.5590e+03, 1.4200e+02, 1.2500e+02, 1.0000e+00, 5.1900e+02,\n",
            "        2.0000e+00, 4.0000e+00, 2.2790e+03, 3.0000e+00, 2.1680e+03, 3.5000e+01,\n",
            "        1.0000e+00, 8.4300e+02, 2.0000e+00, 1.0000e+00, 2.2680e+03, 3.2700e+03,\n",
            "        2.5590e+03, 1.4200e+02, 1.2500e+02, 1.0000e+00, 5.1900e+02, 2.0000e+00,\n",
            "        4.0000e+00, 2.2790e+03, 3.0000e+00, 2.1680e+03, 3.5000e+01, 1.0000e+00,\n",
            "        8.4300e+02, 2.0000e+00, 1.0000e+00, 2.2680e+03])\n",
            "['Incomplete', 'dominance', 'occurs', 'when', 'the', 'phenotype', 'of', 'a', 'heterozygote', 'is', 'intermediate', 'between', 'the', 'phenotypes', 'of', 'the', 'homozygotes.', 'Incomplete', 'dominance', 'occurs', 'when', 'the', 'phenotype', 'of', 'a', 'heterozygote', 'is', 'intermediate', 'between', 'the', 'phenotypes', 'of', 'the', 'homozygotes.']\n",
            "[('Incomplete', 'dominance'), ('dominance', 'occurs'), ('occurs', 'when'), ('when', 'the'), ('the', 'phenotype'), ('phenotype', 'of'), ('of', 'a'), ('a', 'heterozygote'), ('heterozygote', 'is'), ('is', 'intermediate'), ('intermediate', 'between'), ('between', 'the'), ('the', 'phenotypes'), ('phenotypes', 'of'), ('of', 'the'), ('the', 'homozygotes.'), ('Incomplete', 'dominance'), ('dominance', 'occurs'), ('occurs', 'when'), ('when', 'the'), ('the', 'phenotype'), ('phenotype', 'of'), ('of', 'a'), ('a', 'heterozygote'), ('heterozygote', 'is'), ('is', 'intermediate'), ('intermediate', 'between'), ('between', 'the'), ('the', 'phenotypes'), ('phenotypes', 'of'), ('of', 'the'), ('the', 'homozygotes.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([1193., 2234.,    3.,   21., 2491.,  265.,   99.,  413.,  286.,   13.,\n",
            "         400.,    8.,    4., 1856.,  897., 1193., 2234.,    3.,   21., 2491.,\n",
            "         265.,   99.,  413.,  286.,   13.,  400.,    8.,    4., 1856.,  897.])\n",
            "['Genomic', 'imprinting', 'is', 'an', 'epigenetic', 'phenomenon', 'where', 'certain', 'genes', 'are', 'expressed', 'in', 'a', 'parent-of-origin-specific', 'manner.', 'Genomic', 'imprinting', 'is', 'an', 'epigenetic', 'phenomenon', 'where', 'certain', 'genes', 'are', 'expressed', 'in', 'a', 'parent-of-origin-specific', 'manner.']\n",
            "[('Genomic', 'imprinting'), ('imprinting', 'is'), ('is', 'an'), ('an', 'epigenetic'), ('epigenetic', 'phenomenon'), ('phenomenon', 'where'), ('where', 'certain'), ('certain', 'genes'), ('genes', 'are'), ('are', 'expressed'), ('expressed', 'in'), ('in', 'a'), ('a', 'parent-of-origin-specific'), ('parent-of-origin-specific', 'manner.'), ('Genomic', 'imprinting'), ('imprinting', 'is'), ('is', 'an'), ('an', 'epigenetic'), ('epigenetic', 'phenomenon'), ('phenomenon', 'where'), ('where', 'certain'), ('certain', 'genes'), ('genes', 'are'), ('are', 'expressed'), ('expressed', 'in'), ('in', 'a'), ('a', 'parent-of-origin-specific'), ('parent-of-origin-specific', 'manner.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([ 437.,  460.,  429.,    6.,  202.,   10.,  514.,   30.,  294.,   18.,\n",
            "        2154., 1623.,   10., 2962.,   30.,  275.,  164.,    4., 1839.,  640.,\n",
            "         437.,  460.,  429.,    6.,  202.,   10.,  514.,   30.,  294.,   18.,\n",
            "        2154., 1623.,   10., 2962.,   30.,  275.,  164.,    4., 1839.,  640.])\n",
            "['Gene', 'therapy', 'aims', 'to', 'treat', 'or', 'prevent', 'genetic', 'disorders', 'by', 'introducing,', 'removing,', 'or', 'altering', 'genetic', 'material', 'within', 'a', \"patient's\", 'cells.', 'Gene', 'therapy', 'aims', 'to', 'treat', 'or', 'prevent', 'genetic', 'disorders', 'by', 'introducing,', 'removing,', 'or', 'altering', 'genetic', 'material', 'within', 'a', \"patient's\", 'cells.']\n",
            "[('Gene', 'therapy'), ('therapy', 'aims'), ('aims', 'to'), ('to', 'treat'), ('treat', 'or'), ('or', 'prevent'), ('prevent', 'genetic'), ('genetic', 'disorders'), ('disorders', 'by'), ('by', 'introducing,'), ('introducing,', 'removing,'), ('removing,', 'or'), ('or', 'altering'), ('altering', 'genetic'), ('genetic', 'material'), ('material', 'within'), ('within', 'a'), ('a', \"patient's\"), (\"patient's\", 'cells.'), ('Gene', 'therapy'), ('therapy', 'aims'), ('aims', 'to'), ('to', 'treat'), ('treat', 'or'), ('or', 'prevent'), ('prevent', 'genetic'), ('genetic', 'disorders'), ('disorders', 'by'), ('by', 'introducing,'), ('introducing,', 'removing,'), ('removing,', 'or'), ('or', 'altering'), ('altering', 'genetic'), ('genetic', 'material'), ('material', 'within'), ('within', 'a'), ('a', \"patient's\"), (\"patient's\", 'cells.')]\n",
            "44\n",
            "42\n",
            "946\n",
            "86\n",
            "tensor([  11.,   30., 2043.,    3.,    4.,   80.,   97.,  172.,   19.,    4.,\n",
            "         106.,  909.,   23.,    4.,  639.,    7.,   16.,   25.,   31.,   12.,\n",
            "          30., 1135.,   11.,   30., 2043.,    3.,    4.,   80.,   97.,  172.,\n",
            "          19.,    4.,  106.,  909.,   23.,    4.,  639.,    7.,   16.,   25.,\n",
            "          31.,   12.,   30., 1135.])\n",
            "['A', 'genetic', 'marker', 'is', 'a', 'specific', 'DNA', 'sequence', 'with', 'a', 'known', 'location', 'on', 'a', 'chromosome', 'that', 'can', 'be', 'used', 'for', 'genetic', 'analysis.', 'A', 'genetic', 'marker', 'is', 'a', 'specific', 'DNA', 'sequence', 'with', 'a', 'known', 'location', 'on', 'a', 'chromosome', 'that', 'can', 'be', 'used', 'for', 'genetic', 'analysis.']\n",
            "[('A', 'genetic'), ('genetic', 'marker'), ('marker', 'is'), ('is', 'a'), ('a', 'specific'), ('specific', 'DNA'), ('DNA', 'sequence'), ('sequence', 'with'), ('with', 'a'), ('a', 'known'), ('known', 'location'), ('location', 'on'), ('on', 'a'), ('a', 'chromosome'), ('chromosome', 'that'), ('that', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'for'), ('for', 'genetic'), ('genetic', 'analysis.'), ('A', 'genetic'), ('genetic', 'marker'), ('marker', 'is'), ('is', 'a'), ('a', 'specific'), ('specific', 'DNA'), ('DNA', 'sequence'), ('sequence', 'with'), ('with', 'a'), ('a', 'known'), ('known', 'location'), ('location', 'on'), ('on', 'a'), ('a', 'chromosome'), ('chromosome', 'that'), ('that', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'for'), ('for', 'genetic'), ('genetic', 'analysis.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([9.0000e+00, 3.2880e+03, 2.4880e+03, 4.9000e+01, 4.0000e+00, 1.1600e+02,\n",
            "        8.0000e+00, 2.2000e+01, 6.5600e+02, 5.9000e+02, 8.0000e+00, 4.0000e+00,\n",
            "        8.3100e+02, 7.9100e+02, 2.9700e+02, 7.4000e+01, 5.8200e+02, 8.0000e+00,\n",
            "        1.0000e+00, 3.0180e+03, 2.0000e+00, 1.0110e+03, 2.3700e+03, 9.0000e+00,\n",
            "        3.2880e+03, 2.4880e+03, 4.9000e+01, 4.0000e+00, 1.1600e+02, 8.0000e+00,\n",
            "        2.2000e+01, 6.5600e+02, 5.9000e+02, 8.0000e+00, 4.0000e+00, 8.3100e+02,\n",
            "        7.9100e+02, 2.9700e+02, 7.4000e+01, 5.8200e+02, 8.0000e+00, 1.0000e+00,\n",
            "        3.0180e+03, 2.0000e+00, 1.0110e+03, 2.3700e+03])\n",
            "['The', 'Hardy-Weinberg', 'equilibrium', 'describes', 'a', 'state', 'in', 'which', 'allele', 'frequencies', 'in', 'a', 'population', 'remain', 'constant', 'over', 'generations', 'in', 'the', 'absence', 'of', 'evolutionary', 'forces.', 'The', 'Hardy-Weinberg', 'equilibrium', 'describes', 'a', 'state', 'in', 'which', 'allele', 'frequencies', 'in', 'a', 'population', 'remain', 'constant', 'over', 'generations', 'in', 'the', 'absence', 'of', 'evolutionary', 'forces.']\n",
            "[('The', 'Hardy-Weinberg'), ('Hardy-Weinberg', 'equilibrium'), ('equilibrium', 'describes'), ('describes', 'a'), ('a', 'state'), ('state', 'in'), ('in', 'which'), ('which', 'allele'), ('allele', 'frequencies'), ('frequencies', 'in'), ('in', 'a'), ('a', 'population'), ('population', 'remain'), ('remain', 'constant'), ('constant', 'over'), ('over', 'generations'), ('generations', 'in'), ('in', 'the'), ('the', 'absence'), ('absence', 'of'), ('of', 'evolutionary'), ('evolutionary', 'forces.'), ('The', 'Hardy-Weinberg'), ('Hardy-Weinberg', 'equilibrium'), ('equilibrium', 'describes'), ('describes', 'a'), ('a', 'state'), ('state', 'in'), ('in', 'which'), ('which', 'allele'), ('allele', 'frequencies'), ('frequencies', 'in'), ('in', 'a'), ('a', 'population'), ('population', 'remain'), ('remain', 'constant'), ('constant', 'over'), ('over', 'generations'), ('generations', 'in'), ('in', 'the'), ('the', 'absence'), ('absence', 'of'), ('of', 'evolutionary'), ('evolutionary', 'forces.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([  11.,  881.,    8.,    4.,  768., 1926.,  106.,   14.,    4.,  358.,\n",
            "        1967.,   16.,   42.,  771.,  291.,   23.,  148.,  586.,   11.,  881.,\n",
            "           8.,    4.,  768., 1926.,  106.,   14.,    4.,  358., 1967.,   16.,\n",
            "          42.,  771.,  291.,   23.,  148.,  586.])\n",
            "['A', 'mutation', 'in', 'a', 'single', 'nucleotide,', 'known', 'as', 'a', 'point', 'mutation,', 'can', 'have', 'significant', 'effects', 'on', 'gene', 'function.', 'A', 'mutation', 'in', 'a', 'single', 'nucleotide,', 'known', 'as', 'a', 'point', 'mutation,', 'can', 'have', 'significant', 'effects', 'on', 'gene', 'function.']\n",
            "[('A', 'mutation'), ('mutation', 'in'), ('in', 'a'), ('a', 'single'), ('single', 'nucleotide,'), ('nucleotide,', 'known'), ('known', 'as'), ('as', 'a'), ('a', 'point'), ('point', 'mutation,'), ('mutation,', 'can'), ('can', 'have'), ('have', 'significant'), ('significant', 'effects'), ('effects', 'on'), ('on', 'gene'), ('gene', 'function.'), ('A', 'mutation'), ('mutation', 'in'), ('in', 'a'), ('a', 'single'), ('single', 'nucleotide,'), ('nucleotide,', 'known'), ('known', 'as'), ('as', 'a'), ('a', 'point'), ('point', 'mutation,'), ('mutation,', 'can'), ('can', 'have'), ('have', 'significant'), ('significant', 'effects'), ('effects', 'on'), ('on', 'gene'), ('gene', 'function.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([9.0000e+00, 1.7770e+03, 4.1200e+02, 1.6740e+03, 3.4890e+03, 3.0000e+00,\n",
            "        4.0000e+00, 7.3500e+02, 3.1000e+01, 6.0000e+00, 2.9560e+03, 8.0000e+01,\n",
            "        9.7000e+01, 1.5460e+03, 1.2000e+01, 1.1350e+03, 9.0000e+00, 1.7770e+03,\n",
            "        4.1200e+02, 1.6740e+03, 3.4890e+03, 3.0000e+00, 4.0000e+00, 7.3500e+02,\n",
            "        3.1000e+01, 6.0000e+00, 2.9560e+03, 8.0000e+01, 9.7000e+01, 1.5460e+03,\n",
            "        1.2000e+01, 1.1350e+03])\n",
            "['The', 'polymerase', 'chain', 'reaction', '(PCR)', 'is', 'a', 'technique', 'used', 'to', 'amplify', 'specific', 'DNA', 'sequences', 'for', 'analysis.', 'The', 'polymerase', 'chain', 'reaction', '(PCR)', 'is', 'a', 'technique', 'used', 'to', 'amplify', 'specific', 'DNA', 'sequences', 'for', 'analysis.']\n",
            "[('The', 'polymerase'), ('polymerase', 'chain'), ('chain', 'reaction'), ('reaction', '(PCR)'), ('(PCR)', 'is'), ('is', 'a'), ('a', 'technique'), ('technique', 'used'), ('used', 'to'), ('to', 'amplify'), ('amplify', 'specific'), ('specific', 'DNA'), ('DNA', 'sequences'), ('sequences', 'for'), ('for', 'analysis.'), ('The', 'polymerase'), ('polymerase', 'chain'), ('chain', 'reaction'), ('reaction', '(PCR)'), ('(PCR)', 'is'), ('is', 'a'), ('a', 'technique'), ('technique', 'used'), ('used', 'to'), ('to', 'amplify'), ('amplify', 'specific'), ('specific', 'DNA'), ('DNA', 'sequences'), ('sequences', 'for'), ('for', 'analysis.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([4.3700e+02, 1.6370e+03, 1.0800e+02, 2.0230e+03, 7.0000e+00, 6.2700e+02,\n",
            "        1.0000e+00, 1.3830e+03, 2.0740e+03, 5.0000e+00, 1.1370e+03, 2.0000e+00,\n",
            "        1.4800e+02, 1.0000e+03, 4.3700e+02, 1.6370e+03, 1.0800e+02, 2.0230e+03,\n",
            "        7.0000e+00, 6.2700e+02, 1.0000e+00, 1.3830e+03, 2.0740e+03, 5.0000e+00,\n",
            "        1.1370e+03, 2.0000e+00, 1.4800e+02, 1.0000e+03])\n",
            "['Gene', 'regulation', 'involves', 'mechanisms', 'that', 'control', 'the', 'timing,', 'location,', 'and', 'amount', 'of', 'gene', 'expression.', 'Gene', 'regulation', 'involves', 'mechanisms', 'that', 'control', 'the', 'timing,', 'location,', 'and', 'amount', 'of', 'gene', 'expression.']\n",
            "[('Gene', 'regulation'), ('regulation', 'involves'), ('involves', 'mechanisms'), ('mechanisms', 'that'), ('that', 'control'), ('control', 'the'), ('the', 'timing,'), ('timing,', 'location,'), ('location,', 'and'), ('and', 'amount'), ('amount', 'of'), ('of', 'gene'), ('gene', 'expression.'), ('Gene', 'regulation'), ('regulation', 'involves'), ('involves', 'mechanisms'), ('mechanisms', 'that'), ('that', 'control'), ('control', 'the'), ('the', 'timing,'), ('timing,', 'location,'), ('location,', 'and'), ('and', 'amount'), ('amount', 'of'), ('of', 'gene'), ('gene', 'expression.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([  11.,   30., 1982.,    3.,   21.,  527.,   19.,  414.,    7.,   42.,\n",
            "          84.,   30.,  899.,  405.,    6., 1966.,  404., 1057.,   11.,   30.,\n",
            "        1982.,    3.,   21.,  527.,   19.,  414.,    7.,   42.,   84.,   30.,\n",
            "         899.,  405.,    6., 1966.,  404., 1057.])\n",
            "['A', 'genetic', 'mosaic', 'is', 'an', 'organism', 'with', 'cells', 'that', 'have', 'different', 'genetic', 'makeup', 'due', 'to', 'mutations', 'during', 'development.', 'A', 'genetic', 'mosaic', 'is', 'an', 'organism', 'with', 'cells', 'that', 'have', 'different', 'genetic', 'makeup', 'due', 'to', 'mutations', 'during', 'development.']\n",
            "[('A', 'genetic'), ('genetic', 'mosaic'), ('mosaic', 'is'), ('is', 'an'), ('an', 'organism'), ('organism', 'with'), ('with', 'cells'), ('cells', 'that'), ('that', 'have'), ('have', 'different'), ('different', 'genetic'), ('genetic', 'makeup'), ('makeup', 'due'), ('due', 'to'), ('to', 'mutations'), ('mutations', 'during'), ('during', 'development.'), ('A', 'genetic'), ('genetic', 'mosaic'), ('mosaic', 'is'), ('is', 'an'), ('an', 'organism'), ('organism', 'with'), ('with', 'cells'), ('cells', 'that'), ('that', 'have'), ('have', 'different'), ('different', 'genetic'), ('genetic', 'makeup'), ('makeup', 'due'), ('due', 'to'), ('to', 'mutations'), ('mutations', 'during'), ('during', 'development.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.3010e+03, 2.2300e+02, 1.5300e+02, 7.6000e+01, 3.0000e+01, 5.0000e+00,\n",
            "        4.0200e+02, 2.4290e+03, 3.8600e+02, 1.0000e+00, 8.4400e+02, 3.3010e+03,\n",
            "        2.2300e+02, 1.5300e+02, 7.6000e+01, 3.0000e+01, 5.0000e+00, 4.0200e+02,\n",
            "        2.4290e+03, 3.8600e+02, 1.0000e+00, 8.4400e+02])\n",
            "['Gene-environment', 'interactions', 'describe', 'how', 'genetic', 'and', 'environmental', 'factors', 'influence', 'the', 'phenotype.', 'Gene-environment', 'interactions', 'describe', 'how', 'genetic', 'and', 'environmental', 'factors', 'influence', 'the', 'phenotype.']\n",
            "[('Gene-environment', 'interactions'), ('interactions', 'describe'), ('describe', 'how'), ('how', 'genetic'), ('genetic', 'and'), ('and', 'environmental'), ('environmental', 'factors'), ('factors', 'influence'), ('influence', 'the'), ('the', 'phenotype.'), ('Gene-environment', 'interactions'), ('interactions', 'describe'), ('describe', 'how'), ('how', 'genetic'), ('genetic', 'and'), ('and', 'environmental'), ('environmental', 'factors'), ('factors', 'influence'), ('influence', 'the'), ('the', 'phenotype.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([1.1930e+03, 1.5440e+03, 1.4180e+03, 4.2000e+01, 7.8600e+02, 1.0000e+00,\n",
            "        3.0800e+02, 6.0000e+00, 3.4000e+01, 3.0000e+01, 4.4400e+02, 5.0000e+00,\n",
            "        1.0480e+03, 1.1930e+03, 1.5440e+03, 1.4180e+03, 4.2000e+01, 7.8600e+02,\n",
            "        1.0000e+00, 3.0800e+02, 6.0000e+00, 3.4000e+01, 3.0000e+01, 4.4400e+02,\n",
            "        5.0000e+00, 1.0480e+03])\n",
            "['Genomic', 'sequencing', 'technologies', 'have', 'revolutionized', 'the', 'ability', 'to', 'study', 'genetic', 'variation', 'and', 'disease.', 'Genomic', 'sequencing', 'technologies', 'have', 'revolutionized', 'the', 'ability', 'to', 'study', 'genetic', 'variation', 'and', 'disease.']\n",
            "[('Genomic', 'sequencing'), ('sequencing', 'technologies'), ('technologies', 'have'), ('have', 'revolutionized'), ('revolutionized', 'the'), ('the', 'ability'), ('ability', 'to'), ('to', 'study'), ('study', 'genetic'), ('genetic', 'variation'), ('variation', 'and'), ('and', 'disease.'), ('Genomic', 'sequencing'), ('sequencing', 'technologies'), ('technologies', 'have'), ('have', 'revolutionized'), ('revolutionized', 'the'), ('the', 'ability'), ('ability', 'to'), ('to', 'study'), ('study', 'genetic'), ('genetic', 'variation'), ('variation', 'and'), ('and', 'disease.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.3140e+03, 9.7600e+02, 4.2900e+02, 6.0000e+00, 2.0000e+02, 1.0000e+00,\n",
            "        7.8500e+02, 5.0000e+00, 2.2300e+02, 2.0000e+00, 2.8600e+02, 5.0000e+00,\n",
            "        5.0900e+02, 1.6400e+02, 4.0000e+00, 2.3300e+03, 3.3140e+03, 9.7600e+02,\n",
            "        4.2900e+02, 6.0000e+00, 2.0000e+02, 1.0000e+00, 7.8500e+02, 5.0000e+00,\n",
            "        2.2300e+02, 2.0000e+00, 2.8600e+02, 5.0000e+00, 5.0900e+02, 1.6400e+02,\n",
            "        4.0000e+00, 2.3300e+03])\n",
            "['Functional', 'genomics', 'aims', 'to', 'understand', 'the', 'roles', 'and', 'interactions', 'of', 'genes', 'and', 'proteins', 'within', 'a', 'genome.', 'Functional', 'genomics', 'aims', 'to', 'understand', 'the', 'roles', 'and', 'interactions', 'of', 'genes', 'and', 'proteins', 'within', 'a', 'genome.']\n",
            "[('Functional', 'genomics'), ('genomics', 'aims'), ('aims', 'to'), ('to', 'understand'), ('understand', 'the'), ('the', 'roles'), ('roles', 'and'), ('and', 'interactions'), ('interactions', 'of'), ('of', 'genes'), ('genes', 'and'), ('and', 'proteins'), ('proteins', 'within'), ('within', 'a'), ('a', 'genome.'), ('Functional', 'genomics'), ('genomics', 'aims'), ('aims', 'to'), ('to', 'understand'), ('understand', 'the'), ('the', 'roles'), ('roles', 'and'), ('and', 'interactions'), ('interactions', 'of'), ('of', 'genes'), ('genes', 'and'), ('and', 'proteins'), ('proteins', 'within'), ('within', 'a'), ('a', 'genome.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([3.1390e+03, 3.0000e+00, 1.0000e+00, 2.1230e+03, 3.4000e+01, 2.0000e+00,\n",
            "        8.1000e+02, 8.5100e+02, 4.1000e+01, 2.0700e+02, 5.0000e+00, 9.8100e+02,\n",
            "        3.1390e+03, 3.0000e+00, 1.0000e+00, 2.1230e+03, 3.4000e+01, 2.0000e+00,\n",
            "        8.1000e+02, 8.5100e+02, 4.1000e+01, 2.0700e+02, 5.0000e+00, 9.8100e+02])\n",
            "['Proteomics', 'is', 'the', 'large-scale', 'study', 'of', 'proteins,', 'particularly', 'their', 'structures', 'and', 'functions.', 'Proteomics', 'is', 'the', 'large-scale', 'study', 'of', 'proteins,', 'particularly', 'their', 'structures', 'and', 'functions.']\n",
            "[('Proteomics', 'is'), ('is', 'the'), ('the', 'large-scale'), ('large-scale', 'study'), ('study', 'of'), ('of', 'proteins,'), ('proteins,', 'particularly'), ('particularly', 'their'), ('their', 'structures'), ('structures', 'and'), ('and', 'functions.'), ('Proteomics', 'is'), ('is', 'the'), ('the', 'large-scale'), ('large-scale', 'study'), ('study', 'of'), ('of', 'proteins,'), ('proteins,', 'particularly'), ('particularly', 'their'), ('their', 'structures'), ('structures', 'and'), ('and', 'functions.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.2150e+03, 3.6000e+01, 1.0000e+00, 3.0000e+01, 2.7500e+02, 1.6540e+03,\n",
            "        4.0700e+02, 2.4000e+01, 4.0200e+02, 1.5740e+03, 1.1400e+03, 1.2000e+01,\n",
            "        1.0000e+00, 3.0400e+02, 2.0000e+00, 2.0090e+03, 2.7420e+03, 3.2150e+03,\n",
            "        3.6000e+01, 1.0000e+00, 3.0000e+01, 2.7500e+02, 1.6540e+03, 4.0700e+02,\n",
            "        2.4000e+01, 4.0200e+02, 1.5740e+03, 1.1400e+03, 1.2000e+01, 1.0000e+00,\n",
            "        3.0400e+02, 2.0000e+00, 2.0090e+03, 2.7420e+03])\n",
            "['Metagenomics', 'studies', 'the', 'genetic', 'material', 'recovered', 'directly', 'from', 'environmental', 'samples,', 'allowing', 'for', 'the', 'analysis', 'of', 'microbial', 'communities.', 'Metagenomics', 'studies', 'the', 'genetic', 'material', 'recovered', 'directly', 'from', 'environmental', 'samples,', 'allowing', 'for', 'the', 'analysis', 'of', 'microbial', 'communities.']\n",
            "[('Metagenomics', 'studies'), ('studies', 'the'), ('the', 'genetic'), ('genetic', 'material'), ('material', 'recovered'), ('recovered', 'directly'), ('directly', 'from'), ('from', 'environmental'), ('environmental', 'samples,'), ('samples,', 'allowing'), ('allowing', 'for'), ('for', 'the'), ('the', 'analysis'), ('analysis', 'of'), ('of', 'microbial'), ('microbial', 'communities.'), ('Metagenomics', 'studies'), ('studies', 'the'), ('the', 'genetic'), ('genetic', 'material'), ('material', 'recovered'), ('recovered', 'directly'), ('directly', 'from'), ('from', 'environmental'), ('environmental', 'samples,'), ('samples,', 'allowing'), ('allowing', 'for'), ('for', 'the'), ('the', 'analysis'), ('analysis', 'of'), ('of', 'microbial'), ('microbial', 'communities.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3.2220e+03, 3.0000e+00, 1.0000e+00, 1.1520e+03, 3.4500e+02, 2.0000e+00,\n",
            "        1.9240e+03, 1.6950e+03, 5.0000e+00, 7.5900e+02, 3.2220e+03, 3.0000e+00,\n",
            "        1.0000e+00, 1.1520e+03, 3.4500e+02, 2.0000e+00, 1.9240e+03, 1.6950e+03,\n",
            "        5.0000e+00, 7.5900e+02])\n",
            "['Mathematics', 'is', 'the', 'abstract', 'science', 'of', 'number,', 'quantity,', 'and', 'space.', 'Mathematics', 'is', 'the', 'abstract', 'science', 'of', 'number,', 'quantity,', 'and', 'space.']\n",
            "[('Mathematics', 'is'), ('is', 'the'), ('the', 'abstract'), ('abstract', 'science'), ('science', 'of'), ('of', 'number,'), ('number,', 'quantity,'), ('quantity,', 'and'), ('and', 'space.'), ('Mathematics', 'is'), ('is', 'the'), ('the', 'abstract'), ('abstract', 'science'), ('science', 'of'), ('of', 'number,'), ('number,', 'quantity,'), ('quantity,', 'and'), ('and', 'space.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.4360e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.4400e+02,\n",
            "        6.2300e+02, 1.9000e+01, 6.5000e+02, 5.3000e+02, 4.6000e+01, 1.1450e+03,\n",
            "        7.4300e+02, 8.8400e+02, 5.0000e+00, 2.5710e+03, 3.4360e+03, 3.0000e+00,\n",
            "        1.0000e+00, 2.7000e+01, 2.0000e+00, 1.4400e+02, 6.2300e+02, 1.9000e+01,\n",
            "        6.5000e+02, 5.3000e+02, 4.6000e+01, 1.1450e+03, 7.4300e+02, 8.8400e+02,\n",
            "        5.0000e+00, 2.5710e+03])\n",
            "['Arithmetic', 'is', 'the', 'branch', 'of', 'mathematics', 'dealing', 'with', 'basic', 'operations', 'like', 'addition,', 'subtraction,', 'multiplication,', 'and', 'division.', 'Arithmetic', 'is', 'the', 'branch', 'of', 'mathematics', 'dealing', 'with', 'basic', 'operations', 'like', 'addition,', 'subtraction,', 'multiplication,', 'and', 'division.']\n",
            "[('Arithmetic', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'dealing'), ('dealing', 'with'), ('with', 'basic'), ('basic', 'operations'), ('operations', 'like'), ('like', 'addition,'), ('addition,', 'subtraction,'), ('subtraction,', 'multiplication,'), ('multiplication,', 'and'), ('and', 'division.'), ('Arithmetic', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'dealing'), ('dealing', 'with'), ('with', 'basic'), ('basic', 'operations'), ('operations', 'like'), ('like', 'addition,'), ('addition,', 'subtraction,'), ('subtraction,', 'multiplication,'), ('multiplication,', 'and'), ('and', 'division.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.4510e+03, 1.0800e+02, 1.0000e+00, 3.4000e+01, 2.0000e+00, 6.2000e+01,\n",
            "        1.4340e+03, 5.0000e+00, 1.0000e+00, 2.5500e+02, 1.2000e+01, 2.0470e+03,\n",
            "        1.3950e+03, 1.4330e+03, 3.4510e+03, 1.0800e+02, 1.0000e+00, 3.4000e+01,\n",
            "        2.0000e+00, 6.2000e+01, 1.4340e+03, 5.0000e+00, 1.0000e+00, 2.5500e+02,\n",
            "        1.2000e+01, 2.0470e+03, 1.3950e+03, 1.4330e+03])\n",
            "['Algebra', 'involves', 'the', 'study', 'of', 'mathematical', 'symbols', 'and', 'the', 'rules', 'for', 'manipulating', 'these', 'symbols.', 'Algebra', 'involves', 'the', 'study', 'of', 'mathematical', 'symbols', 'and', 'the', 'rules', 'for', 'manipulating', 'these', 'symbols.']\n",
            "[('Algebra', 'involves'), ('involves', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'mathematical'), ('mathematical', 'symbols'), ('symbols', 'and'), ('and', 'the'), ('the', 'rules'), ('rules', 'for'), ('for', 'manipulating'), ('manipulating', 'these'), ('these', 'symbols.'), ('Algebra', 'involves'), ('involves', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'mathematical'), ('mathematical', 'symbols'), ('symbols', 'and'), ('and', 'the'), ('the', 'rules'), ('rules', 'for'), ('for', 'manipulating'), ('manipulating', 'these'), ('these', 'symbols.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.2960e+03, 3.0000e+00, 2.9800e+02, 1.9000e+01, 1.0000e+00, 1.4000e+02,\n",
            "        5.0000e+00, 1.6350e+03, 2.0000e+00, 8.3400e+02, 9.1100e+02, 1.4450e+03,\n",
            "        5.0000e+00, 1.5160e+03, 3.2960e+03, 3.0000e+00, 2.9800e+02, 1.9000e+01,\n",
            "        1.0000e+00, 1.4000e+02, 5.0000e+00, 1.6350e+03, 2.0000e+00, 8.3400e+02,\n",
            "        9.1100e+02, 1.4450e+03, 5.0000e+00, 1.5160e+03])\n",
            "['Geometry', 'is', 'concerned', 'with', 'the', 'properties', 'and', 'relations', 'of', 'points,', 'lines,', 'surfaces,', 'and', 'solids.', 'Geometry', 'is', 'concerned', 'with', 'the', 'properties', 'and', 'relations', 'of', 'points,', 'lines,', 'surfaces,', 'and', 'solids.']\n",
            "[('Geometry', 'is'), ('is', 'concerned'), ('concerned', 'with'), ('with', 'the'), ('the', 'properties'), ('properties', 'and'), ('and', 'relations'), ('relations', 'of'), ('of', 'points,'), ('points,', 'lines,'), ('lines,', 'surfaces,'), ('surfaces,', 'and'), ('and', 'solids.'), ('Geometry', 'is'), ('is', 'concerned'), ('concerned', 'with'), ('with', 'the'), ('the', 'properties'), ('properties', 'and'), ('and', 'relations'), ('relations', 'of'), ('of', 'points,'), ('points,', 'lines,'), ('lines,', 'surfaces,'), ('surfaces,', 'and'), ('and', 'solids.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.4090e+03, 3.0000e+00, 1.0000e+00, 6.2000e+01, 3.4000e+01, 2.0000e+00,\n",
            "        6.2800e+02, 2.7920e+03, 6.2300e+02, 1.9000e+01, 1.0600e+03, 5.0000e+00,\n",
            "        2.1820e+03, 3.4090e+03, 3.0000e+00, 1.0000e+00, 6.2000e+01, 3.4000e+01,\n",
            "        2.0000e+00, 6.2800e+02, 2.7920e+03, 6.2300e+02, 1.9000e+01, 1.0600e+03,\n",
            "        5.0000e+00, 2.1820e+03])\n",
            "['Calculus', 'is', 'the', 'mathematical', 'study', 'of', 'continuous', 'change,', 'dealing', 'with', 'derivatives', 'and', 'integrals.', 'Calculus', 'is', 'the', 'mathematical', 'study', 'of', 'continuous', 'change,', 'dealing', 'with', 'derivatives', 'and', 'integrals.']\n",
            "[('Calculus', 'is'), ('is', 'the'), ('the', 'mathematical'), ('mathematical', 'study'), ('study', 'of'), ('of', 'continuous'), ('continuous', 'change,'), ('change,', 'dealing'), ('dealing', 'with'), ('with', 'derivatives'), ('derivatives', 'and'), ('and', 'integrals.'), ('Calculus', 'is'), ('is', 'the'), ('the', 'mathematical'), ('mathematical', 'study'), ('study', 'of'), ('of', 'continuous'), ('continuous', 'change,'), ('change,', 'dealing'), ('dealing', 'with'), ('with', 'derivatives'), ('derivatives', 'and'), ('and', 'integrals.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.1430e+03, 4.8000e+01, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.4400e+02, 7.0000e+00, 1.2200e+02, 1.9000e+01, 1.0000e+00, 3.0400e+02,\n",
            "        2.0000e+00, 5.0700e+02, 1.8110e+03, 3.1430e+03, 4.8000e+01, 3.0000e+00,\n",
            "        1.0000e+00, 2.7000e+01, 2.0000e+00, 1.4400e+02, 7.0000e+00, 1.2200e+02,\n",
            "        1.9000e+01, 1.0000e+00, 3.0400e+02, 2.0000e+00, 5.0700e+02, 1.8110e+03])\n",
            "['Probability', 'theory', 'is', 'the', 'branch', 'of', 'mathematics', 'that', 'deals', 'with', 'the', 'analysis', 'of', 'random', 'phenomena.', 'Probability', 'theory', 'is', 'the', 'branch', 'of', 'mathematics', 'that', 'deals', 'with', 'the', 'analysis', 'of', 'random', 'phenomena.']\n",
            "[('Probability', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'analysis'), ('analysis', 'of'), ('of', 'random'), ('random', 'phenomena.'), ('Probability', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'analysis'), ('analysis', 'of'), ('of', 'random'), ('random', 'phenomena.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3.0900e+03, 1.0800e+02, 1.0000e+00, 2.7570e+03, 2.9520e+03, 2.1650e+03,\n",
            "        5.0000e+00, 1.7500e+03, 2.0000e+00, 6.2400e+02, 3.0900e+03, 1.0800e+02,\n",
            "        1.0000e+00, 2.7570e+03, 2.9520e+03, 2.1650e+03, 5.0000e+00, 1.7500e+03,\n",
            "        2.0000e+00, 6.2400e+02])\n",
            "['Statistics', 'involves', 'the', 'collection,', 'analysis,', 'interpretation,', 'and', 'presentation', 'of', 'data.', 'Statistics', 'involves', 'the', 'collection,', 'analysis,', 'interpretation,', 'and', 'presentation', 'of', 'data.']\n",
            "[('Statistics', 'involves'), ('involves', 'the'), ('the', 'collection,'), ('collection,', 'analysis,'), ('analysis,', 'interpretation,'), ('interpretation,', 'and'), ('and', 'presentation'), ('presentation', 'of'), ('of', 'data.'), ('Statistics', 'involves'), ('involves', 'the'), ('the', 'collection,'), ('collection,', 'analysis,'), ('analysis,', 'interpretation,'), ('interpretation,', 'and'), ('and', 'presentation'), ('presentation', 'of'), ('of', 'data.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([1.1000e+01, 6.2000e+01, 5.1100e+02, 3.0000e+00, 4.0000e+00, 2.0720e+03,\n",
            "        2.9270e+03, 7.0000e+00, 2.4820e+03, 1.0000e+00, 2.4800e+02, 2.0000e+00,\n",
            "        4.0000e+00, 6.2000e+01, 1.4760e+03, 1.1000e+01, 6.2000e+01, 5.1100e+02,\n",
            "        3.0000e+00, 4.0000e+00, 2.0720e+03, 2.9270e+03, 7.0000e+00, 2.4820e+03,\n",
            "        1.0000e+00, 2.4800e+02, 2.0000e+00, 4.0000e+00, 6.2000e+01, 1.4760e+03])\n",
            "['A', 'mathematical', 'proof', 'is', 'a', 'logical', 'argument', 'that', 'establishes', 'the', 'truth', 'of', 'a', 'mathematical', 'statement.', 'A', 'mathematical', 'proof', 'is', 'a', 'logical', 'argument', 'that', 'establishes', 'the', 'truth', 'of', 'a', 'mathematical', 'statement.']\n",
            "[('A', 'mathematical'), ('mathematical', 'proof'), ('proof', 'is'), ('is', 'a'), ('a', 'logical'), ('logical', 'argument'), ('argument', 'that'), ('that', 'establishes'), ('establishes', 'the'), ('the', 'truth'), ('truth', 'of'), ('of', 'a'), ('a', 'mathematical'), ('mathematical', 'statement.'), ('A', 'mathematical'), ('mathematical', 'proof'), ('proof', 'is'), ('is', 'a'), ('a', 'logical'), ('logical', 'argument'), ('argument', 'that'), ('that', 'establishes'), ('establishes', 'the'), ('the', 'truth'), ('truth', 'of'), ('of', 'a'), ('a', 'mathematical'), ('mathematical', 'statement.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([3.1870e+03, 4.8000e+01, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.4400e+02, 2.6070e+03, 6.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00,\n",
            "        1.0000e+00, 2.1850e+03, 5.0000e+00, 6.0000e+01, 2.3390e+03, 6.0000e+00,\n",
            "        2.6800e+02, 2.8280e+03, 3.6600e+02, 2.0000e+00, 1.4020e+03, 3.1870e+03,\n",
            "        4.8000e+01, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.4400e+02,\n",
            "        2.6070e+03, 6.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 1.0000e+00,\n",
            "        2.1850e+03, 5.0000e+00, 6.0000e+01, 2.3390e+03, 6.0000e+00, 2.6800e+02,\n",
            "        2.8280e+03, 3.6600e+02, 2.0000e+00, 1.4020e+03])\n",
            "['Number', 'theory', 'is', 'the', 'branch', 'of', 'mathematics', 'devoted', 'to', 'the', 'study', 'of', 'the', 'integers', 'and', 'more', 'generally', 'to', 'objects', 'built', 'out', 'of', 'them.', 'Number', 'theory', 'is', 'the', 'branch', 'of', 'mathematics', 'devoted', 'to', 'the', 'study', 'of', 'the', 'integers', 'and', 'more', 'generally', 'to', 'objects', 'built', 'out', 'of', 'them.']\n",
            "[('Number', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'devoted'), ('devoted', 'to'), ('to', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'integers'), ('integers', 'and'), ('and', 'more'), ('more', 'generally'), ('generally', 'to'), ('to', 'objects'), ('objects', 'built'), ('built', 'out'), ('out', 'of'), ('of', 'them.'), ('Number', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'devoted'), ('devoted', 'to'), ('to', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'integers'), ('integers', 'and'), ('and', 'more'), ('more', 'generally'), ('generally', 'to'), ('to', 'objects'), ('objects', 'built'), ('built', 'out'), ('out', 'of'), ('of', 'them.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([  11.,  354.,   59.,    3.,    4.,  181.,   59.,  575.,   66.,  315.,\n",
            "           7.,   54.,  179.,  828., 2570.,   58.,   66.,  315.,    5.,  930.,\n",
            "          11.,  354.,   59.,    3.,    4.,  181.,   59.,  575.,   66.,  315.,\n",
            "           7.,   54.,  179.,  828., 2570.,   58.,   66.,  315.,    5.,  930.])\n",
            "['A', 'prime', 'number', 'is', 'a', 'natural', 'number', 'greater', 'than', '1', 'that', 'has', 'no', 'positive', 'divisors', 'other', 'than', '1', 'and', 'itself.', 'A', 'prime', 'number', 'is', 'a', 'natural', 'number', 'greater', 'than', '1', 'that', 'has', 'no', 'positive', 'divisors', 'other', 'than', '1', 'and', 'itself.']\n",
            "[('A', 'prime'), ('prime', 'number'), ('number', 'is'), ('is', 'a'), ('a', 'natural'), ('natural', 'number'), ('number', 'greater'), ('greater', 'than'), ('than', '1'), ('1', 'that'), ('that', 'has'), ('has', 'no'), ('no', 'positive'), ('positive', 'divisors'), ('divisors', 'other'), ('other', 'than'), ('than', '1'), ('1', 'and'), ('and', 'itself.'), ('A', 'prime'), ('prime', 'number'), ('number', 'is'), ('is', 'a'), ('a', 'natural'), ('natural', 'number'), ('number', 'greater'), ('greater', 'than'), ('than', '1'), ('1', 'that'), ('that', 'has'), ('has', 'no'), ('no', 'positive'), ('positive', 'divisors'), ('divisors', 'other'), ('other', 'than'), ('than', '1'), ('1', 'and'), ('and', 'itself.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([1.1960e+03, 3.3430e+03, 3.0000e+00, 4.0000e+00, 6.3800e+02, 2.0000e+00,\n",
            "        2.8490e+03, 2.6740e+03, 2.1800e+02, 1.1270e+03, 2.0000e+00, 8.9500e+02,\n",
            "        1.4700e+02, 5.7900e+02, 5.0000e+00, 5.9000e+01, 4.6100e+02, 1.1960e+03,\n",
            "        3.3430e+03, 3.0000e+00, 4.0000e+00, 6.3800e+02, 2.0000e+00, 2.8490e+03,\n",
            "        2.6740e+03, 2.1800e+02, 1.1270e+03, 2.0000e+00, 8.9500e+02, 1.4700e+02,\n",
            "        5.7900e+02, 5.0000e+00, 5.9000e+01, 4.6100e+02])\n",
            "[\"Euclid's\", 'Elements', 'is', 'a', 'collection', 'of', 'books', 'covering', 'many', 'aspects', 'of', 'mathematics,', 'including', 'geometry', 'and', 'number', 'theory.', \"Euclid's\", 'Elements', 'is', 'a', 'collection', 'of', 'books', 'covering', 'many', 'aspects', 'of', 'mathematics,', 'including', 'geometry', 'and', 'number', 'theory.']\n",
            "[(\"Euclid's\", 'Elements'), ('Elements', 'is'), ('is', 'a'), ('a', 'collection'), ('collection', 'of'), ('of', 'books'), ('books', 'covering'), ('covering', 'many'), ('many', 'aspects'), ('aspects', 'of'), ('of', 'mathematics,'), ('mathematics,', 'including'), ('including', 'geometry'), ('geometry', 'and'), ('and', 'number'), ('number', 'theory.'), (\"Euclid's\", 'Elements'), ('Elements', 'is'), ('is', 'a'), ('a', 'collection'), ('collection', 'of'), ('of', 'books'), ('books', 'covering'), ('covering', 'many'), ('many', 'aspects'), ('aspects', 'of'), ('of', 'mathematics,'), ('mathematics,', 'including'), ('including', 'geometry'), ('geometry', 'and'), ('and', 'number'), ('number', 'theory.')]\n",
            "54\n",
            "52\n",
            "1431\n",
            "106\n",
            "tensor([9.0000e+00, 3.1350e+03, 2.0400e+02, 3.2000e+01, 7.0000e+00, 8.0000e+00,\n",
            "        4.0000e+00, 1.5860e+03, 1.3450e+03, 1.0000e+00, 1.4810e+03, 2.0000e+00,\n",
            "        1.0000e+00, 2.2600e+03, 3.0000e+00, 2.3000e+02, 6.0000e+00, 1.0000e+00,\n",
            "        4.7100e+02, 2.0000e+00, 1.0000e+00, 1.4790e+03, 2.0000e+00, 1.0000e+00,\n",
            "        5.8000e+01, 3.9000e+01, 1.5300e+03, 9.0000e+00, 3.1350e+03, 2.0400e+02,\n",
            "        3.2000e+01, 7.0000e+00, 8.0000e+00, 4.0000e+00, 1.5860e+03, 1.3450e+03,\n",
            "        1.0000e+00, 1.4810e+03, 2.0000e+00, 1.0000e+00, 2.2600e+03, 3.0000e+00,\n",
            "        2.3000e+02, 6.0000e+00, 1.0000e+00, 4.7100e+02, 2.0000e+00, 1.0000e+00,\n",
            "        1.4790e+03, 2.0000e+00, 1.0000e+00, 5.8000e+01, 3.9000e+01, 1.5300e+03])\n",
            "['The', 'Pythagorean', 'theorem', 'states', 'that', 'in', 'a', 'right-angled', 'triangle,', 'the', 'square', 'of', 'the', 'hypotenuse', 'is', 'equal', 'to', 'the', 'sum', 'of', 'the', 'squares', 'of', 'the', 'other', 'two', 'sides.', 'The', 'Pythagorean', 'theorem', 'states', 'that', 'in', 'a', 'right-angled', 'triangle,', 'the', 'square', 'of', 'the', 'hypotenuse', 'is', 'equal', 'to', 'the', 'sum', 'of', 'the', 'squares', 'of', 'the', 'other', 'two', 'sides.']\n",
            "[('The', 'Pythagorean'), ('Pythagorean', 'theorem'), ('theorem', 'states'), ('states', 'that'), ('that', 'in'), ('in', 'a'), ('a', 'right-angled'), ('right-angled', 'triangle,'), ('triangle,', 'the'), ('the', 'square'), ('square', 'of'), ('of', 'the'), ('the', 'hypotenuse'), ('hypotenuse', 'is'), ('is', 'equal'), ('equal', 'to'), ('to', 'the'), ('the', 'sum'), ('sum', 'of'), ('of', 'the'), ('the', 'squares'), ('squares', 'of'), ('of', 'the'), ('the', 'other'), ('other', 'two'), ('two', 'sides.'), ('The', 'Pythagorean'), ('Pythagorean', 'theorem'), ('theorem', 'states'), ('states', 'that'), ('that', 'in'), ('in', 'a'), ('a', 'right-angled'), ('right-angled', 'triangle,'), ('triangle,', 'the'), ('the', 'square'), ('square', 'of'), ('of', 'the'), ('the', 'hypotenuse'), ('hypotenuse', 'is'), ('is', 'equal'), ('equal', 'to'), ('to', 'the'), ('the', 'sum'), ('sum', 'of'), ('of', 'the'), ('the', 'squares'), ('squares', 'of'), ('of', 'the'), ('the', 'other'), ('other', 'two'), ('two', 'sides.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([1.1000e+01, 2.0350e+03, 3.0000e+00, 4.0000e+00, 1.6530e+03, 2.9230e+03,\n",
            "        2.0000e+00, 1.4300e+02, 2.9240e+03, 8.0000e+00, 1.5790e+03, 5.0000e+00,\n",
            "        2.7540e+03, 1.1000e+01, 2.0350e+03, 3.0000e+00, 4.0000e+00, 1.6530e+03,\n",
            "        2.9230e+03, 2.0000e+00, 1.4300e+02, 2.9240e+03, 8.0000e+00, 1.5790e+03,\n",
            "        5.0000e+00, 2.7540e+03])\n",
            "['A', 'matrix', 'is', 'a', 'rectangular', 'array', 'of', 'numbers', 'arranged', 'in', 'rows', 'and', 'columns.', 'A', 'matrix', 'is', 'a', 'rectangular', 'array', 'of', 'numbers', 'arranged', 'in', 'rows', 'and', 'columns.']\n",
            "[('A', 'matrix'), ('matrix', 'is'), ('is', 'a'), ('a', 'rectangular'), ('rectangular', 'array'), ('array', 'of'), ('of', 'numbers'), ('numbers', 'arranged'), ('arranged', 'in'), ('in', 'rows'), ('rows', 'and'), ('and', 'columns.'), ('A', 'matrix'), ('matrix', 'is'), ('is', 'a'), ('a', 'rectangular'), ('rectangular', 'array'), ('array', 'of'), ('of', 'numbers'), ('numbers', 'arranged'), ('arranged', 'in'), ('in', 'rows'), ('rows', 'and'), ('and', 'columns.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([3.2380e+03, 6.5700e+02, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.4400e+02, 1.0830e+03, 5.5100e+02, 2.4890e+03, 5.5100e+02, 5.8500e+02,\n",
            "        5.0000e+00, 4.1000e+01, 1.6210e+03, 5.2000e+01, 2.0360e+03, 5.0000e+00,\n",
            "        2.4400e+02, 1.5020e+03, 3.2380e+03, 6.5700e+02, 3.0000e+00, 1.0000e+00,\n",
            "        2.7000e+01, 2.0000e+00, 1.4400e+02, 1.0830e+03, 5.5100e+02, 2.4890e+03,\n",
            "        5.5100e+02, 5.8500e+02, 5.0000e+00, 4.1000e+01, 1.6210e+03, 5.2000e+01,\n",
            "        2.0360e+03, 5.0000e+00, 2.4400e+02, 1.5020e+03])\n",
            "['Linear', 'algebra', 'is', 'the', 'branch', 'of', 'mathematics', 'concerning', 'linear', 'equations,', 'linear', 'functions,', 'and', 'their', 'representations', 'through', 'matrices', 'and', 'vector', 'spaces.', 'Linear', 'algebra', 'is', 'the', 'branch', 'of', 'mathematics', 'concerning', 'linear', 'equations,', 'linear', 'functions,', 'and', 'their', 'representations', 'through', 'matrices', 'and', 'vector', 'spaces.']\n",
            "[('Linear', 'algebra'), ('algebra', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'concerning'), ('concerning', 'linear'), ('linear', 'equations,'), ('equations,', 'linear'), ('linear', 'functions,'), ('functions,', 'and'), ('and', 'their'), ('their', 'representations'), ('representations', 'through'), ('through', 'matrices'), ('matrices', 'and'), ('and', 'vector'), ('vector', 'spaces.'), ('Linear', 'algebra'), ('algebra', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'concerning'), ('concerning', 'linear'), ('linear', 'equations,'), ('equations,', 'linear'), ('linear', 'functions,'), ('functions,', 'and'), ('and', 'their'), ('their', 'representations'), ('representations', 'through'), ('through', 'matrices'), ('matrices', 'and'), ('and', 'vector'), ('vector', 'spaces.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 1.4900e+02, 3.0000e+00, 4.0000e+00, 5.0200e+02, 3.5000e+01,\n",
            "        4.0000e+00, 1.2800e+02, 2.0000e+00, 2.1960e+03, 5.0000e+00, 4.0000e+00,\n",
            "        1.2800e+02, 2.0000e+00, 1.8230e+03, 1.8690e+03, 1.1000e+01, 1.4900e+02,\n",
            "        3.0000e+00, 4.0000e+00, 5.0200e+02, 3.5000e+01, 4.0000e+00, 1.2800e+02,\n",
            "        2.0000e+00, 2.1960e+03, 5.0000e+00, 4.0000e+00, 1.2800e+02, 2.0000e+00,\n",
            "        1.8230e+03, 1.8690e+03])\n",
            "['A', 'function', 'is', 'a', 'relation', 'between', 'a', 'set', 'of', 'inputs', 'and', 'a', 'set', 'of', 'permissible', 'outputs.', 'A', 'function', 'is', 'a', 'relation', 'between', 'a', 'set', 'of', 'inputs', 'and', 'a', 'set', 'of', 'permissible', 'outputs.']\n",
            "[('A', 'function'), ('function', 'is'), ('is', 'a'), ('a', 'relation'), ('relation', 'between'), ('between', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'inputs'), ('inputs', 'and'), ('and', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'permissible'), ('permissible', 'outputs.'), ('A', 'function'), ('function', 'is'), ('is', 'a'), ('a', 'relation'), ('relation', 'between'), ('between', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'inputs'), ('inputs', 'and'), ('and', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'permissible'), ('permissible', 'outputs.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.3620e+03, 6.0700e+02, 1.3000e+01, 6.0700e+02, 7.0000e+00, 3.8400e+02,\n",
            "        1.0000e+00, 1.0600e+03, 2.0000e+00, 4.0000e+00, 5.8600e+02, 3.3620e+03,\n",
            "        6.0700e+02, 1.3000e+01, 6.0700e+02, 7.0000e+00, 3.8400e+02, 1.0000e+00,\n",
            "        1.0600e+03, 2.0000e+00, 4.0000e+00, 5.8600e+02])\n",
            "['Differential', 'equations', 'are', 'equations', 'that', 'involve', 'the', 'derivatives', 'of', 'a', 'function.', 'Differential', 'equations', 'are', 'equations', 'that', 'involve', 'the', 'derivatives', 'of', 'a', 'function.']\n",
            "[('Differential', 'equations'), ('equations', 'are'), ('are', 'equations'), ('equations', 'that'), ('that', 'involve'), ('involve', 'the'), ('the', 'derivatives'), ('derivatives', 'of'), ('of', 'a'), ('a', 'function.'), ('Differential', 'equations'), ('equations', 'are'), ('are', 'equations'), ('equations', 'that'), ('that', 'involve'), ('involve', 'the'), ('the', 'derivatives'), ('derivatives', 'of'), ('of', 'a'), ('a', 'function.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([9.0000e+00, 3.3280e+03, 1.7200e+02, 3.0000e+00, 4.0000e+00, 7.7600e+02,\n",
            "        2.0000e+00, 1.4300e+02, 8.0000e+00, 2.2000e+01, 2.9200e+02, 5.9000e+01,\n",
            "        3.0000e+00, 1.0000e+00, 4.7100e+02, 2.0000e+00, 1.0000e+00, 3.9000e+01,\n",
            "        1.7610e+03, 1.8990e+03, 9.0000e+00, 3.3280e+03, 1.7200e+02, 3.0000e+00,\n",
            "        4.0000e+00, 7.7600e+02, 2.0000e+00, 1.4300e+02, 8.0000e+00, 2.2000e+01,\n",
            "        2.9200e+02, 5.9000e+01, 3.0000e+00, 1.0000e+00, 4.7100e+02, 2.0000e+00,\n",
            "        1.0000e+00, 3.9000e+01, 1.7610e+03, 1.8990e+03])\n",
            "['The', 'Fibonacci', 'sequence', 'is', 'a', 'series', 'of', 'numbers', 'in', 'which', 'each', 'number', 'is', 'the', 'sum', 'of', 'the', 'two', 'preceding', 'ones.', 'The', 'Fibonacci', 'sequence', 'is', 'a', 'series', 'of', 'numbers', 'in', 'which', 'each', 'number', 'is', 'the', 'sum', 'of', 'the', 'two', 'preceding', 'ones.']\n",
            "[('The', 'Fibonacci'), ('Fibonacci', 'sequence'), ('sequence', 'is'), ('is', 'a'), ('a', 'series'), ('series', 'of'), ('of', 'numbers'), ('numbers', 'in'), ('in', 'which'), ('which', 'each'), ('each', 'number'), ('number', 'is'), ('is', 'the'), ('the', 'sum'), ('sum', 'of'), ('of', 'the'), ('the', 'two'), ('two', 'preceding'), ('preceding', 'ones.'), ('The', 'Fibonacci'), ('Fibonacci', 'sequence'), ('sequence', 'is'), ('is', 'a'), ('a', 'series'), ('series', 'of'), ('of', 'numbers'), ('numbers', 'in'), ('in', 'which'), ('which', 'each'), ('each', 'number'), ('number', 'is'), ('is', 'the'), ('the', 'sum'), ('sum', 'of'), ('of', 'the'), ('the', 'two'), ('two', 'preceding'), ('preceding', 'ones.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.1010e+03, 4.8000e+01, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        6.2000e+01, 9.0800e+02, 7.0000e+00, 3.6000e+01, 1.5430e+03, 2.2000e+01,\n",
            "        1.3000e+01, 2.7560e+03, 2.0000e+00, 8.6800e+02, 3.1010e+03, 4.8000e+01,\n",
            "        3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 6.2000e+01, 9.0800e+02,\n",
            "        7.0000e+00, 3.6000e+01, 1.5430e+03, 2.2000e+01, 1.3000e+01, 2.7560e+03,\n",
            "        2.0000e+00, 8.6800e+02])\n",
            "['Set', 'theory', 'is', 'the', 'branch', 'of', 'mathematical', 'logic', 'that', 'studies', 'sets,', 'which', 'are', 'collections', 'of', 'objects.', 'Set', 'theory', 'is', 'the', 'branch', 'of', 'mathematical', 'logic', 'that', 'studies', 'sets,', 'which', 'are', 'collections', 'of', 'objects.']\n",
            "[('Set', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematical'), ('mathematical', 'logic'), ('logic', 'that'), ('that', 'studies'), ('studies', 'sets,'), ('sets,', 'which'), ('which', 'are'), ('are', 'collections'), ('collections', 'of'), ('of', 'objects.'), ('Set', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematical'), ('mathematical', 'logic'), ('logic', 'that'), ('that', 'studies'), ('studies', 'sets,'), ('sets,', 'which'), ('which', 'are'), ('are', 'collections'), ('collections', 'of'), ('of', 'objects.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([  11.,  244.,    3.,    4.,  803.,    7.,   54.,  113., 2051.,    5.,\n",
            "        2592.,   11.,  244.,    3.,    4.,  803.,    7.,   54.,  113., 2051.,\n",
            "           5., 2592.])\n",
            "['A', 'vector', 'is', 'a', 'quantity', 'that', 'has', 'both', 'magnitude', 'and', 'direction.', 'A', 'vector', 'is', 'a', 'quantity', 'that', 'has', 'both', 'magnitude', 'and', 'direction.']\n",
            "[('A', 'vector'), ('vector', 'is'), ('is', 'a'), ('a', 'quantity'), ('quantity', 'that'), ('that', 'has'), ('has', 'both'), ('both', 'magnitude'), ('magnitude', 'and'), ('and', 'direction.'), ('A', 'vector'), ('vector', 'is'), ('is', 'a'), ('a', 'quantity'), ('quantity', 'that'), ('that', 'has'), ('has', 'both'), ('both', 'magnitude'), ('magnitude', 'and'), ('and', 'direction.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([1202.,  143.,   13.,  143.,    7.,   42.,    4.,  349.,  267.,    5.,\n",
            "          21.,  563., 1854., 1202.,  143.,   13.,  143.,    7.,   42.,    4.,\n",
            "         349.,  267.,    5.,   21.,  563., 1854.])\n",
            "['Complex', 'numbers', 'are', 'numbers', 'that', 'have', 'a', 'real', 'part', 'and', 'an', 'imaginary', 'part.', 'Complex', 'numbers', 'are', 'numbers', 'that', 'have', 'a', 'real', 'part', 'and', 'an', 'imaginary', 'part.']\n",
            "[('Complex', 'numbers'), ('numbers', 'are'), ('are', 'numbers'), ('numbers', 'that'), ('that', 'have'), ('have', 'a'), ('a', 'real'), ('real', 'part'), ('part', 'and'), ('and', 'an'), ('an', 'imaginary'), ('imaginary', 'part.'), ('Complex', 'numbers'), ('numbers', 'are'), ('are', 'numbers'), ('numbers', 'that'), ('that', 'have'), ('have', 'a'), ('a', 'real'), ('real', 'part'), ('part', 'and'), ('and', 'an'), ('an', 'imaginary'), ('imaginary', 'part.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([3.0610e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.4400e+02,\n",
            "        7.0000e+00, 3.6000e+01, 1.0000e+00, 1.4000e+02, 2.0000e+00, 3.3900e+02,\n",
            "        7.0000e+00, 1.3000e+01, 1.7490e+03, 3.2300e+02, 6.2800e+02, 1.3620e+03,\n",
            "        3.0610e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.4400e+02,\n",
            "        7.0000e+00, 3.6000e+01, 1.0000e+00, 1.4000e+02, 2.0000e+00, 3.3900e+02,\n",
            "        7.0000e+00, 1.3000e+01, 1.7490e+03, 3.2300e+02, 6.2800e+02, 1.3620e+03])\n",
            "['Topology', 'is', 'the', 'branch', 'of', 'mathematics', 'that', 'studies', 'the', 'properties', 'of', 'space', 'that', 'are', 'preserved', 'under', 'continuous', 'transformations.', 'Topology', 'is', 'the', 'branch', 'of', 'mathematics', 'that', 'studies', 'the', 'properties', 'of', 'space', 'that', 'are', 'preserved', 'under', 'continuous', 'transformations.']\n",
            "[('Topology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'properties'), ('properties', 'of'), ('of', 'space'), ('space', 'that'), ('that', 'are'), ('are', 'preserved'), ('preserved', 'under'), ('under', 'continuous'), ('continuous', 'transformations.'), ('Topology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'properties'), ('properties', 'of'), ('of', 'space'), ('space', 'that'), ('that', 'are'), ('are', 'preserved'), ('preserved', 'under'), ('under', 'continuous'), ('continuous', 'transformations.')]\n",
            "44\n",
            "42\n",
            "946\n",
            "86\n",
            "tensor([1.1000e+01, 1.7760e+03, 3.0000e+00, 2.1000e+01, 1.8700e+02, 1.0780e+03,\n",
            "        2.0000e+00, 7.0400e+02, 5.0000e+00, 2.7630e+03, 5.5600e+02, 1.4100e+02,\n",
            "        1.0000e+00, 5.3000e+02, 2.0000e+00, 1.1450e+03, 7.4300e+02, 8.8400e+02,\n",
            "        5.0000e+00, 1.9350e+03, 9.4300e+02, 2.4410e+03, 1.1000e+01, 1.7760e+03,\n",
            "        3.0000e+00, 2.1000e+01, 1.8700e+02, 1.0780e+03, 2.0000e+00, 7.0400e+02,\n",
            "        5.0000e+00, 2.7630e+03, 5.5600e+02, 1.4100e+02, 1.0000e+00, 5.3000e+02,\n",
            "        2.0000e+00, 1.1450e+03, 7.4300e+02, 8.8400e+02, 5.0000e+00, 1.9350e+03,\n",
            "        9.4300e+02, 2.4410e+03])\n",
            "['A', 'polynomial', 'is', 'an', 'expression', 'consisting', 'of', 'variables', 'and', 'coefficients,', 'involving', 'only', 'the', 'operations', 'of', 'addition,', 'subtraction,', 'multiplication,', 'and', 'non-negative', 'integer', 'exponents.', 'A', 'polynomial', 'is', 'an', 'expression', 'consisting', 'of', 'variables', 'and', 'coefficients,', 'involving', 'only', 'the', 'operations', 'of', 'addition,', 'subtraction,', 'multiplication,', 'and', 'non-negative', 'integer', 'exponents.']\n",
            "[('A', 'polynomial'), ('polynomial', 'is'), ('is', 'an'), ('an', 'expression'), ('expression', 'consisting'), ('consisting', 'of'), ('of', 'variables'), ('variables', 'and'), ('and', 'coefficients,'), ('coefficients,', 'involving'), ('involving', 'only'), ('only', 'the'), ('the', 'operations'), ('operations', 'of'), ('of', 'addition,'), ('addition,', 'subtraction,'), ('subtraction,', 'multiplication,'), ('multiplication,', 'and'), ('and', 'non-negative'), ('non-negative', 'integer'), ('integer', 'exponents.'), ('A', 'polynomial'), ('polynomial', 'is'), ('is', 'an'), ('an', 'expression'), ('expression', 'consisting'), ('consisting', 'of'), ('of', 'variables'), ('variables', 'and'), ('and', 'coefficients,'), ('coefficients,', 'involving'), ('involving', 'only'), ('only', 'the'), ('the', 'operations'), ('operations', 'of'), ('of', 'addition,'), ('addition,', 'subtraction,'), ('subtraction,', 'multiplication,'), ('multiplication,', 'and'), ('and', 'non-negative'), ('non-negative', 'integer'), ('integer', 'exponents.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 8.0500e+02, 1.1100e+02, 1.3900e+02, 1.0000e+00, 1.5140e+03,\n",
            "        6.0000e+00, 1.0000e+00, 8.0500e+02, 1.3200e+02, 2.8940e+03, 1.2170e+03,\n",
            "        2.8240e+03, 1.2170e+03, 1.1070e+03, 6.8400e+02, 3.4810e+03, 9.0000e+00,\n",
            "        8.0500e+02, 1.1100e+02, 1.3900e+02, 1.0000e+00, 1.5140e+03, 6.0000e+00,\n",
            "        1.0000e+00, 8.0500e+02, 1.3200e+02, 2.8940e+03, 1.2170e+03, 2.8240e+03,\n",
            "        1.2170e+03, 1.1070e+03, 6.8400e+02, 3.4810e+03])\n",
            "['The', 'quadratic', 'formula', 'provides', 'the', 'solution', 'to', 'the', 'quadratic', 'equation', 'ax^2', '+', 'bx', '+', 'c', '=', '0.', 'The', 'quadratic', 'formula', 'provides', 'the', 'solution', 'to', 'the', 'quadratic', 'equation', 'ax^2', '+', 'bx', '+', 'c', '=', '0.']\n",
            "[('The', 'quadratic'), ('quadratic', 'formula'), ('formula', 'provides'), ('provides', 'the'), ('the', 'solution'), ('solution', 'to'), ('to', 'the'), ('the', 'quadratic'), ('quadratic', 'equation'), ('equation', 'ax^2'), ('ax^2', '+'), ('+', 'bx'), ('bx', '+'), ('+', 'c'), ('c', '='), ('=', '0.'), ('The', 'quadratic'), ('quadratic', 'formula'), ('formula', 'provides'), ('provides', 'the'), ('the', 'solution'), ('solution', 'to'), ('to', 'the'), ('the', 'quadratic'), ('quadratic', 'equation'), ('equation', 'ax^2'), ('ax^2', '+'), ('+', 'bx'), ('bx', '+'), ('+', 'c'), ('c', '='), ('=', '0.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([  11., 1053.,    3.,   21., 2210.,   85.,    8.,    4., 1305.,   11.,\n",
            "        1053.,    3.,   21., 2210.,   85.,    8.,    4., 1305.])\n",
            "['A', 'differential', 'is', 'an', 'infinitesimal', 'change', 'in', 'a', 'variable.', 'A', 'differential', 'is', 'an', 'infinitesimal', 'change', 'in', 'a', 'variable.']\n",
            "[('A', 'differential'), ('differential', 'is'), ('is', 'an'), ('an', 'infinitesimal'), ('infinitesimal', 'change'), ('change', 'in'), ('in', 'a'), ('a', 'variable.'), ('A', 'differential'), ('differential', 'is'), ('is', 'an'), ('an', 'infinitesimal'), ('infinitesimal', 'change'), ('change', 'in'), ('in', 'a'), ('a', 'variable.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([9.0000e+00, 2.8610e+03, 2.0400e+02, 4.9000e+01, 1.0000e+00, 2.9700e+03,\n",
            "        1.0080e+03, 2.0000e+00, 1.7620e+03, 2.0000e+00, 4.0000e+00, 2.8600e+03,\n",
            "        9.0000e+00, 2.8610e+03, 2.0400e+02, 4.9000e+01, 1.0000e+00, 2.9700e+03,\n",
            "        1.0080e+03, 2.0000e+00, 1.7620e+03, 2.0000e+00, 4.0000e+00, 2.8600e+03])\n",
            "['The', 'binomial', 'theorem', 'describes', 'the', 'algebraic', 'expansion', 'of', 'powers', 'of', 'a', 'binomial.', 'The', 'binomial', 'theorem', 'describes', 'the', 'algebraic', 'expansion', 'of', 'powers', 'of', 'a', 'binomial.']\n",
            "[('The', 'binomial'), ('binomial', 'theorem'), ('theorem', 'describes'), ('describes', 'the'), ('the', 'algebraic'), ('algebraic', 'expansion'), ('expansion', 'of'), ('of', 'powers'), ('powers', 'of'), ('of', 'a'), ('a', 'binomial.'), ('The', 'binomial'), ('binomial', 'theorem'), ('theorem', 'describes'), ('describes', 'the'), ('the', 'algebraic'), ('algebraic', 'expansion'), ('expansion', 'of'), ('of', 'powers'), ('powers', 'of'), ('of', 'a'), ('a', 'binomial.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([3.3920e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.4400e+02,\n",
            "        6.2300e+02, 1.9000e+01, 2.7520e+03, 2.0000e+00, 2.6800e+02, 2.8700e+03,\n",
            "        6.0000e+00, 4.0000e+00, 2.3930e+03, 1.2800e+02, 8.0000e+00, 3.0120e+03,\n",
            "        1.9000e+01, 4.1300e+02, 2.7070e+03, 3.3920e+03, 3.0000e+00, 1.0000e+00,\n",
            "        2.7000e+01, 2.0000e+00, 1.4400e+02, 6.2300e+02, 1.9000e+01, 2.7520e+03,\n",
            "        2.0000e+00, 2.6800e+02, 2.8700e+03, 6.0000e+00, 4.0000e+00, 2.3930e+03,\n",
            "        1.2800e+02, 8.0000e+00, 3.0120e+03, 1.9000e+01, 4.1300e+02, 2.7070e+03])\n",
            "['Combinatorics', 'is', 'the', 'branch', 'of', 'mathematics', 'dealing', 'with', 'combinations', 'of', 'objects', 'belonging', 'to', 'a', 'finite', 'set', 'in', 'accordance', 'with', 'certain', 'constraints.', 'Combinatorics', 'is', 'the', 'branch', 'of', 'mathematics', 'dealing', 'with', 'combinations', 'of', 'objects', 'belonging', 'to', 'a', 'finite', 'set', 'in', 'accordance', 'with', 'certain', 'constraints.']\n",
            "[('Combinatorics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'dealing'), ('dealing', 'with'), ('with', 'combinations'), ('combinations', 'of'), ('of', 'objects'), ('objects', 'belonging'), ('belonging', 'to'), ('to', 'a'), ('a', 'finite'), ('finite', 'set'), ('set', 'in'), ('in', 'accordance'), ('accordance', 'with'), ('with', 'certain'), ('certain', 'constraints.'), ('Combinatorics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'mathematics'), ('mathematics', 'dealing'), ('dealing', 'with'), ('with', 'combinations'), ('combinations', 'of'), ('of', 'objects'), ('objects', 'belonging'), ('belonging', 'to'), ('to', 'a'), ('a', 'finite'), ('finite', 'set'), ('set', 'in'), ('in', 'accordance'), ('accordance', 'with'), ('with', 'certain'), ('certain', 'constraints.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 9.7000e+02, 1.6750e+03, 3.0000e+00, 4.0000e+00, 7.5500e+02,\n",
            "        5.9000e+01, 1.9300e+02, 2.3000e+02, 6.0000e+00, 3.4780e+03, 5.3000e+01,\n",
            "        2.5050e+03, 8.0000e+00, 1.4400e+02, 5.0000e+00, 2.9200e+03, 9.0000e+00,\n",
            "        9.7000e+02, 1.6750e+03, 3.0000e+00, 4.0000e+00, 7.5500e+02, 5.9000e+01,\n",
            "        1.9300e+02, 2.3000e+02, 6.0000e+00, 3.4780e+03, 5.3000e+01, 2.5050e+03,\n",
            "        8.0000e+00, 1.4400e+02, 5.0000e+00, 2.9200e+03])\n",
            "['The', 'golden', 'ratio', 'is', 'a', 'special', 'number', 'approximately', 'equal', 'to', '1.618,', 'often', 'encountered', 'in', 'mathematics', 'and', 'art.', 'The', 'golden', 'ratio', 'is', 'a', 'special', 'number', 'approximately', 'equal', 'to', '1.618,', 'often', 'encountered', 'in', 'mathematics', 'and', 'art.']\n",
            "[('The', 'golden'), ('golden', 'ratio'), ('ratio', 'is'), ('is', 'a'), ('a', 'special'), ('special', 'number'), ('number', 'approximately'), ('approximately', 'equal'), ('equal', 'to'), ('to', '1.618,'), ('1.618,', 'often'), ('often', 'encountered'), ('encountered', 'in'), ('in', 'mathematics'), ('mathematics', 'and'), ('and', 'art.'), ('The', 'golden'), ('golden', 'ratio'), ('ratio', 'is'), ('is', 'a'), ('a', 'special'), ('special', 'number'), ('number', 'approximately'), ('approximately', 'equal'), ('equal', 'to'), ('to', '1.618,'), ('1.618,', 'often'), ('often', 'encountered'), ('encountered', 'in'), ('in', 'mathematics'), ('mathematics', 'and'), ('and', 'art.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([3.3200e+03, 1.3000e+01, 1.2300e+02, 5.8000e+02, 1.5370e+03, 7.0000e+00,\n",
            "        1.6000e+01, 2.5000e+01, 1.4870e+03, 6.9000e+01, 1.8490e+03, 2.9200e+02,\n",
            "        2.0000e+00, 2.2000e+01, 3.0000e+00, 4.0000e+00, 1.6460e+03, 2.6860e+03,\n",
            "        2.0000e+00, 1.0000e+00, 1.2520e+03, 3.3200e+03, 1.3000e+01, 1.2300e+02,\n",
            "        5.8000e+02, 1.5370e+03, 7.0000e+00, 1.6000e+01, 2.5000e+01, 1.4870e+03,\n",
            "        6.9000e+01, 1.8490e+03, 2.9200e+02, 2.0000e+00, 2.2000e+01, 3.0000e+00,\n",
            "        4.0000e+00, 1.6460e+03, 2.6860e+03, 2.0000e+00, 1.0000e+00, 1.2520e+03])\n",
            "['Fractals', 'are', 'complex', 'geometric', 'shapes', 'that', 'can', 'be', 'split', 'into', 'parts,', 'each', 'of', 'which', 'is', 'a', 'reduced-scale', 'copy', 'of', 'the', 'whole.', 'Fractals', 'are', 'complex', 'geometric', 'shapes', 'that', 'can', 'be', 'split', 'into', 'parts,', 'each', 'of', 'which', 'is', 'a', 'reduced-scale', 'copy', 'of', 'the', 'whole.']\n",
            "[('Fractals', 'are'), ('are', 'complex'), ('complex', 'geometric'), ('geometric', 'shapes'), ('shapes', 'that'), ('that', 'can'), ('can', 'be'), ('be', 'split'), ('split', 'into'), ('into', 'parts,'), ('parts,', 'each'), ('each', 'of'), ('of', 'which'), ('which', 'is'), ('is', 'a'), ('a', 'reduced-scale'), ('reduced-scale', 'copy'), ('copy', 'of'), ('of', 'the'), ('the', 'whole.'), ('Fractals', 'are'), ('are', 'complex'), ('complex', 'geometric'), ('geometric', 'shapes'), ('shapes', 'that'), ('that', 'can'), ('can', 'be'), ('be', 'split'), ('split', 'into'), ('into', 'parts,'), ('parts,', 'each'), ('each', 'of'), ('of', 'which'), ('which', 'is'), ('is', 'a'), ('a', 'reduced-scale'), ('reduced-scale', 'copy'), ('copy', 'of'), ('of', 'the'), ('the', 'whole.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([1.1000e+01, 2.0730e+03, 3.0000e+00, 1.0000e+00, 2.4420e+03, 6.0000e+00,\n",
            "        2.2000e+01, 4.0000e+00, 2.8790e+03, 5.9000e+01, 1.9680e+03, 2.5000e+01,\n",
            "        1.6820e+03, 6.0000e+00, 1.0100e+02, 4.0000e+00, 5.7800e+02, 8.7000e+02,\n",
            "        1.1000e+01, 2.0730e+03, 3.0000e+00, 1.0000e+00, 2.4420e+03, 6.0000e+00,\n",
            "        2.2000e+01, 4.0000e+00, 2.8790e+03, 5.9000e+01, 1.9680e+03, 2.5000e+01,\n",
            "        1.6820e+03, 6.0000e+00, 1.0100e+02, 4.0000e+00, 5.7800e+02, 8.7000e+02])\n",
            "['A', 'logarithm', 'is', 'the', 'exponent', 'to', 'which', 'a', 'base', 'number', 'must', 'be', 'raised', 'to', 'produce', 'a', 'given', 'number.', 'A', 'logarithm', 'is', 'the', 'exponent', 'to', 'which', 'a', 'base', 'number', 'must', 'be', 'raised', 'to', 'produce', 'a', 'given', 'number.']\n",
            "[('A', 'logarithm'), ('logarithm', 'is'), ('is', 'the'), ('the', 'exponent'), ('exponent', 'to'), ('to', 'which'), ('which', 'a'), ('a', 'base'), ('base', 'number'), ('number', 'must'), ('must', 'be'), ('be', 'raised'), ('raised', 'to'), ('to', 'produce'), ('produce', 'a'), ('a', 'given'), ('given', 'number.'), ('A', 'logarithm'), ('logarithm', 'is'), ('is', 'the'), ('the', 'exponent'), ('exponent', 'to'), ('to', 'which'), ('which', 'a'), ('a', 'base'), ('base', 'number'), ('number', 'must'), ('must', 'be'), ('be', 'raised'), ('raised', 'to'), ('to', 'produce'), ('produce', 'a'), ('a', 'given'), ('given', 'number.')]\n",
            "50\n",
            "48\n",
            "1225\n",
            "98\n",
            "tensor([9.0000e+00, 8.2000e+01, 2.0400e+02, 2.0000e+00, 2.9260e+03, 3.2000e+01,\n",
            "        7.0000e+00, 2.2900e+02, 9.4300e+02, 5.7500e+02, 6.6000e+01, 3.1500e+02,\n",
            "        3.0000e+00, 1.0370e+03, 4.0000e+00, 3.5400e+02, 5.9000e+01, 1.0000e+01,\n",
            "        1.6000e+01, 2.5000e+01, 1.3240e+03, 2.4300e+03, 6.9000e+01, 3.5400e+02,\n",
            "        2.1600e+02, 9.0000e+00, 8.2000e+01, 2.0400e+02, 2.0000e+00, 2.9260e+03,\n",
            "        3.2000e+01, 7.0000e+00, 2.2900e+02, 9.4300e+02, 5.7500e+02, 6.6000e+01,\n",
            "        3.1500e+02, 3.0000e+00, 1.0370e+03, 4.0000e+00, 3.5400e+02, 5.9000e+01,\n",
            "        1.0000e+01, 1.6000e+01, 2.5000e+01, 1.3240e+03, 2.4300e+03, 6.9000e+01,\n",
            "        3.5400e+02, 2.1600e+02])\n",
            "['The', 'fundamental', 'theorem', 'of', 'arithmetic', 'states', 'that', 'every', 'integer', 'greater', 'than', '1', 'is', 'either', 'a', 'prime', 'number', 'or', 'can', 'be', 'uniquely', 'factorized', 'into', 'prime', 'numbers.', 'The', 'fundamental', 'theorem', 'of', 'arithmetic', 'states', 'that', 'every', 'integer', 'greater', 'than', '1', 'is', 'either', 'a', 'prime', 'number', 'or', 'can', 'be', 'uniquely', 'factorized', 'into', 'prime', 'numbers.']\n",
            "[('The', 'fundamental'), ('fundamental', 'theorem'), ('theorem', 'of'), ('of', 'arithmetic'), ('arithmetic', 'states'), ('states', 'that'), ('that', 'every'), ('every', 'integer'), ('integer', 'greater'), ('greater', 'than'), ('than', '1'), ('1', 'is'), ('is', 'either'), ('either', 'a'), ('a', 'prime'), ('prime', 'number'), ('number', 'or'), ('or', 'can'), ('can', 'be'), ('be', 'uniquely'), ('uniquely', 'factorized'), ('factorized', 'into'), ('into', 'prime'), ('prime', 'numbers.'), ('The', 'fundamental'), ('fundamental', 'theorem'), ('theorem', 'of'), ('of', 'arithmetic'), ('arithmetic', 'states'), ('states', 'that'), ('that', 'every'), ('every', 'integer'), ('integer', 'greater'), ('greater', 'than'), ('than', '1'), ('1', 'is'), ('is', 'either'), ('either', 'a'), ('a', 'prime'), ('prime', 'number'), ('number', 'or'), ('or', 'can'), ('can', 'be'), ('be', 'uniquely'), ('uniquely', 'factorized'), ('factorized', 'into'), ('into', 'prime'), ('prime', 'numbers.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([1.1000e+01, 2.6210e+03, 2.5700e+02, 1.0000e+00, 1.6770e+03, 7.1000e+01,\n",
            "        2.2000e+01, 4.0000e+00, 8.0300e+02, 1.3300e+02, 1.9000e+01, 7.8900e+02,\n",
            "        6.0000e+00, 1.3500e+02, 8.0200e+02, 1.1000e+01, 2.6210e+03, 2.5700e+02,\n",
            "        1.0000e+00, 1.6770e+03, 7.1000e+01, 2.2000e+01, 4.0000e+00, 8.0300e+02,\n",
            "        1.3300e+02, 1.9000e+01, 7.8900e+02, 6.0000e+00, 1.3500e+02, 8.0200e+02])\n",
            "['A', 'derivative', 'represents', 'the', 'rate', 'at', 'which', 'a', 'quantity', 'changes', 'with', 'respect', 'to', 'another', 'quantity.', 'A', 'derivative', 'represents', 'the', 'rate', 'at', 'which', 'a', 'quantity', 'changes', 'with', 'respect', 'to', 'another', 'quantity.']\n",
            "[('A', 'derivative'), ('derivative', 'represents'), ('represents', 'the'), ('the', 'rate'), ('rate', 'at'), ('at', 'which'), ('which', 'a'), ('a', 'quantity'), ('quantity', 'changes'), ('changes', 'with'), ('with', 'respect'), ('respect', 'to'), ('to', 'another'), ('another', 'quantity.'), ('A', 'derivative'), ('derivative', 'represents'), ('represents', 'the'), ('the', 'rate'), ('rate', 'at'), ('at', 'which'), ('which', 'a'), ('a', 'quantity'), ('quantity', 'changes'), ('changes', 'with'), ('with', 'respect'), ('respect', 'to'), ('to', 'another'), ('another', 'quantity.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([4.5000e+01, 9.4200e+02, 3.0000e+00, 4.0000e+00, 6.2000e+01, 1.1800e+02,\n",
            "        7.0000e+00, 2.5700e+02, 1.0000e+00, 4.2600e+02, 3.2300e+02, 4.0000e+00,\n",
            "        2.6530e+03, 4.5000e+01, 9.4200e+02, 3.0000e+00, 4.0000e+00, 6.2000e+01,\n",
            "        1.1800e+02, 7.0000e+00, 2.5700e+02, 1.0000e+00, 4.2600e+02, 3.2300e+02,\n",
            "        4.0000e+00, 2.6530e+03])\n",
            "['An', 'integral', 'is', 'a', 'mathematical', 'object', 'that', 'represents', 'the', 'area', 'under', 'a', 'curve.', 'An', 'integral', 'is', 'a', 'mathematical', 'object', 'that', 'represents', 'the', 'area', 'under', 'a', 'curve.']\n",
            "[('An', 'integral'), ('integral', 'is'), ('is', 'a'), ('a', 'mathematical'), ('mathematical', 'object'), ('object', 'that'), ('that', 'represents'), ('represents', 'the'), ('the', 'area'), ('area', 'under'), ('under', 'a'), ('a', 'curve.'), ('An', 'integral'), ('integral', 'is'), ('is', 'a'), ('a', 'mathematical'), ('mathematical', 'object'), ('object', 'that'), ('that', 'represents'), ('represents', 'the'), ('the', 'area'), ('area', 'under'), ('under', 'a'), ('a', 'curve.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([9.0000e+00, 8.9400e+02, 3.0000e+00, 1.0000e+00, 2.8970e+03, 2.0000e+00,\n",
            "        4.0000e+00, 1.2800e+02, 2.0000e+00, 2.1600e+02, 9.0000e+00, 8.9400e+02,\n",
            "        3.0000e+00, 1.0000e+00, 2.8970e+03, 2.0000e+00, 4.0000e+00, 1.2800e+02,\n",
            "        2.0000e+00, 2.1600e+02])\n",
            "['The', 'mean', 'is', 'the', 'average', 'of', 'a', 'set', 'of', 'numbers.', 'The', 'mean', 'is', 'the', 'average', 'of', 'a', 'set', 'of', 'numbers.']\n",
            "[('The', 'mean'), ('mean', 'is'), ('is', 'the'), ('the', 'average'), ('average', 'of'), ('of', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'numbers.'), ('The', 'mean'), ('mean', 'is'), ('is', 'the'), ('the', 'average'), ('average', 'of'), ('of', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'numbers.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([9.0000e+00, 2.0200e+03, 3.0000e+00, 1.0000e+00, 2.0050e+03, 4.4500e+02,\n",
            "        8.0000e+00, 4.0000e+00, 9.1000e+02, 2.0000e+00, 2.1600e+02, 9.0000e+00,\n",
            "        2.0200e+03, 3.0000e+00, 1.0000e+00, 2.0050e+03, 4.4500e+02, 8.0000e+00,\n",
            "        4.0000e+00, 9.1000e+02, 2.0000e+00, 2.1600e+02])\n",
            "['The', 'median', 'is', 'the', 'middle', 'value', 'in', 'a', 'list', 'of', 'numbers.', 'The', 'median', 'is', 'the', 'middle', 'value', 'in', 'a', 'list', 'of', 'numbers.']\n",
            "[('The', 'median'), ('median', 'is'), ('is', 'the'), ('the', 'middle'), ('middle', 'value'), ('value', 'in'), ('in', 'a'), ('a', 'list'), ('list', 'of'), ('of', 'numbers.'), ('The', 'median'), ('median', 'is'), ('is', 'the'), ('the', 'middle'), ('middle', 'value'), ('value', 'in'), ('in', 'a'), ('a', 'list'), ('list', 'of'), ('of', 'numbers.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([9.0000e+00, 1.9940e+03, 3.0000e+00, 1.0000e+00, 5.9000e+01, 7.0000e+00,\n",
            "        2.9370e+03, 1.2100e+02, 2.3550e+03, 8.0000e+00, 4.0000e+00, 9.5000e+01,\n",
            "        7.7500e+02, 9.0000e+00, 1.9940e+03, 3.0000e+00, 1.0000e+00, 5.9000e+01,\n",
            "        7.0000e+00, 2.9370e+03, 1.2100e+02, 2.3550e+03, 8.0000e+00, 4.0000e+00,\n",
            "        9.5000e+01, 7.7500e+02])\n",
            "['The', 'mode', 'is', 'the', 'number', 'that', 'appears', 'most', 'frequently', 'in', 'a', 'data', 'set.', 'The', 'mode', 'is', 'the', 'number', 'that', 'appears', 'most', 'frequently', 'in', 'a', 'data', 'set.']\n",
            "[('The', 'mode'), ('mode', 'is'), ('is', 'the'), ('the', 'number'), ('number', 'that'), ('that', 'appears'), ('appears', 'most'), ('most', 'frequently'), ('frequently', 'in'), ('in', 'a'), ('a', 'data'), ('data', 'set.'), ('The', 'mode'), ('mode', 'is'), ('is', 'the'), ('the', 'number'), ('number', 'that'), ('that', 'appears'), ('appears', 'most'), ('most', 'frequently'), ('frequently', 'in'), ('in', 'a'), ('a', 'data'), ('data', 'set.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([1.1000e+01, 2.6200e+02, 4.0600e+02, 4.9000e+01, 7.6000e+01, 1.0000e+00,\n",
            "        1.9800e+02, 2.0000e+00, 4.0000e+00, 5.0700e+02, 7.0500e+02, 1.3000e+01,\n",
            "        2.5750e+03, 1.1000e+01, 2.6200e+02, 4.0600e+02, 4.9000e+01, 7.6000e+01,\n",
            "        1.0000e+00, 1.9800e+02, 2.0000e+00, 4.0000e+00, 5.0700e+02, 7.0500e+02,\n",
            "        1.3000e+01, 2.5750e+03])\n",
            "['A', 'probability', 'distribution', 'describes', 'how', 'the', 'values', 'of', 'a', 'random', 'variable', 'are', 'distributed.', 'A', 'probability', 'distribution', 'describes', 'how', 'the', 'values', 'of', 'a', 'random', 'variable', 'are', 'distributed.']\n",
            "[('A', 'probability'), ('probability', 'distribution'), ('distribution', 'describes'), ('describes', 'how'), ('how', 'the'), ('the', 'values'), ('values', 'of'), ('of', 'a'), ('a', 'random'), ('random', 'variable'), ('variable', 'are'), ('are', 'distributed.'), ('A', 'probability'), ('probability', 'distribution'), ('distribution', 'describes'), ('describes', 'how'), ('how', 'the'), ('the', 'values'), ('values', 'of'), ('of', 'a'), ('a', 'random'), ('random', 'variable'), ('variable', 'are'), ('are', 'distributed.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([3.4270e+03, 2.0400e+02, 4.9000e+01, 1.0000e+00, 2.6200e+02, 2.0000e+00,\n",
            "        2.1000e+01, 6.0400e+02, 1.5700e+02, 2.3000e+01, 1.7420e+03, 1.3100e+02,\n",
            "        2.0000e+00, 6.3400e+02, 3.4800e+02, 6.0000e+00, 1.0000e+00, 2.4760e+03,\n",
            "        3.4270e+03, 2.0400e+02, 4.9000e+01, 1.0000e+00, 2.6200e+02, 2.0000e+00,\n",
            "        2.1000e+01, 6.0400e+02, 1.5700e+02, 2.3000e+01, 1.7420e+03, 1.3100e+02,\n",
            "        2.0000e+00, 6.3400e+02, 3.4800e+02, 6.0000e+00, 1.0000e+00, 2.4760e+03])\n",
            "[\"Bayes'\", 'theorem', 'describes', 'the', 'probability', 'of', 'an', 'event', 'based', 'on', 'prior', 'knowledge', 'of', 'conditions', 'related', 'to', 'the', 'event.', \"Bayes'\", 'theorem', 'describes', 'the', 'probability', 'of', 'an', 'event', 'based', 'on', 'prior', 'knowledge', 'of', 'conditions', 'related', 'to', 'the', 'event.']\n",
            "[(\"Bayes'\", 'theorem'), ('theorem', 'describes'), ('describes', 'the'), ('the', 'probability'), ('probability', 'of'), ('of', 'an'), ('an', 'event'), ('event', 'based'), ('based', 'on'), ('on', 'prior'), ('prior', 'knowledge'), ('knowledge', 'of'), ('of', 'conditions'), ('conditions', 'related'), ('related', 'to'), ('to', 'the'), ('the', 'event.'), (\"Bayes'\", 'theorem'), ('theorem', 'describes'), ('describes', 'the'), ('the', 'probability'), ('probability', 'of'), ('of', 'an'), ('an', 'event'), ('event', 'based'), ('based', 'on'), ('on', 'prior'), ('prior', 'knowledge'), ('knowledge', 'of'), ('of', 'conditions'), ('conditions', 'related'), ('related', 'to'), ('to', 'the'), ('the', 'event.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.3100e+03, 4.8000e+01, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00,\n",
            "        6.2000e+01, 6.1000e+01, 2.0000e+00, 1.4680e+03, 9.3900e+02, 2.9570e+03,\n",
            "        5.0600e+02, 2.6400e+03, 3.3100e+03, 4.8000e+01, 3.0000e+00, 1.0000e+00,\n",
            "        3.4000e+01, 2.0000e+00, 6.2000e+01, 6.1000e+01, 2.0000e+00, 1.4680e+03,\n",
            "        9.3900e+02, 2.9570e+03, 5.0600e+02, 2.6400e+03])\n",
            "['Game', 'theory', 'is', 'the', 'study', 'of', 'mathematical', 'models', 'of', 'strategic', 'interaction', 'among', 'rational', 'decision-makers.', 'Game', 'theory', 'is', 'the', 'study', 'of', 'mathematical', 'models', 'of', 'strategic', 'interaction', 'among', 'rational', 'decision-makers.']\n",
            "[('Game', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'mathematical'), ('mathematical', 'models'), ('models', 'of'), ('of', 'strategic'), ('strategic', 'interaction'), ('interaction', 'among'), ('among', 'rational'), ('rational', 'decision-makers.'), ('Game', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'mathematical'), ('mathematical', 'models'), ('models', 'of'), ('of', 'strategic'), ('strategic', 'interaction'), ('interaction', 'among'), ('among', 'rational'), ('rational', 'decision-makers.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([9.0000e+00, 3.3210e+03, 7.1600e+02, 3.0000e+00, 4.0000e+00, 6.2000e+01,\n",
            "        7.1600e+02, 7.0000e+00, 2.6360e+03, 2.8700e+02, 1.0610e+03, 2.3000e+01,\n",
            "        3.3900e+02, 1.0000e+01, 3.3000e+02, 6.9000e+01, 2.8700e+02, 1.0610e+03,\n",
            "        2.3000e+01, 1.5000e+03, 1.0000e+01, 1.4120e+03, 2.3570e+03, 9.0000e+00,\n",
            "        3.3210e+03, 7.1600e+02, 3.0000e+00, 4.0000e+00, 6.2000e+01, 7.1600e+02,\n",
            "        7.0000e+00, 2.6360e+03, 2.8700e+02, 1.0610e+03, 2.3000e+01, 3.3900e+02,\n",
            "        1.0000e+01, 3.3000e+02, 6.9000e+01, 2.8700e+02, 1.0610e+03, 2.3000e+01,\n",
            "        1.5000e+03, 1.0000e+01, 1.4120e+03, 2.3570e+03])\n",
            "['The', 'Fourier', 'transform', 'is', 'a', 'mathematical', 'transform', 'that', 'decomposes', 'functions', 'depending', 'on', 'space', 'or', 'time', 'into', 'functions', 'depending', 'on', 'spatial', 'or', 'temporal', 'frequency.', 'The', 'Fourier', 'transform', 'is', 'a', 'mathematical', 'transform', 'that', 'decomposes', 'functions', 'depending', 'on', 'space', 'or', 'time', 'into', 'functions', 'depending', 'on', 'spatial', 'or', 'temporal', 'frequency.']\n",
            "[('The', 'Fourier'), ('Fourier', 'transform'), ('transform', 'is'), ('is', 'a'), ('a', 'mathematical'), ('mathematical', 'transform'), ('transform', 'that'), ('that', 'decomposes'), ('decomposes', 'functions'), ('functions', 'depending'), ('depending', 'on'), ('on', 'space'), ('space', 'or'), ('or', 'time'), ('time', 'into'), ('into', 'functions'), ('functions', 'depending'), ('depending', 'on'), ('on', 'spatial'), ('spatial', 'or'), ('or', 'temporal'), ('temporal', 'frequency.'), ('The', 'Fourier'), ('Fourier', 'transform'), ('transform', 'is'), ('is', 'a'), ('a', 'mathematical'), ('mathematical', 'transform'), ('transform', 'that'), ('that', 'decomposes'), ('decomposes', 'functions'), ('functions', 'depending'), ('depending', 'on'), ('on', 'space'), ('space', 'or'), ('or', 'time'), ('time', 'into'), ('into', 'functions'), ('functions', 'depending'), ('depending', 'on'), ('on', 'spatial'), ('spatial', 'or'), ('or', 'temporal'), ('temporal', 'frequency.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([3.4150e+03, 6.5700e+02, 3.0000e+00, 4.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        6.5700e+02, 8.0000e+00, 2.2000e+01, 1.0000e+00, 1.9800e+02, 2.0000e+00,\n",
            "        1.0000e+00, 7.0400e+02, 1.3000e+01, 4.5000e+02, 5.0000e+00, 2.4220e+03,\n",
            "        3.2400e+02, 2.6250e+03, 3.1500e+02, 5.0000e+00, 1.2150e+03, 1.6080e+03,\n",
            "        3.4150e+03, 6.5700e+02, 3.0000e+00, 4.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        6.5700e+02, 8.0000e+00, 2.2000e+01, 1.0000e+00, 1.9800e+02, 2.0000e+00,\n",
            "        1.0000e+00, 7.0400e+02, 1.3000e+01, 4.5000e+02, 5.0000e+00, 2.4220e+03,\n",
            "        3.2400e+02, 2.6250e+03, 3.1500e+02, 5.0000e+00, 1.2150e+03, 1.6080e+03])\n",
            "['Boolean', 'algebra', 'is', 'a', 'branch', 'of', 'algebra', 'in', 'which', 'the', 'values', 'of', 'the', 'variables', 'are', 'true', 'and', 'false,', 'typically', 'denoted', '1', 'and', '0', 'respectively.', 'Boolean', 'algebra', 'is', 'a', 'branch', 'of', 'algebra', 'in', 'which', 'the', 'values', 'of', 'the', 'variables', 'are', 'true', 'and', 'false,', 'typically', 'denoted', '1', 'and', '0', 'respectively.']\n",
            "[('Boolean', 'algebra'), ('algebra', 'is'), ('is', 'a'), ('a', 'branch'), ('branch', 'of'), ('of', 'algebra'), ('algebra', 'in'), ('in', 'which'), ('which', 'the'), ('the', 'values'), ('values', 'of'), ('of', 'the'), ('the', 'variables'), ('variables', 'are'), ('are', 'true'), ('true', 'and'), ('and', 'false,'), ('false,', 'typically'), ('typically', 'denoted'), ('denoted', '1'), ('1', 'and'), ('and', '0'), ('0', 'respectively.'), ('Boolean', 'algebra'), ('algebra', 'is'), ('is', 'a'), ('a', 'branch'), ('branch', 'of'), ('of', 'algebra'), ('algebra', 'in'), ('in', 'which'), ('which', 'the'), ('the', 'values'), ('values', 'of'), ('of', 'the'), ('the', 'variables'), ('variables', 'are'), ('are', 'true'), ('true', 'and'), ('and', 'false,'), ('false,', 'typically'), ('typically', 'denoted'), ('denoted', '1'), ('1', 'and'), ('and', '0'), ('0', 'respectively.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([  45., 2526.,    3.,    4., 1570.,    7., 2225.,   76., 1977.,    4.,\n",
            "        2683., 2525.,    3., 1465.,   10., 2734.,  404.,    4.,  551., 1364.,\n",
            "          45., 2526.,    3.,    4., 1570.,    7., 2225.,   76., 1977.,    4.,\n",
            "        2683., 2525.,    3., 1465.,   10., 2734.,  404.,    4.,  551., 1364.])\n",
            "['An', 'eigenvalue', 'is', 'a', 'scalar', 'that', 'indicates', 'how', 'much', 'a', 'corresponding', 'eigenvector', 'is', 'stretched', 'or', 'compressed', 'during', 'a', 'linear', 'transformation.', 'An', 'eigenvalue', 'is', 'a', 'scalar', 'that', 'indicates', 'how', 'much', 'a', 'corresponding', 'eigenvector', 'is', 'stretched', 'or', 'compressed', 'during', 'a', 'linear', 'transformation.']\n",
            "[('An', 'eigenvalue'), ('eigenvalue', 'is'), ('is', 'a'), ('a', 'scalar'), ('scalar', 'that'), ('that', 'indicates'), ('indicates', 'how'), ('how', 'much'), ('much', 'a'), ('a', 'corresponding'), ('corresponding', 'eigenvector'), ('eigenvector', 'is'), ('is', 'stretched'), ('stretched', 'or'), ('or', 'compressed'), ('compressed', 'during'), ('during', 'a'), ('a', 'linear'), ('linear', 'transformation.'), ('An', 'eigenvalue'), ('eigenvalue', 'is'), ('is', 'a'), ('a', 'scalar'), ('scalar', 'that'), ('that', 'indicates'), ('indicates', 'how'), ('how', 'much'), ('much', 'a'), ('a', 'corresponding'), ('corresponding', 'eigenvector'), ('eigenvector', 'is'), ('is', 'stretched'), ('stretched', 'or'), ('or', 'compressed'), ('compressed', 'during'), ('during', 'a'), ('a', 'linear'), ('linear', 'transformation.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([  11., 1822.,    3.,   21., 1130.,    2.,  268.,    8.,    4.,   80.,\n",
            "        1891.,   11., 1822.,    3.,   21., 1130.,    2.,  268.,    8.,    4.,\n",
            "          80., 1891.])\n",
            "['A', 'permutation', 'is', 'an', 'arrangement', 'of', 'objects', 'in', 'a', 'specific', 'order.', 'A', 'permutation', 'is', 'an', 'arrangement', 'of', 'objects', 'in', 'a', 'specific', 'order.']\n",
            "[('A', 'permutation'), ('permutation', 'is'), ('is', 'an'), ('an', 'arrangement'), ('arrangement', 'of'), ('of', 'objects'), ('objects', 'in'), ('in', 'a'), ('a', 'specific'), ('specific', 'order.'), ('A', 'permutation'), ('permutation', 'is'), ('is', 'an'), ('an', 'arrangement'), ('arrangement', 'of'), ('of', 'objects'), ('objects', 'in'), ('in', 'a'), ('a', 'specific'), ('specific', 'order.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 2.7530e+03, 3.0000e+00, 4.0000e+00, 4.8800e+02, 2.0000e+00,\n",
            "        2.1440e+03, 2.4000e+01, 4.0000e+00, 9.2000e+02, 8.3200e+02, 9.9000e+01,\n",
            "        5.2800e+02, 2.9300e+02, 6.7000e+01, 2.7300e+02, 1.1000e+01, 2.7530e+03,\n",
            "        3.0000e+00, 4.0000e+00, 4.8800e+02, 2.0000e+00, 2.1440e+03, 2.4000e+01,\n",
            "        4.0000e+00, 9.2000e+02, 8.3200e+02, 9.9000e+01, 5.2800e+02, 2.9300e+02,\n",
            "        6.7000e+01, 2.7300e+02])\n",
            "['A', 'combination', 'is', 'a', 'selection', 'of', 'items', 'from', 'a', 'larger', 'pool', 'where', 'order', 'does', 'not', 'matter.', 'A', 'combination', 'is', 'a', 'selection', 'of', 'items', 'from', 'a', 'larger', 'pool', 'where', 'order', 'does', 'not', 'matter.']\n",
            "[('A', 'combination'), ('combination', 'is'), ('is', 'a'), ('a', 'selection'), ('selection', 'of'), ('of', 'items'), ('items', 'from'), ('from', 'a'), ('a', 'larger'), ('larger', 'pool'), ('pool', 'where'), ('where', 'order'), ('order', 'does'), ('does', 'not'), ('not', 'matter.'), ('A', 'combination'), ('combination', 'is'), ('is', 'a'), ('a', 'selection'), ('selection', 'of'), ('of', 'items'), ('items', 'from'), ('from', 'a'), ('a', 'larger'), ('larger', 'pool'), ('pool', 'where'), ('where', 'order'), ('order', 'does'), ('does', 'not'), ('not', 'matter.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 1.7200e+02, 3.0000e+00, 2.1000e+01, 1.8900e+03, 9.1000e+02,\n",
            "        2.0000e+00, 1.4300e+02, 7.0000e+00, 5.3000e+01, 2.3740e+03, 4.0000e+00,\n",
            "        8.0000e+01, 1.8380e+03, 1.0000e+01, 5.8600e+02, 1.1000e+01, 1.7200e+02,\n",
            "        3.0000e+00, 2.1000e+01, 1.8900e+03, 9.1000e+02, 2.0000e+00, 1.4300e+02,\n",
            "        7.0000e+00, 5.3000e+01, 2.3740e+03, 4.0000e+00, 8.0000e+01, 1.8380e+03,\n",
            "        1.0000e+01, 5.8600e+02])\n",
            "['A', 'sequence', 'is', 'an', 'ordered', 'list', 'of', 'numbers', 'that', 'often', 'follow', 'a', 'specific', 'pattern', 'or', 'function.', 'A', 'sequence', 'is', 'an', 'ordered', 'list', 'of', 'numbers', 'that', 'often', 'follow', 'a', 'specific', 'pattern', 'or', 'function.']\n",
            "[('A', 'sequence'), ('sequence', 'is'), ('is', 'an'), ('an', 'ordered'), ('ordered', 'list'), ('list', 'of'), ('of', 'numbers'), ('numbers', 'that'), ('that', 'often'), ('often', 'follow'), ('follow', 'a'), ('a', 'specific'), ('specific', 'pattern'), ('pattern', 'or'), ('or', 'function.'), ('A', 'sequence'), ('sequence', 'is'), ('is', 'an'), ('an', 'ordered'), ('ordered', 'list'), ('list', 'of'), ('of', 'numbers'), ('numbers', 'that'), ('that', 'often'), ('often', 'follow'), ('follow', 'a'), ('a', 'specific'), ('specific', 'pattern'), ('pattern', 'or'), ('or', 'function.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([1183.,  952.,    3.,    4.,  535.,    2.,   62.,  511.,   31.,    6.,\n",
            "        1706.,    7.,    4.,  138.,    3.,  450.,   12.,   51.,  181.,  216.,\n",
            "        1183.,  952.,    3.,    4.,  535.,    2.,   62.,  511.,   31.,    6.,\n",
            "        1706.,    7.,    4.,  138.,    3.,  450.,   12.,   51.,  181.,  216.])\n",
            "['Mathematical', 'induction', 'is', 'a', 'method', 'of', 'mathematical', 'proof', 'used', 'to', 'prove', 'that', 'a', 'statement', 'is', 'true', 'for', 'all', 'natural', 'numbers.', 'Mathematical', 'induction', 'is', 'a', 'method', 'of', 'mathematical', 'proof', 'used', 'to', 'prove', 'that', 'a', 'statement', 'is', 'true', 'for', 'all', 'natural', 'numbers.']\n",
            "[('Mathematical', 'induction'), ('induction', 'is'), ('is', 'a'), ('a', 'method'), ('method', 'of'), ('of', 'mathematical'), ('mathematical', 'proof'), ('proof', 'used'), ('used', 'to'), ('to', 'prove'), ('prove', 'that'), ('that', 'a'), ('a', 'statement'), ('statement', 'is'), ('is', 'true'), ('true', 'for'), ('for', 'all'), ('all', 'natural'), ('natural', 'numbers.'), ('Mathematical', 'induction'), ('induction', 'is'), ('is', 'a'), ('a', 'method'), ('method', 'of'), ('of', 'mathematical'), ('mathematical', 'proof'), ('proof', 'used'), ('used', 'to'), ('to', 'prove'), ('prove', 'that'), ('that', 'a'), ('a', 'statement'), ('statement', 'is'), ('is', 'true'), ('true', 'for'), ('for', 'all'), ('all', 'natural'), ('natural', 'numbers.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([1.1000e+01, 9.1300e+02, 3.0000e+00, 4.0000e+00, 4.4500e+02, 7.0000e+00,\n",
            "        4.0000e+00, 1.4900e+02, 4.2700e+02, 1.4000e+01, 1.0000e+00, 2.1970e+03,\n",
            "        4.2700e+02, 3.4100e+02, 1.3070e+03, 1.1000e+01, 9.1300e+02, 3.0000e+00,\n",
            "        4.0000e+00, 4.4500e+02, 7.0000e+00, 4.0000e+00, 1.4900e+02, 4.2700e+02,\n",
            "        1.4000e+01, 1.0000e+00, 2.1970e+03, 4.2700e+02, 3.4100e+02, 1.3070e+03])\n",
            "['A', 'limit', 'is', 'a', 'value', 'that', 'a', 'function', 'approaches', 'as', 'the', 'input', 'approaches', 'some', 'value.', 'A', 'limit', 'is', 'a', 'value', 'that', 'a', 'function', 'approaches', 'as', 'the', 'input', 'approaches', 'some', 'value.']\n",
            "[('A', 'limit'), ('limit', 'is'), ('is', 'a'), ('a', 'value'), ('value', 'that'), ('that', 'a'), ('a', 'function'), ('function', 'approaches'), ('approaches', 'as'), ('as', 'the'), ('the', 'input'), ('input', 'approaches'), ('approaches', 'some'), ('some', 'value.'), ('A', 'limit'), ('limit', 'is'), ('is', 'a'), ('a', 'value'), ('value', 'that'), ('that', 'a'), ('a', 'function'), ('function', 'approaches'), ('approaches', 'as'), ('as', 'the'), ('the', 'input'), ('input', 'approaches'), ('approaches', 'some'), ('some', 'value.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.2680e+03, 3.0000e+00, 4.0000e+00, 1.5400e+02, 6.2000e+02, 4.7900e+02,\n",
            "        1.6300e+02, 1.9400e+02, 2.8450e+03, 1.0000e+01, 9.2000e+02, 6.6000e+01,\n",
            "        1.9400e+02, 1.8100e+02, 8.7000e+02, 3.2680e+03, 3.0000e+00, 4.0000e+00,\n",
            "        1.5400e+02, 6.2000e+02, 4.7900e+02, 1.6300e+02, 1.9400e+02, 2.8450e+03,\n",
            "        1.0000e+01, 9.2000e+02, 6.6000e+01, 1.9400e+02, 1.8100e+02, 8.7000e+02])\n",
            "['Infinity', 'is', 'a', 'concept', 'describing', 'something', 'without', 'any', 'bound', 'or', 'larger', 'than', 'any', 'natural', 'number.', 'Infinity', 'is', 'a', 'concept', 'describing', 'something', 'without', 'any', 'bound', 'or', 'larger', 'than', 'any', 'natural', 'number.']\n",
            "[('Infinity', 'is'), ('is', 'a'), ('a', 'concept'), ('concept', 'describing'), ('describing', 'something'), ('something', 'without'), ('without', 'any'), ('any', 'bound'), ('bound', 'or'), ('or', 'larger'), ('larger', 'than'), ('than', 'any'), ('any', 'natural'), ('natural', 'number.'), ('Infinity', 'is'), ('is', 'a'), ('a', 'concept'), ('concept', 'describing'), ('describing', 'something'), ('something', 'without'), ('without', 'any'), ('any', 'bound'), ('bound', 'or'), ('or', 'larger'), ('larger', 'than'), ('than', 'any'), ('any', 'natural'), ('natural', 'number.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([1.1000e+01, 2.3150e+03, 3.0000e+00, 4.0000e+00, 6.3800e+02, 2.0000e+00,\n",
            "        8.3400e+02, 6.4500e+02, 1.2950e+03, 1.0820e+03, 1.8000e+01, 9.1100e+02,\n",
            "        6.4500e+02, 2.5370e+03, 1.1000e+01, 2.3150e+03, 3.0000e+00, 4.0000e+00,\n",
            "        6.3800e+02, 2.0000e+00, 8.3400e+02, 6.4500e+02, 1.2950e+03, 1.0820e+03,\n",
            "        1.8000e+01, 9.1100e+02, 6.4500e+02, 2.5370e+03])\n",
            "['A', 'graph', 'is', 'a', 'collection', 'of', 'points,', 'called', 'vertices,', 'connected', 'by', 'lines,', 'called', 'edges.', 'A', 'graph', 'is', 'a', 'collection', 'of', 'points,', 'called', 'vertices,', 'connected', 'by', 'lines,', 'called', 'edges.']\n",
            "[('A', 'graph'), ('graph', 'is'), ('is', 'a'), ('a', 'collection'), ('collection', 'of'), ('of', 'points,'), ('points,', 'called'), ('called', 'vertices,'), ('vertices,', 'connected'), ('connected', 'by'), ('by', 'lines,'), ('lines,', 'called'), ('called', 'edges.'), ('A', 'graph'), ('graph', 'is'), ('is', 'a'), ('a', 'collection'), ('collection', 'of'), ('of', 'points,'), ('points,', 'called'), ('called', 'vertices,'), ('vertices,', 'connected'), ('connected', 'by'), ('by', 'lines,'), ('lines,', 'called'), ('called', 'edges.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([1.1920e+03, 4.8000e+01, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00,\n",
            "        9.6900e+02, 5.0000e+00, 4.1000e+01, 2.1400e+02, 1.1920e+03, 4.8000e+01,\n",
            "        3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 9.6900e+02, 5.0000e+00,\n",
            "        4.1000e+01, 2.1400e+02])\n",
            "['Graph', 'theory', 'is', 'the', 'study', 'of', 'graphs', 'and', 'their', 'properties.', 'Graph', 'theory', 'is', 'the', 'study', 'of', 'graphs', 'and', 'their', 'properties.']\n",
            "[('Graph', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'graphs'), ('graphs', 'and'), ('and', 'their'), ('their', 'properties.'), ('Graph', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'graphs'), ('graphs', 'and'), ('and', 'their'), ('their', 'properties.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([ 11., 204.,   3.,   4.,  62., 138.,   7.,  54., 649., 809.,   6.,  25.,\n",
            "        449.,  11., 204.,   3.,   4.,  62., 138.,   7.,  54., 649., 809.,   6.,\n",
            "         25., 449.])\n",
            "['A', 'theorem', 'is', 'a', 'mathematical', 'statement', 'that', 'has', 'been', 'proven', 'to', 'be', 'true.', 'A', 'theorem', 'is', 'a', 'mathematical', 'statement', 'that', 'has', 'been', 'proven', 'to', 'be', 'true.']\n",
            "[('A', 'theorem'), ('theorem', 'is'), ('is', 'a'), ('a', 'mathematical'), ('mathematical', 'statement'), ('statement', 'that'), ('that', 'has'), ('has', 'been'), ('been', 'proven'), ('proven', 'to'), ('to', 'be'), ('be', 'true.'), ('A', 'theorem'), ('theorem', 'is'), ('is', 'a'), ('a', 'mathematical'), ('mathematical', 'statement'), ('statement', 'that'), ('that', 'has'), ('has', 'been'), ('been', 'proven'), ('proven', 'to'), ('to', 'be'), ('be', 'true.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([  45., 2892.,    3.,    4.,  138.,   10.,  813.,    7.,    3.,  504.,\n",
            "          14.,  192., 1018., 1150.,   10.,  780.,  449.,   45., 2892.,    3.,\n",
            "           4.,  138.,   10.,  813.,    7.,    3.,  504.,   14.,  192., 1018.,\n",
            "        1150.,   10.,  780.,  449.])\n",
            "['An', 'axiom', 'is', 'a', 'statement', 'or', 'proposition', 'that', 'is', 'regarded', 'as', 'being', 'established,', 'accepted,', 'or', 'self-evidently', 'true.', 'An', 'axiom', 'is', 'a', 'statement', 'or', 'proposition', 'that', 'is', 'regarded', 'as', 'being', 'established,', 'accepted,', 'or', 'self-evidently', 'true.']\n",
            "[('An', 'axiom'), ('axiom', 'is'), ('is', 'a'), ('a', 'statement'), ('statement', 'or'), ('or', 'proposition'), ('proposition', 'that'), ('that', 'is'), ('is', 'regarded'), ('regarded', 'as'), ('as', 'being'), ('being', 'established,'), ('established,', 'accepted,'), ('accepted,', 'or'), ('or', 'self-evidently'), ('self-evidently', 'true.'), ('An', 'axiom'), ('axiom', 'is'), ('is', 'a'), ('a', 'statement'), ('statement', 'or'), ('or', 'proposition'), ('proposition', 'that'), ('that', 'is'), ('is', 'regarded'), ('regarded', 'as'), ('as', 'being'), ('being', 'established,'), ('established,', 'accepted,'), ('accepted,', 'or'), ('or', 'self-evidently'), ('self-evidently', 'true.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([3071.,   13., 2619.,   24., 2891.,    5.,  820., 1019., 1400., 3071.,\n",
            "          13., 2619.,   24., 2891.,    5.,  820., 1019., 1400.])\n",
            "['Theorems', 'are', 'derived', 'from', 'axioms', 'and', 'previously', 'established', 'theorems.', 'Theorems', 'are', 'derived', 'from', 'axioms', 'and', 'previously', 'established', 'theorems.']\n",
            "[('Theorems', 'are'), ('are', 'derived'), ('derived', 'from'), ('from', 'axioms'), ('axioms', 'and'), ('and', 'previously'), ('previously', 'established'), ('established', 'theorems.'), ('Theorems', 'are'), ('are', 'derived'), ('derived', 'from'), ('from', 'axioms'), ('axioms', 'and'), ('and', 'previously'), ('previously', 'established'), ('established', 'theorems.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([  11., 2716.,    3.,    4.,   62.,  138.,    7.,    3.,  351.,    6.,\n",
            "          25.,  450.,   38.,   54.,   67., 1225.,  649.,  809.,   10., 2582.,\n",
            "          11., 2716.,    3.,    4.,   62.,  138.,    7.,    3.,  351.,    6.,\n",
            "          25.,  450.,   38.,   54.,   67., 1225.,  649.,  809.,   10., 2582.])\n",
            "['A', 'conjecture', 'is', 'a', 'mathematical', 'statement', 'that', 'is', 'proposed', 'to', 'be', 'true', 'but', 'has', 'not', 'yet', 'been', 'proven', 'or', 'disproven.', 'A', 'conjecture', 'is', 'a', 'mathematical', 'statement', 'that', 'is', 'proposed', 'to', 'be', 'true', 'but', 'has', 'not', 'yet', 'been', 'proven', 'or', 'disproven.']\n",
            "[('A', 'conjecture'), ('conjecture', 'is'), ('is', 'a'), ('a', 'mathematical'), ('mathematical', 'statement'), ('statement', 'that'), ('that', 'is'), ('is', 'proposed'), ('proposed', 'to'), ('to', 'be'), ('be', 'true'), ('true', 'but'), ('but', 'has'), ('has', 'not'), ('not', 'yet'), ('yet', 'been'), ('been', 'proven'), ('proven', 'or'), ('or', 'disproven.'), ('A', 'conjecture'), ('conjecture', 'is'), ('is', 'a'), ('a', 'mathematical'), ('mathematical', 'statement'), ('statement', 'that'), ('that', 'is'), ('is', 'proposed'), ('proposed', 'to'), ('to', 'be'), ('be', 'true'), ('true', 'but'), ('but', 'has'), ('has', 'not'), ('not', 'yet'), ('yet', 'been'), ('been', 'proven'), ('proven', 'or'), ('or', 'disproven.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([4.5000e+01, 2.9690e+03, 3.0000e+00, 4.0000e+00, 1.4740e+03, 5.1200e+02,\n",
            "        1.2000e+01, 1.5130e+03, 4.0000e+00, 1.7390e+03, 1.0000e+01, 3.0130e+03,\n",
            "        4.0000e+00, 1.4210e+03, 4.5000e+01, 2.9690e+03, 3.0000e+00, 4.0000e+00,\n",
            "        1.4740e+03, 5.1200e+02, 1.2000e+01, 1.5130e+03, 4.0000e+00, 1.7390e+03,\n",
            "        1.0000e+01, 3.0130e+03, 4.0000e+00, 1.4210e+03])\n",
            "['An', 'algorithm', 'is', 'a', 'step-by-step', 'procedure', 'for', 'solving', 'a', 'problem', 'or', 'accomplishing', 'a', 'task.', 'An', 'algorithm', 'is', 'a', 'step-by-step', 'procedure', 'for', 'solving', 'a', 'problem', 'or', 'accomplishing', 'a', 'task.']\n",
            "[('An', 'algorithm'), ('algorithm', 'is'), ('is', 'a'), ('a', 'step-by-step'), ('step-by-step', 'procedure'), ('procedure', 'for'), ('for', 'solving'), ('solving', 'a'), ('a', 'problem'), ('problem', 'or'), ('or', 'accomplishing'), ('accomplishing', 'a'), ('a', 'task.'), ('An', 'algorithm'), ('algorithm', 'is'), ('is', 'a'), ('a', 'step-by-step'), ('step-by-step', 'procedure'), ('procedure', 'for'), ('for', 'solving'), ('solving', 'a'), ('a', 'problem'), ('problem', 'or'), ('or', 'accomplishing'), ('accomplishing', 'a'), ('a', 'task.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.3770e+03, 3.0000e+00, 1.0000e+00, 3.5500e+02, 5.0000e+00, 3.4000e+01,\n",
            "        2.0000e+00, 4.6400e+02, 1.2000e+01, 4.8900e+02, 4.1000e+02, 8.0000e+00,\n",
            "        1.0000e+00, 1.7520e+03, 2.0000e+00, 4.5700e+02, 1.8510e+03, 3.3770e+03,\n",
            "        3.0000e+00, 1.0000e+00, 3.5500e+02, 5.0000e+00, 3.4000e+01, 2.0000e+00,\n",
            "        4.6400e+02, 1.2000e+01, 4.8900e+02, 4.1000e+02, 8.0000e+00, 1.0000e+00,\n",
            "        1.7520e+03, 2.0000e+00, 4.5700e+02, 1.8510e+03])\n",
            "['Cryptography', 'is', 'the', 'practice', 'and', 'study', 'of', 'techniques', 'for', 'secure', 'communication', 'in', 'the', 'presence', 'of', 'third', 'parties.', 'Cryptography', 'is', 'the', 'practice', 'and', 'study', 'of', 'techniques', 'for', 'secure', 'communication', 'in', 'the', 'presence', 'of', 'third', 'parties.']\n",
            "[('Cryptography', 'is'), ('is', 'the'), ('the', 'practice'), ('practice', 'and'), ('and', 'study'), ('study', 'of'), ('of', 'techniques'), ('techniques', 'for'), ('for', 'secure'), ('secure', 'communication'), ('communication', 'in'), ('in', 'the'), ('the', 'presence'), ('presence', 'of'), ('of', 'third'), ('third', 'parties.'), ('Cryptography', 'is'), ('is', 'the'), ('the', 'practice'), ('practice', 'and'), ('and', 'study'), ('study', 'of'), ('of', 'techniques'), ('techniques', 'for'), ('for', 'secure'), ('secure', 'communication'), ('communication', 'in'), ('in', 'the'), ('the', 'presence'), ('presence', 'of'), ('of', 'third'), ('third', 'parties.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([  11.,  742.,    8.,  144.,    3.,   21.,  863.,    7.,  822.,  341.,\n",
            "        1714.,    2.,    4.,  580.,  118.,   10.,  775.,   11.,  742.,    8.,\n",
            "         144.,    3.,   21.,  863.,    7.,  822.,  341., 1714.,    2.,    4.,\n",
            "         580.,  118.,   10.,  775.])\n",
            "['A', 'symmetry', 'in', 'mathematics', 'is', 'an', 'operation', 'that', 'preserves', 'some', 'property', 'of', 'a', 'geometric', 'object', 'or', 'set.', 'A', 'symmetry', 'in', 'mathematics', 'is', 'an', 'operation', 'that', 'preserves', 'some', 'property', 'of', 'a', 'geometric', 'object', 'or', 'set.']\n",
            "[('A', 'symmetry'), ('symmetry', 'in'), ('in', 'mathematics'), ('mathematics', 'is'), ('is', 'an'), ('an', 'operation'), ('operation', 'that'), ('that', 'preserves'), ('preserves', 'some'), ('some', 'property'), ('property', 'of'), ('of', 'a'), ('a', 'geometric'), ('geometric', 'object'), ('object', 'or'), ('or', 'set.'), ('A', 'symmetry'), ('symmetry', 'in'), ('in', 'mathematics'), ('mathematics', 'is'), ('is', 'an'), ('an', 'operation'), ('operation', 'that'), ('that', 'preserves'), ('preserves', 'some'), ('some', 'property'), ('property', 'of'), ('of', 'a'), ('a', 'geometric'), ('geometric', 'object'), ('object', 'or'), ('or', 'set.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([9.0000e+00, 3.1150e+03, 3.2750e+03, 3.0000e+00, 3.7000e+01, 2.0000e+00,\n",
            "        1.0000e+00, 1.2100e+02, 9.9900e+02, 1.3180e+03, 1.7380e+03, 8.0000e+00,\n",
            "        8.9500e+02, 1.0830e+03, 1.0000e+00, 4.0600e+02, 2.0000e+00, 3.5400e+02,\n",
            "        2.1600e+02, 9.0000e+00, 3.1150e+03, 3.2750e+03, 3.0000e+00, 3.7000e+01,\n",
            "        2.0000e+00, 1.0000e+00, 1.2100e+02, 9.9900e+02, 1.3180e+03, 1.7380e+03,\n",
            "        8.0000e+00, 8.9500e+02, 1.0830e+03, 1.0000e+00, 4.0600e+02, 2.0000e+00,\n",
            "        3.5400e+02, 2.1600e+02])\n",
            "['The', 'Riemann', 'Hypothesis', 'is', 'one', 'of', 'the', 'most', 'famous', 'unsolved', 'problems', 'in', 'mathematics,', 'concerning', 'the', 'distribution', 'of', 'prime', 'numbers.', 'The', 'Riemann', 'Hypothesis', 'is', 'one', 'of', 'the', 'most', 'famous', 'unsolved', 'problems', 'in', 'mathematics,', 'concerning', 'the', 'distribution', 'of', 'prime', 'numbers.']\n",
            "[('The', 'Riemann'), ('Riemann', 'Hypothesis'), ('Hypothesis', 'is'), ('is', 'one'), ('one', 'of'), ('of', 'the'), ('the', 'most'), ('most', 'famous'), ('famous', 'unsolved'), ('unsolved', 'problems'), ('problems', 'in'), ('in', 'mathematics,'), ('mathematics,', 'concerning'), ('concerning', 'the'), ('the', 'distribution'), ('distribution', 'of'), ('of', 'prime'), ('prime', 'numbers.'), ('The', 'Riemann'), ('Riemann', 'Hypothesis'), ('Hypothesis', 'is'), ('is', 'one'), ('one', 'of'), ('of', 'the'), ('the', 'most'), ('most', 'famous'), ('famous', 'unsolved'), ('unsolved', 'problems'), ('problems', 'in'), ('in', 'mathematics,'), ('mathematics,', 'concerning'), ('concerning', 'the'), ('the', 'distribution'), ('distribution', 'of'), ('of', 'prime'), ('prime', 'numbers.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([1.1000e+01, 5.0600e+02, 5.9000e+01, 3.0000e+00, 4.0000e+00, 5.9000e+01,\n",
            "        7.0000e+00, 1.6000e+01, 2.5000e+01, 4.0000e+02, 1.4000e+01, 1.0000e+00,\n",
            "        1.6880e+03, 1.0000e+01, 9.8500e+02, 2.0000e+00, 3.9000e+01, 2.1840e+03,\n",
            "        1.1000e+01, 5.0600e+02, 5.9000e+01, 3.0000e+00, 4.0000e+00, 5.9000e+01,\n",
            "        7.0000e+00, 1.6000e+01, 2.5000e+01, 4.0000e+02, 1.4000e+01, 1.0000e+00,\n",
            "        1.6880e+03, 1.0000e+01, 9.8500e+02, 2.0000e+00, 3.9000e+01, 2.1840e+03])\n",
            "['A', 'rational', 'number', 'is', 'a', 'number', 'that', 'can', 'be', 'expressed', 'as', 'the', 'quotient', 'or', 'fraction', 'of', 'two', 'integers.', 'A', 'rational', 'number', 'is', 'a', 'number', 'that', 'can', 'be', 'expressed', 'as', 'the', 'quotient', 'or', 'fraction', 'of', 'two', 'integers.']\n",
            "[('A', 'rational'), ('rational', 'number'), ('number', 'is'), ('is', 'a'), ('a', 'number'), ('number', 'that'), ('that', 'can'), ('can', 'be'), ('be', 'expressed'), ('expressed', 'as'), ('as', 'the'), ('the', 'quotient'), ('quotient', 'or'), ('or', 'fraction'), ('fraction', 'of'), ('of', 'two'), ('two', 'integers.'), ('A', 'rational'), ('rational', 'number'), ('number', 'is'), ('is', 'a'), ('a', 'number'), ('number', 'that'), ('that', 'can'), ('can', 'be'), ('be', 'expressed'), ('expressed', 'as'), ('as', 'the'), ('the', 'quotient'), ('quotient', 'or'), ('or', 'fraction'), ('fraction', 'of'), ('of', 'two'), ('two', 'integers.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([4.5000e+01, 9.3500e+02, 5.9000e+01, 6.4300e+02, 2.5000e+01, 4.0000e+02,\n",
            "        1.4000e+01, 4.0000e+00, 9.8500e+02, 2.0000e+00, 3.9000e+01, 2.1830e+03,\n",
            "        4.3000e+01, 2.6410e+03, 9.4000e+01, 3.0000e+00, 1.9340e+03, 5.0000e+00,\n",
            "        1.9330e+03, 4.5000e+01, 9.3500e+02, 5.9000e+01, 6.4300e+02, 2.5000e+01,\n",
            "        4.0000e+02, 1.4000e+01, 4.0000e+00, 9.8500e+02, 2.0000e+00, 3.9000e+01,\n",
            "        2.1830e+03, 4.3000e+01, 2.6410e+03, 9.4000e+01, 3.0000e+00, 1.9340e+03,\n",
            "        5.0000e+00, 1.9330e+03])\n",
            "['An', 'irrational', 'number', 'cannot', 'be', 'expressed', 'as', 'a', 'fraction', 'of', 'two', 'integers;', 'its', 'decimal', 'form', 'is', 'non-repeating', 'and', 'non-terminating.', 'An', 'irrational', 'number', 'cannot', 'be', 'expressed', 'as', 'a', 'fraction', 'of', 'two', 'integers;', 'its', 'decimal', 'form', 'is', 'non-repeating', 'and', 'non-terminating.']\n",
            "[('An', 'irrational'), ('irrational', 'number'), ('number', 'cannot'), ('cannot', 'be'), ('be', 'expressed'), ('expressed', 'as'), ('as', 'a'), ('a', 'fraction'), ('fraction', 'of'), ('of', 'two'), ('two', 'integers;'), ('integers;', 'its'), ('its', 'decimal'), ('decimal', 'form'), ('form', 'is'), ('is', 'non-repeating'), ('non-repeating', 'and'), ('and', 'non-terminating.'), ('An', 'irrational'), ('irrational', 'number'), ('number', 'cannot'), ('cannot', 'be'), ('be', 'expressed'), ('expressed', 'as'), ('as', 'a'), ('a', 'fraction'), ('fraction', 'of'), ('of', 'two'), ('two', 'integers;'), ('integers;', 'its'), ('its', 'decimal'), ('decimal', 'form'), ('form', 'is'), ('is', 'non-repeating'), ('non-repeating', 'and'), ('and', 'non-terminating.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([1.1000e+01, 3.4900e+02, 5.9000e+01, 3.0000e+00, 1.9400e+02, 4.4500e+02,\n",
            "        1.1390e+03, 1.0000e+00, 2.7010e+03, 2.0000e+00, 1.0000e+00, 5.9000e+01,\n",
            "        2.0980e+03, 1.4700e+02, 1.1300e+02, 5.0600e+02, 5.0000e+00, 9.3500e+02,\n",
            "        2.1600e+02, 1.1000e+01, 3.4900e+02, 5.9000e+01, 3.0000e+00, 1.9400e+02,\n",
            "        4.4500e+02, 1.1390e+03, 1.0000e+00, 2.7010e+03, 2.0000e+00, 1.0000e+00,\n",
            "        5.9000e+01, 2.0980e+03, 1.4700e+02, 1.1300e+02, 5.0600e+02, 5.0000e+00,\n",
            "        9.3500e+02, 2.1600e+02])\n",
            "['A', 'real', 'number', 'is', 'any', 'value', 'along', 'the', 'continuum', 'of', 'the', 'number', 'line,', 'including', 'both', 'rational', 'and', 'irrational', 'numbers.', 'A', 'real', 'number', 'is', 'any', 'value', 'along', 'the', 'continuum', 'of', 'the', 'number', 'line,', 'including', 'both', 'rational', 'and', 'irrational', 'numbers.']\n",
            "[('A', 'real'), ('real', 'number'), ('number', 'is'), ('is', 'any'), ('any', 'value'), ('value', 'along'), ('along', 'the'), ('the', 'continuum'), ('continuum', 'of'), ('of', 'the'), ('the', 'number'), ('number', 'line,'), ('line,', 'including'), ('including', 'both'), ('both', 'rational'), ('rational', 'and'), ('and', 'irrational'), ('irrational', 'numbers.'), ('A', 'real'), ('real', 'number'), ('number', 'is'), ('is', 'any'), ('any', 'value'), ('value', 'along'), ('along', 'the'), ('the', 'continuum'), ('continuum', 'of'), ('of', 'the'), ('the', 'number'), ('number', 'line,'), ('line,', 'including'), ('including', 'both'), ('both', 'rational'), ('rational', 'and'), ('and', 'irrational'), ('irrational', 'numbers.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([  45.,  563.,   59.,    3.,    4.,   59.,    7.,  125., 1480., 2326.,\n",
            "           4.,  875., 1603.,   45.,  563.,   59.,    3.,    4.,   59.,    7.,\n",
            "         125., 1480., 2326.,    4.,  875., 1603.])\n",
            "['An', 'imaginary', 'number', 'is', 'a', 'number', 'that', 'when', 'squared', 'gives', 'a', 'negative', 'result.', 'An', 'imaginary', 'number', 'is', 'a', 'number', 'that', 'when', 'squared', 'gives', 'a', 'negative', 'result.']\n",
            "[('An', 'imaginary'), ('imaginary', 'number'), ('number', 'is'), ('is', 'a'), ('a', 'number'), ('number', 'that'), ('that', 'when'), ('when', 'squared'), ('squared', 'gives'), ('gives', 'a'), ('a', 'negative'), ('negative', 'result.'), ('An', 'imaginary'), ('imaginary', 'number'), ('number', 'is'), ('is', 'a'), ('a', 'number'), ('number', 'that'), ('that', 'when'), ('when', 'squared'), ('squared', 'gives'), ('gives', 'a'), ('a', 'negative'), ('negative', 'result.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([1.1000e+01, 1.2300e+02, 1.7910e+03, 3.0000e+00, 4.0000e+00, 5.8000e+02,\n",
            "        3.4600e+02, 2.0000e+00, 1.2300e+02, 1.4300e+02, 1.0190e+03, 1.8000e+01,\n",
            "        1.0000e+00, 3.4900e+02, 5.0000e+00, 5.6300e+02, 2.8930e+03, 1.1000e+01,\n",
            "        1.2300e+02, 1.7910e+03, 3.0000e+00, 4.0000e+00, 5.8000e+02, 3.4600e+02,\n",
            "        2.0000e+00, 1.2300e+02, 1.4300e+02, 1.0190e+03, 1.8000e+01, 1.0000e+00,\n",
            "        3.4900e+02, 5.0000e+00, 5.6300e+02, 2.8930e+03])\n",
            "['A', 'complex', 'plane', 'is', 'a', 'geometric', 'representation', 'of', 'complex', 'numbers', 'established', 'by', 'the', 'real', 'and', 'imaginary', 'axes.', 'A', 'complex', 'plane', 'is', 'a', 'geometric', 'representation', 'of', 'complex', 'numbers', 'established', 'by', 'the', 'real', 'and', 'imaginary', 'axes.']\n",
            "[('A', 'complex'), ('complex', 'plane'), ('plane', 'is'), ('is', 'a'), ('a', 'geometric'), ('geometric', 'representation'), ('representation', 'of'), ('of', 'complex'), ('complex', 'numbers'), ('numbers', 'established'), ('established', 'by'), ('by', 'the'), ('the', 'real'), ('real', 'and'), ('and', 'imaginary'), ('imaginary', 'axes.'), ('A', 'complex'), ('complex', 'plane'), ('plane', 'is'), ('is', 'a'), ('a', 'geometric'), ('geometric', 'representation'), ('representation', 'of'), ('of', 'complex'), ('complex', 'numbers'), ('numbers', 'established'), ('established', 'by'), ('by', 'the'), ('the', 'real'), ('real', 'and'), ('and', 'imaginary'), ('imaginary', 'axes.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([  11.,   62.,  217.,    3.,    4.,  346.,    2.,    4., 1669.,  767.,\n",
            "         199.,   62.,  635.,    5.,   92.,   11.,   62.,  217.,    3.,    4.,\n",
            "         346.,    2.,    4., 1669.,  767.,  199.,   62.,  635.,    5.,   92.])\n",
            "['A', 'mathematical', 'model', 'is', 'a', 'representation', 'of', 'a', 'real-world', 'situation', 'using', 'mathematical', 'concepts', 'and', 'language.', 'A', 'mathematical', 'model', 'is', 'a', 'representation', 'of', 'a', 'real-world', 'situation', 'using', 'mathematical', 'concepts', 'and', 'language.']\n",
            "[('A', 'mathematical'), ('mathematical', 'model'), ('model', 'is'), ('is', 'a'), ('a', 'representation'), ('representation', 'of'), ('of', 'a'), ('a', 'real-world'), ('real-world', 'situation'), ('situation', 'using'), ('using', 'mathematical'), ('mathematical', 'concepts'), ('concepts', 'and'), ('and', 'language.'), ('A', 'mathematical'), ('mathematical', 'model'), ('model', 'is'), ('is', 'a'), ('a', 'representation'), ('representation', 'of'), ('of', 'a'), ('a', 'real-world'), ('real-world', 'situation'), ('situation', 'using'), ('using', 'mathematical'), ('mathematical', 'concepts'), ('concepts', 'and'), ('and', 'language.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([1.1000e+01, 1.0530e+03, 1.3200e+02, 4.9000e+01, 1.0000e+00, 3.4700e+02,\n",
            "        3.5000e+01, 4.0000e+00, 1.4900e+02, 5.0000e+00, 4.3000e+01, 2.6200e+03,\n",
            "        1.1000e+01, 1.0530e+03, 1.3200e+02, 4.9000e+01, 1.0000e+00, 3.4700e+02,\n",
            "        3.5000e+01, 4.0000e+00, 1.4900e+02, 5.0000e+00, 4.3000e+01, 2.6200e+03])\n",
            "['A', 'differential', 'equation', 'describes', 'the', 'relationship', 'between', 'a', 'function', 'and', 'its', 'derivatives.', 'A', 'differential', 'equation', 'describes', 'the', 'relationship', 'between', 'a', 'function', 'and', 'its', 'derivatives.']\n",
            "[('A', 'differential'), ('differential', 'equation'), ('equation', 'describes'), ('describes', 'the'), ('the', 'relationship'), ('relationship', 'between'), ('between', 'a'), ('a', 'function'), ('function', 'and'), ('and', 'its'), ('its', 'derivatives.'), ('A', 'differential'), ('differential', 'equation'), ('equation', 'describes'), ('describes', 'the'), ('the', 'relationship'), ('relationship', 'between'), ('between', 'a'), ('a', 'function'), ('function', 'and'), ('and', 'its'), ('its', 'derivatives.')]\n",
            "44\n",
            "42\n",
            "946\n",
            "86\n",
            "tensor([1.2060e+03, 4.8000e+01, 3.6000e+01, 1.0000e+00, 1.2400e+02, 2.0000e+00,\n",
            "        1.0410e+03, 1.6900e+02, 7.0000e+00, 1.3000e+01, 5.7000e+02, 7.7700e+02,\n",
            "        6.0000e+00, 5.5900e+02, 6.3300e+02, 5.3000e+01, 7.9600e+02, 6.0000e+00,\n",
            "        1.4000e+01, 1.0000e+00, 2.8250e+03, 4.0300e+02, 1.2060e+03, 4.8000e+01,\n",
            "        3.6000e+01, 1.0000e+00, 1.2400e+02, 2.0000e+00, 1.0410e+03, 1.6900e+02,\n",
            "        7.0000e+00, 1.3000e+01, 5.7000e+02, 7.7700e+02, 6.0000e+00, 5.5900e+02,\n",
            "        6.3300e+02, 5.3000e+01, 7.9600e+02, 6.0000e+00, 1.4000e+01, 1.0000e+00,\n",
            "        2.8250e+03, 4.0300e+02])\n",
            "['Chaos', 'theory', 'studies', 'the', 'behavior', 'of', 'dynamical', 'systems', 'that', 'are', 'highly', 'sensitive', 'to', 'initial', 'conditions,', 'often', 'referred', 'to', 'as', 'the', 'butterfly', 'effect.', 'Chaos', 'theory', 'studies', 'the', 'behavior', 'of', 'dynamical', 'systems', 'that', 'are', 'highly', 'sensitive', 'to', 'initial', 'conditions,', 'often', 'referred', 'to', 'as', 'the', 'butterfly', 'effect.']\n",
            "[('Chaos', 'theory'), ('theory', 'studies'), ('studies', 'the'), ('the', 'behavior'), ('behavior', 'of'), ('of', 'dynamical'), ('dynamical', 'systems'), ('systems', 'that'), ('that', 'are'), ('are', 'highly'), ('highly', 'sensitive'), ('sensitive', 'to'), ('to', 'initial'), ('initial', 'conditions,'), ('conditions,', 'often'), ('often', 'referred'), ('referred', 'to'), ('to', 'as'), ('as', 'the'), ('the', 'butterfly'), ('butterfly', 'effect.'), ('Chaos', 'theory'), ('theory', 'studies'), ('studies', 'the'), ('the', 'behavior'), ('behavior', 'of'), ('of', 'dynamical'), ('dynamical', 'systems'), ('systems', 'that'), ('that', 'are'), ('are', 'highly'), ('highly', 'sensitive'), ('sensitive', 'to'), ('to', 'initial'), ('initial', 'conditions,'), ('conditions,', 'often'), ('often', 'referred'), ('referred', 'to'), ('to', 'as'), ('as', 'the'), ('the', 'butterfly'), ('butterfly', 'effect.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.1890e+03, 5.7900e+02, 3.0000e+00, 4.0000e+00, 2.0100e+02, 2.0000e+00,\n",
            "        5.7900e+02, 7.0000e+00, 1.6320e+03, 1.0000e+01, 2.9580e+03, 1.1960e+03,\n",
            "        2.3980e+03, 1.7670e+03, 2.8000e+01, 8.5200e+02, 2.0960e+03, 3.1890e+03,\n",
            "        5.7900e+02, 3.0000e+00, 4.0000e+00, 2.0100e+02, 2.0000e+00, 5.7900e+02,\n",
            "        7.0000e+00, 1.6320e+03, 1.0000e+01, 2.9580e+03, 1.1960e+03, 2.3980e+03,\n",
            "        1.7670e+03, 2.8000e+01, 8.5200e+02, 2.0960e+03])\n",
            "['Non-Euclidean', 'geometry', 'is', 'a', 'type', 'of', 'geometry', 'that', 'relaxes', 'or', 'alters', \"Euclid's\", 'fifth', 'postulate', 'about', 'parallel', 'lines.', 'Non-Euclidean', 'geometry', 'is', 'a', 'type', 'of', 'geometry', 'that', 'relaxes', 'or', 'alters', \"Euclid's\", 'fifth', 'postulate', 'about', 'parallel', 'lines.']\n",
            "[('Non-Euclidean', 'geometry'), ('geometry', 'is'), ('is', 'a'), ('a', 'type'), ('type', 'of'), ('of', 'geometry'), ('geometry', 'that'), ('that', 'relaxes'), ('relaxes', 'or'), ('or', 'alters'), ('alters', \"Euclid's\"), (\"Euclid's\", 'fifth'), ('fifth', 'postulate'), ('postulate', 'about'), ('about', 'parallel'), ('parallel', 'lines.'), ('Non-Euclidean', 'geometry'), ('geometry', 'is'), ('is', 'a'), ('a', 'type'), ('type', 'of'), ('of', 'geometry'), ('geometry', 'that'), ('that', 'relaxes'), ('relaxes', 'or'), ('or', 'alters'), ('alters', \"Euclid's\"), (\"Euclid's\", 'fifth'), ('fifth', 'postulate'), ('postulate', 'about'), ('about', 'parallel'), ('parallel', 'lines.')]\n",
            "44\n",
            "42\n",
            "946\n",
            "86\n",
            "tensor([9.0000e+00, 1.1200e+02, 2.0000e+00, 6.2000e+01, 9.0800e+02, 3.6000e+01,\n",
            "        3.9700e+02, 1.6900e+02, 8.0000e+00, 5.0200e+02, 6.0000e+00, 1.0000e+00,\n",
            "        1.9700e+02, 7.2400e+02, 1.0270e+03, 2.1530e+03, 6.3500e+02, 2.0000e+00,\n",
            "        6.2000e+01, 5.1100e+02, 5.0000e+00, 2.7320e+03, 9.0000e+00, 1.1200e+02,\n",
            "        2.0000e+00, 6.2000e+01, 9.0800e+02, 3.6000e+01, 3.9700e+02, 1.6900e+02,\n",
            "        8.0000e+00, 5.0200e+02, 6.0000e+00, 1.0000e+00, 1.9700e+02, 7.2400e+02,\n",
            "        1.0270e+03, 2.1530e+03, 6.3500e+02, 2.0000e+00, 6.2000e+01, 5.1100e+02,\n",
            "        5.0000e+00, 2.7320e+03])\n",
            "['The', 'field', 'of', 'mathematical', 'logic', 'studies', 'formal', 'systems', 'in', 'relation', 'to', 'the', 'way', 'they', 'encode', 'intuitive', 'concepts', 'of', 'mathematical', 'proof', 'and', 'computation.', 'The', 'field', 'of', 'mathematical', 'logic', 'studies', 'formal', 'systems', 'in', 'relation', 'to', 'the', 'way', 'they', 'encode', 'intuitive', 'concepts', 'of', 'mathematical', 'proof', 'and', 'computation.']\n",
            "[('The', 'field'), ('field', 'of'), ('of', 'mathematical'), ('mathematical', 'logic'), ('logic', 'studies'), ('studies', 'formal'), ('formal', 'systems'), ('systems', 'in'), ('in', 'relation'), ('relation', 'to'), ('to', 'the'), ('the', 'way'), ('way', 'they'), ('they', 'encode'), ('encode', 'intuitive'), ('intuitive', 'concepts'), ('concepts', 'of'), ('of', 'mathematical'), ('mathematical', 'proof'), ('proof', 'and'), ('and', 'computation.'), ('The', 'field'), ('field', 'of'), ('of', 'mathematical'), ('mathematical', 'logic'), ('logic', 'studies'), ('studies', 'formal'), ('formal', 'systems'), ('systems', 'in'), ('in', 'relation'), ('relation', 'to'), ('to', 'the'), ('the', 'way'), ('way', 'they'), ('they', 'encode'), ('encode', 'intuitive'), ('intuitive', 'concepts'), ('concepts', 'of'), ('of', 'mathematical'), ('mathematical', 'proof'), ('proof', 'and'), ('and', 'computation.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3180.,  256.,  108.,  199.,  659., 2951.,  889.,    6.,  279., 1067.,\n",
            "        3180.,  256.,  108.,  199.,  659., 2951.,  889.,    6.,  279., 1067.])\n",
            "['Operations', 'research', 'involves', 'using', 'advanced', 'analytical', 'methods', 'to', 'improve', 'decision-making.', 'Operations', 'research', 'involves', 'using', 'advanced', 'analytical', 'methods', 'to', 'improve', 'decision-making.']\n",
            "[('Operations', 'research'), ('research', 'involves'), ('involves', 'using'), ('using', 'advanced'), ('advanced', 'analytical'), ('analytical', 'methods'), ('methods', 'to'), ('to', 'improve'), ('improve', 'decision-making.'), ('Operations', 'research'), ('research', 'involves'), ('involves', 'using'), ('using', 'advanced'), ('advanced', 'analytical'), ('analytical', 'methods'), ('methods', 'to'), ('to', 'improve'), ('improve', 'decision-making.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([1.1830e+03, 1.8920e+03, 3.0000e+00, 1.0000e+00, 4.8800e+02, 2.0000e+00,\n",
            "        1.0000e+00, 1.1160e+03, 2.8900e+02, 2.4000e+01, 3.4100e+02, 1.2800e+02,\n",
            "        2.0000e+00, 2.8980e+03, 2.9590e+03, 1.1830e+03, 1.8920e+03, 3.0000e+00,\n",
            "        1.0000e+00, 4.8800e+02, 2.0000e+00, 1.0000e+00, 1.1160e+03, 2.8900e+02,\n",
            "        2.4000e+01, 3.4100e+02, 1.2800e+02, 2.0000e+00, 2.8980e+03, 2.9590e+03])\n",
            "['Mathematical', 'optimization', 'is', 'the', 'selection', 'of', 'the', 'best', 'element', 'from', 'some', 'set', 'of', 'available', 'alternatives.', 'Mathematical', 'optimization', 'is', 'the', 'selection', 'of', 'the', 'best', 'element', 'from', 'some', 'set', 'of', 'available', 'alternatives.']\n",
            "[('Mathematical', 'optimization'), ('optimization', 'is'), ('is', 'the'), ('the', 'selection'), ('selection', 'of'), ('of', 'the'), ('the', 'best'), ('best', 'element'), ('element', 'from'), ('from', 'some'), ('some', 'set'), ('set', 'of'), ('of', 'available'), ('available', 'alternatives.'), ('Mathematical', 'optimization'), ('optimization', 'is'), ('is', 'the'), ('the', 'selection'), ('selection', 'of'), ('of', 'the'), ('the', 'best'), ('best', 'element'), ('element', 'from'), ('from', 'some'), ('some', 'set'), ('set', 'of'), ('of', 'available'), ('available', 'alternatives.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3452.,  345., 2933.,   62.,    5., 1475.,  889.,    6., 1126.,  494.,\n",
            "           8., 2187., 2395.,    5.,   58.,  951., 3452.,  345., 2933.,   62.,\n",
            "           5., 1475.,  889.,    6., 1126.,  494.,    8., 2187., 2395.,    5.,\n",
            "          58.,  951.])\n",
            "['Actuarial', 'science', 'applies', 'mathematical', 'and', 'statistical', 'methods', 'to', 'assess', 'risk', 'in', 'insurance,', 'finance,', 'and', 'other', 'industries.', 'Actuarial', 'science', 'applies', 'mathematical', 'and', 'statistical', 'methods', 'to', 'assess', 'risk', 'in', 'insurance,', 'finance,', 'and', 'other', 'industries.']\n",
            "[('Actuarial', 'science'), ('science', 'applies'), ('applies', 'mathematical'), ('mathematical', 'and'), ('and', 'statistical'), ('statistical', 'methods'), ('methods', 'to'), ('to', 'assess'), ('assess', 'risk'), ('risk', 'in'), ('in', 'insurance,'), ('insurance,', 'finance,'), ('finance,', 'and'), ('and', 'other'), ('other', 'industries.'), ('Actuarial', 'science'), ('science', 'applies'), ('applies', 'mathematical'), ('mathematical', 'and'), ('and', 'statistical'), ('statistical', 'methods'), ('methods', 'to'), ('to', 'assess'), ('assess', 'risk'), ('risk', 'in'), ('in', 'insurance,'), ('insurance,', 'finance,'), ('finance,', 'and'), ('and', 'other'), ('other', 'industries.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([9.0000e+00, 2.6900e+02, 1.0450e+03, 7.8000e+01, 1.0600e+02, 1.4000e+01,\n",
            "        1.0000e+00, 3.3040e+03, 1.0450e+03, 3.0000e+00, 4.0000e+00, 9.6000e+01,\n",
            "        6.2800e+02, 2.6200e+02, 2.5740e+03, 9.0000e+00, 2.6900e+02, 1.0450e+03,\n",
            "        7.8000e+01, 1.0600e+02, 1.4000e+01, 1.0000e+00, 3.3040e+03, 1.0450e+03,\n",
            "        3.0000e+00, 4.0000e+00, 9.6000e+01, 6.2800e+02, 2.6200e+02, 2.5740e+03])\n",
            "['The', 'normal', 'distribution,', 'also', 'known', 'as', 'the', 'Gaussian', 'distribution,', 'is', 'a', 'common', 'continuous', 'probability', 'distribution.', 'The', 'normal', 'distribution,', 'also', 'known', 'as', 'the', 'Gaussian', 'distribution,', 'is', 'a', 'common', 'continuous', 'probability', 'distribution.']\n",
            "[('The', 'normal'), ('normal', 'distribution,'), ('distribution,', 'also'), ('also', 'known'), ('known', 'as'), ('as', 'the'), ('the', 'Gaussian'), ('Gaussian', 'distribution,'), ('distribution,', 'is'), ('is', 'a'), ('a', 'common'), ('common', 'continuous'), ('continuous', 'probability'), ('probability', 'distribution.'), ('The', 'normal'), ('normal', 'distribution,'), ('distribution,', 'also'), ('also', 'known'), ('known', 'as'), ('as', 'the'), ('the', 'Gaussian'), ('Gaussian', 'distribution,'), ('distribution,', 'is'), ('is', 'a'), ('a', 'common'), ('common', 'continuous'), ('continuous', 'probability'), ('probability', 'distribution.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([3.1570e+03, 3.0000e+00, 1.0000e+00, 1.8100e+02, 3.4500e+02, 7.0000e+00,\n",
            "        3.6000e+01, 5.4000e+02, 4.3000e+01, 1.2000e+02, 5.0000e+00, 1.2400e+02,\n",
            "        5.2000e+01, 3.3900e+02, 5.0000e+00, 4.5400e+02, 5.0000e+00, 1.0000e+00,\n",
            "        3.4800e+02, 2.4960e+03, 2.0000e+00, 8.3000e+01, 5.0000e+00, 3.9800e+02,\n",
            "        3.1570e+03, 3.0000e+00, 1.0000e+00, 1.8100e+02, 3.4500e+02, 7.0000e+00,\n",
            "        3.6000e+01, 5.4000e+02, 4.3000e+01, 1.2000e+02, 5.0000e+00, 1.2400e+02,\n",
            "        5.2000e+01, 3.3900e+02, 5.0000e+00, 4.5400e+02, 5.0000e+00, 1.0000e+00,\n",
            "        3.4800e+02, 2.4960e+03, 2.0000e+00, 8.3000e+01, 5.0000e+00, 3.9800e+02])\n",
            "['Physics', 'is', 'the', 'natural', 'science', 'that', 'studies', 'matter,', 'its', 'motion', 'and', 'behavior', 'through', 'space', 'and', 'time,', 'and', 'the', 'related', 'entities', 'of', 'energy', 'and', 'force.', 'Physics', 'is', 'the', 'natural', 'science', 'that', 'studies', 'matter,', 'its', 'motion', 'and', 'behavior', 'through', 'space', 'and', 'time,', 'and', 'the', 'related', 'entities', 'of', 'energy', 'and', 'force.']\n",
            "[('Physics', 'is'), ('is', 'the'), ('the', 'natural'), ('natural', 'science'), ('science', 'that'), ('that', 'studies'), ('studies', 'matter,'), ('matter,', 'its'), ('its', 'motion'), ('motion', 'and'), ('and', 'behavior'), ('behavior', 'through'), ('through', 'space'), ('space', 'and'), ('and', 'time,'), ('time,', 'and'), ('and', 'the'), ('the', 'related'), ('related', 'entities'), ('entities', 'of'), ('of', 'energy'), ('energy', 'and'), ('and', 'force.'), ('Physics', 'is'), ('is', 'the'), ('the', 'natural'), ('natural', 'science'), ('science', 'that'), ('that', 'studies'), ('studies', 'matter,'), ('matter,', 'its'), ('its', 'motion'), ('motion', 'and'), ('and', 'behavior'), ('behavior', 'through'), ('through', 'space'), ('space', 'and'), ('and', 'time,'), ('time,', 'and'), ('and', 'the'), ('the', 'related'), ('related', 'entities'), ('entities', 'of'), ('of', 'energy'), ('energy', 'and'), ('and', 'force.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([3.3980e+03, 2.7100e+02, 7.8000e+01, 1.0600e+02, 1.4000e+01, 3.1950e+03,\n",
            "        2.7100e+02, 4.9000e+01, 1.0000e+00, 1.2000e+02, 2.0000e+00, 9.0300e+02,\n",
            "        2.6800e+02, 2.4000e+01, 1.7220e+03, 6.0000e+00, 1.8500e+03, 2.0000e+00,\n",
            "        2.0550e+03, 1.4000e+01, 1.2630e+03, 1.4000e+01, 2.9130e+03, 8.6800e+02,\n",
            "        3.3980e+03, 2.7100e+02, 7.8000e+01, 1.0600e+02, 1.4000e+01, 3.1950e+03,\n",
            "        2.7100e+02, 4.9000e+01, 1.0000e+00, 1.2000e+02, 2.0000e+00, 9.0300e+02,\n",
            "        2.6800e+02, 2.4000e+01, 1.7220e+03, 6.0000e+00, 1.8500e+03, 2.0000e+00,\n",
            "        2.0550e+03, 1.4000e+01, 1.2630e+03, 1.4000e+01, 2.9130e+03, 8.6800e+02])\n",
            "['Classical', 'mechanics,', 'also', 'known', 'as', 'Newtonian', 'mechanics,', 'describes', 'the', 'motion', 'of', 'macroscopic', 'objects', 'from', 'projectiles', 'to', 'parts', 'of', 'machinery,', 'as', 'well', 'as', 'astronomical', 'objects.', 'Classical', 'mechanics,', 'also', 'known', 'as', 'Newtonian', 'mechanics,', 'describes', 'the', 'motion', 'of', 'macroscopic', 'objects', 'from', 'projectiles', 'to', 'parts', 'of', 'machinery,', 'as', 'well', 'as', 'astronomical', 'objects.']\n",
            "[('Classical', 'mechanics,'), ('mechanics,', 'also'), ('also', 'known'), ('known', 'as'), ('as', 'Newtonian'), ('Newtonian', 'mechanics,'), ('mechanics,', 'describes'), ('describes', 'the'), ('the', 'motion'), ('motion', 'of'), ('of', 'macroscopic'), ('macroscopic', 'objects'), ('objects', 'from'), ('from', 'projectiles'), ('projectiles', 'to'), ('to', 'parts'), ('parts', 'of'), ('of', 'machinery,'), ('machinery,', 'as'), ('as', 'well'), ('well', 'as'), ('as', 'astronomical'), ('astronomical', 'objects.'), ('Classical', 'mechanics,'), ('mechanics,', 'also'), ('also', 'known'), ('known', 'as'), ('as', 'Newtonian'), ('Newtonian', 'mechanics,'), ('mechanics,', 'describes'), ('describes', 'the'), ('the', 'motion'), ('motion', 'of'), ('of', 'macroscopic'), ('macroscopic', 'objects'), ('objects', 'from'), ('from', 'projectiles'), ('projectiles', 'to'), ('to', 'parts'), ('parts', 'of'), ('of', 'machinery,'), ('machinery,', 'as'), ('as', 'well'), ('well', 'as'), ('as', 'astronomical'), ('astronomical', 'objects.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.2610e+03, 3.1960e+03, 3.9500e+02, 1.0000e+00, 5.5400e+02, 2.0000e+00,\n",
            "        1.2000e+02, 5.0000e+00, 3.2200e+02, 2.3120e+03, 2.2000e+01, 5.5500e+02,\n",
            "        1.0000e+00, 2.3640e+03, 1.2000e+01, 1.5500e+02, 3.7400e+02, 3.2610e+03,\n",
            "        3.1960e+03, 3.9500e+02, 1.0000e+00, 5.5400e+02, 2.0000e+00, 1.2000e+02,\n",
            "        5.0000e+00, 3.2200e+02, 2.3120e+03, 2.2000e+01, 5.5500e+02, 1.0000e+00,\n",
            "        2.3640e+03, 1.2000e+01, 1.5500e+02, 3.7400e+02])\n",
            "['Isaac', 'Newton', 'formulated', 'the', 'laws', 'of', 'motion', 'and', 'universal', 'gravitation,', 'which', 'laid', 'the', 'foundation', 'for', 'classical', 'mechanics.', 'Isaac', 'Newton', 'formulated', 'the', 'laws', 'of', 'motion', 'and', 'universal', 'gravitation,', 'which', 'laid', 'the', 'foundation', 'for', 'classical', 'mechanics.']\n",
            "[('Isaac', 'Newton'), ('Newton', 'formulated'), ('formulated', 'the'), ('the', 'laws'), ('laws', 'of'), ('of', 'motion'), ('motion', 'and'), ('and', 'universal'), ('universal', 'gravitation,'), ('gravitation,', 'which'), ('which', 'laid'), ('laid', 'the'), ('the', 'foundation'), ('foundation', 'for'), ('for', 'classical'), ('classical', 'mechanics.'), ('Isaac', 'Newton'), ('Newton', 'formulated'), ('formulated', 'the'), ('the', 'laws'), ('laws', 'of'), ('of', 'motion'), ('motion', 'and'), ('and', 'universal'), ('universal', 'gravitation,'), ('gravitation,', 'which'), ('which', 'laid'), ('laid', 'the'), ('the', 'foundation'), ('foundation', 'for'), ('for', 'classical'), ('classical', 'mechanics.')]\n",
            "54\n",
            "52\n",
            "1431\n",
            "106\n",
            "tensor([9.0000e+00, 6.8000e+01, 2.0000e+00, 2.2170e+03, 3.2000e+01, 7.0000e+00,\n",
            "        2.1000e+01, 1.1800e+02, 4.4100e+02, 7.9100e+02, 7.1000e+01, 7.8700e+02,\n",
            "        1.0000e+01, 8.0000e+00, 1.3250e+03, 1.2000e+02, 8.0000e+00, 4.0000e+00,\n",
            "        1.4690e+03, 9.1200e+02, 2.4600e+02, 3.0040e+03, 7.1000e+02, 1.8000e+01,\n",
            "        2.1000e+01, 1.8600e+02, 3.9800e+02, 9.0000e+00, 6.8000e+01, 2.0000e+00,\n",
            "        2.2170e+03, 3.2000e+01, 7.0000e+00, 2.1000e+01, 1.1800e+02, 4.4100e+02,\n",
            "        7.9100e+02, 7.1000e+01, 7.8700e+02, 1.0000e+01, 8.0000e+00, 1.3250e+03,\n",
            "        1.2000e+02, 8.0000e+00, 4.0000e+00, 1.4690e+03, 9.1200e+02, 2.4600e+02,\n",
            "        3.0040e+03, 7.1000e+02, 1.8000e+01, 2.1000e+01, 1.8600e+02, 3.9800e+02])\n",
            "['The', 'law', 'of', 'inertia', 'states', 'that', 'an', 'object', 'will', 'remain', 'at', 'rest', 'or', 'in', 'uniform', 'motion', 'in', 'a', 'straight', 'line', 'unless', 'acted', 'upon', 'by', 'an', 'external', 'force.', 'The', 'law', 'of', 'inertia', 'states', 'that', 'an', 'object', 'will', 'remain', 'at', 'rest', 'or', 'in', 'uniform', 'motion', 'in', 'a', 'straight', 'line', 'unless', 'acted', 'upon', 'by', 'an', 'external', 'force.']\n",
            "[('The', 'law'), ('law', 'of'), ('of', 'inertia'), ('inertia', 'states'), ('states', 'that'), ('that', 'an'), ('an', 'object'), ('object', 'will'), ('will', 'remain'), ('remain', 'at'), ('at', 'rest'), ('rest', 'or'), ('or', 'in'), ('in', 'uniform'), ('uniform', 'motion'), ('motion', 'in'), ('in', 'a'), ('a', 'straight'), ('straight', 'line'), ('line', 'unless'), ('unless', 'acted'), ('acted', 'upon'), ('upon', 'by'), ('by', 'an'), ('an', 'external'), ('external', 'force.'), ('The', 'law'), ('law', 'of'), ('of', 'inertia'), ('inertia', 'states'), ('states', 'that'), ('that', 'an'), ('an', 'object'), ('object', 'will'), ('will', 'remain'), ('remain', 'at'), ('at', 'rest'), ('rest', 'or'), ('or', 'in'), ('in', 'uniform'), ('uniform', 'motion'), ('motion', 'in'), ('in', 'a'), ('a', 'straight'), ('straight', 'line'), ('line', 'unless'), ('unless', 'acted'), ('acted', 'upon'), ('upon', 'by'), ('by', 'an'), ('an', 'external'), ('external', 'force.')]\n",
            "56\n",
            "54\n",
            "1540\n",
            "110\n",
            "tensor([9.0000e+00, 4.9000e+02, 6.8000e+01, 2.0000e+00, 1.2000e+02, 3.2000e+01,\n",
            "        7.0000e+00, 1.0000e+00, 1.5000e+02, 1.1460e+03, 2.3000e+01, 2.1000e+01,\n",
            "        1.1800e+02, 3.0000e+00, 2.3000e+02, 6.0000e+00, 1.0000e+00, 9.0000e+01,\n",
            "        2.0000e+00, 1.0000e+00, 1.1800e+02, 1.9750e+03, 1.8000e+01, 4.3000e+01,\n",
            "        1.1510e+03, 3.4910e+03, 6.8400e+02, 2.0570e+03, 9.0000e+00, 4.9000e+02,\n",
            "        6.8000e+01, 2.0000e+00, 1.2000e+02, 3.2000e+01, 7.0000e+00, 1.0000e+00,\n",
            "        1.5000e+02, 1.1460e+03, 2.3000e+01, 2.1000e+01, 1.1800e+02, 3.0000e+00,\n",
            "        2.3000e+02, 6.0000e+00, 1.0000e+00, 9.0000e+01, 2.0000e+00, 1.0000e+00,\n",
            "        1.1800e+02, 1.9750e+03, 1.8000e+01, 4.3000e+01, 1.1510e+03, 3.4910e+03,\n",
            "        6.8400e+02, 2.0570e+03])\n",
            "['The', 'second', 'law', 'of', 'motion', 'states', 'that', 'the', 'force', 'acting', 'on', 'an', 'object', 'is', 'equal', 'to', 'the', 'mass', 'of', 'the', 'object', 'multiplied', 'by', 'its', 'acceleration', '(F', '=', 'ma).', 'The', 'second', 'law', 'of', 'motion', 'states', 'that', 'the', 'force', 'acting', 'on', 'an', 'object', 'is', 'equal', 'to', 'the', 'mass', 'of', 'the', 'object', 'multiplied', 'by', 'its', 'acceleration', '(F', '=', 'ma).']\n",
            "[('The', 'second'), ('second', 'law'), ('law', 'of'), ('of', 'motion'), ('motion', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'force'), ('force', 'acting'), ('acting', 'on'), ('on', 'an'), ('an', 'object'), ('object', 'is'), ('is', 'equal'), ('equal', 'to'), ('to', 'the'), ('the', 'mass'), ('mass', 'of'), ('of', 'the'), ('the', 'object'), ('object', 'multiplied'), ('multiplied', 'by'), ('by', 'its'), ('its', 'acceleration'), ('acceleration', '(F'), ('(F', '='), ('=', 'ma).'), ('The', 'second'), ('second', 'law'), ('law', 'of'), ('of', 'motion'), ('motion', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'force'), ('force', 'acting'), ('acting', 'on'), ('on', 'an'), ('an', 'object'), ('object', 'is'), ('is', 'equal'), ('equal', 'to'), ('to', 'the'), ('the', 'mass'), ('mass', 'of'), ('of', 'the'), ('the', 'object'), ('object', 'multiplied'), ('multiplied', 'by'), ('by', 'its'), ('its', 'acceleration'), ('acceleration', '(F'), ('(F', '='), ('=', 'ma).')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 4.5700e+02, 6.8000e+01, 2.0000e+00, 1.2000e+02, 3.2000e+01,\n",
            "        7.0000e+00, 1.2000e+01, 2.2900e+02, 3.0030e+03, 1.3990e+03, 3.0000e+00,\n",
            "        2.1000e+01, 2.3000e+02, 5.0000e+00, 5.2900e+02, 1.6730e+03, 9.0000e+00,\n",
            "        4.5700e+02, 6.8000e+01, 2.0000e+00, 1.2000e+02, 3.2000e+01, 7.0000e+00,\n",
            "        1.2000e+01, 2.2900e+02, 3.0030e+03, 1.3990e+03, 3.0000e+00, 2.1000e+01,\n",
            "        2.3000e+02, 5.0000e+00, 5.2900e+02, 1.6730e+03])\n",
            "['The', 'third', 'law', 'of', 'motion', 'states', 'that', 'for', 'every', 'action,', 'there', 'is', 'an', 'equal', 'and', 'opposite', 'reaction.', 'The', 'third', 'law', 'of', 'motion', 'states', 'that', 'for', 'every', 'action,', 'there', 'is', 'an', 'equal', 'and', 'opposite', 'reaction.']\n",
            "[('The', 'third'), ('third', 'law'), ('law', 'of'), ('of', 'motion'), ('motion', 'states'), ('states', 'that'), ('that', 'for'), ('for', 'every'), ('every', 'action,'), ('action,', 'there'), ('there', 'is'), ('is', 'an'), ('an', 'equal'), ('equal', 'and'), ('and', 'opposite'), ('opposite', 'reaction.'), ('The', 'third'), ('third', 'law'), ('law', 'of'), ('of', 'motion'), ('motion', 'states'), ('states', 'that'), ('that', 'for'), ('for', 'every'), ('every', 'action,'), ('action,', 'there'), ('there', 'is'), ('is', 'an'), ('an', 'equal'), ('equal', 'and'), ('and', 'opposite'), ('opposite', 'reaction.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.0270e+03, 3.0000e+00, 1.0630e+03, 1.4000e+01, 1.0000e+00, 8.1600e+02,\n",
            "        2.0000e+00, 1.5000e+02, 5.0000e+00, 2.5850e+03, 8.0000e+00, 1.0000e+00,\n",
            "        2.9600e+02, 2.0000e+00, 1.0000e+00, 3.9800e+02, 3.0270e+03, 3.0000e+00,\n",
            "        1.0630e+03, 1.4000e+01, 1.0000e+00, 8.1600e+02, 2.0000e+00, 1.5000e+02,\n",
            "        5.0000e+00, 2.5850e+03, 8.0000e+00, 1.0000e+00, 2.9600e+02, 2.0000e+00,\n",
            "        1.0000e+00, 3.9800e+02])\n",
            "['Work', 'is', 'defined', 'as', 'the', 'product', 'of', 'force', 'and', 'displacement', 'in', 'the', 'direction', 'of', 'the', 'force.', 'Work', 'is', 'defined', 'as', 'the', 'product', 'of', 'force', 'and', 'displacement', 'in', 'the', 'direction', 'of', 'the', 'force.']\n",
            "[('Work', 'is'), ('is', 'defined'), ('defined', 'as'), ('as', 'the'), ('the', 'product'), ('product', 'of'), ('of', 'force'), ('force', 'and'), ('and', 'displacement'), ('displacement', 'in'), ('in', 'the'), ('the', 'direction'), ('direction', 'of'), ('of', 'the'), ('the', 'force.'), ('Work', 'is'), ('is', 'defined'), ('defined', 'as'), ('as', 'the'), ('the', 'product'), ('product', 'of'), ('of', 'force'), ('force', 'and'), ('and', 'displacement'), ('displacement', 'in'), ('in', 'the'), ('the', 'direction'), ('direction', 'of'), ('of', 'the'), ('the', 'force.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([3.3420e+03, 3.0000e+00, 1.0000e+00, 2.8180e+03, 6.0000e+00, 2.3300e+02,\n",
            "        1.6200e+02, 5.0000e+00, 2.7480e+03, 8.0000e+00, 3.2000e+02, 3.9600e+02,\n",
            "        4.0000e+01, 1.4000e+01, 2.1290e+03, 1.7650e+03, 1.3970e+03, 5.0000e+00,\n",
            "        5.6000e+01, 1.5100e+02, 3.3420e+03, 3.0000e+00, 1.0000e+00, 2.8180e+03,\n",
            "        6.0000e+00, 2.3300e+02, 1.6200e+02, 5.0000e+00, 2.7480e+03, 8.0000e+00,\n",
            "        3.2000e+02, 3.9600e+02, 4.0000e+01, 1.4000e+01, 2.1290e+03, 1.7650e+03,\n",
            "        1.3970e+03, 5.0000e+00, 5.6000e+01, 1.5100e+02])\n",
            "['Energy', 'is', 'the', 'capacity', 'to', 'do', 'work', 'and', 'comes', 'in', 'various', 'forms', 'such', 'as', 'kinetic,', 'potential,', 'thermal,', 'and', 'chemical', 'energy.', 'Energy', 'is', 'the', 'capacity', 'to', 'do', 'work', 'and', 'comes', 'in', 'various', 'forms', 'such', 'as', 'kinetic,', 'potential,', 'thermal,', 'and', 'chemical', 'energy.']\n",
            "[('Energy', 'is'), ('is', 'the'), ('the', 'capacity'), ('capacity', 'to'), ('to', 'do'), ('do', 'work'), ('work', 'and'), ('and', 'comes'), ('comes', 'in'), ('in', 'various'), ('various', 'forms'), ('forms', 'such'), ('such', 'as'), ('as', 'kinetic,'), ('kinetic,', 'potential,'), ('potential,', 'thermal,'), ('thermal,', 'and'), ('and', 'chemical'), ('chemical', 'energy.'), ('Energy', 'is'), ('is', 'the'), ('the', 'capacity'), ('capacity', 'to'), ('to', 'do'), ('do', 'work'), ('work', 'and'), ('and', 'comes'), ('comes', 'in'), ('in', 'various'), ('various', 'forms'), ('forms', 'such'), ('such', 'as'), ('as', 'kinetic,'), ('kinetic,', 'potential,'), ('potential,', 'thermal,'), ('thermal,', 'and'), ('and', 'chemical'), ('chemical', 'energy.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([9.0000e+00, 6.8000e+01, 2.0000e+00, 4.0800e+02, 2.0000e+00, 8.3000e+01,\n",
            "        3.2000e+01, 7.0000e+00, 8.3000e+01, 6.4300e+02, 2.5000e+01, 2.6690e+03,\n",
            "        1.0000e+01, 2.6130e+03, 1.4100e+02, 1.3610e+03, 2.4000e+01, 3.7000e+01,\n",
            "        9.4000e+01, 6.0000e+00, 3.0300e+02, 9.0000e+00, 6.8000e+01, 2.0000e+00,\n",
            "        4.0800e+02, 2.0000e+00, 8.3000e+01, 3.2000e+01, 7.0000e+00, 8.3000e+01,\n",
            "        6.4300e+02, 2.5000e+01, 2.6690e+03, 1.0000e+01, 2.6130e+03, 1.4100e+02,\n",
            "        1.3610e+03, 2.4000e+01, 3.7000e+01, 9.4000e+01, 6.0000e+00, 3.0300e+02])\n",
            "['The', 'law', 'of', 'conservation', 'of', 'energy', 'states', 'that', 'energy', 'cannot', 'be', 'created', 'or', 'destroyed,', 'only', 'transformed', 'from', 'one', 'form', 'to', 'another.', 'The', 'law', 'of', 'conservation', 'of', 'energy', 'states', 'that', 'energy', 'cannot', 'be', 'created', 'or', 'destroyed,', 'only', 'transformed', 'from', 'one', 'form', 'to', 'another.']\n",
            "[('The', 'law'), ('law', 'of'), ('of', 'conservation'), ('conservation', 'of'), ('of', 'energy'), ('energy', 'states'), ('states', 'that'), ('that', 'energy'), ('energy', 'cannot'), ('cannot', 'be'), ('be', 'created'), ('created', 'or'), ('or', 'destroyed,'), ('destroyed,', 'only'), ('only', 'transformed'), ('transformed', 'from'), ('from', 'one'), ('one', 'form'), ('form', 'to'), ('to', 'another.'), ('The', 'law'), ('law', 'of'), ('of', 'conservation'), ('conservation', 'of'), ('of', 'energy'), ('energy', 'states'), ('states', 'that'), ('that', 'energy'), ('energy', 'cannot'), ('cannot', 'be'), ('be', 'created'), ('created', 'or'), ('or', 'destroyed,'), ('destroyed,', 'only'), ('only', 'transformed'), ('transformed', 'from'), ('from', 'one'), ('one', 'form'), ('form', 'to'), ('to', 'another.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.2100e+03, 3.0000e+00, 1.0000e+00, 8.1600e+02, 2.0000e+00, 2.1000e+01,\n",
            "        1.9170e+03, 9.0000e+01, 5.0000e+00, 1.3000e+03, 5.0000e+00, 3.0000e+00,\n",
            "        4.0000e+00, 2.4400e+02, 8.0200e+02, 3.2100e+03, 3.0000e+00, 1.0000e+00,\n",
            "        8.1600e+02, 2.0000e+00, 2.1000e+01, 1.9170e+03, 9.0000e+01, 5.0000e+00,\n",
            "        1.3000e+03, 5.0000e+00, 3.0000e+00, 4.0000e+00, 2.4400e+02, 8.0200e+02])\n",
            "['Momentum', 'is', 'the', 'product', 'of', 'an', \"object's\", 'mass', 'and', 'velocity', 'and', 'is', 'a', 'vector', 'quantity.', 'Momentum', 'is', 'the', 'product', 'of', 'an', \"object's\", 'mass', 'and', 'velocity', 'and', 'is', 'a', 'vector', 'quantity.']\n",
            "[('Momentum', 'is'), ('is', 'the'), ('the', 'product'), ('product', 'of'), ('of', 'an'), ('an', \"object's\"), (\"object's\", 'mass'), ('mass', 'and'), ('and', 'velocity'), ('velocity', 'and'), ('and', 'is'), ('is', 'a'), ('a', 'vector'), ('vector', 'quantity.'), ('Momentum', 'is'), ('is', 'the'), ('the', 'product'), ('product', 'of'), ('of', 'an'), ('an', \"object's\"), (\"object's\", 'mass'), ('mass', 'and'), ('and', 'velocity'), ('velocity', 'and'), ('and', 'is'), ('is', 'a'), ('a', 'vector'), ('vector', 'quantity.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([9.0000e+00, 1.7600e+02, 2.0000e+00, 4.0800e+02, 2.0000e+00, 1.8200e+02,\n",
            "        3.2000e+01, 7.0000e+00, 1.0000e+00, 4.5200e+02, 1.8200e+02, 2.0000e+00,\n",
            "        4.0000e+00, 2.7660e+03, 2.6000e+01, 5.0000e+02, 2.9700e+02, 5.6500e+02,\n",
            "        1.7900e+02, 1.8600e+02, 5.9200e+02, 3.0600e+02, 2.3000e+01, 2.2200e+02,\n",
            "        9.0000e+00, 1.7600e+02, 2.0000e+00, 4.0800e+02, 2.0000e+00, 1.8200e+02,\n",
            "        3.2000e+01, 7.0000e+00, 1.0000e+00, 4.5200e+02, 1.8200e+02, 2.0000e+00,\n",
            "        4.0000e+00, 2.7660e+03, 2.6000e+01, 5.0000e+02, 2.9700e+02, 5.6500e+02,\n",
            "        1.7900e+02, 1.8600e+02, 5.9200e+02, 3.0600e+02, 2.3000e+01, 2.2200e+02])\n",
            "['The', 'principle', 'of', 'conservation', 'of', 'momentum', 'states', 'that', 'the', 'total', 'momentum', 'of', 'a', 'closed', 'system', 'remains', 'constant', 'if', 'no', 'external', 'forces', 'act', 'on', 'it.', 'The', 'principle', 'of', 'conservation', 'of', 'momentum', 'states', 'that', 'the', 'total', 'momentum', 'of', 'a', 'closed', 'system', 'remains', 'constant', 'if', 'no', 'external', 'forces', 'act', 'on', 'it.']\n",
            "[('The', 'principle'), ('principle', 'of'), ('of', 'conservation'), ('conservation', 'of'), ('of', 'momentum'), ('momentum', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'total'), ('total', 'momentum'), ('momentum', 'of'), ('of', 'a'), ('a', 'closed'), ('closed', 'system'), ('system', 'remains'), ('remains', 'constant'), ('constant', 'if'), ('if', 'no'), ('no', 'external'), ('external', 'forces'), ('forces', 'act'), ('act', 'on'), ('on', 'it.'), ('The', 'principle'), ('principle', 'of'), ('of', 'conservation'), ('conservation', 'of'), ('of', 'momentum'), ('momentum', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'total'), ('total', 'momentum'), ('momentum', 'of'), ('of', 'a'), ('a', 'closed'), ('closed', 'system'), ('system', 'remains'), ('remains', 'constant'), ('constant', 'if'), ('if', 'no'), ('no', 'external'), ('external', 'forces'), ('forces', 'act'), ('act', 'on'), ('on', 'it.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.3440e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 2.3200e+02,\n",
            "        5.0000e+00, 1.4500e+02, 5.9500e+02, 5.0000e+00, 4.1000e+01, 2.2300e+02,\n",
            "        1.9000e+01, 2.7300e+02, 3.3440e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01,\n",
            "        2.0000e+00, 2.3200e+02, 5.0000e+00, 1.4500e+02, 5.9500e+02, 5.0000e+00,\n",
            "        4.1000e+01, 2.2300e+02, 1.9000e+01, 2.7300e+02])\n",
            "['Electromagnetism', 'is', 'the', 'study', 'of', 'electric', 'and', 'magnetic', 'fields', 'and', 'their', 'interactions', 'with', 'matter.', 'Electromagnetism', 'is', 'the', 'study', 'of', 'electric', 'and', 'magnetic', 'fields', 'and', 'their', 'interactions', 'with', 'matter.']\n",
            "[('Electromagnetism', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'electric'), ('electric', 'and'), ('and', 'magnetic'), ('magnetic', 'fields'), ('fields', 'and'), ('and', 'their'), ('their', 'interactions'), ('interactions', 'with'), ('with', 'matter.'), ('Electromagnetism', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'electric'), ('electric', 'and'), ('and', 'magnetic'), ('magnetic', 'fields'), ('fields', 'and'), ('and', 'their'), ('their', 'interactions'), ('interactions', 'with'), ('with', 'matter.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([6.7200e+02, 3.3970e+03, 3.2200e+03, 3.9500e+02, 1.0000e+00, 1.5500e+02,\n",
            "        4.8000e+01, 2.0000e+00, 1.0360e+03, 1.6850e+03, 2.8340e+03, 2.0300e+02,\n",
            "        2.5230e+03, 2.0520e+03, 5.0000e+00, 1.0500e+02, 1.4000e+01, 8.4000e+01,\n",
            "        2.0480e+03, 2.0000e+00, 1.0000e+00, 1.7300e+02, 1.8090e+03, 6.7200e+02,\n",
            "        3.3970e+03, 3.2200e+03, 3.9500e+02, 1.0000e+00, 1.5500e+02, 4.8000e+01,\n",
            "        2.0000e+00, 1.0360e+03, 1.6850e+03, 2.8340e+03, 2.0300e+02, 2.5230e+03,\n",
            "        2.0520e+03, 5.0000e+00, 1.0500e+02, 1.4000e+01, 8.4000e+01, 2.0480e+03,\n",
            "        2.0000e+00, 1.0000e+00, 1.7300e+02, 1.8090e+03])\n",
            "['James', 'Clerk', 'Maxwell', 'formulated', 'the', 'classical', 'theory', 'of', 'electromagnetic', 'radiation,', 'bringing', 'together', 'electricity,', 'magnetism,', 'and', 'light', 'as', 'different', 'manifestations', 'of', 'the', 'same', 'phenomenon.', 'James', 'Clerk', 'Maxwell', 'formulated', 'the', 'classical', 'theory', 'of', 'electromagnetic', 'radiation,', 'bringing', 'together', 'electricity,', 'magnetism,', 'and', 'light', 'as', 'different', 'manifestations', 'of', 'the', 'same', 'phenomenon.']\n",
            "[('James', 'Clerk'), ('Clerk', 'Maxwell'), ('Maxwell', 'formulated'), ('formulated', 'the'), ('the', 'classical'), ('classical', 'theory'), ('theory', 'of'), ('of', 'electromagnetic'), ('electromagnetic', 'radiation,'), ('radiation,', 'bringing'), ('bringing', 'together'), ('together', 'electricity,'), ('electricity,', 'magnetism,'), ('magnetism,', 'and'), ('and', 'light'), ('light', 'as'), ('as', 'different'), ('different', 'manifestations'), ('manifestations', 'of'), ('of', 'the'), ('the', 'same'), ('same', 'phenomenon.'), ('James', 'Clerk'), ('Clerk', 'Maxwell'), ('Maxwell', 'formulated'), ('formulated', 'the'), ('the', 'classical'), ('classical', 'theory'), ('theory', 'of'), ('of', 'electromagnetic'), ('electromagnetic', 'radiation,'), ('radiation,', 'bringing'), ('bringing', 'together'), ('together', 'electricity,'), ('electricity,', 'magnetism,'), ('magnetism,', 'and'), ('and', 'light'), ('light', 'as'), ('as', 'different'), ('different', 'manifestations'), ('manifestations', 'of'), ('of', 'the'), ('the', 'same'), ('same', 'phenomenon.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([9.0000e+00, 3.3600e+02, 2.0000e+00, 1.0500e+02, 8.0000e+00, 4.0000e+00,\n",
            "        4.4600e+02, 3.0000e+00, 1.9300e+02, 1.2140e+03, 9.2600e+02, 3.6200e+02,\n",
            "        4.9000e+02, 3.4950e+03, 2.0020e+03, 3.6200e+02, 1.5610e+03, 5.0000e+00,\n",
            "        3.0000e+00, 4.0000e+00, 8.2000e+01, 2.9700e+02, 2.0000e+00, 8.7800e+02,\n",
            "        9.0000e+00, 3.3600e+02, 2.0000e+00, 1.0500e+02, 8.0000e+00, 4.0000e+00,\n",
            "        4.4600e+02, 3.0000e+00, 1.9300e+02, 1.2140e+03, 9.2600e+02, 3.6200e+02,\n",
            "        4.9000e+02, 3.4950e+03, 2.0020e+03, 3.6200e+02, 1.5610e+03, 5.0000e+00,\n",
            "        3.0000e+00, 4.0000e+00, 8.2000e+01, 2.9700e+02, 2.0000e+00, 8.7800e+02])\n",
            "['The', 'speed', 'of', 'light', 'in', 'a', 'vacuum', 'is', 'approximately', '299,792', 'kilometers', 'per', 'second', '(186,282', 'miles', 'per', 'second)', 'and', 'is', 'a', 'fundamental', 'constant', 'of', 'nature.', 'The', 'speed', 'of', 'light', 'in', 'a', 'vacuum', 'is', 'approximately', '299,792', 'kilometers', 'per', 'second', '(186,282', 'miles', 'per', 'second)', 'and', 'is', 'a', 'fundamental', 'constant', 'of', 'nature.']\n",
            "[('The', 'speed'), ('speed', 'of'), ('of', 'light'), ('light', 'in'), ('in', 'a'), ('a', 'vacuum'), ('vacuum', 'is'), ('is', 'approximately'), ('approximately', '299,792'), ('299,792', 'kilometers'), ('kilometers', 'per'), ('per', 'second'), ('second', '(186,282'), ('(186,282', 'miles'), ('miles', 'per'), ('per', 'second)'), ('second)', 'and'), ('and', 'is'), ('is', 'a'), ('a', 'fundamental'), ('fundamental', 'constant'), ('constant', 'of'), ('of', 'nature.'), ('The', 'speed'), ('speed', 'of'), ('of', 'light'), ('light', 'in'), ('in', 'a'), ('a', 'vacuum'), ('vacuum', 'is'), ('is', 'approximately'), ('approximately', '299,792'), ('299,792', 'kilometers'), ('kilometers', 'per'), ('per', 'second'), ('second', '(186,282'), ('(186,282', 'miles'), ('miles', 'per'), ('per', 'second)'), ('second)', 'and'), ('and', 'is'), ('is', 'a'), ('a', 'fundamental'), ('fundamental', 'constant'), ('constant', 'of'), ('of', 'nature.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([3.0360e+03, 6.1300e+02, 3.0000e+00, 4.0000e+00, 8.2000e+01, 1.5400e+02,\n",
            "        8.0000e+00, 1.7000e+01, 8.9000e+01, 7.0000e+00, 4.9000e+01, 7.6000e+01,\n",
            "        2.2900e+02, 1.2900e+02, 1.0000e+01, 1.7000e+01, 2.4950e+03, 1.0100e+03,\n",
            "        1.1300e+02, 3.1800e+02, 5.0000e+00, 3.6500e+02, 2.1400e+02, 3.0360e+03,\n",
            "        6.1300e+02, 3.0000e+00, 4.0000e+00, 8.2000e+01, 1.5400e+02, 8.0000e+00,\n",
            "        1.7000e+01, 8.9000e+01, 7.0000e+00, 4.9000e+01, 7.6000e+01, 2.2900e+02,\n",
            "        1.2900e+02, 1.0000e+01, 1.7000e+01, 2.4950e+03, 1.0100e+03, 1.1300e+02,\n",
            "        3.1800e+02, 5.0000e+00, 3.6500e+02, 2.1400e+02])\n",
            "['Wave-particle', 'duality', 'is', 'a', 'fundamental', 'concept', 'in', 'quantum', 'mechanics', 'that', 'describes', 'how', 'every', 'particle', 'or', 'quantum', 'entity', 'exhibits', 'both', 'wave-like', 'and', 'particle-like', 'properties.', 'Wave-particle', 'duality', 'is', 'a', 'fundamental', 'concept', 'in', 'quantum', 'mechanics', 'that', 'describes', 'how', 'every', 'particle', 'or', 'quantum', 'entity', 'exhibits', 'both', 'wave-like', 'and', 'particle-like', 'properties.']\n",
            "[('Wave-particle', 'duality'), ('duality', 'is'), ('is', 'a'), ('a', 'fundamental'), ('fundamental', 'concept'), ('concept', 'in'), ('in', 'quantum'), ('quantum', 'mechanics'), ('mechanics', 'that'), ('that', 'describes'), ('describes', 'how'), ('how', 'every'), ('every', 'particle'), ('particle', 'or'), ('or', 'quantum'), ('quantum', 'entity'), ('entity', 'exhibits'), ('exhibits', 'both'), ('both', 'wave-like'), ('wave-like', 'and'), ('and', 'particle-like'), ('particle-like', 'properties.'), ('Wave-particle', 'duality'), ('duality', 'is'), ('is', 'a'), ('a', 'fundamental'), ('fundamental', 'concept'), ('concept', 'in'), ('in', 'quantum'), ('quantum', 'mechanics'), ('mechanics', 'that'), ('that', 'describes'), ('describes', 'how'), ('how', 'every'), ('every', 'particle'), ('particle', 'or'), ('or', 'quantum'), ('quantum', 'entity'), ('entity', 'exhibits'), ('exhibits', 'both'), ('both', 'wave-like'), ('wave-like', 'and'), ('and', 'particle-like'), ('particle-like', 'properties.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([4.7000e+01, 8.9000e+01, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.0200e+02, 7.0000e+00, 1.2200e+02, 1.9000e+01, 1.0000e+00, 1.2400e+02,\n",
            "        2.0000e+00, 5.5000e+01, 2.3000e+01, 1.0000e+00, 3.0200e+02, 5.0000e+00,\n",
            "        7.4600e+02, 1.5680e+03, 4.7000e+01, 8.9000e+01, 3.0000e+00, 1.0000e+00,\n",
            "        2.7000e+01, 2.0000e+00, 1.0200e+02, 7.0000e+00, 1.2200e+02, 1.9000e+01,\n",
            "        1.0000e+00, 1.2400e+02, 2.0000e+00, 5.5000e+01, 2.3000e+01, 1.0000e+00,\n",
            "        3.0200e+02, 5.0000e+00, 7.4600e+02, 1.5680e+03])\n",
            "['Quantum', 'mechanics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'deals', 'with', 'the', 'behavior', 'of', 'particles', 'on', 'the', 'atomic', 'and', 'subatomic', 'scale.', 'Quantum', 'mechanics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'deals', 'with', 'the', 'behavior', 'of', 'particles', 'on', 'the', 'atomic', 'and', 'subatomic', 'scale.']\n",
            "[('Quantum', 'mechanics'), ('mechanics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'behavior'), ('behavior', 'of'), ('of', 'particles'), ('particles', 'on'), ('on', 'the'), ('the', 'atomic'), ('atomic', 'and'), ('and', 'subatomic'), ('subatomic', 'scale.'), ('Quantum', 'mechanics'), ('mechanics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'behavior'), ('behavior', 'of'), ('of', 'particles'), ('particles', 'on'), ('on', 'the'), ('the', 'atomic'), ('atomic', 'and'), ('and', 'subatomic'), ('subatomic', 'scale.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([3.0340e+03, 1.1880e+03, 1.3330e+03, 1.7600e+02, 3.2000e+01, 7.0000e+00,\n",
            "        4.4000e+01, 3.0000e+00, 9.5400e+02, 6.0000e+00, 4.8500e+02, 1.0700e+02,\n",
            "        1.0000e+00, 2.4670e+03, 8.2900e+02, 5.0000e+00, 1.8200e+02, 2.0000e+00,\n",
            "        4.0000e+00, 1.8530e+03, 3.0340e+03, 1.1880e+03, 1.3330e+03, 1.7600e+02,\n",
            "        3.2000e+01, 7.0000e+00, 4.4000e+01, 3.0000e+00, 9.5400e+02, 6.0000e+00,\n",
            "        4.8500e+02, 1.0700e+02, 1.0000e+00, 2.4670e+03, 8.2900e+02, 5.0000e+00,\n",
            "        1.8200e+02, 2.0000e+00, 4.0000e+00, 1.8530e+03])\n",
            "['Werner', \"Heisenberg's\", 'uncertainty', 'principle', 'states', 'that', 'it', 'is', 'impossible', 'to', 'simultaneously', 'know', 'the', 'exact', 'position', 'and', 'momentum', 'of', 'a', 'particle.', 'Werner', \"Heisenberg's\", 'uncertainty', 'principle', 'states', 'that', 'it', 'is', 'impossible', 'to', 'simultaneously', 'know', 'the', 'exact', 'position', 'and', 'momentum', 'of', 'a', 'particle.']\n",
            "[('Werner', \"Heisenberg's\"), (\"Heisenberg's\", 'uncertainty'), ('uncertainty', 'principle'), ('principle', 'states'), ('states', 'that'), ('that', 'it'), ('it', 'is'), ('is', 'impossible'), ('impossible', 'to'), ('to', 'simultaneously'), ('simultaneously', 'know'), ('know', 'the'), ('the', 'exact'), ('exact', 'position'), ('position', 'and'), ('and', 'momentum'), ('momentum', 'of'), ('of', 'a'), ('a', 'particle.'), ('Werner', \"Heisenberg's\"), (\"Heisenberg's\", 'uncertainty'), ('uncertainty', 'principle'), ('principle', 'states'), ('states', 'that'), ('that', 'it'), ('it', 'is'), ('is', 'impossible'), ('impossible', 'to'), ('to', 'simultaneously'), ('simultaneously', 'know'), ('know', 'the'), ('the', 'exact'), ('exact', 'position'), ('position', 'and'), ('and', 'momentum'), ('momentum', 'of'), ('of', 'a'), ('a', 'particle.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([9.0000e+00, 1.1740e+03, 1.3200e+02, 3.0000e+00, 4.0000e+00, 8.2000e+01,\n",
            "        1.3200e+02, 2.0000e+00, 1.7000e+01, 8.9000e+01, 7.0000e+00, 4.9000e+01,\n",
            "        7.6000e+01, 1.0000e+00, 1.7000e+01, 1.1600e+02, 2.0000e+00, 4.0000e+00,\n",
            "        3.5900e+02, 2.6000e+01, 1.3300e+02, 7.4000e+01, 2.4900e+02, 9.0000e+00,\n",
            "        1.1740e+03, 1.3200e+02, 3.0000e+00, 4.0000e+00, 8.2000e+01, 1.3200e+02,\n",
            "        2.0000e+00, 1.7000e+01, 8.9000e+01, 7.0000e+00, 4.9000e+01, 7.6000e+01,\n",
            "        1.0000e+00, 1.7000e+01, 1.1600e+02, 2.0000e+00, 4.0000e+00, 3.5900e+02,\n",
            "        2.6000e+01, 1.3300e+02, 7.4000e+01, 2.4900e+02])\n",
            "['The', 'Schrödinger', 'equation', 'is', 'a', 'fundamental', 'equation', 'of', 'quantum', 'mechanics', 'that', 'describes', 'how', 'the', 'quantum', 'state', 'of', 'a', 'physical', 'system', 'changes', 'over', 'time.', 'The', 'Schrödinger', 'equation', 'is', 'a', 'fundamental', 'equation', 'of', 'quantum', 'mechanics', 'that', 'describes', 'how', 'the', 'quantum', 'state', 'of', 'a', 'physical', 'system', 'changes', 'over', 'time.']\n",
            "[('The', 'Schrödinger'), ('Schrödinger', 'equation'), ('equation', 'is'), ('is', 'a'), ('a', 'fundamental'), ('fundamental', 'equation'), ('equation', 'of'), ('of', 'quantum'), ('quantum', 'mechanics'), ('mechanics', 'that'), ('that', 'describes'), ('describes', 'how'), ('how', 'the'), ('the', 'quantum'), ('quantum', 'state'), ('state', 'of'), ('of', 'a'), ('a', 'physical'), ('physical', 'system'), ('system', 'changes'), ('changes', 'over'), ('over', 'time.'), ('The', 'Schrödinger'), ('Schrödinger', 'equation'), ('equation', 'is'), ('is', 'a'), ('a', 'fundamental'), ('fundamental', 'equation'), ('equation', 'of'), ('of', 'quantum'), ('quantum', 'mechanics'), ('mechanics', 'that'), ('that', 'describes'), ('describes', 'how'), ('how', 'the'), ('the', 'quantum'), ('quantum', 'state'), ('state', 'of'), ('of', 'a'), ('a', 'physical'), ('physical', 'system'), ('system', 'changes'), ('changes', 'over'), ('over', 'time.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([6.8300e+02, 1.1970e+03, 4.8000e+01, 2.0000e+00, 7.9400e+02, 7.8600e+02,\n",
            "        8.8000e+01, 2.4700e+02, 2.0000e+00, 1.5040e+03, 4.5400e+02, 5.0000e+00,\n",
            "        2.3100e+03, 6.8300e+02, 1.1970e+03, 4.8000e+01, 2.0000e+00, 7.9400e+02,\n",
            "        7.8600e+02, 8.8000e+01, 2.4700e+02, 2.0000e+00, 1.5040e+03, 4.5400e+02,\n",
            "        5.0000e+00, 2.3100e+03])\n",
            "['Albert', \"Einstein's\", 'theory', 'of', 'relativity', 'revolutionized', 'our', 'understanding', 'of', 'space,', 'time,', 'and', 'gravity.', 'Albert', \"Einstein's\", 'theory', 'of', 'relativity', 'revolutionized', 'our', 'understanding', 'of', 'space,', 'time,', 'and', 'gravity.']\n",
            "[('Albert', \"Einstein's\"), (\"Einstein's\", 'theory'), ('theory', 'of'), ('of', 'relativity'), ('relativity', 'revolutionized'), ('revolutionized', 'our'), ('our', 'understanding'), ('understanding', 'of'), ('of', 'space,'), ('space,', 'time,'), ('time,', 'and'), ('and', 'gravity.'), ('Albert', \"Einstein's\"), (\"Einstein's\", 'theory'), ('theory', 'of'), ('of', 'relativity'), ('relativity', 'revolutionized'), ('revolutionized', 'our'), ('our', 'understanding'), ('understanding', 'of'), ('of', 'space,'), ('space,', 'time,'), ('time,', 'and'), ('and', 'gravity.')]\n",
            "44\n",
            "42\n",
            "946\n",
            "86\n",
            "tensor([3.0930e+03, 7.9300e+02, 2.1570e+03, 1.8000e+01, 6.7700e+02, 8.0000e+00,\n",
            "        3.4760e+03, 2.9920e+03, 1.0000e+00, 3.4700e+02, 3.5000e+01, 3.3900e+02,\n",
            "        5.0000e+00, 3.3000e+02, 5.0000e+00, 1.0900e+02, 1.0000e+00, 9.9900e+02,\n",
            "        1.3200e+02, 1.1990e+03, 6.8400e+02, 2.0310e+03, 3.0930e+03, 7.9300e+02,\n",
            "        2.1570e+03, 1.8000e+01, 6.7700e+02, 8.0000e+00, 3.4760e+03, 2.9920e+03,\n",
            "        1.0000e+00, 3.4700e+02, 3.5000e+01, 3.3900e+02, 5.0000e+00, 3.3000e+02,\n",
            "        5.0000e+00, 1.0900e+02, 1.0000e+00, 9.9900e+02, 1.3200e+02, 1.1990e+03,\n",
            "        6.8400e+02, 2.0310e+03])\n",
            "['Special', 'relativity,', 'introduced', 'by', 'Einstein', 'in', '1905,', 'addresses', 'the', 'relationship', 'between', 'space', 'and', 'time', 'and', 'includes', 'the', 'famous', 'equation', 'E', '=', 'mc^2.', 'Special', 'relativity,', 'introduced', 'by', 'Einstein', 'in', '1905,', 'addresses', 'the', 'relationship', 'between', 'space', 'and', 'time', 'and', 'includes', 'the', 'famous', 'equation', 'E', '=', 'mc^2.']\n",
            "[('Special', 'relativity,'), ('relativity,', 'introduced'), ('introduced', 'by'), ('by', 'Einstein'), ('Einstein', 'in'), ('in', '1905,'), ('1905,', 'addresses'), ('addresses', 'the'), ('the', 'relationship'), ('relationship', 'between'), ('between', 'space'), ('space', 'and'), ('and', 'time'), ('time', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'famous'), ('famous', 'equation'), ('equation', 'E'), ('E', '='), ('=', 'mc^2.'), ('Special', 'relativity,'), ('relativity,', 'introduced'), ('introduced', 'by'), ('by', 'Einstein'), ('Einstein', 'in'), ('in', '1905,'), ('1905,', 'addresses'), ('addresses', 'the'), ('the', 'relationship'), ('relationship', 'between'), ('between', 'space'), ('space', 'and'), ('and', 'time'), ('time', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'famous'), ('famous', 'equation'), ('equation', 'E'), ('E', '='), ('=', 'mc^2.')]\n",
            "50\n",
            "48\n",
            "1225\n",
            "98\n",
            "tensor([1.1940e+03, 7.9300e+02, 5.0800e+02, 1.8000e+01, 6.7700e+02, 8.0000e+00,\n",
            "        3.4750e+03, 3.0000e+00, 4.0000e+00, 4.8000e+01, 2.0000e+00, 9.6700e+02,\n",
            "        7.0000e+00, 4.9000e+01, 5.7600e+02, 1.4000e+01, 4.0000e+00, 2.6540e+03,\n",
            "        2.0000e+00, 7.5800e+02, 4.1500e+02, 1.8000e+01, 9.0000e+01, 5.0000e+00,\n",
            "        1.5100e+02, 1.1940e+03, 7.9300e+02, 5.0800e+02, 1.8000e+01, 6.7700e+02,\n",
            "        8.0000e+00, 3.4750e+03, 3.0000e+00, 4.0000e+00, 4.8000e+01, 2.0000e+00,\n",
            "        9.6700e+02, 7.0000e+00, 4.9000e+01, 5.7600e+02, 1.4000e+01, 4.0000e+00,\n",
            "        2.6540e+03, 2.0000e+00, 7.5800e+02, 4.1500e+02, 1.8000e+01, 9.0000e+01,\n",
            "        5.0000e+00, 1.5100e+02])\n",
            "['General', 'relativity,', 'published', 'by', 'Einstein', 'in', '1915,', 'is', 'a', 'theory', 'of', 'gravitation', 'that', 'describes', 'gravity', 'as', 'a', 'curvature', 'of', 'spacetime', 'caused', 'by', 'mass', 'and', 'energy.', 'General', 'relativity,', 'published', 'by', 'Einstein', 'in', '1915,', 'is', 'a', 'theory', 'of', 'gravitation', 'that', 'describes', 'gravity', 'as', 'a', 'curvature', 'of', 'spacetime', 'caused', 'by', 'mass', 'and', 'energy.']\n",
            "[('General', 'relativity,'), ('relativity,', 'published'), ('published', 'by'), ('by', 'Einstein'), ('Einstein', 'in'), ('in', '1915,'), ('1915,', 'is'), ('is', 'a'), ('a', 'theory'), ('theory', 'of'), ('of', 'gravitation'), ('gravitation', 'that'), ('that', 'describes'), ('describes', 'gravity'), ('gravity', 'as'), ('as', 'a'), ('a', 'curvature'), ('curvature', 'of'), ('of', 'spacetime'), ('spacetime', 'caused'), ('caused', 'by'), ('by', 'mass'), ('mass', 'and'), ('and', 'energy.'), ('General', 'relativity,'), ('relativity,', 'published'), ('published', 'by'), ('by', 'Einstein'), ('Einstein', 'in'), ('in', '1915,'), ('1915,', 'is'), ('is', 'a'), ('a', 'theory'), ('theory', 'of'), ('of', 'gravitation'), ('gravitation', 'that'), ('that', 'describes'), ('describes', 'gravity'), ('gravity', 'as'), ('as', 'a'), ('a', 'curvature'), ('curvature', 'of'), ('of', 'spacetime'), ('spacetime', 'caused'), ('caused', 'by'), ('by', 'mass'), ('mass', 'and'), ('and', 'energy.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([9.0000e+00, 1.7600e+02, 2.0000e+00, 2.4860e+03, 3.2000e+01, 7.0000e+00,\n",
            "        1.0000e+00, 2.9100e+02, 2.0000e+00, 5.7600e+02, 1.3000e+01, 2.2220e+03,\n",
            "        2.4000e+01, 1.0000e+00, 2.9100e+02, 2.0000e+00, 1.1510e+03, 8.0000e+00,\n",
            "        4.0000e+00, 2.0760e+03, 2.2160e+03, 2.3610e+03, 2.0000e+00, 1.6430e+03,\n",
            "        9.0000e+00, 1.7600e+02, 2.0000e+00, 2.4860e+03, 3.2000e+01, 7.0000e+00,\n",
            "        1.0000e+00, 2.9100e+02, 2.0000e+00, 5.7600e+02, 1.3000e+01, 2.2220e+03,\n",
            "        2.4000e+01, 1.0000e+00, 2.9100e+02, 2.0000e+00, 1.1510e+03, 8.0000e+00,\n",
            "        4.0000e+00, 2.0760e+03, 2.2160e+03, 2.3610e+03, 2.0000e+00, 1.6430e+03])\n",
            "['The', 'principle', 'of', 'equivalence', 'states', 'that', 'the', 'effects', 'of', 'gravity', 'are', 'indistinguishable', 'from', 'the', 'effects', 'of', 'acceleration', 'in', 'a', 'locally', 'inertial', 'frame', 'of', 'reference.', 'The', 'principle', 'of', 'equivalence', 'states', 'that', 'the', 'effects', 'of', 'gravity', 'are', 'indistinguishable', 'from', 'the', 'effects', 'of', 'acceleration', 'in', 'a', 'locally', 'inertial', 'frame', 'of', 'reference.']\n",
            "[('The', 'principle'), ('principle', 'of'), ('of', 'equivalence'), ('equivalence', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'effects'), ('effects', 'of'), ('of', 'gravity'), ('gravity', 'are'), ('are', 'indistinguishable'), ('indistinguishable', 'from'), ('from', 'the'), ('the', 'effects'), ('effects', 'of'), ('of', 'acceleration'), ('acceleration', 'in'), ('in', 'a'), ('a', 'locally'), ('locally', 'inertial'), ('inertial', 'frame'), ('frame', 'of'), ('of', 'reference.'), ('The', 'principle'), ('principle', 'of'), ('of', 'equivalence'), ('equivalence', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'effects'), ('effects', 'of'), ('of', 'gravity'), ('gravity', 'are'), ('are', 'indistinguishable'), ('indistinguishable', 'from'), ('from', 'the'), ('the', 'effects'), ('effects', 'of'), ('of', 'acceleration'), ('acceleration', 'in'), ('in', 'a'), ('a', 'locally'), ('locally', 'inertial'), ('inertial', 'frame'), ('frame', 'of'), ('of', 'reference.')]\n",
            "44\n",
            "42\n",
            "946\n",
            "86\n",
            "tensor([1.1000e+01, 1.1120e+03, 2.2700e+03, 3.0000e+00, 4.0000e+00, 5.0300e+02,\n",
            "        2.0000e+00, 7.5800e+02, 9.9000e+01, 5.7600e+02, 3.0000e+00, 7.6400e+02,\n",
            "        3.3500e+02, 7.0000e+00, 1.9310e+03, 6.7000e+01, 2.4770e+03, 9.1400e+02,\n",
            "        1.6000e+01, 1.0200e+03, 2.4000e+01, 2.2200e+02, 1.1000e+01, 1.1120e+03,\n",
            "        2.2700e+03, 3.0000e+00, 4.0000e+00, 5.0300e+02, 2.0000e+00, 7.5800e+02,\n",
            "        9.9000e+01, 5.7600e+02, 3.0000e+00, 7.6400e+02, 3.3500e+02, 7.0000e+00,\n",
            "        1.9310e+03, 6.7000e+01, 2.4770e+03, 9.1400e+02, 1.6000e+01, 1.0200e+03,\n",
            "        2.4000e+01, 2.2200e+02])\n",
            "['A', 'black', 'hole', 'is', 'a', 'region', 'of', 'spacetime', 'where', 'gravity', 'is', 'so', 'strong', 'that', 'nothing,', 'not', 'even', 'light,', 'can', 'escape', 'from', 'it.', 'A', 'black', 'hole', 'is', 'a', 'region', 'of', 'spacetime', 'where', 'gravity', 'is', 'so', 'strong', 'that', 'nothing,', 'not', 'even', 'light,', 'can', 'escape', 'from', 'it.']\n",
            "[('A', 'black'), ('black', 'hole'), ('hole', 'is'), ('is', 'a'), ('a', 'region'), ('region', 'of'), ('of', 'spacetime'), ('spacetime', 'where'), ('where', 'gravity'), ('gravity', 'is'), ('is', 'so'), ('so', 'strong'), ('strong', 'that'), ('that', 'nothing,'), ('nothing,', 'not'), ('not', 'even'), ('even', 'light,'), ('light,', 'can'), ('can', 'escape'), ('escape', 'from'), ('from', 'it.'), ('A', 'black'), ('black', 'hole'), ('hole', 'is'), ('is', 'a'), ('a', 'region'), ('region', 'of'), ('of', 'spacetime'), ('spacetime', 'where'), ('where', 'gravity'), ('gravity', 'is'), ('is', 'so'), ('so', 'strong'), ('strong', 'that'), ('that', 'nothing,'), ('nothing,', 'not'), ('not', 'even'), ('even', 'light,'), ('light,', 'can'), ('can', 'escape'), ('escape', 'from'), ('from', 'it.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.0680e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 9.6000e+02,\n",
            "        1.2430e+03, 5.0000e+00, 1.0000e+00, 3.4800e+02, 1.4000e+02, 2.0000e+00,\n",
            "        4.6500e+02, 3.0680e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00,\n",
            "        9.6000e+02, 1.2430e+03, 5.0000e+00, 1.0000e+00, 3.4800e+02, 1.4000e+02,\n",
            "        2.0000e+00, 4.6500e+02])\n",
            "['Thermodynamics', 'is', 'the', 'study', 'of', 'heat,', 'work,', 'and', 'the', 'related', 'properties', 'of', 'systems.', 'Thermodynamics', 'is', 'the', 'study', 'of', 'heat,', 'work,', 'and', 'the', 'related', 'properties', 'of', 'systems.']\n",
            "[('Thermodynamics', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'heat,'), ('heat,', 'work,'), ('work,', 'and'), ('and', 'the'), ('the', 'related'), ('related', 'properties'), ('properties', 'of'), ('of', 'systems.'), ('Thermodynamics', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'heat,'), ('heat,', 'work,'), ('work,', 'and'), ('and', 'the'), ('the', 'related'), ('related', 'properties'), ('properties', 'of'), ('of', 'systems.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([9.0000e+00, 2.3920e+03, 6.8000e+01, 2.0000e+00, 7.2500e+02, 7.8000e+01,\n",
            "        1.0600e+02, 1.4000e+01, 1.0000e+00, 6.8000e+01, 2.0000e+00, 8.3000e+01,\n",
            "        2.7100e+03, 3.2000e+01, 7.0000e+00, 1.0000e+00, 4.5200e+02, 8.3000e+01,\n",
            "        2.0000e+00, 2.1000e+01, 9.3300e+02, 2.6000e+01, 3.0000e+00, 1.0760e+03,\n",
            "        9.0000e+00, 2.3920e+03, 6.8000e+01, 2.0000e+00, 7.2500e+02, 7.8000e+01,\n",
            "        1.0600e+02, 1.4000e+01, 1.0000e+00, 6.8000e+01, 2.0000e+00, 8.3000e+01,\n",
            "        2.7100e+03, 3.2000e+01, 7.0000e+00, 1.0000e+00, 4.5200e+02, 8.3000e+01,\n",
            "        2.0000e+00, 2.1000e+01, 9.3300e+02, 2.6000e+01, 3.0000e+00, 1.0760e+03])\n",
            "['The', 'first', 'law', 'of', 'thermodynamics,', 'also', 'known', 'as', 'the', 'law', 'of', 'energy', 'conservation,', 'states', 'that', 'the', 'total', 'energy', 'of', 'an', 'isolated', 'system', 'is', 'constant.', 'The', 'first', 'law', 'of', 'thermodynamics,', 'also', 'known', 'as', 'the', 'law', 'of', 'energy', 'conservation,', 'states', 'that', 'the', 'total', 'energy', 'of', 'an', 'isolated', 'system', 'is', 'constant.']\n",
            "[('The', 'first'), ('first', 'law'), ('law', 'of'), ('of', 'thermodynamics,'), ('thermodynamics,', 'also'), ('also', 'known'), ('known', 'as'), ('as', 'the'), ('the', 'law'), ('law', 'of'), ('of', 'energy'), ('energy', 'conservation,'), ('conservation,', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'total'), ('total', 'energy'), ('energy', 'of'), ('of', 'an'), ('an', 'isolated'), ('isolated', 'system'), ('system', 'is'), ('is', 'constant.'), ('The', 'first'), ('first', 'law'), ('law', 'of'), ('of', 'thermodynamics,'), ('thermodynamics,', 'also'), ('also', 'known'), ('known', 'as'), ('as', 'the'), ('the', 'law'), ('law', 'of'), ('of', 'energy'), ('energy', 'conservation,'), ('conservation,', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'total'), ('total', 'energy'), ('energy', 'of'), ('of', 'an'), ('an', 'isolated'), ('isolated', 'system'), ('system', 'is'), ('is', 'constant.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 4.9000e+02, 6.8000e+01, 2.0000e+00, 4.5900e+02, 3.2000e+01,\n",
            "        7.0000e+00, 1.0000e+00, 6.0800e+02, 2.0000e+00, 2.1000e+01, 9.3300e+02,\n",
            "        2.6000e+01, 1.1380e+03, 2.2280e+03, 7.4000e+01, 2.4900e+02, 9.0000e+00,\n",
            "        4.9000e+02, 6.8000e+01, 2.0000e+00, 4.5900e+02, 3.2000e+01, 7.0000e+00,\n",
            "        1.0000e+00, 6.0800e+02, 2.0000e+00, 2.1000e+01, 9.3300e+02, 2.6000e+01,\n",
            "        1.1380e+03, 2.2280e+03, 7.4000e+01, 2.4900e+02])\n",
            "['The', 'second', 'law', 'of', 'thermodynamics', 'states', 'that', 'the', 'entropy', 'of', 'an', 'isolated', 'system', 'always', 'increases', 'over', 'time.', 'The', 'second', 'law', 'of', 'thermodynamics', 'states', 'that', 'the', 'entropy', 'of', 'an', 'isolated', 'system', 'always', 'increases', 'over', 'time.']\n",
            "[('The', 'second'), ('second', 'law'), ('law', 'of'), ('of', 'thermodynamics'), ('thermodynamics', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'entropy'), ('entropy', 'of'), ('of', 'an'), ('an', 'isolated'), ('isolated', 'system'), ('system', 'always'), ('always', 'increases'), ('increases', 'over'), ('over', 'time.'), ('The', 'second'), ('second', 'law'), ('law', 'of'), ('of', 'thermodynamics'), ('thermodynamics', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'entropy'), ('entropy', 'of'), ('of', 'an'), ('an', 'isolated'), ('isolated', 'system'), ('system', 'always'), ('always', 'increases'), ('increases', 'over'), ('over', 'time.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([3.3390e+03, 3.0000e+00, 4.0000e+00, 2.0280e+03, 2.0000e+00, 1.0000e+00,\n",
            "        1.0470e+03, 1.0000e+01, 1.6800e+03, 8.0000e+00, 4.0000e+00, 2.0600e+02,\n",
            "        3.3390e+03, 3.0000e+00, 4.0000e+00, 2.0280e+03, 2.0000e+00, 1.0000e+00,\n",
            "        1.0470e+03, 1.0000e+01, 1.6800e+03, 8.0000e+00, 4.0000e+00, 2.0600e+02])\n",
            "['Entropy', 'is', 'a', 'measure', 'of', 'the', 'disorder', 'or', 'randomness', 'in', 'a', 'system.', 'Entropy', 'is', 'a', 'measure', 'of', 'the', 'disorder', 'or', 'randomness', 'in', 'a', 'system.']\n",
            "[('Entropy', 'is'), ('is', 'a'), ('a', 'measure'), ('measure', 'of'), ('of', 'the'), ('the', 'disorder'), ('disorder', 'or'), ('or', 'randomness'), ('randomness', 'in'), ('in', 'a'), ('a', 'system.'), ('Entropy', 'is'), ('is', 'a'), ('a', 'measure'), ('measure', 'of'), ('of', 'the'), ('the', 'disorder'), ('disorder', 'or'), ('or', 'randomness'), ('randomness', 'in'), ('in', 'a'), ('a', 'system.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([9.0000e+00, 4.5700e+02, 6.8000e+01, 2.0000e+00, 4.5900e+02, 3.2000e+01,\n",
            "        7.0000e+00, 1.4000e+01, 1.0000e+00, 3.3100e+02, 2.0000e+00, 4.0000e+00,\n",
            "        2.6000e+01, 4.2700e+02, 1.1550e+03, 1.2190e+03, 1.0000e+00, 6.0800e+02,\n",
            "        2.0000e+00, 1.0000e+00, 2.6000e+01, 4.2700e+02, 4.0000e+00, 1.9970e+03,\n",
            "        9.0000e+00, 4.5700e+02, 6.8000e+01, 2.0000e+00, 4.5900e+02, 3.2000e+01,\n",
            "        7.0000e+00, 1.4000e+01, 1.0000e+00, 3.3100e+02, 2.0000e+00, 4.0000e+00,\n",
            "        2.6000e+01, 4.2700e+02, 1.1550e+03, 1.2190e+03, 1.0000e+00, 6.0800e+02,\n",
            "        2.0000e+00, 1.0000e+00, 2.6000e+01, 4.2700e+02, 4.0000e+00, 1.9970e+03])\n",
            "['The', 'third', 'law', 'of', 'thermodynamics', 'states', 'that', 'as', 'the', 'temperature', 'of', 'a', 'system', 'approaches', 'absolute', 'zero,', 'the', 'entropy', 'of', 'the', 'system', 'approaches', 'a', 'minimum.', 'The', 'third', 'law', 'of', 'thermodynamics', 'states', 'that', 'as', 'the', 'temperature', 'of', 'a', 'system', 'approaches', 'absolute', 'zero,', 'the', 'entropy', 'of', 'the', 'system', 'approaches', 'a', 'minimum.']\n",
            "[('The', 'third'), ('third', 'law'), ('law', 'of'), ('of', 'thermodynamics'), ('thermodynamics', 'states'), ('states', 'that'), ('that', 'as'), ('as', 'the'), ('the', 'temperature'), ('temperature', 'of'), ('of', 'a'), ('a', 'system'), ('system', 'approaches'), ('approaches', 'absolute'), ('absolute', 'zero,'), ('zero,', 'the'), ('the', 'entropy'), ('entropy', 'of'), ('of', 'the'), ('the', 'system'), ('system', 'approaches'), ('approaches', 'a'), ('a', 'minimum.'), ('The', 'third'), ('third', 'law'), ('law', 'of'), ('of', 'thermodynamics'), ('thermodynamics', 'states'), ('states', 'that'), ('that', 'as'), ('as', 'the'), ('the', 'temperature'), ('temperature', 'of'), ('of', 'a'), ('a', 'system'), ('system', 'approaches'), ('approaches', 'absolute'), ('absolute', 'zero,'), ('zero,', 'the'), ('the', 'entropy'), ('entropy', 'of'), ('of', 'the'), ('the', 'system'), ('system', 'approaches'), ('approaches', 'a'), ('a', 'minimum.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([3.0910e+03, 8.9000e+01, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.0200e+02, 7.0000e+00, 1.2600e+02, 2.6200e+02, 4.8000e+01, 6.0000e+00,\n",
            "        1.5300e+02, 1.0000e+00, 1.2400e+02, 2.0000e+00, 1.6900e+02, 4.0900e+02,\n",
            "        2.0000e+00, 4.0000e+00, 3.8100e+02, 5.9000e+01, 2.0000e+00, 2.6600e+02,\n",
            "        3.0910e+03, 8.9000e+01, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.0200e+02, 7.0000e+00, 1.2600e+02, 2.6200e+02, 4.8000e+01, 6.0000e+00,\n",
            "        1.5300e+02, 1.0000e+00, 1.2400e+02, 2.0000e+00, 1.6900e+02, 4.0900e+02,\n",
            "        2.0000e+00, 4.0000e+00, 3.8100e+02, 5.9000e+01, 2.0000e+00, 2.6600e+02])\n",
            "['Statistical', 'mechanics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'uses', 'probability', 'theory', 'to', 'describe', 'the', 'behavior', 'of', 'systems', 'composed', 'of', 'a', 'large', 'number', 'of', 'particles.', 'Statistical', 'mechanics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'uses', 'probability', 'theory', 'to', 'describe', 'the', 'behavior', 'of', 'systems', 'composed', 'of', 'a', 'large', 'number', 'of', 'particles.']\n",
            "[('Statistical', 'mechanics'), ('mechanics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'uses'), ('uses', 'probability'), ('probability', 'theory'), ('theory', 'to'), ('to', 'describe'), ('describe', 'the'), ('the', 'behavior'), ('behavior', 'of'), ('of', 'systems'), ('systems', 'composed'), ('composed', 'of'), ('of', 'a'), ('a', 'large'), ('large', 'number'), ('number', 'of'), ('of', 'particles.'), ('Statistical', 'mechanics'), ('mechanics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'uses'), ('uses', 'probability'), ('probability', 'theory'), ('theory', 'to'), ('to', 'describe'), ('describe', 'the'), ('the', 'behavior'), ('behavior', 'of'), ('of', 'systems'), ('systems', 'composed'), ('composed', 'of'), ('of', 'a'), ('a', 'large'), ('large', 'number'), ('number', 'of'), ('of', 'particles.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([9.0000e+00, 9.2500e+02, 4.8000e+01, 2.0000e+00, 9.7800e+02, 1.0030e+03,\n",
            "        1.0000e+00, 9.0300e+02, 1.4000e+02, 2.0000e+00, 9.7800e+02, 8.0000e+00,\n",
            "        1.4100e+03, 2.0000e+00, 1.0000e+00, 1.2000e+02, 2.0000e+00, 5.6100e+02,\n",
            "        1.9880e+03, 9.0000e+00, 9.2500e+02, 4.8000e+01, 2.0000e+00, 9.7800e+02,\n",
            "        1.0030e+03, 1.0000e+00, 9.0300e+02, 1.4000e+02, 2.0000e+00, 9.7800e+02,\n",
            "        8.0000e+00, 1.4100e+03, 2.0000e+00, 1.0000e+00, 1.2000e+02, 2.0000e+00,\n",
            "        5.6100e+02, 1.9880e+03])\n",
            "['The', 'kinetic', 'theory', 'of', 'gases', 'explains', 'the', 'macroscopic', 'properties', 'of', 'gases', 'in', 'terms', 'of', 'the', 'motion', 'of', 'individual', 'molecules.', 'The', 'kinetic', 'theory', 'of', 'gases', 'explains', 'the', 'macroscopic', 'properties', 'of', 'gases', 'in', 'terms', 'of', 'the', 'motion', 'of', 'individual', 'molecules.']\n",
            "[('The', 'kinetic'), ('kinetic', 'theory'), ('theory', 'of'), ('of', 'gases'), ('gases', 'explains'), ('explains', 'the'), ('the', 'macroscopic'), ('macroscopic', 'properties'), ('properties', 'of'), ('of', 'gases'), ('gases', 'in'), ('in', 'terms'), ('terms', 'of'), ('of', 'the'), ('the', 'motion'), ('motion', 'of'), ('of', 'individual'), ('individual', 'molecules.'), ('The', 'kinetic'), ('kinetic', 'theory'), ('theory', 'of'), ('of', 'gases'), ('gases', 'explains'), ('explains', 'the'), ('the', 'macroscopic'), ('macroscopic', 'properties'), ('properties', 'of'), ('of', 'gases'), ('gases', 'in'), ('in', 'terms'), ('terms', 'of'), ('of', 'the'), ('the', 'motion'), ('motion', 'of'), ('of', 'individual'), ('individual', 'molecules.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([9.0000e+00, 8.4100e+02, 1.8900e+02, 3.0000e+00, 1.0000e+00, 1.0320e+03,\n",
            "        2.0000e+00, 2.9000e+02, 2.4000e+01, 4.0000e+00, 2.7500e+02, 1.2500e+02,\n",
            "        4.4000e+01, 1.1540e+03, 1.0500e+02, 2.0000e+00, 1.4520e+03, 1.5100e+02,\n",
            "        9.0000e+00, 8.4100e+02, 1.8900e+02, 3.0000e+00, 1.0000e+00, 1.0320e+03,\n",
            "        2.0000e+00, 2.9000e+02, 2.4000e+01, 4.0000e+00, 2.7500e+02, 1.2500e+02,\n",
            "        4.4000e+01, 1.1540e+03, 1.0500e+02, 2.0000e+00, 1.4520e+03, 1.5100e+02])\n",
            "['The', 'photoelectric', 'effect', 'is', 'the', 'emission', 'of', 'electrons', 'from', 'a', 'material', 'when', 'it', 'absorbs', 'light', 'of', 'sufficient', 'energy.', 'The', 'photoelectric', 'effect', 'is', 'the', 'emission', 'of', 'electrons', 'from', 'a', 'material', 'when', 'it', 'absorbs', 'light', 'of', 'sufficient', 'energy.']\n",
            "[('The', 'photoelectric'), ('photoelectric', 'effect'), ('effect', 'is'), ('is', 'the'), ('the', 'emission'), ('emission', 'of'), ('of', 'electrons'), ('electrons', 'from'), ('from', 'a'), ('a', 'material'), ('material', 'when'), ('when', 'it'), ('it', 'absorbs'), ('absorbs', 'light'), ('light', 'of'), ('of', 'sufficient'), ('sufficient', 'energy.'), ('The', 'photoelectric'), ('photoelectric', 'effect'), ('effect', 'is'), ('is', 'the'), ('the', 'emission'), ('emission', 'of'), ('of', 'electrons'), ('electrons', 'from'), ('from', 'a'), ('a', 'material'), ('material', 'when'), ('when', 'it'), ('it', 'absorbs'), ('absorbs', 'light'), ('light', 'of'), ('of', 'sufficient'), ('sufficient', 'energy.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([1.1970e+03, 2.4460e+03, 2.0000e+00, 1.0000e+00, 8.4100e+02, 1.8900e+02,\n",
            "        1.7030e+03, 2.4730e+03, 1.2000e+01, 1.0000e+00, 8.0100e+02, 2.0000e+00,\n",
            "        1.0500e+02, 5.0000e+00, 2.6970e+03, 6.0000e+00, 1.0000e+00, 1.5200e+02,\n",
            "        2.0000e+00, 1.7000e+01, 4.6100e+02, 1.1970e+03, 2.4460e+03, 2.0000e+00,\n",
            "        1.0000e+00, 8.4100e+02, 1.8900e+02, 1.7030e+03, 2.4730e+03, 1.2000e+01,\n",
            "        1.0000e+00, 8.0100e+02, 2.0000e+00, 1.0500e+02, 5.0000e+00, 2.6970e+03,\n",
            "        6.0000e+00, 1.0000e+00, 1.5200e+02, 2.0000e+00, 1.7000e+01, 4.6100e+02])\n",
            "[\"Einstein's\", 'explanation', 'of', 'the', 'photoelectric', 'effect', 'provided', 'evidence', 'for', 'the', 'quantization', 'of', 'light', 'and', 'contributed', 'to', 'the', 'development', 'of', 'quantum', 'theory.', \"Einstein's\", 'explanation', 'of', 'the', 'photoelectric', 'effect', 'provided', 'evidence', 'for', 'the', 'quantization', 'of', 'light', 'and', 'contributed', 'to', 'the', 'development', 'of', 'quantum', 'theory.']\n",
            "[(\"Einstein's\", 'explanation'), ('explanation', 'of'), ('of', 'the'), ('the', 'photoelectric'), ('photoelectric', 'effect'), ('effect', 'provided'), ('provided', 'evidence'), ('evidence', 'for'), ('for', 'the'), ('the', 'quantization'), ('quantization', 'of'), ('of', 'light'), ('light', 'and'), ('and', 'contributed'), ('contributed', 'to'), ('to', 'the'), ('the', 'development'), ('development', 'of'), ('of', 'quantum'), ('quantum', 'theory.'), (\"Einstein's\", 'explanation'), ('explanation', 'of'), ('of', 'the'), ('the', 'photoelectric'), ('photoelectric', 'effect'), ('effect', 'provided'), ('provided', 'evidence'), ('evidence', 'for'), ('for', 'the'), ('the', 'quantization'), ('quantization', 'of'), ('of', 'light'), ('light', 'and'), ('and', 'contributed'), ('contributed', 'to'), ('to', 'the'), ('the', 'development'), ('development', 'of'), ('of', 'quantum'), ('quantum', 'theory.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.1880e+03, 1.0200e+02, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.0200e+02, 7.0000e+00, 3.6000e+01, 3.0200e+02, 8.7100e+02, 5.0000e+00,\n",
            "        4.1000e+01, 5.5800e+02, 3.1880e+03, 1.0200e+02, 3.0000e+00, 1.0000e+00,\n",
            "        2.7000e+01, 2.0000e+00, 1.0200e+02, 7.0000e+00, 3.6000e+01, 3.0200e+02,\n",
            "        8.7100e+02, 5.0000e+00, 4.1000e+01, 5.5800e+02])\n",
            "['Nuclear', 'physics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'studies', 'atomic', 'nuclei', 'and', 'their', 'interactions.', 'Nuclear', 'physics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'studies', 'atomic', 'nuclei', 'and', 'their', 'interactions.']\n",
            "[('Nuclear', 'physics'), ('physics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'studies'), ('studies', 'atomic'), ('atomic', 'nuclei'), ('nuclei', 'and'), ('and', 'their'), ('their', 'interactions.'), ('Nuclear', 'physics'), ('physics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'studies'), ('studies', 'atomic'), ('atomic', 'nuclei'), ('nuclei', 'and'), ('and', 'their'), ('their', 'interactions.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.1280e+03, 3.0000e+00, 1.0000e+00, 1.4850e+03, 1.0320e+03, 2.0000e+00,\n",
            "        5.5000e+01, 1.0000e+01, 1.6860e+03, 2.4000e+01, 1.0000e+00, 1.3170e+03,\n",
            "        5.3100e+02, 2.0000e+00, 2.1000e+01, 2.9100e+03, 3.1280e+03, 3.0000e+00,\n",
            "        1.0000e+00, 1.4850e+03, 1.0320e+03, 2.0000e+00, 5.5000e+01, 1.0000e+01,\n",
            "        1.6860e+03, 2.4000e+01, 1.0000e+00, 1.3170e+03, 5.3100e+02, 2.0000e+00,\n",
            "        2.1000e+01, 2.9100e+03])\n",
            "['Radioactivity', 'is', 'the', 'spontaneous', 'emission', 'of', 'particles', 'or', 'radiation', 'from', 'the', 'unstable', 'nucleus', 'of', 'an', 'atom.', 'Radioactivity', 'is', 'the', 'spontaneous', 'emission', 'of', 'particles', 'or', 'radiation', 'from', 'the', 'unstable', 'nucleus', 'of', 'an', 'atom.']\n",
            "[('Radioactivity', 'is'), ('is', 'the'), ('the', 'spontaneous'), ('spontaneous', 'emission'), ('emission', 'of'), ('of', 'particles'), ('particles', 'or'), ('or', 'radiation'), ('radiation', 'from'), ('from', 'the'), ('the', 'unstable'), ('unstable', 'nucleus'), ('nucleus', 'of'), ('of', 'an'), ('an', 'atom.'), ('Radioactivity', 'is'), ('is', 'the'), ('the', 'spontaneous'), ('spontaneous', 'emission'), ('emission', 'of'), ('of', 'particles'), ('particles', 'or'), ('or', 'radiation'), ('radiation', 'from'), ('from', 'the'), ('the', 'unstable'), ('unstable', 'nucleus'), ('nucleus', 'of'), ('of', 'an'), ('an', 'atom.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([3.3250e+03, 3.0000e+00, 1.0000e+00, 1.4860e+03, 2.0000e+00, 4.0000e+00,\n",
            "        2.2860e+03, 3.0200e+02, 5.3100e+02, 6.9000e+01, 3.9000e+01, 2.1000e+03,\n",
            "        1.9280e+03, 7.9200e+02, 4.0000e+00, 3.8100e+02, 1.1370e+03, 2.0000e+00,\n",
            "        1.5100e+02, 3.3250e+03, 3.0000e+00, 1.0000e+00, 1.4860e+03, 2.0000e+00,\n",
            "        4.0000e+00, 2.2860e+03, 3.0200e+02, 5.3100e+02, 6.9000e+01, 3.9000e+01,\n",
            "        2.1000e+03, 1.9280e+03, 7.9200e+02, 4.0000e+00, 3.8100e+02, 1.1370e+03,\n",
            "        2.0000e+00, 1.5100e+02])\n",
            "['Fission', 'is', 'the', 'splitting', 'of', 'a', 'heavy', 'atomic', 'nucleus', 'into', 'two', 'lighter', 'nuclei,', 'releasing', 'a', 'large', 'amount', 'of', 'energy.', 'Fission', 'is', 'the', 'splitting', 'of', 'a', 'heavy', 'atomic', 'nucleus', 'into', 'two', 'lighter', 'nuclei,', 'releasing', 'a', 'large', 'amount', 'of', 'energy.']\n",
            "[('Fission', 'is'), ('is', 'the'), ('the', 'splitting'), ('splitting', 'of'), ('of', 'a'), ('a', 'heavy'), ('heavy', 'atomic'), ('atomic', 'nucleus'), ('nucleus', 'into'), ('into', 'two'), ('two', 'lighter'), ('lighter', 'nuclei,'), ('nuclei,', 'releasing'), ('releasing', 'a'), ('a', 'large'), ('large', 'amount'), ('amount', 'of'), ('of', 'energy.'), ('Fission', 'is'), ('is', 'the'), ('the', 'splitting'), ('splitting', 'of'), ('of', 'a'), ('a', 'heavy'), ('heavy', 'atomic'), ('atomic', 'nucleus'), ('nucleus', 'into'), ('into', 'two'), ('two', 'lighter'), ('lighter', 'nuclei,'), ('nuclei,', 'releasing'), ('releasing', 'a'), ('a', 'large'), ('large', 'amount'), ('amount', 'of'), ('of', 'energy.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([3.3130e+03, 3.0000e+00, 1.0000e+00, 5.7000e+01, 1.8000e+01, 2.2000e+01,\n",
            "        3.9000e+01, 1.0500e+02, 3.0200e+02, 8.7100e+02, 2.7510e+03, 6.0000e+00,\n",
            "        9.4000e+01, 4.0000e+00, 2.2870e+03, 1.9250e+03, 7.9200e+02, 8.3000e+01,\n",
            "        8.0000e+00, 1.0000e+00, 1.7360e+03, 3.3130e+03, 3.0000e+00, 1.0000e+00,\n",
            "        5.7000e+01, 1.8000e+01, 2.2000e+01, 3.9000e+01, 1.0500e+02, 3.0200e+02,\n",
            "        8.7100e+02, 2.7510e+03, 6.0000e+00, 9.4000e+01, 4.0000e+00, 2.2870e+03,\n",
            "        1.9250e+03, 7.9200e+02, 8.3000e+01, 8.0000e+00, 1.0000e+00, 1.7360e+03])\n",
            "['Fusion', 'is', 'the', 'process', 'by', 'which', 'two', 'light', 'atomic', 'nuclei', 'combine', 'to', 'form', 'a', 'heavier', 'nucleus,', 'releasing', 'energy', 'in', 'the', 'process.', 'Fusion', 'is', 'the', 'process', 'by', 'which', 'two', 'light', 'atomic', 'nuclei', 'combine', 'to', 'form', 'a', 'heavier', 'nucleus,', 'releasing', 'energy', 'in', 'the', 'process.']\n",
            "[('Fusion', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'two'), ('two', 'light'), ('light', 'atomic'), ('atomic', 'nuclei'), ('nuclei', 'combine'), ('combine', 'to'), ('to', 'form'), ('form', 'a'), ('a', 'heavier'), ('heavier', 'nucleus,'), ('nucleus,', 'releasing'), ('releasing', 'energy'), ('energy', 'in'), ('in', 'the'), ('the', 'process.'), ('Fusion', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'two'), ('two', 'light'), ('light', 'atomic'), ('atomic', 'nuclei'), ('nuclei', 'combine'), ('combine', 'to'), ('to', 'form'), ('form', 'a'), ('a', 'heavier'), ('heavier', 'nucleus,'), ('nucleus,', 'releasing'), ('releasing', 'energy'), ('energy', 'in'), ('in', 'the'), ('the', 'process.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([3.1700e+03, 1.0200e+02, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.0200e+02, 7.0000e+00, 3.6000e+01, 1.0000e+00, 8.2000e+01, 5.5000e+01,\n",
            "        2.0000e+00, 1.0000e+00, 1.0000e+02, 5.0000e+00, 4.1000e+01, 5.5800e+02,\n",
            "        3.1700e+03, 1.0200e+02, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.0200e+02, 7.0000e+00, 3.6000e+01, 1.0000e+00, 8.2000e+01, 5.5000e+01,\n",
            "        2.0000e+00, 1.0000e+00, 1.0000e+02, 5.0000e+00, 4.1000e+01, 5.5800e+02])\n",
            "['Particle', 'physics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'studies', 'the', 'fundamental', 'particles', 'of', 'the', 'universe', 'and', 'their', 'interactions.', 'Particle', 'physics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'studies', 'the', 'fundamental', 'particles', 'of', 'the', 'universe', 'and', 'their', 'interactions.']\n",
            "[('Particle', 'physics'), ('physics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'fundamental'), ('fundamental', 'particles'), ('particles', 'of'), ('of', 'the'), ('the', 'universe'), ('universe', 'and'), ('and', 'their'), ('their', 'interactions.'), ('Particle', 'physics'), ('physics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'fundamental'), ('fundamental', 'particles'), ('particles', 'of'), ('of', 'the'), ('the', 'universe'), ('universe', 'and'), ('and', 'their'), ('their', 'interactions.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([9.0000e+00, 6.6800e+02, 6.6900e+02, 3.0000e+00, 4.0000e+00, 4.8000e+01,\n",
            "        7.0000e+00, 4.9000e+01, 1.0000e+00, 8.2000e+01, 5.5000e+01, 5.0000e+00,\n",
            "        5.9200e+02, 3.4850e+03, 1.2000e+01, 2.3110e+03, 7.0000e+00, 2.7600e+02,\n",
            "        2.4500e+02, 1.0000e+00, 1.6500e+02, 9.0000e+00, 6.6800e+02, 6.6900e+02,\n",
            "        3.0000e+00, 4.0000e+00, 4.8000e+01, 7.0000e+00, 4.9000e+01, 1.0000e+00,\n",
            "        8.2000e+01, 5.5000e+01, 5.0000e+00, 5.9200e+02, 3.4850e+03, 1.2000e+01,\n",
            "        2.3110e+03, 7.0000e+00, 2.7600e+02, 2.4500e+02, 1.0000e+00, 1.6500e+02])\n",
            "['The', 'Standard', 'Model', 'is', 'a', 'theory', 'that', 'describes', 'the', 'fundamental', 'particles', 'and', 'forces', '(except', 'for', 'gravity)', 'that', 'make', 'up', 'the', 'universe.', 'The', 'Standard', 'Model', 'is', 'a', 'theory', 'that', 'describes', 'the', 'fundamental', 'particles', 'and', 'forces', '(except', 'for', 'gravity)', 'that', 'make', 'up', 'the', 'universe.']\n",
            "[('The', 'Standard'), ('Standard', 'Model'), ('Model', 'is'), ('is', 'a'), ('a', 'theory'), ('theory', 'that'), ('that', 'describes'), ('describes', 'the'), ('the', 'fundamental'), ('fundamental', 'particles'), ('particles', 'and'), ('and', 'forces'), ('forces', '(except'), ('(except', 'for'), ('for', 'gravity)'), ('gravity)', 'that'), ('that', 'make'), ('make', 'up'), ('up', 'the'), ('the', 'universe.'), ('The', 'Standard'), ('Standard', 'Model'), ('Model', 'is'), ('is', 'a'), ('a', 'theory'), ('theory', 'that'), ('that', 'describes'), ('describes', 'the'), ('the', 'fundamental'), ('fundamental', 'particles'), ('particles', 'and'), ('and', 'forces'), ('forces', '(except'), ('(except', 'for'), ('for', 'gravity)'), ('gravity)', 'that'), ('that', 'make'), ('make', 'up'), ('up', 'the'), ('the', 'universe.')]\n",
            "44\n",
            "42\n",
            "946\n",
            "86\n",
            "tensor([9.0000e+00, 3.2850e+03, 2.8470e+03, 3.0000e+00, 4.0000e+00, 1.2900e+02,\n",
            "        1.7570e+03, 1.8000e+01, 1.0000e+00, 6.6800e+02, 6.6900e+02, 5.0000e+00,\n",
            "        2.9500e+02, 8.0000e+00, 3.4690e+03, 7.8800e+02, 1.2000e+01, 9.7400e+02,\n",
            "        9.0000e+01, 6.0000e+00, 5.8000e+01, 2.6600e+02, 9.0000e+00, 3.2850e+03,\n",
            "        2.8470e+03, 3.0000e+00, 4.0000e+00, 1.2900e+02, 1.7570e+03, 1.8000e+01,\n",
            "        1.0000e+00, 6.6800e+02, 6.6900e+02, 5.0000e+00, 2.9500e+02, 8.0000e+00,\n",
            "        3.4690e+03, 7.8800e+02, 1.2000e+01, 9.7400e+02, 9.0000e+01, 6.0000e+00,\n",
            "        5.8000e+01, 2.6600e+02])\n",
            "['The', 'Higgs', 'boson', 'is', 'a', 'particle', 'predicted', 'by', 'the', 'Standard', 'Model', 'and', 'discovered', 'in', '2012,', 'responsible', 'for', 'giving', 'mass', 'to', 'other', 'particles.', 'The', 'Higgs', 'boson', 'is', 'a', 'particle', 'predicted', 'by', 'the', 'Standard', 'Model', 'and', 'discovered', 'in', '2012,', 'responsible', 'for', 'giving', 'mass', 'to', 'other', 'particles.']\n",
            "[('The', 'Higgs'), ('Higgs', 'boson'), ('boson', 'is'), ('is', 'a'), ('a', 'particle'), ('particle', 'predicted'), ('predicted', 'by'), ('by', 'the'), ('the', 'Standard'), ('Standard', 'Model'), ('Model', 'and'), ('and', 'discovered'), ('discovered', 'in'), ('in', '2012,'), ('2012,', 'responsible'), ('responsible', 'for'), ('for', 'giving'), ('giving', 'mass'), ('mass', 'to'), ('to', 'other'), ('other', 'particles.'), ('The', 'Higgs'), ('Higgs', 'boson'), ('boson', 'is'), ('is', 'a'), ('a', 'particle'), ('particle', 'predicted'), ('predicted', 'by'), ('by', 'the'), ('the', 'Standard'), ('Standard', 'Model'), ('Model', 'and'), ('and', 'discovered'), ('discovered', 'in'), ('in', '2012,'), ('2012,', 'responsible'), ('responsible', 'for'), ('for', 'giving'), ('giving', 'mass'), ('mass', 'to'), ('to', 'other'), ('other', 'particles.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.3820e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 1.0000e+00,\n",
            "        1.8820e+03, 2.4690e+03, 5.0000e+00, 2.4740e+03, 2.4150e+03, 2.0000e+00,\n",
            "        1.0000e+00, 1.6500e+02, 3.3820e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01,\n",
            "        2.0000e+00, 1.0000e+00, 1.8820e+03, 2.4690e+03, 5.0000e+00, 2.4740e+03,\n",
            "        2.4150e+03, 2.0000e+00, 1.0000e+00, 1.6500e+02])\n",
            "['Cosmology', 'is', 'the', 'study', 'of', 'the', 'origin,', 'evolution,', 'and', 'eventual', 'fate', 'of', 'the', 'universe.', 'Cosmology', 'is', 'the', 'study', 'of', 'the', 'origin,', 'evolution,', 'and', 'eventual', 'fate', 'of', 'the', 'universe.']\n",
            "[('Cosmology', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'origin,'), ('origin,', 'evolution,'), ('evolution,', 'and'), ('and', 'eventual'), ('eventual', 'fate'), ('fate', 'of'), ('of', 'the'), ('the', 'universe.'), ('Cosmology', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'origin,'), ('origin,', 'evolution,'), ('evolution,', 'and'), ('and', 'eventual'), ('eventual', 'fate'), ('fate', 'of'), ('of', 'the'), ('the', 'universe.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([9.0000e+00, 3.4230e+03, 3.4280e+03, 4.8000e+01, 3.0000e+00, 1.0000e+00,\n",
            "        1.7470e+03, 2.6810e+03, 2.1700e+02, 2.4470e+03, 1.0000e+00, 6.1200e+02,\n",
            "        1.5200e+02, 2.0000e+00, 1.0000e+00, 1.6500e+02, 9.0000e+00, 3.4230e+03,\n",
            "        3.4280e+03, 4.8000e+01, 3.0000e+00, 1.0000e+00, 1.7470e+03, 2.6810e+03,\n",
            "        2.1700e+02, 2.4470e+03, 1.0000e+00, 6.1200e+02, 1.5200e+02, 2.0000e+00,\n",
            "        1.0000e+00, 1.6500e+02])\n",
            "['The', 'Big', 'Bang', 'theory', 'is', 'the', 'prevailing', 'cosmological', 'model', 'explaining', 'the', 'early', 'development', 'of', 'the', 'universe.', 'The', 'Big', 'Bang', 'theory', 'is', 'the', 'prevailing', 'cosmological', 'model', 'explaining', 'the', 'early', 'development', 'of', 'the', 'universe.']\n",
            "[('The', 'Big'), ('Big', 'Bang'), ('Bang', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'prevailing'), ('prevailing', 'cosmological'), ('cosmological', 'model'), ('model', 'explaining'), ('explaining', 'the'), ('the', 'early'), ('early', 'development'), ('development', 'of'), ('of', 'the'), ('the', 'universe.'), ('The', 'Big'), ('Big', 'Bang'), ('Bang', 'theory'), ('theory', 'is'), ('is', 'the'), ('the', 'prevailing'), ('prevailing', 'cosmological'), ('cosmological', 'model'), ('model', 'explaining'), ('explaining', 'the'), ('the', 'early'), ('early', 'development'), ('development', 'of'), ('of', 'the'), ('the', 'universe.')]\n",
            "56\n",
            "54\n",
            "1540\n",
            "110\n",
            "tensor([1.2010e+03, 2.7400e+02, 3.0000e+00, 4.0000e+00, 9.4000e+01, 2.0000e+00,\n",
            "        2.7400e+02, 7.0000e+00, 2.9300e+02, 6.7000e+01, 2.5130e+03, 3.0170e+03,\n",
            "        1.0000e+01, 1.6420e+03, 1.0500e+02, 5.0000e+00, 3.0000e+00, 7.2300e+02,\n",
            "        6.0000e+00, 2.7600e+02, 2.4500e+02, 1.2100e+02, 2.0000e+00, 1.0000e+00,\n",
            "        9.0000e+01, 8.0000e+00, 1.0000e+00, 1.6500e+02, 1.2010e+03, 2.7400e+02,\n",
            "        3.0000e+00, 4.0000e+00, 9.4000e+01, 2.0000e+00, 2.7400e+02, 7.0000e+00,\n",
            "        2.9300e+02, 6.7000e+01, 2.5130e+03, 3.0170e+03, 1.0000e+01, 1.6420e+03,\n",
            "        1.0500e+02, 5.0000e+00, 3.0000e+00, 7.2300e+02, 6.0000e+00, 2.7600e+02,\n",
            "        2.4500e+02, 1.2100e+02, 2.0000e+00, 1.0000e+00, 9.0000e+01, 8.0000e+00,\n",
            "        1.0000e+00, 1.6500e+02])\n",
            "['Dark', 'matter', 'is', 'a', 'form', 'of', 'matter', 'that', 'does', 'not', 'emit,', 'absorb,', 'or', 'reflect', 'light', 'and', 'is', 'thought', 'to', 'make', 'up', 'most', 'of', 'the', 'mass', 'in', 'the', 'universe.', 'Dark', 'matter', 'is', 'a', 'form', 'of', 'matter', 'that', 'does', 'not', 'emit,', 'absorb,', 'or', 'reflect', 'light', 'and', 'is', 'thought', 'to', 'make', 'up', 'most', 'of', 'the', 'mass', 'in', 'the', 'universe.']\n",
            "[('Dark', 'matter'), ('matter', 'is'), ('is', 'a'), ('a', 'form'), ('form', 'of'), ('of', 'matter'), ('matter', 'that'), ('that', 'does'), ('does', 'not'), ('not', 'emit,'), ('emit,', 'absorb,'), ('absorb,', 'or'), ('or', 'reflect'), ('reflect', 'light'), ('light', 'and'), ('and', 'is'), ('is', 'thought'), ('thought', 'to'), ('to', 'make'), ('make', 'up'), ('up', 'most'), ('most', 'of'), ('of', 'the'), ('the', 'mass'), ('mass', 'in'), ('in', 'the'), ('the', 'universe.'), ('Dark', 'matter'), ('matter', 'is'), ('is', 'a'), ('a', 'form'), ('form', 'of'), ('of', 'matter'), ('matter', 'that'), ('that', 'does'), ('does', 'not'), ('not', 'emit,'), ('emit,', 'absorb,'), ('absorb,', 'or'), ('or', 'reflect'), ('reflect', 'light'), ('light', 'and'), ('and', 'is'), ('is', 'thought'), ('thought', 'to'), ('to', 'make'), ('make', 'up'), ('up', 'most'), ('most', 'of'), ('of', 'the'), ('the', 'mass'), ('mass', 'in'), ('in', 'the'), ('the', 'universe.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([1.2010e+03, 8.3000e+01, 3.0000e+00, 4.0000e+00, 8.8000e+02, 9.4000e+01,\n",
            "        2.0000e+00, 8.3000e+01, 7.0000e+00, 3.0000e+00, 1.1030e+03, 1.0000e+00,\n",
            "        3.0160e+03, 1.0080e+03, 2.0000e+00, 1.0000e+00, 1.6500e+02, 1.2010e+03,\n",
            "        8.3000e+01, 3.0000e+00, 4.0000e+00, 8.8000e+02, 9.4000e+01, 2.0000e+00,\n",
            "        8.3000e+01, 7.0000e+00, 3.0000e+00, 1.1030e+03, 1.0000e+00, 3.0160e+03,\n",
            "        1.0080e+03, 2.0000e+00, 1.0000e+00, 1.6500e+02])\n",
            "['Dark', 'energy', 'is', 'a', 'mysterious', 'form', 'of', 'energy', 'that', 'is', 'causing', 'the', 'accelerated', 'expansion', 'of', 'the', 'universe.', 'Dark', 'energy', 'is', 'a', 'mysterious', 'form', 'of', 'energy', 'that', 'is', 'causing', 'the', 'accelerated', 'expansion', 'of', 'the', 'universe.']\n",
            "[('Dark', 'energy'), ('energy', 'is'), ('is', 'a'), ('a', 'mysterious'), ('mysterious', 'form'), ('form', 'of'), ('of', 'energy'), ('energy', 'that'), ('that', 'is'), ('is', 'causing'), ('causing', 'the'), ('the', 'accelerated'), ('accelerated', 'expansion'), ('expansion', 'of'), ('of', 'the'), ('the', 'universe.'), ('Dark', 'energy'), ('energy', 'is'), ('is', 'a'), ('a', 'mysterious'), ('mysterious', 'form'), ('form', 'of'), ('of', 'energy'), ('energy', 'that'), ('that', 'is'), ('is', 'causing'), ('causing', 'the'), ('the', 'accelerated'), ('accelerated', 'expansion'), ('expansion', 'of'), ('of', 'the'), ('the', 'universe.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([3.0860e+03, 4.8000e+01, 3.0000e+00, 4.0000e+00, 4.6200e+02, 2.3600e+03,\n",
            "        7.0000e+00, 2.9080e+03, 6.0000e+00, 1.6580e+03, 1.7000e+01, 8.9000e+01,\n",
            "        5.0000e+00, 3.9300e+02, 7.9400e+02, 1.8000e+01, 1.7710e+03, 7.0000e+00,\n",
            "        8.2000e+01, 5.5000e+01, 1.3000e+01, 1.9010e+03, 1.4640e+03, 3.0860e+03,\n",
            "        4.8000e+01, 3.0000e+00, 4.0000e+00, 4.6200e+02, 2.3600e+03, 7.0000e+00,\n",
            "        2.9080e+03, 6.0000e+00, 1.6580e+03, 1.7000e+01, 8.9000e+01, 5.0000e+00,\n",
            "        3.9300e+02, 7.9400e+02, 1.8000e+01, 1.7710e+03, 7.0000e+00, 8.2000e+01,\n",
            "        5.5000e+01, 1.3000e+01, 1.9010e+03, 1.4640e+03])\n",
            "['String', 'theory', 'is', 'a', 'theoretical', 'framework', 'that', 'attempts', 'to', 'reconcile', 'quantum', 'mechanics', 'and', 'general', 'relativity', 'by', 'positing', 'that', 'fundamental', 'particles', 'are', 'one-dimensional', 'strings.', 'String', 'theory', 'is', 'a', 'theoretical', 'framework', 'that', 'attempts', 'to', 'reconcile', 'quantum', 'mechanics', 'and', 'general', 'relativity', 'by', 'positing', 'that', 'fundamental', 'particles', 'are', 'one-dimensional', 'strings.']\n",
            "[('String', 'theory'), ('theory', 'is'), ('is', 'a'), ('a', 'theoretical'), ('theoretical', 'framework'), ('framework', 'that'), ('that', 'attempts'), ('attempts', 'to'), ('to', 'reconcile'), ('reconcile', 'quantum'), ('quantum', 'mechanics'), ('mechanics', 'and'), ('and', 'general'), ('general', 'relativity'), ('relativity', 'by'), ('by', 'positing'), ('positing', 'that'), ('that', 'fundamental'), ('fundamental', 'particles'), ('particles', 'are'), ('are', 'one-dimensional'), ('one-dimensional', 'strings.'), ('String', 'theory'), ('theory', 'is'), ('is', 'a'), ('a', 'theoretical'), ('theoretical', 'framework'), ('framework', 'that'), ('that', 'attempts'), ('attempts', 'to'), ('to', 'reconcile'), ('reconcile', 'quantum'), ('quantum', 'mechanics'), ('mechanics', 'and'), ('and', 'general'), ('general', 'relativity'), ('relativity', 'by'), ('by', 'positing'), ('positing', 'that'), ('that', 'fundamental'), ('fundamental', 'particles'), ('particles', 'are'), ('are', 'one-dimensional'), ('one-dimensional', 'strings.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.0820e+03, 3.0000e+00, 4.0000e+00, 4.6200e+02, 1.5400e+02, 7.0000e+00,\n",
            "        1.7130e+03, 4.0000e+00, 7.4200e+02, 3.5000e+01, 9.9500e+02, 5.0000e+00,\n",
            "        2.8460e+03, 3.0820e+03, 3.0000e+00, 4.0000e+00, 4.6200e+02, 1.5400e+02,\n",
            "        7.0000e+00, 1.7130e+03, 4.0000e+00, 7.4200e+02, 3.5000e+01, 9.9500e+02,\n",
            "        5.0000e+00, 2.8460e+03])\n",
            "['Supersymmetry', 'is', 'a', 'theoretical', 'concept', 'that', 'proposes', 'a', 'symmetry', 'between', 'fermions', 'and', 'bosons.', 'Supersymmetry', 'is', 'a', 'theoretical', 'concept', 'that', 'proposes', 'a', 'symmetry', 'between', 'fermions', 'and', 'bosons.']\n",
            "[('Supersymmetry', 'is'), ('is', 'a'), ('a', 'theoretical'), ('theoretical', 'concept'), ('concept', 'that'), ('that', 'proposes'), ('proposes', 'a'), ('a', 'symmetry'), ('symmetry', 'between'), ('between', 'fermions'), ('fermions', 'and'), ('and', 'bosons.'), ('Supersymmetry', 'is'), ('is', 'a'), ('a', 'theoretical'), ('theoretical', 'concept'), ('concept', 'that'), ('that', 'proposes'), ('proposes', 'a'), ('a', 'symmetry'), ('symmetry', 'between'), ('between', 'fermions'), ('fermions', 'and'), ('and', 'bosons.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([9.0000e+00, 1.9740e+03, 9.5500e+02, 2.5300e+02, 7.0000e+00, 8.8000e+01,\n",
            "        1.0000e+02, 3.0000e+00, 3.8300e+02, 3.7000e+01, 2.0000e+00, 2.1800e+02,\n",
            "        1.3220e+03, 7.0000e+00, 2.4580e+03, 9.0000e+00, 1.9740e+03, 9.5500e+02,\n",
            "        2.5300e+02, 7.0000e+00, 8.8000e+01, 1.0000e+02, 3.0000e+00, 3.8300e+02,\n",
            "        3.7000e+01, 2.0000e+00, 2.1800e+02, 1.3220e+03, 7.0000e+00, 2.4580e+03])\n",
            "['The', 'multiverse', 'hypothesis', 'suggests', 'that', 'our', 'universe', 'is', 'just', 'one', 'of', 'many', 'universes', 'that', 'exist.', 'The', 'multiverse', 'hypothesis', 'suggests', 'that', 'our', 'universe', 'is', 'just', 'one', 'of', 'many', 'universes', 'that', 'exist.']\n",
            "[('The', 'multiverse'), ('multiverse', 'hypothesis'), ('hypothesis', 'suggests'), ('suggests', 'that'), ('that', 'our'), ('our', 'universe'), ('universe', 'is'), ('is', 'just'), ('just', 'one'), ('one', 'of'), ('of', 'many'), ('many', 'universes'), ('universes', 'that'), ('that', 'exist.'), ('The', 'multiverse'), ('multiverse', 'hypothesis'), ('hypothesis', 'suggests'), ('suggests', 'that'), ('that', 'our'), ('our', 'universe'), ('universe', 'is'), ('is', 'just'), ('just', 'one'), ('one', 'of'), ('of', 'many'), ('many', 'universes'), ('universes', 'that'), ('that', 'exist.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([1.2060e+03, 4.8000e+01, 3.6000e+01, 1.0000e+00, 1.2400e+02, 2.0000e+00,\n",
            "        1.0410e+03, 1.6900e+02, 7.0000e+00, 1.3000e+01, 5.7000e+02, 7.7700e+02,\n",
            "        6.0000e+00, 5.5900e+02, 6.3300e+02, 5.3000e+01, 9.1900e+02, 6.0000e+00,\n",
            "        1.5590e+03, 5.0700e+02, 1.1200e+03, 1.2060e+03, 4.8000e+01, 3.6000e+01,\n",
            "        1.0000e+00, 1.2400e+02, 2.0000e+00, 1.0410e+03, 1.6900e+02, 7.0000e+00,\n",
            "        1.3000e+01, 5.7000e+02, 7.7700e+02, 6.0000e+00, 5.5900e+02, 6.3300e+02,\n",
            "        5.3000e+01, 9.1900e+02, 6.0000e+00, 1.5590e+03, 5.0700e+02, 1.1200e+03])\n",
            "['Chaos', 'theory', 'studies', 'the', 'behavior', 'of', 'dynamical', 'systems', 'that', 'are', 'highly', 'sensitive', 'to', 'initial', 'conditions,', 'often', 'leading', 'to', 'seemingly', 'random', 'behavior.', 'Chaos', 'theory', 'studies', 'the', 'behavior', 'of', 'dynamical', 'systems', 'that', 'are', 'highly', 'sensitive', 'to', 'initial', 'conditions,', 'often', 'leading', 'to', 'seemingly', 'random', 'behavior.']\n",
            "[('Chaos', 'theory'), ('theory', 'studies'), ('studies', 'the'), ('the', 'behavior'), ('behavior', 'of'), ('of', 'dynamical'), ('dynamical', 'systems'), ('systems', 'that'), ('that', 'are'), ('are', 'highly'), ('highly', 'sensitive'), ('sensitive', 'to'), ('to', 'initial'), ('initial', 'conditions,'), ('conditions,', 'often'), ('often', 'leading'), ('leading', 'to'), ('to', 'seemingly'), ('seemingly', 'random'), ('random', 'behavior.'), ('Chaos', 'theory'), ('theory', 'studies'), ('studies', 'the'), ('the', 'behavior'), ('behavior', 'of'), ('of', 'dynamical'), ('dynamical', 'systems'), ('systems', 'that'), ('that', 'are'), ('are', 'highly'), ('highly', 'sensitive'), ('sensitive', 'to'), ('to', 'initial'), ('initial', 'conditions,'), ('conditions,', 'often'), ('often', 'leading'), ('leading', 'to'), ('to', 'seemingly'), ('seemingly', 'random'), ('random', 'behavior.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([1.1000e+01, 1.8120e+03, 1.3590e+03, 3.0000e+00, 4.0000e+00, 8.5000e+01,\n",
            "        8.0000e+00, 1.0000e+00, 1.1600e+02, 2.0000e+00, 5.4000e+02, 4.0000e+01,\n",
            "        1.4000e+01, 2.4000e+01, 1.5170e+03, 6.0000e+00, 2.0910e+03, 5.5600e+02,\n",
            "        1.0000e+00, 1.6300e+03, 1.0000e+01, 1.1530e+03, 2.0000e+00, 1.5100e+02,\n",
            "        1.1000e+01, 1.8120e+03, 1.3590e+03, 3.0000e+00, 4.0000e+00, 8.5000e+01,\n",
            "        8.0000e+00, 1.0000e+00, 1.1600e+02, 2.0000e+00, 5.4000e+02, 4.0000e+01,\n",
            "        1.4000e+01, 2.4000e+01, 1.5170e+03, 6.0000e+00, 2.0910e+03, 5.5600e+02,\n",
            "        1.0000e+00, 1.6300e+03, 1.0000e+01, 1.1530e+03, 2.0000e+00, 1.5100e+02])\n",
            "['A', 'phase', 'transition', 'is', 'a', 'change', 'in', 'the', 'state', 'of', 'matter,', 'such', 'as', 'from', 'solid', 'to', 'liquid,', 'involving', 'the', 'release', 'or', 'absorption', 'of', 'energy.', 'A', 'phase', 'transition', 'is', 'a', 'change', 'in', 'the', 'state', 'of', 'matter,', 'such', 'as', 'from', 'solid', 'to', 'liquid,', 'involving', 'the', 'release', 'or', 'absorption', 'of', 'energy.']\n",
            "[('A', 'phase'), ('phase', 'transition'), ('transition', 'is'), ('is', 'a'), ('a', 'change'), ('change', 'in'), ('in', 'the'), ('the', 'state'), ('state', 'of'), ('of', 'matter,'), ('matter,', 'such'), ('such', 'as'), ('as', 'from'), ('from', 'solid'), ('solid', 'to'), ('to', 'liquid,'), ('liquid,', 'involving'), ('involving', 'the'), ('the', 'release'), ('release', 'or'), ('or', 'absorption'), ('absorption', 'of'), ('of', 'energy.'), ('A', 'phase'), ('phase', 'transition'), ('transition', 'is'), ('is', 'a'), ('a', 'change'), ('change', 'in'), ('in', 'the'), ('the', 'state'), ('state', 'of'), ('of', 'matter,'), ('matter,', 'such'), ('such', 'as'), ('as', 'from'), ('from', 'solid'), ('solid', 'to'), ('to', 'liquid,'), ('liquid,', 'involving'), ('involving', 'the'), ('the', 'release'), ('release', 'or'), ('or', 'absorption'), ('absorption', 'of'), ('of', 'energy.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.0830e+03, 3.0000e+00, 4.0000e+00, 2.6500e+02, 9.9000e+01, 4.0000e+00,\n",
            "        2.7500e+02, 1.0100e+03, 1.2200e+03, 6.1100e+02, 1.6120e+03, 4.2100e+02,\n",
            "        4.0000e+00, 4.1300e+02, 1.4140e+03, 3.0830e+03, 3.0000e+00, 4.0000e+00,\n",
            "        2.6500e+02, 9.9000e+01, 4.0000e+00, 2.7500e+02, 1.0100e+03, 1.2200e+03,\n",
            "        6.1100e+02, 1.6120e+03, 4.2100e+02, 4.0000e+00, 4.1300e+02, 1.4140e+03])\n",
            "['Superconductivity', 'is', 'a', 'phenomenon', 'where', 'a', 'material', 'exhibits', 'zero', 'electrical', 'resistance', 'below', 'a', 'certain', 'temperature.', 'Superconductivity', 'is', 'a', 'phenomenon', 'where', 'a', 'material', 'exhibits', 'zero', 'electrical', 'resistance', 'below', 'a', 'certain', 'temperature.']\n",
            "[('Superconductivity', 'is'), ('is', 'a'), ('a', 'phenomenon'), ('phenomenon', 'where'), ('where', 'a'), ('a', 'material'), ('material', 'exhibits'), ('exhibits', 'zero'), ('zero', 'electrical'), ('electrical', 'resistance'), ('resistance', 'below'), ('below', 'a'), ('a', 'certain'), ('certain', 'temperature.'), ('Superconductivity', 'is'), ('is', 'a'), ('a', 'phenomenon'), ('phenomenon', 'where'), ('where', 'a'), ('a', 'material'), ('material', 'exhibits'), ('exhibits', 'zero'), ('zero', 'electrical'), ('electrical', 'resistance'), ('resistance', 'below'), ('below', 'a'), ('a', 'certain'), ('certain', 'temperature.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([9.0000e+00, 3.3530e+03, 1.8900e+02, 3.0000e+00, 1.0000e+00, 8.5000e+01,\n",
            "        8.0000e+00, 3.9400e+02, 1.0000e+01, 1.2680e+03, 2.0000e+00, 4.0000e+00,\n",
            "        1.3700e+02, 8.0000e+00, 5.0200e+02, 6.0000e+00, 2.1000e+01, 3.7000e+02,\n",
            "        8.8500e+02, 5.0100e+02, 6.0000e+00, 1.0000e+00, 1.3700e+02, 1.5070e+03,\n",
            "        9.0000e+00, 3.3530e+03, 1.8900e+02, 3.0000e+00, 1.0000e+00, 8.5000e+01,\n",
            "        8.0000e+00, 3.9400e+02, 1.0000e+01, 1.2680e+03, 2.0000e+00, 4.0000e+00,\n",
            "        1.3700e+02, 8.0000e+00, 5.0200e+02, 6.0000e+00, 2.1000e+01, 3.7000e+02,\n",
            "        8.8500e+02, 5.0100e+02, 6.0000e+00, 1.0000e+00, 1.3700e+02, 1.5070e+03])\n",
            "['The', 'Doppler', 'effect', 'is', 'the', 'change', 'in', 'frequency', 'or', 'wavelength', 'of', 'a', 'wave', 'in', 'relation', 'to', 'an', 'observer', 'moving', 'relative', 'to', 'the', 'wave', 'source.', 'The', 'Doppler', 'effect', 'is', 'the', 'change', 'in', 'frequency', 'or', 'wavelength', 'of', 'a', 'wave', 'in', 'relation', 'to', 'an', 'observer', 'moving', 'relative', 'to', 'the', 'wave', 'source.']\n",
            "[('The', 'Doppler'), ('Doppler', 'effect'), ('effect', 'is'), ('is', 'the'), ('the', 'change'), ('change', 'in'), ('in', 'frequency'), ('frequency', 'or'), ('or', 'wavelength'), ('wavelength', 'of'), ('of', 'a'), ('a', 'wave'), ('wave', 'in'), ('in', 'relation'), ('relation', 'to'), ('to', 'an'), ('an', 'observer'), ('observer', 'moving'), ('moving', 'relative'), ('relative', 'to'), ('to', 'the'), ('the', 'wave'), ('wave', 'source.'), ('The', 'Doppler'), ('Doppler', 'effect'), ('effect', 'is'), ('is', 'the'), ('the', 'change'), ('change', 'in'), ('in', 'frequency'), ('frequency', 'or'), ('or', 'wavelength'), ('wavelength', 'of'), ('of', 'a'), ('a', 'wave'), ('wave', 'in'), ('in', 'relation'), ('relation', 'to'), ('to', 'an'), ('an', 'observer'), ('observer', 'moving'), ('moving', 'relative'), ('relative', 'to'), ('to', 'the'), ('the', 'wave'), ('wave', 'source.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3120.,  142.,  125.,    4.,   26., 1877.,   71.,   43.,  181.,  394.,\n",
            "         405.,    6.,   21.,  186.,  520.,  398., 3120.,  142.,  125.,    4.,\n",
            "          26., 1877.,   71.,   43.,  181.,  394.,  405.,    6.,   21.,  186.,\n",
            "         520.,  398.])\n",
            "['Resonance', 'occurs', 'when', 'a', 'system', 'oscillates', 'at', 'its', 'natural', 'frequency', 'due', 'to', 'an', 'external', 'periodic', 'force.', 'Resonance', 'occurs', 'when', 'a', 'system', 'oscillates', 'at', 'its', 'natural', 'frequency', 'due', 'to', 'an', 'external', 'periodic', 'force.']\n",
            "[('Resonance', 'occurs'), ('occurs', 'when'), ('when', 'a'), ('a', 'system'), ('system', 'oscillates'), ('oscillates', 'at'), ('at', 'its'), ('its', 'natural'), ('natural', 'frequency'), ('frequency', 'due'), ('due', 'to'), ('to', 'an'), ('an', 'external'), ('external', 'periodic'), ('periodic', 'force.'), ('Resonance', 'occurs'), ('occurs', 'when'), ('when', 'a'), ('a', 'system'), ('system', 'oscillates'), ('oscillates', 'at'), ('at', 'its'), ('its', 'natural'), ('natural', 'frequency'), ('frequency', 'due'), ('due', 'to'), ('to', 'an'), ('an', 'external'), ('external', 'periodic'), ('periodic', 'force.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([3.1790e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0200e+02,\n",
            "        7.0000e+00, 3.6000e+01, 1.0000e+00, 1.2400e+02, 5.0000e+00, 1.4000e+02,\n",
            "        2.0000e+00, 1.0500e+02, 5.0000e+00, 4.3000e+01, 2.2300e+02, 1.9000e+01,\n",
            "        2.7300e+02, 3.1790e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.0200e+02, 7.0000e+00, 3.6000e+01, 1.0000e+00, 1.2400e+02, 5.0000e+00,\n",
            "        1.4000e+02, 2.0000e+00, 1.0500e+02, 5.0000e+00, 4.3000e+01, 2.2300e+02,\n",
            "        1.9000e+01, 2.7300e+02])\n",
            "['Optics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'studies', 'the', 'behavior', 'and', 'properties', 'of', 'light', 'and', 'its', 'interactions', 'with', 'matter.', 'Optics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'studies', 'the', 'behavior', 'and', 'properties', 'of', 'light', 'and', 'its', 'interactions', 'with', 'matter.']\n",
            "[('Optics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'behavior'), ('behavior', 'and'), ('and', 'properties'), ('properties', 'of'), ('of', 'light'), ('light', 'and'), ('and', 'its'), ('its', 'interactions'), ('interactions', 'with'), ('with', 'matter.'), ('Optics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'behavior'), ('behavior', 'and'), ('and', 'properties'), ('properties', 'of'), ('of', 'light'), ('light', 'and'), ('and', 'its'), ('its', 'interactions'), ('interactions', 'with'), ('with', 'matter.')]\n",
            "56\n",
            "54\n",
            "1540\n",
            "110\n",
            "tensor([3.1240e+03, 3.0000e+00, 1.0000e+00, 8.5000e+01, 8.0000e+00, 2.9600e+02,\n",
            "        2.0000e+00, 4.0000e+00, 6.9800e+02, 7.1000e+01, 2.1000e+01, 2.1690e+03,\n",
            "        3.5000e+01, 3.9000e+01, 8.4000e+01, 2.0210e+03, 1.1030e+03, 1.0000e+00,\n",
            "        6.9800e+02, 6.0000e+00, 1.5990e+03, 6.9000e+01, 1.0000e+00, 8.9100e+02,\n",
            "        2.4000e+01, 2.2000e+01, 4.4000e+01, 1.8790e+03, 3.1240e+03, 3.0000e+00,\n",
            "        1.0000e+00, 8.5000e+01, 8.0000e+00, 2.9600e+02, 2.0000e+00, 4.0000e+00,\n",
            "        6.9800e+02, 7.1000e+01, 2.1000e+01, 2.1690e+03, 3.5000e+01, 3.9000e+01,\n",
            "        8.4000e+01, 2.0210e+03, 1.1030e+03, 1.0000e+00, 6.9800e+02, 6.0000e+00,\n",
            "        1.5990e+03, 6.9000e+01, 1.0000e+00, 8.9100e+02, 2.4000e+01, 2.2000e+01,\n",
            "        4.4000e+01, 1.8790e+03])\n",
            "['Reflection', 'is', 'the', 'change', 'in', 'direction', 'of', 'a', 'wavefront', 'at', 'an', 'interface', 'between', 'two', 'different', 'media,', 'causing', 'the', 'wavefront', 'to', 'return', 'into', 'the', 'medium', 'from', 'which', 'it', 'originated.', 'Reflection', 'is', 'the', 'change', 'in', 'direction', 'of', 'a', 'wavefront', 'at', 'an', 'interface', 'between', 'two', 'different', 'media,', 'causing', 'the', 'wavefront', 'to', 'return', 'into', 'the', 'medium', 'from', 'which', 'it', 'originated.']\n",
            "[('Reflection', 'is'), ('is', 'the'), ('the', 'change'), ('change', 'in'), ('in', 'direction'), ('direction', 'of'), ('of', 'a'), ('a', 'wavefront'), ('wavefront', 'at'), ('at', 'an'), ('an', 'interface'), ('interface', 'between'), ('between', 'two'), ('two', 'different'), ('different', 'media,'), ('media,', 'causing'), ('causing', 'the'), ('the', 'wavefront'), ('wavefront', 'to'), ('to', 'return'), ('return', 'into'), ('into', 'the'), ('the', 'medium'), ('medium', 'from'), ('from', 'which'), ('which', 'it'), ('it', 'originated.'), ('Reflection', 'is'), ('is', 'the'), ('the', 'change'), ('change', 'in'), ('in', 'direction'), ('direction', 'of'), ('of', 'a'), ('a', 'wavefront'), ('wavefront', 'at'), ('at', 'an'), ('an', 'interface'), ('interface', 'between'), ('between', 'two'), ('two', 'different'), ('different', 'media,'), ('media,', 'causing'), ('causing', 'the'), ('the', 'wavefront'), ('wavefront', 'to'), ('to', 'return'), ('return', 'into'), ('into', 'the'), ('the', 'medium'), ('medium', 'from'), ('from', 'which'), ('which', 'it'), ('it', 'originated.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([3.1230e+03, 3.0000e+00, 1.0000e+00, 8.5000e+01, 8.0000e+00, 2.9600e+02,\n",
            "        2.0000e+00, 4.0000e+00, 1.3700e+02, 1.8450e+03, 2.4000e+01, 3.7000e+01,\n",
            "        8.9100e+02, 6.0000e+00, 1.3500e+02, 4.1500e+02, 1.8000e+01, 4.3000e+01,\n",
            "        8.5000e+01, 8.0000e+00, 1.4930e+03, 3.1230e+03, 3.0000e+00, 1.0000e+00,\n",
            "        8.5000e+01, 8.0000e+00, 2.9600e+02, 2.0000e+00, 4.0000e+00, 1.3700e+02,\n",
            "        1.8450e+03, 2.4000e+01, 3.7000e+01, 8.9100e+02, 6.0000e+00, 1.3500e+02,\n",
            "        4.1500e+02, 1.8000e+01, 4.3000e+01, 8.5000e+01, 8.0000e+00, 1.4930e+03])\n",
            "['Refraction', 'is', 'the', 'change', 'in', 'direction', 'of', 'a', 'wave', 'passing', 'from', 'one', 'medium', 'to', 'another', 'caused', 'by', 'its', 'change', 'in', 'speed.', 'Refraction', 'is', 'the', 'change', 'in', 'direction', 'of', 'a', 'wave', 'passing', 'from', 'one', 'medium', 'to', 'another', 'caused', 'by', 'its', 'change', 'in', 'speed.']\n",
            "[('Refraction', 'is'), ('is', 'the'), ('the', 'change'), ('change', 'in'), ('in', 'direction'), ('direction', 'of'), ('of', 'a'), ('a', 'wave'), ('wave', 'passing'), ('passing', 'from'), ('from', 'one'), ('one', 'medium'), ('medium', 'to'), ('to', 'another'), ('another', 'caused'), ('caused', 'by'), ('by', 'its'), ('its', 'change'), ('change', 'in'), ('in', 'speed.'), ('Refraction', 'is'), ('is', 'the'), ('the', 'change'), ('change', 'in'), ('in', 'direction'), ('direction', 'of'), ('of', 'a'), ('a', 'wave'), ('wave', 'passing'), ('passing', 'from'), ('from', 'one'), ('one', 'medium'), ('medium', 'to'), ('to', 'another'), ('another', 'caused'), ('caused', 'by'), ('by', 'its'), ('its', 'change'), ('change', 'in'), ('in', 'speed.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([3.3610e+03, 3.0000e+00, 1.0000e+00, 2.8690e+03, 2.0000e+00, 3.1700e+02,\n",
            "        4.2500e+02, 1.9110e+03, 5.0000e+00, 1.8950e+03, 2.2000e+01, 1.4200e+02,\n",
            "        1.9000e+01, 5.1000e+01, 1.3370e+03, 2.0000e+00, 1.2670e+03, 1.4700e+02,\n",
            "        1.0500e+02, 5.0000e+00, 7.6000e+02, 3.3610e+03, 3.0000e+00, 1.0000e+00,\n",
            "        2.8690e+03, 2.0000e+00, 3.1700e+02, 4.2500e+02, 1.9110e+03, 5.0000e+00,\n",
            "        1.8950e+03, 2.2000e+01, 1.4200e+02, 1.9000e+01, 5.1000e+01, 1.3370e+03,\n",
            "        2.0000e+00, 1.2670e+03, 1.4700e+02, 1.0500e+02, 5.0000e+00, 7.6000e+02])\n",
            "['Diffraction', 'is', 'the', 'bending', 'of', 'waves', 'around', 'obstacles', 'and', 'openings,', 'which', 'occurs', 'with', 'all', 'types', 'of', 'waves,', 'including', 'light', 'and', 'sound.', 'Diffraction', 'is', 'the', 'bending', 'of', 'waves', 'around', 'obstacles', 'and', 'openings,', 'which', 'occurs', 'with', 'all', 'types', 'of', 'waves,', 'including', 'light', 'and', 'sound.']\n",
            "[('Diffraction', 'is'), ('is', 'the'), ('the', 'bending'), ('bending', 'of'), ('of', 'waves'), ('waves', 'around'), ('around', 'obstacles'), ('obstacles', 'and'), ('and', 'openings,'), ('openings,', 'which'), ('which', 'occurs'), ('occurs', 'with'), ('with', 'all'), ('all', 'types'), ('types', 'of'), ('of', 'waves,'), ('waves,', 'including'), ('including', 'light'), ('light', 'and'), ('and', 'sound.'), ('Diffraction', 'is'), ('is', 'the'), ('the', 'bending'), ('bending', 'of'), ('of', 'waves'), ('waves', 'around'), ('around', 'obstacles'), ('obstacles', 'and'), ('and', 'openings,'), ('openings,', 'which'), ('which', 'occurs'), ('occurs', 'with'), ('with', 'all'), ('all', 'types'), ('types', 'of'), ('of', 'waves,'), ('waves,', 'including'), ('including', 'light'), ('light', 'and'), ('and', 'sound.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([3.2650e+03, 3.0000e+00, 1.0000e+00, 2.6500e+02, 7.0000e+00, 1.4200e+02,\n",
            "        1.2500e+02, 3.9000e+01, 1.0000e+01, 6.0000e+01, 3.1700e+02, 1.4480e+03,\n",
            "        6.0000e+00, 9.4000e+01, 4.0000e+00, 1.6020e+03, 1.3700e+02, 2.0000e+00,\n",
            "        2.3090e+03, 2.0660e+03, 1.0000e+01, 1.0000e+00, 1.7300e+02, 2.9550e+03,\n",
            "        3.2650e+03, 3.0000e+00, 1.0000e+00, 2.6500e+02, 7.0000e+00, 1.4200e+02,\n",
            "        1.2500e+02, 3.9000e+01, 1.0000e+01, 6.0000e+01, 3.1700e+02, 1.4480e+03,\n",
            "        6.0000e+00, 9.4000e+01, 4.0000e+00, 1.6020e+03, 1.3700e+02, 2.0000e+00,\n",
            "        2.3090e+03, 2.0660e+03, 1.0000e+01, 1.0000e+00, 1.7300e+02, 2.9550e+03])\n",
            "['Interference', 'is', 'the', 'phenomenon', 'that', 'occurs', 'when', 'two', 'or', 'more', 'waves', 'superpose', 'to', 'form', 'a', 'resultant', 'wave', 'of', 'greater,', 'lower,', 'or', 'the', 'same', 'amplitude.', 'Interference', 'is', 'the', 'phenomenon', 'that', 'occurs', 'when', 'two', 'or', 'more', 'waves', 'superpose', 'to', 'form', 'a', 'resultant', 'wave', 'of', 'greater,', 'lower,', 'or', 'the', 'same', 'amplitude.']\n",
            "[('Interference', 'is'), ('is', 'the'), ('the', 'phenomenon'), ('phenomenon', 'that'), ('that', 'occurs'), ('occurs', 'when'), ('when', 'two'), ('two', 'or'), ('or', 'more'), ('more', 'waves'), ('waves', 'superpose'), ('superpose', 'to'), ('to', 'form'), ('form', 'a'), ('a', 'resultant'), ('resultant', 'wave'), ('wave', 'of'), ('of', 'greater,'), ('greater,', 'lower,'), ('lower,', 'or'), ('or', 'the'), ('the', 'same'), ('same', 'amplitude.'), ('Interference', 'is'), ('is', 'the'), ('the', 'phenomenon'), ('phenomenon', 'that'), ('that', 'occurs'), ('occurs', 'when'), ('when', 'two'), ('two', 'or'), ('or', 'more'), ('more', 'waves'), ('waves', 'superpose'), ('superpose', 'to'), ('to', 'form'), ('form', 'a'), ('a', 'resultant'), ('resultant', 'wave'), ('wave', 'of'), ('of', 'greater,'), ('greater,', 'lower,'), ('lower,', 'or'), ('or', 'the'), ('the', 'same'), ('same', 'amplitude.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([3.1510e+03, 3.0000e+00, 1.0000e+00, 1.8840e+03, 2.0000e+00, 1.0000e+00,\n",
            "        1.8760e+03, 8.0000e+00, 4.0000e+00, 1.3530e+03, 1.2690e+03, 4.0000e+01,\n",
            "        1.4000e+01, 9.1400e+02, 5.0100e+02, 6.0000e+00, 4.3000e+01, 2.9600e+02,\n",
            "        2.0000e+00, 1.3520e+03, 3.1510e+03, 3.0000e+00, 1.0000e+00, 1.8840e+03,\n",
            "        2.0000e+00, 1.0000e+00, 1.8760e+03, 8.0000e+00, 4.0000e+00, 1.3530e+03,\n",
            "        1.2690e+03, 4.0000e+01, 1.4000e+01, 9.1400e+02, 5.0100e+02, 6.0000e+00,\n",
            "        4.3000e+01, 2.9600e+02, 2.0000e+00, 1.3520e+03])\n",
            "['Polarization', 'is', 'the', 'orientation', 'of', 'the', 'oscillations', 'in', 'a', 'transverse', 'wave,', 'such', 'as', 'light,', 'relative', 'to', 'its', 'direction', 'of', 'travel.', 'Polarization', 'is', 'the', 'orientation', 'of', 'the', 'oscillations', 'in', 'a', 'transverse', 'wave,', 'such', 'as', 'light,', 'relative', 'to', 'its', 'direction', 'of', 'travel.']\n",
            "[('Polarization', 'is'), ('is', 'the'), ('the', 'orientation'), ('orientation', 'of'), ('of', 'the'), ('the', 'oscillations'), ('oscillations', 'in'), ('in', 'a'), ('a', 'transverse'), ('transverse', 'wave,'), ('wave,', 'such'), ('such', 'as'), ('as', 'light,'), ('light,', 'relative'), ('relative', 'to'), ('to', 'its'), ('its', 'direction'), ('direction', 'of'), ('of', 'travel.'), ('Polarization', 'is'), ('is', 'the'), ('the', 'orientation'), ('orientation', 'of'), ('of', 'the'), ('the', 'oscillations'), ('oscillations', 'in'), ('in', 'a'), ('a', 'transverse'), ('transverse', 'wave,'), ('wave,', 'such'), ('such', 'as'), ('as', 'light,'), ('light,', 'relative'), ('relative', 'to'), ('to', 'its'), ('its', 'direction'), ('direction', 'of'), ('of', 'travel.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([9.0000e+00, 3.3600e+02, 2.0000e+00, 1.7100e+02, 3.0000e+00, 1.0000e+00,\n",
            "        2.5810e+03, 1.3510e+03, 3.6200e+02, 1.2700e+02, 3.3000e+02, 1.8000e+01,\n",
            "        4.0000e+00, 1.7100e+02, 1.3700e+02, 1.4000e+01, 4.4000e+01, 1.7160e+03,\n",
            "        5.2000e+01, 4.0000e+00, 2.0190e+03, 9.0000e+00, 3.3600e+02, 2.0000e+00,\n",
            "        1.7100e+02, 3.0000e+00, 1.0000e+00, 2.5810e+03, 1.3510e+03, 3.6200e+02,\n",
            "        1.2700e+02, 3.3000e+02, 1.8000e+01, 4.0000e+00, 1.7100e+02, 1.3700e+02,\n",
            "        1.4000e+01, 4.4000e+01, 1.7160e+03, 5.2000e+01, 4.0000e+00, 2.0190e+03])\n",
            "['The', 'speed', 'of', 'sound', 'is', 'the', 'distance', 'traveled', 'per', 'unit', 'time', 'by', 'a', 'sound', 'wave', 'as', 'it', 'propagates', 'through', 'a', 'medium.', 'The', 'speed', 'of', 'sound', 'is', 'the', 'distance', 'traveled', 'per', 'unit', 'time', 'by', 'a', 'sound', 'wave', 'as', 'it', 'propagates', 'through', 'a', 'medium.']\n",
            "[('The', 'speed'), ('speed', 'of'), ('of', 'sound'), ('sound', 'is'), ('is', 'the'), ('the', 'distance'), ('distance', 'traveled'), ('traveled', 'per'), ('per', 'unit'), ('unit', 'time'), ('time', 'by'), ('by', 'a'), ('a', 'sound'), ('sound', 'wave'), ('wave', 'as'), ('as', 'it'), ('it', 'propagates'), ('propagates', 'through'), ('through', 'a'), ('a', 'medium.'), ('The', 'speed'), ('speed', 'of'), ('of', 'sound'), ('sound', 'is'), ('is', 'the'), ('the', 'distance'), ('distance', 'traveled'), ('traveled', 'per'), ('per', 'unit'), ('unit', 'time'), ('time', 'by'), ('by', 'a'), ('a', 'sound'), ('sound', 'wave'), ('wave', 'as'), ('as', 'it'), ('it', 'propagates'), ('propagates', 'through'), ('through', 'a'), ('a', 'medium.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([3.4540e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0200e+02,\n",
            "        7.0000e+00, 3.6000e+01, 1.0000e+00, 1.4000e+02, 2.0000e+00, 7.6000e+02,\n",
            "        3.4540e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0200e+02,\n",
            "        7.0000e+00, 3.6000e+01, 1.0000e+00, 1.4000e+02, 2.0000e+00, 7.6000e+02])\n",
            "['Acoustics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'studies', 'the', 'properties', 'of', 'sound.', 'Acoustics', 'is', 'the', 'branch', 'of', 'physics', 'that', 'studies', 'the', 'properties', 'of', 'sound.']\n",
            "[('Acoustics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'properties'), ('properties', 'of'), ('of', 'sound.'), ('Acoustics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'physics'), ('physics', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'properties'), ('properties', 'of'), ('of', 'sound.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([3.3240e+03, 2.5440e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00,\n",
            "        1.0000e+00, 5.3300e+02, 2.0000e+00, 2.0900e+03, 5.0000e+00, 2.3430e+03,\n",
            "        3.3240e+03, 2.5440e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00,\n",
            "        1.0000e+00, 5.3300e+02, 2.0000e+00, 2.0900e+03, 5.0000e+00, 2.3430e+03])\n",
            "['Fluid', 'dynamics', 'is', 'the', 'study', 'of', 'the', 'movement', 'of', 'liquids', 'and', 'gases.', 'Fluid', 'dynamics', 'is', 'the', 'study', 'of', 'the', 'movement', 'of', 'liquids', 'and', 'gases.']\n",
            "[('Fluid', 'dynamics'), ('dynamics', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'movement'), ('movement', 'of'), ('of', 'liquids'), ('liquids', 'and'), ('and', 'gases.'), ('Fluid', 'dynamics'), ('dynamics', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'movement'), ('movement', 'of'), ('of', 'liquids'), ('liquids', 'and'), ('and', 'gases.')]\n",
            "54\n",
            "52\n",
            "1431\n",
            "106\n",
            "tensor([3.4240e+03, 1.7600e+02, 3.2000e+01, 7.0000e+00, 2.1000e+01, 9.5300e+02,\n",
            "        8.0000e+00, 1.0000e+00, 3.3600e+02, 2.0000e+00, 4.0000e+00, 9.8900e+02,\n",
            "        1.4200e+02, 4.8500e+02, 1.9000e+01, 4.0000e+00, 1.0650e+03, 8.0000e+00,\n",
            "        1.7480e+03, 1.0000e+01, 4.0000e+00, 1.0650e+03, 8.0000e+00, 1.0000e+00,\n",
            "        2.3790e+03, 3.5600e+02, 1.5100e+02, 3.4240e+03, 1.7600e+02, 3.2000e+01,\n",
            "        7.0000e+00, 2.1000e+01, 9.5300e+02, 8.0000e+00, 1.0000e+00, 3.3600e+02,\n",
            "        2.0000e+00, 4.0000e+00, 9.8900e+02, 1.4200e+02, 4.8500e+02, 1.9000e+01,\n",
            "        4.0000e+00, 1.0650e+03, 8.0000e+00, 1.7480e+03, 1.0000e+01, 4.0000e+00,\n",
            "        1.0650e+03, 8.0000e+00, 1.0000e+00, 2.3790e+03, 3.5600e+02, 1.5100e+02])\n",
            "[\"Bernoulli's\", 'principle', 'states', 'that', 'an', 'increase', 'in', 'the', 'speed', 'of', 'a', 'fluid', 'occurs', 'simultaneously', 'with', 'a', 'decrease', 'in', 'pressure', 'or', 'a', 'decrease', 'in', 'the', \"fluid's\", 'potential', 'energy.', \"Bernoulli's\", 'principle', 'states', 'that', 'an', 'increase', 'in', 'the', 'speed', 'of', 'a', 'fluid', 'occurs', 'simultaneously', 'with', 'a', 'decrease', 'in', 'pressure', 'or', 'a', 'decrease', 'in', 'the', \"fluid's\", 'potential', 'energy.']\n",
            "[(\"Bernoulli's\", 'principle'), ('principle', 'states'), ('states', 'that'), ('that', 'an'), ('an', 'increase'), ('increase', 'in'), ('in', 'the'), ('the', 'speed'), ('speed', 'of'), ('of', 'a'), ('a', 'fluid'), ('fluid', 'occurs'), ('occurs', 'simultaneously'), ('simultaneously', 'with'), ('with', 'a'), ('a', 'decrease'), ('decrease', 'in'), ('in', 'pressure'), ('pressure', 'or'), ('or', 'a'), ('a', 'decrease'), ('decrease', 'in'), ('in', 'the'), ('the', \"fluid's\"), (\"fluid's\", 'potential'), ('potential', 'energy.'), (\"Bernoulli's\", 'principle'), ('principle', 'states'), ('states', 'that'), ('that', 'an'), ('an', 'increase'), ('increase', 'in'), ('in', 'the'), ('the', 'speed'), ('speed', 'of'), ('of', 'a'), ('a', 'fluid'), ('fluid', 'occurs'), ('occurs', 'simultaneously'), ('simultaneously', 'with'), ('with', 'a'), ('a', 'decrease'), ('decrease', 'in'), ('in', 'pressure'), ('pressure', 'or'), ('or', 'a'), ('a', 'decrease'), ('decrease', 'in'), ('in', 'the'), ('the', \"fluid's\"), (\"fluid's\", 'potential'), ('potential', 'energy.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([3.0580e+03, 3.0000e+00, 1.0000e+00, 2.7900e+03, 2.1490e+03, 5.9300e+02,\n",
            "        2.0000e+00, 4.0000e+00, 2.3780e+03, 3.0580e+03, 3.0000e+00, 1.0000e+00,\n",
            "        2.7900e+03, 2.1490e+03, 5.9300e+02, 2.0000e+00, 4.0000e+00, 2.3780e+03])\n",
            "['Turbulence', 'is', 'the', 'chaotic,', 'irregular', 'flow', 'of', 'a', 'fluid.', 'Turbulence', 'is', 'the', 'chaotic,', 'irregular', 'flow', 'of', 'a', 'fluid.']\n",
            "[('Turbulence', 'is'), ('is', 'the'), ('the', 'chaotic,'), ('chaotic,', 'irregular'), ('irregular', 'flow'), ('flow', 'of'), ('of', 'a'), ('a', 'fluid.'), ('Turbulence', 'is'), ('is', 'the'), ('the', 'chaotic,'), ('chaotic,', 'irregular'), ('irregular', 'flow'), ('flow', 'of'), ('of', 'a'), ('a', 'fluid.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([9.0000e+00, 3.2000e+03, 6.0700e+02, 1.5300e+02, 1.0000e+00, 1.2000e+02,\n",
            "        2.0000e+00, 1.2810e+03, 9.8900e+02, 7.4400e+02, 9.0000e+00, 3.2000e+03,\n",
            "        6.0700e+02, 1.5300e+02, 1.0000e+00, 1.2000e+02, 2.0000e+00, 1.2810e+03,\n",
            "        9.8900e+02, 7.4400e+02])\n",
            "['The', 'Navier-Stokes', 'equations', 'describe', 'the', 'motion', 'of', 'viscous', 'fluid', 'substances.', 'The', 'Navier-Stokes', 'equations', 'describe', 'the', 'motion', 'of', 'viscous', 'fluid', 'substances.']\n",
            "[('The', 'Navier-Stokes'), ('Navier-Stokes', 'equations'), ('equations', 'describe'), ('describe', 'the'), ('the', 'motion'), ('motion', 'of'), ('of', 'viscous'), ('viscous', 'fluid'), ('fluid', 'substances.'), ('The', 'Navier-Stokes'), ('Navier-Stokes', 'equations'), ('equations', 'describe'), ('describe', 'the'), ('the', 'motion'), ('motion', 'of'), ('of', 'viscous'), ('viscous', 'fluid'), ('fluid', 'substances.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([3.1540e+03, 3.0000e+00, 3.7000e+01, 2.0000e+00, 1.0000e+00, 2.3630e+03,\n",
            "        8.2000e+01, 3.2000e+01, 2.0000e+00, 5.4000e+02, 1.0780e+03, 2.0000e+00,\n",
            "        5.7000e+02, 2.1520e+03, 9.7900e+02, 1.9000e+01, 8.7700e+02, 2.3000e+02,\n",
            "        1.4300e+02, 2.0000e+00, 8.2800e+02, 5.0000e+00, 8.7500e+02, 2.1510e+03,\n",
            "        3.1540e+03, 3.0000e+00, 3.7000e+01, 2.0000e+00, 1.0000e+00, 2.3630e+03,\n",
            "        8.2000e+01, 3.2000e+01, 2.0000e+00, 5.4000e+02, 1.0780e+03, 2.0000e+00,\n",
            "        5.7000e+02, 2.1520e+03, 9.7900e+02, 1.9000e+01, 8.7700e+02, 2.3000e+02,\n",
            "        1.4300e+02, 2.0000e+00, 8.2800e+02, 5.0000e+00, 8.7500e+02, 2.1510e+03])\n",
            "['Plasma', 'is', 'one', 'of', 'the', 'four', 'fundamental', 'states', 'of', 'matter,', 'consisting', 'of', 'highly', 'ionized', 'gas', 'with', 'nearly', 'equal', 'numbers', 'of', 'positive', 'and', 'negative', 'ions.', 'Plasma', 'is', 'one', 'of', 'the', 'four', 'fundamental', 'states', 'of', 'matter,', 'consisting', 'of', 'highly', 'ionized', 'gas', 'with', 'nearly', 'equal', 'numbers', 'of', 'positive', 'and', 'negative', 'ions.']\n",
            "[('Plasma', 'is'), ('is', 'one'), ('one', 'of'), ('of', 'the'), ('the', 'four'), ('four', 'fundamental'), ('fundamental', 'states'), ('states', 'of'), ('of', 'matter,'), ('matter,', 'consisting'), ('consisting', 'of'), ('of', 'highly'), ('highly', 'ionized'), ('ionized', 'gas'), ('gas', 'with'), ('with', 'nearly'), ('nearly', 'equal'), ('equal', 'numbers'), ('numbers', 'of'), ('of', 'positive'), ('positive', 'and'), ('and', 'negative'), ('negative', 'ions.'), ('Plasma', 'is'), ('is', 'one'), ('one', 'of'), ('of', 'the'), ('the', 'four'), ('four', 'fundamental'), ('fundamental', 'states'), ('states', 'of'), ('of', 'matter,'), ('matter,', 'consisting'), ('consisting', 'of'), ('of', 'highly'), ('highly', 'ionized'), ('ionized', 'gas'), ('gas', 'with'), ('with', 'nearly'), ('nearly', 'equal'), ('equal', 'numbers'), ('numbers', 'of'), ('of', 'positive'), ('positive', 'and'), ('and', 'negative'), ('negative', 'ions.')]\n",
            "44\n",
            "42\n",
            "946\n",
            "86\n",
            "tensor([9.0000e+00, 1.5400e+02, 2.0000e+00, 1.2420e+03, 2.0400e+02, 3.2000e+01,\n",
            "        7.0000e+00, 1.0000e+00, 1.6200e+02, 2.5580e+03, 2.3000e+01, 2.1000e+01,\n",
            "        1.1800e+02, 3.0000e+00, 2.3000e+02, 6.0000e+00, 1.0000e+00, 8.5000e+01,\n",
            "        8.0000e+00, 4.3000e+01, 9.2500e+02, 1.5100e+02, 9.0000e+00, 1.5400e+02,\n",
            "        2.0000e+00, 1.2420e+03, 2.0400e+02, 3.2000e+01, 7.0000e+00, 1.0000e+00,\n",
            "        1.6200e+02, 2.5580e+03, 2.3000e+01, 2.1000e+01, 1.1800e+02, 3.0000e+00,\n",
            "        2.3000e+02, 6.0000e+00, 1.0000e+00, 8.5000e+01, 8.0000e+00, 4.3000e+01,\n",
            "        9.2500e+02, 1.5100e+02])\n",
            "['The', 'concept', 'of', 'work-energy', 'theorem', 'states', 'that', 'the', 'work', 'done', 'on', 'an', 'object', 'is', 'equal', 'to', 'the', 'change', 'in', 'its', 'kinetic', 'energy.', 'The', 'concept', 'of', 'work-energy', 'theorem', 'states', 'that', 'the', 'work', 'done', 'on', 'an', 'object', 'is', 'equal', 'to', 'the', 'change', 'in', 'its', 'kinetic', 'energy.']\n",
            "[('The', 'concept'), ('concept', 'of'), ('of', 'work-energy'), ('work-energy', 'theorem'), ('theorem', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'work'), ('work', 'done'), ('done', 'on'), ('on', 'an'), ('an', 'object'), ('object', 'is'), ('is', 'equal'), ('equal', 'to'), ('to', 'the'), ('the', 'change'), ('change', 'in'), ('in', 'its'), ('its', 'kinetic'), ('kinetic', 'energy.'), ('The', 'concept'), ('concept', 'of'), ('of', 'work-energy'), ('work-energy', 'theorem'), ('theorem', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'work'), ('work', 'done'), ('done', 'on'), ('on', 'an'), ('an', 'object'), ('object', 'is'), ('is', 'equal'), ('equal', 'to'), ('to', 'the'), ('the', 'change'), ('change', 'in'), ('in', 'its'), ('its', 'kinetic'), ('kinetic', 'energy.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([9.0000e+00, 4.0800e+02, 2.0000e+00, 6.5400e+02, 1.8200e+02, 3.2000e+01,\n",
            "        7.0000e+00, 5.6500e+02, 1.7900e+02, 1.8600e+02, 1.3710e+03, 2.9960e+03,\n",
            "        2.3000e+01, 4.0000e+00, 7.4100e+02, 1.0000e+00, 4.5200e+02, 6.5400e+02,\n",
            "        1.8200e+02, 2.0000e+00, 1.0000e+00, 2.6000e+01, 5.0000e+02, 1.0760e+03,\n",
            "        9.0000e+00, 4.0800e+02, 2.0000e+00, 6.5400e+02, 1.8200e+02, 3.2000e+01,\n",
            "        7.0000e+00, 5.6500e+02, 1.7900e+02, 1.8600e+02, 1.3710e+03, 2.9960e+03,\n",
            "        2.3000e+01, 4.0000e+00, 7.4100e+02, 1.0000e+00, 4.5200e+02, 6.5400e+02,\n",
            "        1.8200e+02, 2.0000e+00, 1.0000e+00, 2.6000e+01, 5.0000e+02, 1.0760e+03])\n",
            "['The', 'conservation', 'of', 'angular', 'momentum', 'states', 'that', 'if', 'no', 'external', 'torque', 'acts', 'on', 'a', 'system,', 'the', 'total', 'angular', 'momentum', 'of', 'the', 'system', 'remains', 'constant.', 'The', 'conservation', 'of', 'angular', 'momentum', 'states', 'that', 'if', 'no', 'external', 'torque', 'acts', 'on', 'a', 'system,', 'the', 'total', 'angular', 'momentum', 'of', 'the', 'system', 'remains', 'constant.']\n",
            "[('The', 'conservation'), ('conservation', 'of'), ('of', 'angular'), ('angular', 'momentum'), ('momentum', 'states'), ('states', 'that'), ('that', 'if'), ('if', 'no'), ('no', 'external'), ('external', 'torque'), ('torque', 'acts'), ('acts', 'on'), ('on', 'a'), ('a', 'system,'), ('system,', 'the'), ('the', 'total'), ('total', 'angular'), ('angular', 'momentum'), ('momentum', 'of'), ('of', 'the'), ('the', 'system'), ('system', 'remains'), ('remains', 'constant.'), ('The', 'conservation'), ('conservation', 'of'), ('of', 'angular'), ('angular', 'momentum'), ('momentum', 'states'), ('states', 'that'), ('that', 'if'), ('if', 'no'), ('no', 'external'), ('external', 'torque'), ('torque', 'acts'), ('acts', 'on'), ('on', 'a'), ('a', 'system,'), ('system,', 'the'), ('the', 'total'), ('total', 'angular'), ('angular', 'momentum'), ('momentum', 'of'), ('of', 'the'), ('the', 'system'), ('system', 'remains'), ('remains', 'constant.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([3.2870e+03, 1.2000e+02, 3.0000e+00, 4.0000e+00, 2.0100e+02, 2.0000e+00,\n",
            "        5.2000e+02, 1.2000e+02, 9.9000e+01, 1.0000e+00, 1.6040e+03, 1.5000e+02,\n",
            "        3.0000e+00, 4.0700e+02, 8.1400e+02, 6.0000e+00, 1.0000e+00, 2.5840e+03,\n",
            "        3.2870e+03, 1.2000e+02, 3.0000e+00, 4.0000e+00, 2.0100e+02, 2.0000e+00,\n",
            "        5.2000e+02, 1.2000e+02, 9.9000e+01, 1.0000e+00, 1.6040e+03, 1.5000e+02,\n",
            "        3.0000e+00, 4.0700e+02, 8.1400e+02, 6.0000e+00, 1.0000e+00, 2.5840e+03])\n",
            "['Harmonic', 'motion', 'is', 'a', 'type', 'of', 'periodic', 'motion', 'where', 'the', 'restoring', 'force', 'is', 'directly', 'proportional', 'to', 'the', 'displacement.', 'Harmonic', 'motion', 'is', 'a', 'type', 'of', 'periodic', 'motion', 'where', 'the', 'restoring', 'force', 'is', 'directly', 'proportional', 'to', 'the', 'displacement.']\n",
            "[('Harmonic', 'motion'), ('motion', 'is'), ('is', 'a'), ('a', 'type'), ('type', 'of'), ('of', 'periodic'), ('periodic', 'motion'), ('motion', 'where'), ('where', 'the'), ('the', 'restoring'), ('restoring', 'force'), ('force', 'is'), ('is', 'directly'), ('directly', 'proportional'), ('proportional', 'to'), ('to', 'the'), ('the', 'displacement.'), ('Harmonic', 'motion'), ('motion', 'is'), ('is', 'a'), ('a', 'type'), ('type', 'of'), ('of', 'periodic'), ('periodic', 'motion'), ('motion', 'where'), ('where', 'the'), ('the', 'restoring'), ('restoring', 'force'), ('force', 'is'), ('is', 'directly'), ('directly', 'proportional'), ('proportional', 'to'), ('to', 'the'), ('the', 'displacement.')]\n",
            "50\n",
            "48\n",
            "1225\n",
            "98\n",
            "tensor([9.0000e+00, 6.8000e+01, 2.0000e+00, 3.2200e+02, 9.6700e+02, 3.2000e+01,\n",
            "        7.0000e+00, 2.2900e+02, 3.5800e+02, 9.0000e+01, 2.9050e+03, 2.2900e+02,\n",
            "        5.8000e+01, 3.5800e+02, 9.0000e+01, 1.8000e+01, 4.0000e+00, 1.5000e+02,\n",
            "        1.1460e+03, 1.1390e+03, 1.0000e+00, 9.1200e+02, 2.1640e+03, 1.1300e+02,\n",
            "        8.3300e+02, 9.0000e+00, 6.8000e+01, 2.0000e+00, 3.2200e+02, 9.6700e+02,\n",
            "        3.2000e+01, 7.0000e+00, 2.2900e+02, 3.5800e+02, 9.0000e+01, 2.9050e+03,\n",
            "        2.2900e+02, 5.8000e+01, 3.5800e+02, 9.0000e+01, 1.8000e+01, 4.0000e+00,\n",
            "        1.5000e+02, 1.1460e+03, 1.1390e+03, 1.0000e+00, 9.1200e+02, 2.1640e+03,\n",
            "        1.1300e+02, 8.3300e+02])\n",
            "['The', 'law', 'of', 'universal', 'gravitation', 'states', 'that', 'every', 'point', 'mass', 'attracts', 'every', 'other', 'point', 'mass', 'by', 'a', 'force', 'acting', 'along', 'the', 'line', 'intersecting', 'both', 'points.', 'The', 'law', 'of', 'universal', 'gravitation', 'states', 'that', 'every', 'point', 'mass', 'attracts', 'every', 'other', 'point', 'mass', 'by', 'a', 'force', 'acting', 'along', 'the', 'line', 'intersecting', 'both', 'points.']\n",
            "[('The', 'law'), ('law', 'of'), ('of', 'universal'), ('universal', 'gravitation'), ('gravitation', 'states'), ('states', 'that'), ('that', 'every'), ('every', 'point'), ('point', 'mass'), ('mass', 'attracts'), ('attracts', 'every'), ('every', 'other'), ('other', 'point'), ('point', 'mass'), ('mass', 'by'), ('by', 'a'), ('a', 'force'), ('force', 'acting'), ('acting', 'along'), ('along', 'the'), ('the', 'line'), ('line', 'intersecting'), ('intersecting', 'both'), ('both', 'points.'), ('The', 'law'), ('law', 'of'), ('of', 'universal'), ('universal', 'gravitation'), ('gravitation', 'states'), ('states', 'that'), ('that', 'every'), ('every', 'point'), ('point', 'mass'), ('mass', 'attracts'), ('attracts', 'every'), ('every', 'other'), ('other', 'point'), ('point', 'mass'), ('mass', 'by'), ('by', 'a'), ('a', 'force'), ('force', 'acting'), ('acting', 'along'), ('along', 'the'), ('the', 'line'), ('line', 'intersecting'), ('intersecting', 'both'), ('both', 'points.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([4.5000e+01, 2.3200e+02, 1.1200e+02, 3.0000e+00, 4.0000e+00, 2.4400e+02,\n",
            "        1.1200e+02, 4.2500e+02, 4.0000e+00, 2.3600e+02, 1.2900e+02, 7.0000e+00,\n",
            "        2.5700e+02, 1.0000e+00, 1.5000e+02, 2.4590e+03, 2.3000e+01, 5.8000e+01,\n",
            "        2.3600e+02, 2.6600e+02, 4.5000e+01, 2.3200e+02, 1.1200e+02, 3.0000e+00,\n",
            "        4.0000e+00, 2.4400e+02, 1.1200e+02, 4.2500e+02, 4.0000e+00, 2.3600e+02,\n",
            "        1.2900e+02, 7.0000e+00, 2.5700e+02, 1.0000e+00, 1.5000e+02, 2.4590e+03,\n",
            "        2.3000e+01, 5.8000e+01, 2.3600e+02, 2.6600e+02])\n",
            "['An', 'electric', 'field', 'is', 'a', 'vector', 'field', 'around', 'a', 'charged', 'particle', 'that', 'represents', 'the', 'force', 'exerted', 'on', 'other', 'charged', 'particles.', 'An', 'electric', 'field', 'is', 'a', 'vector', 'field', 'around', 'a', 'charged', 'particle', 'that', 'represents', 'the', 'force', 'exerted', 'on', 'other', 'charged', 'particles.']\n",
            "[('An', 'electric'), ('electric', 'field'), ('field', 'is'), ('is', 'a'), ('a', 'vector'), ('vector', 'field'), ('field', 'around'), ('around', 'a'), ('a', 'charged'), ('charged', 'particle'), ('particle', 'that'), ('that', 'represents'), ('represents', 'the'), ('the', 'force'), ('force', 'exerted'), ('exerted', 'on'), ('on', 'other'), ('other', 'charged'), ('charged', 'particles.'), ('An', 'electric'), ('electric', 'field'), ('field', 'is'), ('is', 'a'), ('a', 'vector'), ('vector', 'field'), ('field', 'around'), ('around', 'a'), ('a', 'charged'), ('charged', 'particle'), ('particle', 'that'), ('that', 'represents'), ('represents', 'the'), ('the', 'force'), ('force', 'exerted'), ('exerted', 'on'), ('on', 'other'), ('other', 'charged'), ('charged', 'particles.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([1.1000e+01, 1.4500e+02, 1.1200e+02, 3.0000e+00, 4.0000e+00, 2.4400e+02,\n",
            "        1.1200e+02, 7.0000e+00, 4.9000e+01, 1.0000e+00, 1.4500e+02, 3.8600e+02,\n",
            "        2.3000e+01, 8.8500e+02, 2.3200e+02, 2.7810e+03, 2.3200e+02, 2.6550e+03,\n",
            "        5.0000e+00, 1.4500e+02, 2.0390e+03, 1.1000e+01, 1.4500e+02, 1.1200e+02,\n",
            "        3.0000e+00, 4.0000e+00, 2.4400e+02, 1.1200e+02, 7.0000e+00, 4.9000e+01,\n",
            "        1.0000e+00, 1.4500e+02, 3.8600e+02, 2.3000e+01, 8.8500e+02, 2.3200e+02,\n",
            "        2.7810e+03, 2.3200e+02, 2.6550e+03, 5.0000e+00, 1.4500e+02, 2.0390e+03])\n",
            "['A', 'magnetic', 'field', 'is', 'a', 'vector', 'field', 'that', 'describes', 'the', 'magnetic', 'influence', 'on', 'moving', 'electric', 'charges,', 'electric', 'currents,', 'and', 'magnetic', 'materials.', 'A', 'magnetic', 'field', 'is', 'a', 'vector', 'field', 'that', 'describes', 'the', 'magnetic', 'influence', 'on', 'moving', 'electric', 'charges,', 'electric', 'currents,', 'and', 'magnetic', 'materials.']\n",
            "[('A', 'magnetic'), ('magnetic', 'field'), ('field', 'is'), ('is', 'a'), ('a', 'vector'), ('vector', 'field'), ('field', 'that'), ('that', 'describes'), ('describes', 'the'), ('the', 'magnetic'), ('magnetic', 'influence'), ('influence', 'on'), ('on', 'moving'), ('moving', 'electric'), ('electric', 'charges,'), ('charges,', 'electric'), ('electric', 'currents,'), ('currents,', 'and'), ('and', 'magnetic'), ('magnetic', 'materials.'), ('A', 'magnetic'), ('magnetic', 'field'), ('field', 'is'), ('is', 'a'), ('a', 'vector'), ('vector', 'field'), ('field', 'that'), ('that', 'describes'), ('describes', 'the'), ('the', 'magnetic'), ('magnetic', 'influence'), ('influence', 'on'), ('on', 'moving'), ('moving', 'electric'), ('electric', 'charges,'), ('charges,', 'electric'), ('electric', 'currents,'), ('currents,', 'and'), ('and', 'magnetic'), ('magnetic', 'materials.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.3300e+03, 6.8000e+01, 2.0000e+00, 9.5200e+02, 3.2000e+01, 7.0000e+00,\n",
            "        4.0000e+00, 1.0980e+03, 1.4500e+02, 1.1200e+02, 2.6680e+03, 2.1000e+01,\n",
            "        2.3200e+02, 9.9400e+02, 3.3300e+03, 6.8000e+01, 2.0000e+00, 9.5200e+02,\n",
            "        3.2000e+01, 7.0000e+00, 4.0000e+00, 1.0980e+03, 1.4500e+02, 1.1200e+02,\n",
            "        2.6680e+03, 2.1000e+01, 2.3200e+02, 9.9400e+02])\n",
            "[\"Faraday's\", 'law', 'of', 'induction', 'states', 'that', 'a', 'changing', 'magnetic', 'field', 'creates', 'an', 'electric', 'field.', \"Faraday's\", 'law', 'of', 'induction', 'states', 'that', 'a', 'changing', 'magnetic', 'field', 'creates', 'an', 'electric', 'field.']\n",
            "[(\"Faraday's\", 'law'), ('law', 'of'), ('of', 'induction'), ('induction', 'states'), ('states', 'that'), ('that', 'a'), ('a', 'changing'), ('changing', 'magnetic'), ('magnetic', 'field'), ('field', 'creates'), ('creates', 'an'), ('an', 'electric'), ('electric', 'field.'), (\"Faraday's\", 'law'), ('law', 'of'), ('of', 'induction'), ('induction', 'states'), ('states', 'that'), ('that', 'a'), ('a', 'changing'), ('changing', 'magnetic'), ('magnetic', 'field'), ('field', 'creates'), ('creates', 'an'), ('an', 'electric'), ('electric', 'field.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([3.2420e+03, 6.8000e+01, 3.2000e+01, 7.0000e+00, 1.0000e+00, 2.9600e+02,\n",
            "        2.0000e+00, 2.1000e+01, 2.2180e+03, 1.0690e+03, 3.0000e+00, 4.0000e+01,\n",
            "        7.0000e+00, 4.4000e+01, 8.6200e+02, 1.0000e+00, 8.5000e+01, 8.0000e+00,\n",
            "        1.4500e+02, 2.3760e+03, 7.0000e+00, 3.5300e+02, 2.2200e+02, 3.2420e+03,\n",
            "        6.8000e+01, 3.2000e+01, 7.0000e+00, 1.0000e+00, 2.9600e+02, 2.0000e+00,\n",
            "        2.1000e+01, 2.2180e+03, 1.0690e+03, 3.0000e+00, 4.0000e+01, 7.0000e+00,\n",
            "        4.4000e+01, 8.6200e+02, 1.0000e+00, 8.5000e+01, 8.0000e+00, 1.4500e+02,\n",
            "        2.3760e+03, 7.0000e+00, 3.5300e+02, 2.2200e+02])\n",
            "[\"Lenz's\", 'law', 'states', 'that', 'the', 'direction', 'of', 'an', 'induced', 'current', 'is', 'such', 'that', 'it', 'opposes', 'the', 'change', 'in', 'magnetic', 'flux', 'that', 'produced', 'it.', \"Lenz's\", 'law', 'states', 'that', 'the', 'direction', 'of', 'an', 'induced', 'current', 'is', 'such', 'that', 'it', 'opposes', 'the', 'change', 'in', 'magnetic', 'flux', 'that', 'produced', 'it.']\n",
            "[(\"Lenz's\", 'law'), ('law', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'direction'), ('direction', 'of'), ('of', 'an'), ('an', 'induced'), ('induced', 'current'), ('current', 'is'), ('is', 'such'), ('such', 'that'), ('that', 'it'), ('it', 'opposes'), ('opposes', 'the'), ('the', 'change'), ('change', 'in'), ('in', 'magnetic'), ('magnetic', 'flux'), ('flux', 'that'), ('that', 'produced'), ('produced', 'it.'), (\"Lenz's\", 'law'), ('law', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'direction'), ('direction', 'of'), ('of', 'an'), ('an', 'induced'), ('induced', 'current'), ('current', 'is'), ('is', 'such'), ('such', 'that'), ('that', 'it'), ('it', 'opposes'), ('opposes', 'the'), ('the', 'change'), ('change', 'in'), ('in', 'magnetic'), ('magnetic', 'flux'), ('flux', 'that'), ('that', 'produced'), ('produced', 'it.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3.3810e+03, 6.8000e+01, 4.9000e+01, 1.0000e+00, 1.0350e+03, 1.5000e+02,\n",
            "        3.5000e+01, 2.5240e+03, 2.3600e+02, 2.6600e+02, 3.3810e+03, 6.8000e+01,\n",
            "        4.9000e+01, 1.0000e+00, 1.0350e+03, 1.5000e+02, 3.5000e+01, 2.5240e+03,\n",
            "        2.3600e+02, 2.6600e+02])\n",
            "[\"Coulomb's\", 'law', 'describes', 'the', 'electrostatic', 'force', 'between', 'electrically', 'charged', 'particles.', \"Coulomb's\", 'law', 'describes', 'the', 'electrostatic', 'force', 'between', 'electrically', 'charged', 'particles.']\n",
            "[(\"Coulomb's\", 'law'), ('law', 'describes'), ('describes', 'the'), ('the', 'electrostatic'), ('electrostatic', 'force'), ('force', 'between'), ('between', 'electrically'), ('electrically', 'charged'), ('charged', 'particles.'), (\"Coulomb's\", 'law'), ('law', 'describes'), ('describes', 'the'), ('the', 'electrostatic'), ('electrostatic', 'force'), ('force', 'between'), ('between', 'electrically'), ('electrically', 'charged'), ('charged', 'particles.')]\n",
            "44\n",
            "42\n",
            "946\n",
            "86\n",
            "tensor([3.1830e+03, 6.8000e+01, 3.2000e+01, 7.0000e+00, 1.0000e+00, 1.0690e+03,\n",
            "        5.2000e+01, 4.0000e+00, 2.7190e+03, 3.5000e+01, 3.9000e+01, 1.7800e+03,\n",
            "        3.0000e+00, 4.0700e+02, 8.1400e+02, 6.0000e+00, 1.0000e+00, 1.2770e+03,\n",
            "        1.1470e+03, 1.0000e+00, 3.9000e+01, 8.3300e+02, 3.1830e+03, 6.8000e+01,\n",
            "        3.2000e+01, 7.0000e+00, 1.0000e+00, 1.0690e+03, 5.2000e+01, 4.0000e+00,\n",
            "        2.7190e+03, 3.5000e+01, 3.9000e+01, 1.7800e+03, 3.0000e+00, 4.0700e+02,\n",
            "        8.1400e+02, 6.0000e+00, 1.0000e+00, 1.2770e+03, 1.1470e+03, 1.0000e+00,\n",
            "        3.9000e+01, 8.3300e+02])\n",
            "[\"Ohm's\", 'law', 'states', 'that', 'the', 'current', 'through', 'a', 'conductor', 'between', 'two', 'points', 'is', 'directly', 'proportional', 'to', 'the', 'voltage', 'across', 'the', 'two', 'points.', \"Ohm's\", 'law', 'states', 'that', 'the', 'current', 'through', 'a', 'conductor', 'between', 'two', 'points', 'is', 'directly', 'proportional', 'to', 'the', 'voltage', 'across', 'the', 'two', 'points.']\n",
            "[(\"Ohm's\", 'law'), ('law', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'current'), ('current', 'through'), ('through', 'a'), ('a', 'conductor'), ('conductor', 'between'), ('between', 'two'), ('two', 'points'), ('points', 'is'), ('is', 'directly'), ('directly', 'proportional'), ('proportional', 'to'), ('to', 'the'), ('the', 'voltage'), ('voltage', 'across'), ('across', 'the'), ('the', 'two'), ('two', 'points.'), (\"Ohm's\", 'law'), ('law', 'states'), ('states', 'that'), ('that', 'the'), ('the', 'current'), ('current', 'through'), ('through', 'a'), ('a', 'conductor'), ('conductor', 'between'), ('between', 'two'), ('two', 'points'), ('points', 'is'), ('is', 'directly'), ('directly', 'proportional'), ('proportional', 'to'), ('to', 'the'), ('the', 'voltage'), ('voltage', 'across'), ('across', 'the'), ('the', 'two'), ('two', 'points.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([3.4440e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.1130e+03,\n",
            "        2.9800e+02, 1.9000e+01, 1.0000e+00, 3.4000e+01, 2.0000e+00, 1.0000e+00,\n",
            "        7.3000e+01, 2.0000e+00, 1.8880e+03, 5.0000e+00, 4.1000e+01, 1.8480e+03,\n",
            "        3.4440e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.1130e+03,\n",
            "        2.9800e+02, 1.9000e+01, 1.0000e+00, 3.4000e+01, 2.0000e+00, 1.0000e+00,\n",
            "        7.3000e+01, 2.0000e+00, 1.8880e+03, 5.0000e+00, 4.1000e+01, 1.8480e+03])\n",
            "['Anatomy', 'is', 'the', 'branch', 'of', 'biology', 'concerned', 'with', 'the', 'study', 'of', 'the', 'structure', 'of', 'organisms', 'and', 'their', 'parts.', 'Anatomy', 'is', 'the', 'branch', 'of', 'biology', 'concerned', 'with', 'the', 'study', 'of', 'the', 'structure', 'of', 'organisms', 'and', 'their', 'parts.']\n",
            "[('Anatomy', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'biology'), ('biology', 'concerned'), ('concerned', 'with'), ('with', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'structure'), ('structure', 'of'), ('of', 'organisms'), ('organisms', 'and'), ('and', 'their'), ('their', 'parts.'), ('Anatomy', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'biology'), ('biology', 'concerned'), ('concerned', 'with'), ('with', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'structure'), ('structure', 'of'), ('of', 'organisms'), ('organisms', 'and'), ('and', 'their'), ('their', 'parts.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([   9.,   70.,   50.,    3.,  409.,    2., 1922., 1100., 1381., 1886.,\n",
            "           5.,  169.,    7.,  162.,  203.,    6.,  543.,  379.,    9.,   70.,\n",
            "          50.,    3.,  409.,    2., 1922., 1100., 1381., 1886.,    5.,  169.,\n",
            "           7.,  162.,  203.,    6.,  543.,  379.])\n",
            "['The', 'human', 'body', 'is', 'composed', 'of', 'numerous', 'cells,', 'tissues,', 'organs,', 'and', 'systems', 'that', 'work', 'together', 'to', 'maintain', 'life.', 'The', 'human', 'body', 'is', 'composed', 'of', 'numerous', 'cells,', 'tissues,', 'organs,', 'and', 'systems', 'that', 'work', 'together', 'to', 'maintain', 'life.']\n",
            "[('The', 'human'), ('human', 'body'), ('body', 'is'), ('is', 'composed'), ('composed', 'of'), ('of', 'numerous'), ('numerous', 'cells,'), ('cells,', 'tissues,'), ('tissues,', 'organs,'), ('organs,', 'and'), ('and', 'systems'), ('systems', 'that'), ('that', 'work'), ('work', 'together'), ('together', 'to'), ('to', 'maintain'), ('maintain', 'life.'), ('The', 'human'), ('human', 'body'), ('body', 'is'), ('is', 'composed'), ('composed', 'of'), ('of', 'numerous'), ('numerous', 'cells,'), ('cells,', 'tissues,'), ('tissues,', 'organs,'), ('organs,', 'and'), ('and', 'systems'), ('systems', 'that'), ('that', 'work'), ('work', 'together'), ('together', 'to'), ('to', 'maintain'), ('maintain', 'life.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 7.6600e+02, 2.6000e+01, 1.3900e+02, 3.3400e+02, 4.6900e+02,\n",
            "        5.0000e+00, 1.7100e+03, 1.2000e+01, 1.0000e+00, 5.0000e+01, 5.0000e+00,\n",
            "        1.0900e+02, 2.8510e+03, 2.8120e+03, 5.0000e+00, 2.1010e+03, 9.0000e+00,\n",
            "        7.6600e+02, 2.6000e+01, 1.3900e+02, 3.3400e+02, 4.6900e+02, 5.0000e+00,\n",
            "        1.7100e+03, 1.2000e+01, 1.0000e+00, 5.0000e+01, 5.0000e+00, 1.0900e+02,\n",
            "        2.8510e+03, 2.8120e+03, 5.0000e+00, 2.1010e+03])\n",
            "['The', 'skeletal', 'system', 'provides', 'structural', 'support', 'and', 'protection', 'for', 'the', 'body', 'and', 'includes', 'bones,', 'cartilage,', 'and', 'ligaments.', 'The', 'skeletal', 'system', 'provides', 'structural', 'support', 'and', 'protection', 'for', 'the', 'body', 'and', 'includes', 'bones,', 'cartilage,', 'and', 'ligaments.']\n",
            "[('The', 'skeletal'), ('skeletal', 'system'), ('system', 'provides'), ('provides', 'structural'), ('structural', 'support'), ('support', 'and'), ('and', 'protection'), ('protection', 'for'), ('for', 'the'), ('the', 'body'), ('body', 'and'), ('and', 'includes'), ('includes', 'bones,'), ('bones,', 'cartilage,'), ('cartilage,', 'and'), ('and', 'ligaments.'), ('The', 'skeletal'), ('skeletal', 'system'), ('system', 'provides'), ('provides', 'structural'), ('structural', 'support'), ('support', 'and'), ('and', 'protection'), ('protection', 'for'), ('for', 'the'), ('the', 'body'), ('body', 'and'), ('and', 'includes'), ('includes', 'bones,'), ('bones,', 'cartilage,'), ('cartilage,', 'and'), ('and', 'ligaments.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 8.8200e+02, 2.6000e+01, 3.0000e+00, 7.8800e+02, 1.2000e+01,\n",
            "        5.3300e+02, 5.0000e+00, 2.7080e+03, 2.0000e+00, 7.6600e+02, 8.8300e+02,\n",
            "        1.5180e+03, 8.8300e+02, 5.0000e+00, 6.4100e+02, 1.9700e+03, 9.0000e+00,\n",
            "        8.8200e+02, 2.6000e+01, 3.0000e+00, 7.8800e+02, 1.2000e+01, 5.3300e+02,\n",
            "        5.0000e+00, 2.7080e+03, 2.0000e+00, 7.6600e+02, 8.8300e+02, 1.5180e+03,\n",
            "        8.8300e+02, 5.0000e+00, 6.4100e+02, 1.9700e+03])\n",
            "['The', 'muscular', 'system', 'is', 'responsible', 'for', 'movement', 'and', 'consists', 'of', 'skeletal', 'muscles,', 'smooth', 'muscles,', 'and', 'cardiac', 'muscles.', 'The', 'muscular', 'system', 'is', 'responsible', 'for', 'movement', 'and', 'consists', 'of', 'skeletal', 'muscles,', 'smooth', 'muscles,', 'and', 'cardiac', 'muscles.']\n",
            "[('The', 'muscular'), ('muscular', 'system'), ('system', 'is'), ('is', 'responsible'), ('responsible', 'for'), ('for', 'movement'), ('movement', 'and'), ('and', 'consists'), ('consists', 'of'), ('of', 'skeletal'), ('skeletal', 'muscles,'), ('muscles,', 'smooth'), ('smooth', 'muscles,'), ('muscles,', 'and'), ('and', 'cardiac'), ('cardiac', 'muscles.'), ('The', 'muscular'), ('muscular', 'system'), ('system', 'is'), ('is', 'responsible'), ('responsible', 'for'), ('for', 'movement'), ('movement', 'and'), ('and', 'consists'), ('consists', 'of'), ('of', 'skeletal'), ('skeletal', 'muscles,'), ('muscles,', 'smooth'), ('smooth', 'muscles,'), ('muscles,', 'and'), ('and', 'cardiac'), ('cardiac', 'muscles.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 3.7100e+02, 2.6000e+01, 2.6950e+03, 5.0000e+00, 2.6880e+03,\n",
            "        5.0000e+01, 2.9990e+03, 5.0000e+00, 1.0900e+02, 1.0000e+00, 2.8440e+03,\n",
            "        4.7500e+02, 2.6850e+03, 5.0000e+00, 1.8250e+03, 1.9510e+03, 9.0000e+00,\n",
            "        3.7100e+02, 2.6000e+01, 2.6950e+03, 5.0000e+00, 2.6880e+03, 5.0000e+01,\n",
            "        2.9990e+03, 5.0000e+00, 1.0900e+02, 1.0000e+00, 2.8440e+03, 4.7500e+02,\n",
            "        2.6850e+03, 5.0000e+00, 1.8250e+03, 1.9510e+03])\n",
            "['The', 'nervous', 'system', 'controls', 'and', 'coordinates', 'body', 'activities', 'and', 'includes', 'the', 'brain,', 'spinal', 'cord,', 'and', 'peripheral', 'nerves.', 'The', 'nervous', 'system', 'controls', 'and', 'coordinates', 'body', 'activities', 'and', 'includes', 'the', 'brain,', 'spinal', 'cord,', 'and', 'peripheral', 'nerves.']\n",
            "[('The', 'nervous'), ('nervous', 'system'), ('system', 'controls'), ('controls', 'and'), ('and', 'coordinates'), ('coordinates', 'body'), ('body', 'activities'), ('activities', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'brain,'), ('brain,', 'spinal'), ('spinal', 'cord,'), ('cord,', 'and'), ('and', 'peripheral'), ('peripheral', 'nerves.'), ('The', 'nervous'), ('nervous', 'system'), ('system', 'controls'), ('controls', 'and'), ('and', 'coordinates'), ('coordinates', 'body'), ('body', 'activities'), ('activities', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'brain,'), ('brain,', 'spinal'), ('spinal', 'cord,'), ('cord,', 'and'), ('and', 'peripheral'), ('peripheral', 'nerves.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([9.0000e+00, 2.8150e+03, 2.6000e+01, 2.7710e+03, 7.7000e+01, 4.5500e+02,\n",
            "        1.0000e+00, 5.0000e+01, 5.0000e+00, 1.0900e+02, 1.0000e+00, 5.7200e+02,\n",
            "        7.7000e+01, 1.2930e+03, 5.0000e+00, 1.1100e+03, 9.0000e+00, 2.8150e+03,\n",
            "        2.6000e+01, 2.7710e+03, 7.7000e+01, 4.5500e+02, 1.0000e+00, 5.0000e+01,\n",
            "        5.0000e+00, 1.0900e+02, 1.0000e+00, 5.7200e+02, 7.7000e+01, 1.2930e+03,\n",
            "        5.0000e+00, 1.1100e+03])\n",
            "['The', 'cardiovascular', 'system', 'circulates', 'blood', 'throughout', 'the', 'body', 'and', 'includes', 'the', 'heart,', 'blood', 'vessels,', 'and', 'blood.', 'The', 'cardiovascular', 'system', 'circulates', 'blood', 'throughout', 'the', 'body', 'and', 'includes', 'the', 'heart,', 'blood', 'vessels,', 'and', 'blood.']\n",
            "[('The', 'cardiovascular'), ('cardiovascular', 'system'), ('system', 'circulates'), ('circulates', 'blood'), ('blood', 'throughout'), ('throughout', 'the'), ('the', 'body'), ('body', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'heart,'), ('heart,', 'blood'), ('blood', 'vessels,'), ('vessels,', 'and'), ('and', 'blood.'), ('The', 'cardiovascular'), ('cardiovascular', 'system'), ('system', 'circulates'), ('circulates', 'blood'), ('blood', 'throughout'), ('throughout', 'the'), ('the', 'body'), ('body', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'heart,'), ('heart,', 'blood'), ('blood', 'vessels,'), ('vessels,', 'and'), ('and', 'blood.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([9.0000e+00, 4.9600e+02, 2.6000e+01, 2.4310e+03, 1.0000e+00, 6.0100e+02,\n",
            "        2.0000e+00, 1.8640e+03, 5.0000e+00, 3.0000e+02, 1.0510e+03, 5.0000e+00,\n",
            "        1.0900e+02, 1.0000e+00, 2.0620e+03, 1.3700e+03, 5.0000e+00, 2.8310e+03,\n",
            "        9.0000e+00, 4.9600e+02, 2.6000e+01, 2.4310e+03, 1.0000e+00, 6.0100e+02,\n",
            "        2.0000e+00, 1.8640e+03, 5.0000e+00, 3.0000e+02, 1.0510e+03, 5.0000e+00,\n",
            "        1.0900e+02, 1.0000e+00, 2.0620e+03, 1.3700e+03, 5.0000e+00, 2.8310e+03])\n",
            "['The', 'respiratory', 'system', 'facilitates', 'the', 'exchange', 'of', 'oxygen', 'and', 'carbon', 'dioxide', 'and', 'includes', 'the', 'lungs,', 'trachea,', 'and', 'bronchi.', 'The', 'respiratory', 'system', 'facilitates', 'the', 'exchange', 'of', 'oxygen', 'and', 'carbon', 'dioxide', 'and', 'includes', 'the', 'lungs,', 'trachea,', 'and', 'bronchi.']\n",
            "[('The', 'respiratory'), ('respiratory', 'system'), ('system', 'facilitates'), ('facilitates', 'the'), ('the', 'exchange'), ('exchange', 'of'), ('of', 'oxygen'), ('oxygen', 'and'), ('and', 'carbon'), ('carbon', 'dioxide'), ('dioxide', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'lungs,'), ('lungs,', 'trachea,'), ('trachea,', 'and'), ('and', 'bronchi.'), ('The', 'respiratory'), ('respiratory', 'system'), ('system', 'facilitates'), ('facilitates', 'the'), ('the', 'exchange'), ('exchange', 'of'), ('of', 'oxygen'), ('oxygen', 'and'), ('and', 'carbon'), ('carbon', 'dioxide'), ('dioxide', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'lungs,'), ('lungs,', 'trachea,'), ('trachea,', 'and'), ('and', 'bronchi.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([9.0000e+00, 6.1600e+02, 2.6000e+01, 2.8400e+03, 2.5530e+03, 2.3720e+03,\n",
            "        6.9000e+01, 8.6900e+02, 1.2000e+01, 1.0000e+00, 5.0000e+01, 5.0000e+00,\n",
            "        1.0900e+02, 1.0000e+00, 1.9790e+03, 2.4850e+03, 1.4720e+03, 2.1620e+03,\n",
            "        5.0000e+00, 2.0810e+03, 9.0000e+00, 6.1600e+02, 2.6000e+01, 2.8400e+03,\n",
            "        2.5530e+03, 2.3720e+03, 6.9000e+01, 8.6900e+02, 1.2000e+01, 1.0000e+00,\n",
            "        5.0000e+01, 5.0000e+00, 1.0900e+02, 1.0000e+00, 1.9790e+03, 2.4850e+03,\n",
            "        1.4720e+03, 2.1620e+03, 5.0000e+00, 2.0810e+03])\n",
            "['The', 'digestive', 'system', 'breaks', 'down', 'food', 'into', 'nutrients', 'for', 'the', 'body', 'and', 'includes', 'the', 'mouth,', 'esophagus,', 'stomach,', 'intestines,', 'and', 'liver.', 'The', 'digestive', 'system', 'breaks', 'down', 'food', 'into', 'nutrients', 'for', 'the', 'body', 'and', 'includes', 'the', 'mouth,', 'esophagus,', 'stomach,', 'intestines,', 'and', 'liver.']\n",
            "[('The', 'digestive'), ('digestive', 'system'), ('system', 'breaks'), ('breaks', 'down'), ('down', 'food'), ('food', 'into'), ('into', 'nutrients'), ('nutrients', 'for'), ('for', 'the'), ('the', 'body'), ('body', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'mouth,'), ('mouth,', 'esophagus,'), ('esophagus,', 'stomach,'), ('stomach,', 'intestines,'), ('intestines,', 'and'), ('and', 'liver.'), ('The', 'digestive'), ('digestive', 'system'), ('system', 'breaks'), ('breaks', 'down'), ('down', 'food'), ('food', 'into'), ('into', 'nutrients'), ('nutrients', 'for'), ('for', 'the'), ('the', 'body'), ('body', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'mouth,'), ('mouth,', 'esophagus,'), ('esophagus,', 'stomach,'), ('stomach,', 'intestines,'), ('intestines,', 'and'), ('and', 'liver.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 1.3130e+03, 2.6000e+01, 1.6240e+03, 7.0000e+02, 8.1500e+02,\n",
            "        2.4000e+01, 1.0000e+00, 7.7000e+01, 5.0000e+00, 1.0900e+02, 1.0000e+00,\n",
            "        2.1310e+03, 1.3150e+03, 2.8540e+03, 5.0000e+00, 1.3140e+03, 9.0000e+00,\n",
            "        1.3130e+03, 2.6000e+01, 1.6240e+03, 7.0000e+02, 8.1500e+02, 2.4000e+01,\n",
            "        1.0000e+00, 7.7000e+01, 5.0000e+00, 1.0900e+02, 1.0000e+00, 2.1310e+03,\n",
            "        1.3150e+03, 2.8540e+03, 5.0000e+00, 1.3140e+03])\n",
            "['The', 'urinary', 'system', 'removes', 'waste', 'products', 'from', 'the', 'blood', 'and', 'includes', 'the', 'kidneys,', 'ureters,', 'bladder,', 'and', 'urethra.', 'The', 'urinary', 'system', 'removes', 'waste', 'products', 'from', 'the', 'blood', 'and', 'includes', 'the', 'kidneys,', 'ureters,', 'bladder,', 'and', 'urethra.']\n",
            "[('The', 'urinary'), ('urinary', 'system'), ('system', 'removes'), ('removes', 'waste'), ('waste', 'products'), ('products', 'from'), ('from', 'the'), ('the', 'blood'), ('blood', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'kidneys,'), ('kidneys,', 'ureters,'), ('ureters,', 'bladder,'), ('bladder,', 'and'), ('and', 'urethra.'), ('The', 'urinary'), ('urinary', 'system'), ('system', 'removes'), ('removes', 'waste'), ('waste', 'products'), ('products', 'from'), ('from', 'the'), ('the', 'blood'), ('blood', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'kidneys,'), ('kidneys,', 'ureters,'), ('ureters,', 'bladder,'), ('bladder,', 'and'), ('and', 'urethra.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([9.0000e+00, 1.0240e+03, 2.6000e+01, 7.9500e+02, 6.4700e+02, 2.8700e+02,\n",
            "        5.2000e+01, 3.9000e+02, 5.0000e+00, 1.0900e+02, 2.8500e+02, 4.0000e+01,\n",
            "        1.4000e+01, 1.0000e+00, 1.3870e+03, 1.8580e+03, 5.0000e+00, 1.1440e+03,\n",
            "        2.3240e+03, 9.0000e+00, 1.0240e+03, 2.6000e+01, 7.9500e+02, 6.4700e+02,\n",
            "        2.8700e+02, 5.2000e+01, 3.9000e+02, 5.0000e+00, 1.0900e+02, 2.8500e+02,\n",
            "        4.0000e+01, 1.4000e+01, 1.0000e+00, 1.3870e+03, 1.8580e+03, 5.0000e+00,\n",
            "        1.1440e+03, 2.3240e+03])\n",
            "['The', 'endocrine', 'system', 'regulates', 'bodily', 'functions', 'through', 'hormones', 'and', 'includes', 'glands', 'such', 'as', 'the', 'thyroid,', 'pancreas,', 'and', 'adrenal', 'glands.', 'The', 'endocrine', 'system', 'regulates', 'bodily', 'functions', 'through', 'hormones', 'and', 'includes', 'glands', 'such', 'as', 'the', 'thyroid,', 'pancreas,', 'and', 'adrenal', 'glands.']\n",
            "[('The', 'endocrine'), ('endocrine', 'system'), ('system', 'regulates'), ('regulates', 'bodily'), ('bodily', 'functions'), ('functions', 'through'), ('through', 'hormones'), ('hormones', 'and'), ('and', 'includes'), ('includes', 'glands'), ('glands', 'such'), ('such', 'as'), ('as', 'the'), ('the', 'thyroid,'), ('thyroid,', 'pancreas,'), ('pancreas,', 'and'), ('and', 'adrenal'), ('adrenal', 'glands.'), ('The', 'endocrine'), ('endocrine', 'system'), ('system', 'regulates'), ('regulates', 'bodily'), ('bodily', 'functions'), ('functions', 'through'), ('through', 'hormones'), ('hormones', 'and'), ('and', 'includes'), ('includes', 'glands'), ('glands', 'such'), ('such', 'as'), ('as', 'the'), ('the', 'thyroid,'), ('thyroid,', 'pancreas,'), ('pancreas,', 'and'), ('and', 'adrenal'), ('adrenal', 'glands.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([9.0000e+00, 4.9800e+02, 2.6000e+01, 1.0300e+03, 1.0000e+00, 3.5200e+02,\n",
            "        2.0000e+00, 1.9050e+03, 5.0000e+00, 1.0900e+02, 1.0000e+00, 1.8670e+03,\n",
            "        1.4070e+03, 5.0000e+00, 4.2200e+02, 4.7200e+02, 9.0000e+00, 4.9800e+02,\n",
            "        2.6000e+01, 1.0300e+03, 1.0000e+00, 3.5200e+02, 2.0000e+00, 1.9050e+03,\n",
            "        5.0000e+00, 1.0900e+02, 1.0000e+00, 1.8670e+03, 1.4070e+03, 5.0000e+00,\n",
            "        4.2200e+02, 4.7200e+02])\n",
            "['The', 'reproductive', 'system', 'enables', 'the', 'production', 'of', 'offspring', 'and', 'includes', 'the', 'ovaries,', 'testes,', 'and', 'associated', 'structures.', 'The', 'reproductive', 'system', 'enables', 'the', 'production', 'of', 'offspring', 'and', 'includes', 'the', 'ovaries,', 'testes,', 'and', 'associated', 'structures.']\n",
            "[('The', 'reproductive'), ('reproductive', 'system'), ('system', 'enables'), ('enables', 'the'), ('the', 'production'), ('production', 'of'), ('of', 'offspring'), ('offspring', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'ovaries,'), ('ovaries,', 'testes,'), ('testes,', 'and'), ('and', 'associated'), ('associated', 'structures.'), ('The', 'reproductive'), ('reproductive', 'system'), ('system', 'enables'), ('enables', 'the'), ('the', 'production'), ('production', 'of'), ('of', 'offspring'), ('offspring', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'ovaries,'), ('ovaries,', 'testes,'), ('testes,', 'and'), ('and', 'associated'), ('associated', 'structures.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([9.0000e+00, 2.1790e+03, 2.6000e+01, 2.6100e+02, 1.0000e+00, 5.0000e+01,\n",
            "        2.4000e+01, 1.8600e+02, 2.6450e+03, 5.0000e+00, 1.0900e+02, 1.0000e+00,\n",
            "        4.8300e+02, 2.2980e+03, 5.0000e+00, 1.9620e+03, 9.0000e+00, 2.1790e+03,\n",
            "        2.6000e+01, 2.6100e+02, 1.0000e+00, 5.0000e+01, 2.4000e+01, 1.8600e+02,\n",
            "        2.6450e+03, 5.0000e+00, 1.0900e+02, 1.0000e+00, 4.8300e+02, 2.2980e+03,\n",
            "        5.0000e+00, 1.9620e+03])\n",
            "['The', 'integumentary', 'system', 'protects', 'the', 'body', 'from', 'external', 'damage', 'and', 'includes', 'the', 'skin,', 'hair,', 'and', 'nails.', 'The', 'integumentary', 'system', 'protects', 'the', 'body', 'from', 'external', 'damage', 'and', 'includes', 'the', 'skin,', 'hair,', 'and', 'nails.']\n",
            "[('The', 'integumentary'), ('integumentary', 'system'), ('system', 'protects'), ('protects', 'the'), ('the', 'body'), ('body', 'from'), ('from', 'external'), ('external', 'damage'), ('damage', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'skin,'), ('skin,', 'hair,'), ('hair,', 'and'), ('and', 'nails.'), ('The', 'integumentary'), ('integumentary', 'system'), ('system', 'protects'), ('protects', 'the'), ('the', 'body'), ('body', 'from'), ('from', 'external'), ('external', 'damage'), ('damage', 'and'), ('and', 'includes'), ('includes', 'the'), ('the', 'skin,'), ('skin,', 'hair,'), ('hair,', 'and'), ('and', 'nails.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 2.8000e+02, 2.6000e+01, 2.6320e+03, 1.0000e+00, 5.0000e+01,\n",
            "        1.9500e+02, 2.2120e+03, 5.0000e+00, 1.0900e+02, 1.2530e+03, 7.7000e+01,\n",
            "        1.1000e+03, 2.0600e+03, 1.9380e+03, 5.0000e+00, 2.9420e+03, 9.0000e+00,\n",
            "        2.8000e+02, 2.6000e+01, 2.6320e+03, 1.0000e+00, 5.0000e+01, 1.9500e+02,\n",
            "        2.2120e+03, 5.0000e+00, 1.0900e+02, 1.2530e+03, 7.7000e+01, 1.1000e+03,\n",
            "        2.0600e+03, 1.9380e+03, 5.0000e+00, 2.9420e+03])\n",
            "['The', 'immune', 'system', 'defends', 'the', 'body', 'against', 'infections', 'and', 'includes', 'white', 'blood', 'cells,', 'lymph', 'nodes,', 'and', 'antibodies.', 'The', 'immune', 'system', 'defends', 'the', 'body', 'against', 'infections', 'and', 'includes', 'white', 'blood', 'cells,', 'lymph', 'nodes,', 'and', 'antibodies.']\n",
            "[('The', 'immune'), ('immune', 'system'), ('system', 'defends'), ('defends', 'the'), ('the', 'body'), ('body', 'against'), ('against', 'infections'), ('infections', 'and'), ('and', 'includes'), ('includes', 'white'), ('white', 'blood'), ('blood', 'cells,'), ('cells,', 'lymph'), ('lymph', 'nodes,'), ('nodes,', 'and'), ('and', 'antibodies.'), ('The', 'immune'), ('immune', 'system'), ('system', 'defends'), ('defends', 'the'), ('the', 'body'), ('body', 'against'), ('against', 'infections'), ('infections', 'and'), ('and', 'includes'), ('includes', 'white'), ('white', 'blood'), ('blood', 'cells,'), ('cells,', 'lymph'), ('lymph', 'nodes,'), ('nodes,', 'and'), ('and', 'antibodies.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([3.2820e+03, 3.0000e+00, 1.0000e+00, 9.0100e+02, 2.0000e+00, 4.0000e+00,\n",
            "        7.5400e+02, 3.8500e+02, 2.4940e+03, 1.6400e+02, 1.0000e+00, 1.3400e+02,\n",
            "        3.2820e+03, 3.0000e+00, 1.0000e+00, 9.0100e+02, 2.0000e+00, 4.0000e+00,\n",
            "        7.5400e+02, 3.8500e+02, 2.4940e+03, 1.6400e+02, 1.0000e+00, 1.3400e+02])\n",
            "['Homeostasis', 'is', 'the', 'maintenance', 'of', 'a', 'stable', 'internal', 'environment', 'within', 'the', 'body.', 'Homeostasis', 'is', 'the', 'maintenance', 'of', 'a', 'stable', 'internal', 'environment', 'within', 'the', 'body.']\n",
            "[('Homeostasis', 'is'), ('is', 'the'), ('the', 'maintenance'), ('maintenance', 'of'), ('of', 'a'), ('a', 'stable'), ('stable', 'internal'), ('internal', 'environment'), ('environment', 'within'), ('within', 'the'), ('the', 'body.'), ('Homeostasis', 'is'), ('is', 'the'), ('the', 'maintenance'), ('maintenance', 'of'), ('of', 'a'), ('a', 'stable'), ('stable', 'internal'), ('internal', 'environment'), ('environment', 'within'), ('within', 'the'), ('the', 'body.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 1.1010e+03, 3.0000e+00, 1.0000e+00, 6.5000e+02, 1.2700e+02,\n",
            "        2.0000e+00, 1.4600e+02, 5.0000e+00, 1.6000e+01, 2.5000e+01, 2.7680e+03,\n",
            "        1.4000e+01, 1.7210e+03, 1.0000e+01, 2.4790e+03, 1.1000e+01, 1.1010e+03,\n",
            "        3.0000e+00, 1.0000e+00, 6.5000e+02, 1.2700e+02, 2.0000e+00, 1.4600e+02,\n",
            "        5.0000e+00, 1.6000e+01, 2.5000e+01, 2.7680e+03, 1.4000e+01, 1.7210e+03,\n",
            "        1.0000e+01, 2.4790e+03])\n",
            "['A', 'cell', 'is', 'the', 'basic', 'unit', 'of', 'life', 'and', 'can', 'be', 'classified', 'as', 'prokaryotic', 'or', 'eukaryotic.', 'A', 'cell', 'is', 'the', 'basic', 'unit', 'of', 'life', 'and', 'can', 'be', 'classified', 'as', 'prokaryotic', 'or', 'eukaryotic.']\n",
            "[('A', 'cell'), ('cell', 'is'), ('is', 'the'), ('the', 'basic'), ('basic', 'unit'), ('unit', 'of'), ('of', 'life'), ('life', 'and'), ('and', 'can'), ('can', 'be'), ('be', 'classified'), ('classified', 'as'), ('as', 'prokaryotic'), ('prokaryotic', 'or'), ('or', 'eukaryotic.'), ('A', 'cell'), ('cell', 'is'), ('is', 'the'), ('the', 'basic'), ('basic', 'unit'), ('unit', 'of'), ('of', 'life'), ('life', 'and'), ('and', 'can'), ('can', 'be'), ('be', 'classified'), ('classified', 'as'), ('as', 'prokaryotic'), ('prokaryotic', 'or'), ('or', 'eukaryotic.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([3.0640e+03, 1.3000e+01, 5.7300e+02, 2.0000e+00, 7.7000e+02, 4.1400e+02,\n",
            "        7.0000e+00, 1.7800e+02, 4.0000e+00, 8.0000e+01, 1.4900e+02, 5.0000e+00,\n",
            "        2.2400e+02, 2.4900e+03, 2.7140e+03, 1.9720e+03, 5.0000e+00, 3.7100e+02,\n",
            "        7.1800e+02, 3.0640e+03, 1.3000e+01, 5.7300e+02, 2.0000e+00, 7.7000e+02,\n",
            "        4.1400e+02, 7.0000e+00, 1.7800e+02, 4.0000e+00, 8.0000e+01, 1.4900e+02,\n",
            "        5.0000e+00, 2.2400e+02, 2.4900e+03, 2.7140e+03, 1.9720e+03, 5.0000e+00,\n",
            "        3.7100e+02, 7.1800e+02])\n",
            "['Tissues', 'are', 'groups', 'of', 'similar', 'cells', 'that', 'perform', 'a', 'specific', 'function', 'and', 'include', 'epithelial,', 'connective,', 'muscle,', 'and', 'nervous', 'tissues.', 'Tissues', 'are', 'groups', 'of', 'similar', 'cells', 'that', 'perform', 'a', 'specific', 'function', 'and', 'include', 'epithelial,', 'connective,', 'muscle,', 'and', 'nervous', 'tissues.']\n",
            "[('Tissues', 'are'), ('are', 'groups'), ('groups', 'of'), ('of', 'similar'), ('similar', 'cells'), ('cells', 'that'), ('that', 'perform'), ('perform', 'a'), ('a', 'specific'), ('specific', 'function'), ('function', 'and'), ('and', 'include'), ('include', 'epithelial,'), ('epithelial,', 'connective,'), ('connective,', 'muscle,'), ('muscle,', 'and'), ('and', 'nervous'), ('nervous', 'tissues.'), ('Tissues', 'are'), ('are', 'groups'), ('groups', 'of'), ('of', 'similar'), ('similar', 'cells'), ('cells', 'that'), ('that', 'perform'), ('perform', 'a'), ('a', 'specific'), ('specific', 'function'), ('function', 'and'), ('and', 'include'), ('include', 'epithelial,'), ('epithelial,', 'connective,'), ('connective,', 'muscle,'), ('muscle,', 'and'), ('and', 'nervous'), ('nervous', 'tissues.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([3.1760e+03, 1.3000e+01, 2.0700e+02, 4.0900e+02, 2.0000e+00, 8.4000e+01,\n",
            "        7.1900e+02, 7.0000e+00, 1.7800e+02, 8.0000e+01, 5.8500e+02, 4.0000e+01,\n",
            "        1.4000e+01, 1.0000e+00, 5.7200e+02, 2.0820e+03, 5.0000e+00, 2.8430e+03,\n",
            "        3.1760e+03, 1.3000e+01, 2.0700e+02, 4.0900e+02, 2.0000e+00, 8.4000e+01,\n",
            "        7.1900e+02, 7.0000e+00, 1.7800e+02, 8.0000e+01, 5.8500e+02, 4.0000e+01,\n",
            "        1.4000e+01, 1.0000e+00, 5.7200e+02, 2.0820e+03, 5.0000e+00, 2.8430e+03])\n",
            "['Organs', 'are', 'structures', 'composed', 'of', 'different', 'tissues', 'that', 'perform', 'specific', 'functions,', 'such', 'as', 'the', 'heart,', 'liver,', 'and', 'brain.', 'Organs', 'are', 'structures', 'composed', 'of', 'different', 'tissues', 'that', 'perform', 'specific', 'functions,', 'such', 'as', 'the', 'heart,', 'liver,', 'and', 'brain.']\n",
            "[('Organs', 'are'), ('are', 'structures'), ('structures', 'composed'), ('composed', 'of'), ('of', 'different'), ('different', 'tissues'), ('tissues', 'that'), ('that', 'perform'), ('perform', 'specific'), ('specific', 'functions,'), ('functions,', 'such'), ('such', 'as'), ('as', 'the'), ('the', 'heart,'), ('heart,', 'liver,'), ('liver,', 'and'), ('and', 'brain.'), ('Organs', 'are'), ('are', 'structures'), ('structures', 'composed'), ('composed', 'of'), ('of', 'different'), ('different', 'tissues'), ('tissues', 'that'), ('that', 'perform'), ('perform', 'specific'), ('specific', 'functions,'), ('functions,', 'such'), ('such', 'as'), ('as', 'the'), ('the', 'heart,'), ('heart,', 'liver,'), ('liver,', 'and'), ('and', 'brain.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([3.0790e+03, 1.3000e+01, 5.7300e+02, 2.0000e+00, 5.2600e+02, 7.0000e+00,\n",
            "        1.6200e+02, 2.0300e+02, 6.0000e+00, 1.7800e+02, 1.2300e+02, 5.8500e+02,\n",
            "        4.0000e+01, 1.4000e+01, 1.0000e+00, 6.1600e+02, 5.0000e+00, 4.9600e+02,\n",
            "        4.6500e+02, 3.0790e+03, 1.3000e+01, 5.7300e+02, 2.0000e+00, 5.2600e+02,\n",
            "        7.0000e+00, 1.6200e+02, 2.0300e+02, 6.0000e+00, 1.7800e+02, 1.2300e+02,\n",
            "        5.8500e+02, 4.0000e+01, 1.4000e+01, 1.0000e+00, 6.1600e+02, 5.0000e+00,\n",
            "        4.9600e+02, 4.6500e+02])\n",
            "['Systems', 'are', 'groups', 'of', 'organs', 'that', 'work', 'together', 'to', 'perform', 'complex', 'functions,', 'such', 'as', 'the', 'digestive', 'and', 'respiratory', 'systems.', 'Systems', 'are', 'groups', 'of', 'organs', 'that', 'work', 'together', 'to', 'perform', 'complex', 'functions,', 'such', 'as', 'the', 'digestive', 'and', 'respiratory', 'systems.']\n",
            "[('Systems', 'are'), ('are', 'groups'), ('groups', 'of'), ('of', 'organs'), ('organs', 'that'), ('that', 'work'), ('work', 'together'), ('together', 'to'), ('to', 'perform'), ('perform', 'complex'), ('complex', 'functions,'), ('functions,', 'such'), ('such', 'as'), ('as', 'the'), ('the', 'digestive'), ('digestive', 'and'), ('and', 'respiratory'), ('respiratory', 'systems.'), ('Systems', 'are'), ('are', 'groups'), ('groups', 'of'), ('of', 'organs'), ('organs', 'that'), ('that', 'work'), ('work', 'together'), ('together', 'to'), ('to', 'perform'), ('perform', 'complex'), ('complex', 'functions,'), ('functions,', 'such'), ('such', 'as'), ('as', 'the'), ('the', 'digestive'), ('digestive', 'and'), ('and', 'respiratory'), ('respiratory', 'systems.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([9.0000e+00, 1.5200e+03, 2.6100e+02, 1.0000e+00, 3.0100e+02, 5.0000e+00,\n",
            "        3.3300e+02, 1.0000e+00, 2.0700e+02, 2.0000e+00, 1.0000e+00, 2.4330e+03,\n",
            "        9.0000e+00, 1.5200e+03, 2.6100e+02, 1.0000e+00, 3.0100e+02, 5.0000e+00,\n",
            "        3.3300e+02, 1.0000e+00, 2.0700e+02, 2.0000e+00, 1.0000e+00, 2.4330e+03])\n",
            "['The', 'skull', 'protects', 'the', 'brain', 'and', 'supports', 'the', 'structures', 'of', 'the', 'face.', 'The', 'skull', 'protects', 'the', 'brain', 'and', 'supports', 'the', 'structures', 'of', 'the', 'face.']\n",
            "[('The', 'skull'), ('skull', 'protects'), ('protects', 'the'), ('the', 'brain'), ('brain', 'and'), ('and', 'supports'), ('supports', 'the'), ('the', 'structures'), ('structures', 'of'), ('of', 'the'), ('the', 'face.'), ('The', 'skull'), ('skull', 'protects'), ('protects', 'the'), ('the', 'brain'), ('brain', 'and'), ('and', 'supports'), ('supports', 'the'), ('the', 'structures'), ('structures', 'of'), ('of', 'the'), ('the', 'face.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([9.0000e+00, 1.2960e+03, 2.7550e+03, 1.0000e+01, 1.4880e+03, 2.6100e+02,\n",
            "        1.0000e+00, 4.7500e+02, 1.0720e+03, 5.0000e+00, 3.3300e+02, 1.0000e+00,\n",
            "        1.3400e+02, 9.0000e+00, 1.2960e+03, 2.7550e+03, 1.0000e+01, 1.4880e+03,\n",
            "        2.6100e+02, 1.0000e+00, 4.7500e+02, 1.0720e+03, 5.0000e+00, 3.3300e+02,\n",
            "        1.0000e+00, 1.3400e+02])\n",
            "['The', 'vertebral', 'column,', 'or', 'spine,', 'protects', 'the', 'spinal', 'cord', 'and', 'supports', 'the', 'body.', 'The', 'vertebral', 'column,', 'or', 'spine,', 'protects', 'the', 'spinal', 'cord', 'and', 'supports', 'the', 'body.']\n",
            "[('The', 'vertebral'), ('vertebral', 'column,'), ('column,', 'or'), ('or', 'spine,'), ('spine,', 'protects'), ('protects', 'the'), ('the', 'spinal'), ('spinal', 'cord'), ('cord', 'and'), ('and', 'supports'), ('supports', 'the'), ('the', 'body.'), ('The', 'vertebral'), ('vertebral', 'column,'), ('column,', 'or'), ('or', 'spine,'), ('spine,', 'protects'), ('protects', 'the'), ('the', 'spinal'), ('spinal', 'cord'), ('cord', 'and'), ('and', 'supports'), ('supports', 'the'), ('the', 'body.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([9.0000e+00, 1.5900e+03, 2.8230e+03, 2.6100e+02, 1.0000e+00, 2.8400e+02,\n",
            "        5.0000e+00, 9.0400e+02, 5.0000e+00, 3.3300e+02, 1.0000e+00, 7.0900e+02,\n",
            "        1.3400e+02, 9.0000e+00, 1.5900e+03, 2.8230e+03, 2.6100e+02, 1.0000e+00,\n",
            "        2.8400e+02, 5.0000e+00, 9.0400e+02, 5.0000e+00, 3.3300e+02, 1.0000e+00,\n",
            "        7.0900e+02, 1.3400e+02])\n",
            "['The', 'rib', 'cage', 'protects', 'the', 'heart', 'and', 'lungs', 'and', 'supports', 'the', 'upper', 'body.', 'The', 'rib', 'cage', 'protects', 'the', 'heart', 'and', 'lungs', 'and', 'supports', 'the', 'upper', 'body.']\n",
            "[('The', 'rib'), ('rib', 'cage'), ('cage', 'protects'), ('protects', 'the'), ('the', 'heart'), ('heart', 'and'), ('and', 'lungs'), ('lungs', 'and'), ('and', 'supports'), ('supports', 'the'), ('the', 'upper'), ('upper', 'body.'), ('The', 'rib'), ('rib', 'cage'), ('cage', 'protects'), ('protects', 'the'), ('the', 'heart'), ('heart', 'and'), ('and', 'lungs'), ('lungs', 'and'), ('and', 'supports'), ('supports', 'the'), ('the', 'upper'), ('upper', 'body.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 1.8330e+03, 3.3300e+02, 1.0000e+00, 9.0500e+02, 5.0000e+01,\n",
            "        5.0000e+00, 2.6100e+02, 3.8500e+02, 5.2600e+02, 4.0000e+01, 1.4000e+01,\n",
            "        1.0000e+00, 1.1110e+03, 5.0000e+00, 4.9800e+02, 1.8850e+03, 9.0000e+00,\n",
            "        1.8330e+03, 3.3300e+02, 1.0000e+00, 9.0500e+02, 5.0000e+01, 5.0000e+00,\n",
            "        2.6100e+02, 3.8500e+02, 5.2600e+02, 4.0000e+01, 1.4000e+01, 1.0000e+00,\n",
            "        1.1110e+03, 5.0000e+00, 4.9800e+02, 1.8850e+03])\n",
            "['The', 'pelvis', 'supports', 'the', 'lower', 'body', 'and', 'protects', 'internal', 'organs', 'such', 'as', 'the', 'bladder', 'and', 'reproductive', 'organs.', 'The', 'pelvis', 'supports', 'the', 'lower', 'body', 'and', 'protects', 'internal', 'organs', 'such', 'as', 'the', 'bladder', 'and', 'reproductive', 'organs.']\n",
            "[('The', 'pelvis'), ('pelvis', 'supports'), ('supports', 'the'), ('the', 'lower'), ('lower', 'body'), ('body', 'and'), ('and', 'protects'), ('protects', 'internal'), ('internal', 'organs'), ('organs', 'such'), ('such', 'as'), ('as', 'the'), ('the', 'bladder'), ('bladder', 'and'), ('and', 'reproductive'), ('reproductive', 'organs.'), ('The', 'pelvis'), ('pelvis', 'supports'), ('supports', 'the'), ('the', 'lower'), ('lower', 'body'), ('body', 'and'), ('and', 'protects'), ('protects', 'internal'), ('internal', 'organs'), ('organs', 'such'), ('such', 'as'), ('as', 'the'), ('the', 'bladder'), ('bladder', 'and'), ('and', 'reproductive'), ('reproductive', 'organs.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([9.0000e+00, 2.2640e+03, 1.6830e+03, 5.0000e+00, 1.3350e+03, 1.3000e+01,\n",
            "        1.0000e+00, 9.0000e+02, 4.1900e+02, 2.0000e+00, 1.0000e+00, 2.9250e+03,\n",
            "        9.0000e+00, 2.2640e+03, 1.6830e+03, 5.0000e+00, 1.3350e+03, 1.3000e+01,\n",
            "        1.0000e+00, 9.0000e+02, 4.1900e+02, 2.0000e+00, 1.0000e+00, 2.9250e+03])\n",
            "['The', 'humerus,', 'radius,', 'and', 'ulna', 'are', 'the', 'major', 'bones', 'of', 'the', 'arm.', 'The', 'humerus,', 'radius,', 'and', 'ulna', 'are', 'the', 'major', 'bones', 'of', 'the', 'arm.']\n",
            "[('The', 'humerus,'), ('humerus,', 'radius,'), ('radius,', 'and'), ('and', 'ulna'), ('ulna', 'are'), ('are', 'the'), ('the', 'major'), ('major', 'bones'), ('bones', 'of'), ('of', 'the'), ('the', 'arm.'), ('The', 'humerus,'), ('humerus,', 'radius,'), ('radius,', 'and'), ('and', 'ulna'), ('ulna', 'are'), ('are', 'the'), ('the', 'major'), ('major', 'bones'), ('bones', 'of'), ('of', 'the'), ('the', 'arm.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([9.0000e+00, 2.4030e+03, 1.3860e+03, 5.0000e+00, 2.4000e+03, 1.3000e+01,\n",
            "        1.0000e+00, 9.0000e+02, 4.1900e+02, 2.0000e+00, 1.0000e+00, 2.1140e+03,\n",
            "        9.0000e+00, 2.4030e+03, 1.3860e+03, 5.0000e+00, 2.4000e+03, 1.3000e+01,\n",
            "        1.0000e+00, 9.0000e+02, 4.1900e+02, 2.0000e+00, 1.0000e+00, 2.1140e+03])\n",
            "['The', 'femur,', 'tibia,', 'and', 'fibula', 'are', 'the', 'major', 'bones', 'of', 'the', 'leg.', 'The', 'femur,', 'tibia,', 'and', 'fibula', 'are', 'the', 'major', 'bones', 'of', 'the', 'leg.']\n",
            "[('The', 'femur,'), ('femur,', 'tibia,'), ('tibia,', 'and'), ('and', 'fibula'), ('fibula', 'are'), ('are', 'the'), ('the', 'major'), ('major', 'bones'), ('bones', 'of'), ('of', 'the'), ('the', 'leg.'), ('The', 'femur,'), ('femur,', 'tibia,'), ('tibia,', 'and'), ('and', 'fibula'), ('fibula', 'are'), ('are', 'the'), ('the', 'major'), ('major', 'bones'), ('bones', 'of'), ('of', 'the'), ('the', 'leg.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3254.,   13., 2715.,   35.,  419.,    7., 2965.,   12.,  533.,    5.,\n",
            "         224., 2274., 2882.,    5., 1793.,  929., 3254.,   13., 2715.,   35.,\n",
            "         419.,    7., 2965.,   12.,  533.,    5.,  224., 2274., 2882.,    5.,\n",
            "        1793.,  929.])\n",
            "['Joints', 'are', 'connections', 'between', 'bones', 'that', 'allow', 'for', 'movement', 'and', 'include', 'hinge,', 'ball-and-socket,', 'and', 'pivot', 'joints.', 'Joints', 'are', 'connections', 'between', 'bones', 'that', 'allow', 'for', 'movement', 'and', 'include', 'hinge,', 'ball-and-socket,', 'and', 'pivot', 'joints.']\n",
            "[('Joints', 'are'), ('are', 'connections'), ('connections', 'between'), ('between', 'bones'), ('bones', 'that'), ('that', 'allow'), ('allow', 'for'), ('for', 'movement'), ('movement', 'and'), ('and', 'include'), ('include', 'hinge,'), ('hinge,', 'ball-and-socket,'), ('ball-and-socket,', 'and'), ('and', 'pivot'), ('pivot', 'joints.'), ('Joints', 'are'), ('are', 'connections'), ('connections', 'between'), ('between', 'bones'), ('bones', 'that'), ('that', 'allow'), ('allow', 'for'), ('for', 'movement'), ('movement', 'and'), ('and', 'include'), ('include', 'hinge,'), ('hinge,', 'ball-and-socket,'), ('ball-and-socket,', 'and'), ('and', 'pivot'), ('pivot', 'joints.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([3.2390e+03, 1.3000e+01, 1.1230e+03, 2.0000e+00, 6.3100e+02, 3.2900e+02,\n",
            "        7.0000e+00, 6.3200e+02, 4.1900e+02, 6.0000e+00, 5.8000e+01, 1.1080e+03,\n",
            "        3.2390e+03, 1.3000e+01, 1.1230e+03, 2.0000e+00, 6.3100e+02, 3.2900e+02,\n",
            "        7.0000e+00, 6.3200e+02, 4.1900e+02, 6.0000e+00, 5.8000e+01, 1.1080e+03])\n",
            "['Ligaments', 'are', 'bands', 'of', 'connective', 'tissue', 'that', 'connect', 'bones', 'to', 'other', 'bones.', 'Ligaments', 'are', 'bands', 'of', 'connective', 'tissue', 'that', 'connect', 'bones', 'to', 'other', 'bones.']\n",
            "[('Ligaments', 'are'), ('are', 'bands'), ('bands', 'of'), ('of', 'connective'), ('connective', 'tissue'), ('tissue', 'that'), ('that', 'connect'), ('connect', 'bones'), ('bones', 'to'), ('to', 'other'), ('other', 'bones.'), ('Ligaments', 'are'), ('are', 'bands'), ('bands', 'of'), ('of', 'connective'), ('connective', 'tissue'), ('tissue', 'that'), ('that', 'connect'), ('connect', 'bones'), ('bones', 'to'), ('to', 'other'), ('other', 'bones.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.0740e+03, 1.3000e+01, 1.1230e+03, 2.0000e+00, 6.3100e+02, 3.2900e+02,\n",
            "        7.0000e+00, 6.3200e+02, 1.9710e+03, 6.0000e+00, 1.1080e+03, 3.0740e+03,\n",
            "        1.3000e+01, 1.1230e+03, 2.0000e+00, 6.3100e+02, 3.2900e+02, 7.0000e+00,\n",
            "        6.3200e+02, 1.9710e+03, 6.0000e+00, 1.1080e+03])\n",
            "['Tendons', 'are', 'bands', 'of', 'connective', 'tissue', 'that', 'connect', 'muscles', 'to', 'bones.', 'Tendons', 'are', 'bands', 'of', 'connective', 'tissue', 'that', 'connect', 'muscles', 'to', 'bones.']\n",
            "[('Tendons', 'are'), ('are', 'bands'), ('bands', 'of'), ('of', 'connective'), ('connective', 'tissue'), ('tissue', 'that'), ('that', 'connect'), ('connect', 'muscles'), ('muscles', 'to'), ('to', 'bones.'), ('Tendons', 'are'), ('are', 'bands'), ('bands', 'of'), ('of', 'connective'), ('connective', 'tissue'), ('tissue', 'that'), ('that', 'connect'), ('connect', 'muscles'), ('muscles', 'to'), ('to', 'bones.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.4030e+03, 3.0000e+00, 4.0000e+00, 5.9400e+02, 6.3100e+02, 3.2900e+02,\n",
            "        7.0000e+00, 1.3900e+02, 2.6520e+03, 5.0000e+00, 4.6900e+02, 1.2000e+01,\n",
            "        9.2900e+02, 3.4030e+03, 3.0000e+00, 4.0000e+00, 5.9400e+02, 6.3100e+02,\n",
            "        3.2900e+02, 7.0000e+00, 1.3900e+02, 2.6520e+03, 5.0000e+00, 4.6900e+02,\n",
            "        1.2000e+01, 9.2900e+02])\n",
            "['Cartilage', 'is', 'a', 'flexible', 'connective', 'tissue', 'that', 'provides', 'cushioning', 'and', 'support', 'for', 'joints.', 'Cartilage', 'is', 'a', 'flexible', 'connective', 'tissue', 'that', 'provides', 'cushioning', 'and', 'support', 'for', 'joints.']\n",
            "[('Cartilage', 'is'), ('is', 'a'), ('a', 'flexible'), ('flexible', 'connective'), ('connective', 'tissue'), ('tissue', 'that'), ('that', 'provides'), ('provides', 'cushioning'), ('cushioning', 'and'), ('and', 'support'), ('support', 'for'), ('for', 'joints.'), ('Cartilage', 'is'), ('is', 'a'), ('a', 'flexible'), ('flexible', 'connective'), ('connective', 'tissue'), ('tissue', 'that'), ('that', 'provides'), ('provides', 'cushioning'), ('cushioning', 'and'), ('and', 'support'), ('support', 'for'), ('for', 'joints.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([9.0000e+00, 3.0100e+02, 3.0000e+00, 1.0000e+00, 6.2700e+02, 2.8000e+03,\n",
            "        2.0000e+00, 1.0000e+00, 3.7100e+02, 2.6000e+01, 5.0000e+00, 3.0000e+00,\n",
            "        2.5720e+03, 6.9000e+01, 1.0000e+00, 2.7980e+03, 2.7990e+03, 5.0000e+00,\n",
            "        2.8420e+03, 9.0000e+00, 3.0100e+02, 3.0000e+00, 1.0000e+00, 6.2700e+02,\n",
            "        2.8000e+03, 2.0000e+00, 1.0000e+00, 3.7100e+02, 2.6000e+01, 5.0000e+00,\n",
            "        3.0000e+00, 2.5720e+03, 6.9000e+01, 1.0000e+00, 2.7980e+03, 2.7990e+03,\n",
            "        5.0000e+00, 2.8420e+03])\n",
            "['The', 'brain', 'is', 'the', 'control', 'center', 'of', 'the', 'nervous', 'system', 'and', 'is', 'divided', 'into', 'the', 'cerebrum,', 'cerebellum,', 'and', 'brainstem.', 'The', 'brain', 'is', 'the', 'control', 'center', 'of', 'the', 'nervous', 'system', 'and', 'is', 'divided', 'into', 'the', 'cerebrum,', 'cerebellum,', 'and', 'brainstem.']\n",
            "[('The', 'brain'), ('brain', 'is'), ('is', 'the'), ('the', 'control'), ('control', 'center'), ('center', 'of'), ('of', 'the'), ('the', 'nervous'), ('nervous', 'system'), ('system', 'and'), ('and', 'is'), ('is', 'divided'), ('divided', 'into'), ('into', 'the'), ('the', 'cerebrum,'), ('cerebrum,', 'cerebellum,'), ('cerebellum,', 'and'), ('and', 'brainstem.'), ('The', 'brain'), ('brain', 'is'), ('is', 'the'), ('the', 'control'), ('control', 'center'), ('center', 'of'), ('of', 'the'), ('the', 'nervous'), ('nervous', 'system'), ('system', 'and'), ('and', 'is'), ('is', 'divided'), ('divided', 'into'), ('into', 'the'), ('the', 'cerebrum,'), ('cerebrum,', 'cerebellum,'), ('cerebellum,', 'and'), ('and', 'brainstem.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([9.0000e+00, 4.7500e+02, 1.0720e+03, 1.3550e+03, 7.7200e+02, 3.5000e+01,\n",
            "        1.0000e+00, 3.0100e+02, 5.0000e+00, 1.0000e+00, 7.8700e+02, 2.0000e+00,\n",
            "        1.0000e+00, 1.3400e+02, 9.0000e+00, 4.7500e+02, 1.0720e+03, 1.3550e+03,\n",
            "        7.7200e+02, 3.5000e+01, 1.0000e+00, 3.0100e+02, 5.0000e+00, 1.0000e+00,\n",
            "        7.8700e+02, 2.0000e+00, 1.0000e+00, 1.3400e+02])\n",
            "['The', 'spinal', 'cord', 'transmits', 'signals', 'between', 'the', 'brain', 'and', 'the', 'rest', 'of', 'the', 'body.', 'The', 'spinal', 'cord', 'transmits', 'signals', 'between', 'the', 'brain', 'and', 'the', 'rest', 'of', 'the', 'body.']\n",
            "[('The', 'spinal'), ('spinal', 'cord'), ('cord', 'transmits'), ('transmits', 'signals'), ('signals', 'between'), ('between', 'the'), ('the', 'brain'), ('brain', 'and'), ('and', 'the'), ('the', 'rest'), ('rest', 'of'), ('of', 'the'), ('the', 'body.'), ('The', 'spinal'), ('spinal', 'cord'), ('cord', 'transmits'), ('transmits', 'signals'), ('signals', 'between'), ('between', 'the'), ('the', 'brain'), ('brain', 'and'), ('and', 'the'), ('the', 'rest'), ('rest', 'of'), ('of', 'the'), ('the', 'body.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3197.,   13.,  477.,  414.,    7., 1356., 1952., 2232.,    5.,  224.,\n",
            "        1550., 1980.,    5., 2166., 3197.,   13.,  477.,  414.,    7., 1356.,\n",
            "        1952., 2232.,    5.,  224., 1550., 1980.,    5., 2166.])\n",
            "['Neurons', 'are', 'specialized', 'cells', 'that', 'transmit', 'nerve', 'impulses', 'and', 'include', 'sensory,', 'motor,', 'and', 'interneurons.', 'Neurons', 'are', 'specialized', 'cells', 'that', 'transmit', 'nerve', 'impulses', 'and', 'include', 'sensory,', 'motor,', 'and', 'interneurons.']\n",
            "[('Neurons', 'are'), ('are', 'specialized'), ('specialized', 'cells'), ('cells', 'that'), ('that', 'transmit'), ('transmit', 'nerve'), ('nerve', 'impulses'), ('impulses', 'and'), ('and', 'include'), ('include', 'sensory,'), ('sensory,', 'motor,'), ('motor,', 'and'), ('and', 'interneurons.'), ('Neurons', 'are'), ('are', 'specialized'), ('specialized', 'cells'), ('cells', 'that'), ('that', 'transmit'), ('transmit', 'nerve'), ('nerve', 'impulses'), ('impulses', 'and'), ('and', 'include'), ('include', 'sensory,'), ('sensory,', 'motor,'), ('motor,', 'and'), ('and', 'interneurons.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([9.0000e+00, 2.8400e+02, 3.0000e+00, 4.0000e+00, 8.8200e+02, 3.6700e+02,\n",
            "        7.0000e+00, 1.7000e+03, 7.7000e+01, 4.5500e+02, 1.0000e+00, 1.3400e+02,\n",
            "        9.0000e+00, 2.8400e+02, 3.0000e+00, 4.0000e+00, 8.8200e+02, 3.6700e+02,\n",
            "        7.0000e+00, 1.7000e+03, 7.7000e+01, 4.5500e+02, 1.0000e+00, 1.3400e+02])\n",
            "['The', 'heart', 'is', 'a', 'muscular', 'organ', 'that', 'pumps', 'blood', 'throughout', 'the', 'body.', 'The', 'heart', 'is', 'a', 'muscular', 'organ', 'that', 'pumps', 'blood', 'throughout', 'the', 'body.']\n",
            "[('The', 'heart'), ('heart', 'is'), ('is', 'a'), ('a', 'muscular'), ('muscular', 'organ'), ('organ', 'that'), ('that', 'pumps'), ('pumps', 'blood'), ('blood', 'throughout'), ('throughout', 'the'), ('the', 'body.'), ('The', 'heart'), ('heart', 'is'), ('is', 'a'), ('a', 'muscular'), ('muscular', 'organ'), ('organ', 'that'), ('that', 'pumps'), ('pumps', 'blood'), ('blood', 'throughout'), ('throughout', 'the'), ('the', 'body.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.4340e+03, 4.1600e+02, 1.8620e+03, 7.7000e+01, 2.8950e+03, 2.4000e+01,\n",
            "        1.0000e+00, 5.7200e+02, 1.9600e+02, 1.3010e+03, 4.1600e+02, 1.8630e+03,\n",
            "        7.7000e+01, 6.5200e+02, 6.0000e+00, 1.0000e+00, 9.6100e+02, 3.4340e+03,\n",
            "        4.1600e+02, 1.8620e+03, 7.7000e+01, 2.8950e+03, 2.4000e+01, 1.0000e+00,\n",
            "        5.7200e+02, 1.9600e+02, 1.3010e+03, 4.1600e+02, 1.8630e+03, 7.7000e+01,\n",
            "        6.5200e+02, 6.0000e+00, 1.0000e+00, 9.6100e+02])\n",
            "['Arteries', 'carry', 'oxygen-rich', 'blood', 'away', 'from', 'the', 'heart,', 'while', 'veins', 'carry', 'oxygen-poor', 'blood', 'back', 'to', 'the', 'heart.', 'Arteries', 'carry', 'oxygen-rich', 'blood', 'away', 'from', 'the', 'heart,', 'while', 'veins', 'carry', 'oxygen-poor', 'blood', 'back', 'to', 'the', 'heart.']\n",
            "[('Arteries', 'carry'), ('carry', 'oxygen-rich'), ('oxygen-rich', 'blood'), ('blood', 'away'), ('away', 'from'), ('from', 'the'), ('the', 'heart,'), ('heart,', 'while'), ('while', 'veins'), ('veins', 'carry'), ('carry', 'oxygen-poor'), ('oxygen-poor', 'blood'), ('blood', 'back'), ('back', 'to'), ('to', 'the'), ('the', 'heart.'), ('Arteries', 'carry'), ('carry', 'oxygen-rich'), ('oxygen-rich', 'blood'), ('blood', 'away'), ('away', 'from'), ('from', 'the'), ('the', 'heart,'), ('heart,', 'while'), ('while', 'veins'), ('veins', 'carry'), ('carry', 'oxygen-poor'), ('oxygen-poor', 'blood'), ('blood', 'back'), ('back', 'to'), ('to', 'the'), ('the', 'heart.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.4070e+03, 1.3000e+01, 1.3820e+03, 7.7000e+01, 1.2940e+03, 9.9000e+01,\n",
            "        1.0000e+00, 6.0100e+02, 2.0000e+00, 5.2400e+02, 3.0000e+02, 1.0500e+03,\n",
            "        5.0000e+00, 8.6900e+02, 1.9060e+03, 3.4070e+03, 1.3000e+01, 1.3820e+03,\n",
            "        7.7000e+01, 1.2940e+03, 9.9000e+01, 1.0000e+00, 6.0100e+02, 2.0000e+00,\n",
            "        5.2400e+02, 3.0000e+02, 1.0500e+03, 5.0000e+00, 8.6900e+02, 1.9060e+03])\n",
            "['Capillaries', 'are', 'tiny', 'blood', 'vessels', 'where', 'the', 'exchange', 'of', 'oxygen,', 'carbon', 'dioxide,', 'and', 'nutrients', 'occurs.', 'Capillaries', 'are', 'tiny', 'blood', 'vessels', 'where', 'the', 'exchange', 'of', 'oxygen,', 'carbon', 'dioxide,', 'and', 'nutrients', 'occurs.']\n",
            "[('Capillaries', 'are'), ('are', 'tiny'), ('tiny', 'blood'), ('blood', 'vessels'), ('vessels', 'where'), ('where', 'the'), ('the', 'exchange'), ('exchange', 'of'), ('of', 'oxygen,'), ('oxygen,', 'carbon'), ('carbon', 'dioxide,'), ('dioxide,', 'and'), ('and', 'nutrients'), ('nutrients', 'occurs.'), ('Capillaries', 'are'), ('are', 'tiny'), ('tiny', 'blood'), ('blood', 'vessels'), ('vessels', 'where'), ('where', 'the'), ('the', 'exchange'), ('exchange', 'of'), ('of', 'oxygen,'), ('oxygen,', 'carbon'), ('carbon', 'dioxide,'), ('dioxide,', 'and'), ('and', 'nutrients'), ('nutrients', 'occurs.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([9.0000e+00, 9.0400e+02, 1.3000e+01, 1.0000e+00, 2.6400e+02, 5.2600e+02,\n",
            "        2.0000e+00, 1.0000e+00, 4.9600e+02, 2.6000e+01, 5.0000e+00, 2.4320e+03,\n",
            "        9.7900e+02, 2.4630e+03, 9.0000e+00, 9.0400e+02, 1.3000e+01, 1.0000e+00,\n",
            "        2.6400e+02, 5.2600e+02, 2.0000e+00, 1.0000e+00, 4.9600e+02, 2.6000e+01,\n",
            "        5.0000e+00, 2.4320e+03, 9.7900e+02, 2.4630e+03])\n",
            "['The', 'lungs', 'are', 'the', 'primary', 'organs', 'of', 'the', 'respiratory', 'system', 'and', 'facilitate', 'gas', 'exchange.', 'The', 'lungs', 'are', 'the', 'primary', 'organs', 'of', 'the', 'respiratory', 'system', 'and', 'facilitate', 'gas', 'exchange.']\n",
            "[('The', 'lungs'), ('lungs', 'are'), ('are', 'the'), ('the', 'primary'), ('primary', 'organs'), ('organs', 'of'), ('of', 'the'), ('the', 'respiratory'), ('respiratory', 'system'), ('system', 'and'), ('and', 'facilitate'), ('facilitate', 'gas'), ('gas', 'exchange.'), ('The', 'lungs'), ('lungs', 'are'), ('are', 'the'), ('the', 'primary'), ('primary', 'organs'), ('organs', 'of'), ('of', 'the'), ('the', 'respiratory'), ('respiratory', 'system'), ('system', 'and'), ('and', 'facilitate'), ('facilitate', 'gas'), ('gas', 'exchange.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([9.0000e+00, 2.6030e+03, 3.0000e+00, 4.0000e+00, 1.9730e+03, 7.0000e+00,\n",
            "        1.7840e+03, 4.0000e+00, 1.0700e+03, 4.9300e+02, 8.0000e+00, 2.8370e+03,\n",
            "        1.8000e+01, 2.7000e+03, 5.0000e+00, 1.6310e+03, 6.0000e+00, 8.5000e+01,\n",
            "        1.0000e+00, 1.2760e+03, 2.0000e+00, 1.0000e+00, 1.3920e+03, 1.1020e+03,\n",
            "        9.0000e+00, 2.6030e+03, 3.0000e+00, 4.0000e+00, 1.9730e+03, 7.0000e+00,\n",
            "        1.7840e+03, 4.0000e+00, 1.0700e+03, 4.9300e+02, 8.0000e+00, 2.8370e+03,\n",
            "        1.8000e+01, 2.7000e+03, 5.0000e+00, 1.6310e+03, 6.0000e+00, 8.5000e+01,\n",
            "        1.0000e+00, 1.2760e+03, 2.0000e+00, 1.0000e+00, 1.3920e+03, 1.1020e+03])\n",
            "['The', 'diaphragm', 'is', 'a', 'muscle', 'that', 'plays', 'a', 'crucial', 'role', 'in', 'breathing', 'by', 'contracting', 'and', 'relaxing', 'to', 'change', 'the', 'volume', 'of', 'the', 'thoracic', 'cavity.', 'The', 'diaphragm', 'is', 'a', 'muscle', 'that', 'plays', 'a', 'crucial', 'role', 'in', 'breathing', 'by', 'contracting', 'and', 'relaxing', 'to', 'change', 'the', 'volume', 'of', 'the', 'thoracic', 'cavity.']\n",
            "[('The', 'diaphragm'), ('diaphragm', 'is'), ('is', 'a'), ('a', 'muscle'), ('muscle', 'that'), ('that', 'plays'), ('plays', 'a'), ('a', 'crucial'), ('crucial', 'role'), ('role', 'in'), ('in', 'breathing'), ('breathing', 'by'), ('by', 'contracting'), ('contracting', 'and'), ('and', 'relaxing'), ('relaxing', 'to'), ('to', 'change'), ('change', 'the'), ('the', 'volume'), ('volume', 'of'), ('of', 'the'), ('the', 'thoracic'), ('thoracic', 'cavity.'), ('The', 'diaphragm'), ('diaphragm', 'is'), ('is', 'a'), ('a', 'muscle'), ('muscle', 'that'), ('that', 'plays'), ('plays', 'a'), ('a', 'crucial'), ('crucial', 'role'), ('role', 'in'), ('in', 'breathing'), ('breathing', 'by'), ('by', 'contracting'), ('contracting', 'and'), ('and', 'relaxing'), ('relaxing', 'to'), ('to', 'change'), ('change', 'the'), ('the', 'volume'), ('volume', 'of'), ('of', 'the'), ('the', 'thoracic'), ('thoracic', 'cavity.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([9.0000e+00, 2.0830e+03, 8.1700e+02, 2.8630e+03, 2.2000e+01, 2.9730e+03,\n",
            "        8.0000e+00, 1.0000e+00, 1.0520e+03, 2.0000e+00, 2.4140e+03, 5.0000e+00,\n",
            "        2.6110e+03, 2.2920e+03, 1.4560e+03, 8.0000e+00, 1.0000e+00, 1.1100e+03,\n",
            "        9.0000e+00, 2.0830e+03, 8.1700e+02, 2.8630e+03, 2.2000e+01, 2.9730e+03,\n",
            "        8.0000e+00, 1.0000e+00, 1.0520e+03, 2.0000e+00, 2.4140e+03, 5.0000e+00,\n",
            "        2.6110e+03, 2.2920e+03, 1.4560e+03, 8.0000e+00, 1.0000e+00, 1.1100e+03])\n",
            "['The', 'liver', 'produces', 'bile,', 'which', 'aids', 'in', 'the', 'digestion', 'of', 'fats,', 'and', 'detoxifies', 'harmful', 'substances', 'in', 'the', 'blood.', 'The', 'liver', 'produces', 'bile,', 'which', 'aids', 'in', 'the', 'digestion', 'of', 'fats,', 'and', 'detoxifies', 'harmful', 'substances', 'in', 'the', 'blood.']\n",
            "[('The', 'liver'), ('liver', 'produces'), ('produces', 'bile,'), ('bile,', 'which'), ('which', 'aids'), ('aids', 'in'), ('in', 'the'), ('the', 'digestion'), ('digestion', 'of'), ('of', 'fats,'), ('fats,', 'and'), ('and', 'detoxifies'), ('detoxifies', 'harmful'), ('harmful', 'substances'), ('substances', 'in'), ('in', 'the'), ('the', 'blood.'), ('The', 'liver'), ('liver', 'produces'), ('produces', 'bile,'), ('bile,', 'which'), ('which', 'aids'), ('aids', 'in'), ('in', 'the'), ('the', 'digestion'), ('digestion', 'of'), ('of', 'fats,'), ('fats,', 'and'), ('and', 'detoxifies'), ('detoxifies', 'harmful'), ('harmful', 'substances'), ('substances', 'in'), ('in', 'the'), ('the', 'blood.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([   9., 1859.,  817., 2493.,    7., 1142.,    8., 1052.,    5.,  390.,\n",
            "          40.,   14., 2188.,    7.,  259.,   77., 1451.,  380.,    9., 1859.,\n",
            "         817., 2493.,    7., 1142.,    8., 1052.,    5.,  390.,   40.,   14.,\n",
            "        2188.,    7.,  259.,   77., 1451.,  380.])\n",
            "['The', 'pancreas', 'produces', 'enzymes', 'that', 'aid', 'in', 'digestion', 'and', 'hormones', 'such', 'as', 'insulin', 'that', 'regulate', 'blood', 'sugar', 'levels.', 'The', 'pancreas', 'produces', 'enzymes', 'that', 'aid', 'in', 'digestion', 'and', 'hormones', 'such', 'as', 'insulin', 'that', 'regulate', 'blood', 'sugar', 'levels.']\n",
            "[('The', 'pancreas'), ('pancreas', 'produces'), ('produces', 'enzymes'), ('enzymes', 'that'), ('that', 'aid'), ('aid', 'in'), ('in', 'digestion'), ('digestion', 'and'), ('and', 'hormones'), ('hormones', 'such'), ('such', 'as'), ('as', 'insulin'), ('insulin', 'that'), ('that', 'regulate'), ('regulate', 'blood'), ('blood', 'sugar'), ('sugar', 'levels.'), ('The', 'pancreas'), ('pancreas', 'produces'), ('produces', 'enzymes'), ('enzymes', 'that'), ('that', 'aid'), ('aid', 'in'), ('in', 'digestion'), ('digestion', 'and'), ('and', 'hormones'), ('hormones', 'such'), ('such', 'as'), ('as', 'insulin'), ('insulin', 'that'), ('that', 'regulate'), ('regulate', 'blood'), ('blood', 'sugar'), ('sugar', 'levels.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([9.0000e+00, 4.8200e+02, 9.3700e+02, 3.0000e+00, 1.0000e+00, 2.6400e+02,\n",
            "        1.5250e+03, 2.0000e+00, 1.9190e+03, 1.1530e+03, 8.0000e+00, 1.0000e+00,\n",
            "        6.1600e+02, 2.0600e+02, 9.0000e+00, 4.8200e+02, 9.3700e+02, 3.0000e+00,\n",
            "        1.0000e+00, 2.6400e+02, 1.5250e+03, 2.0000e+00, 1.9190e+03, 1.1530e+03,\n",
            "        8.0000e+00, 1.0000e+00, 6.1600e+02, 2.0600e+02])\n",
            "['The', 'small', 'intestine', 'is', 'the', 'primary', 'site', 'of', 'nutrient', 'absorption', 'in', 'the', 'digestive', 'system.', 'The', 'small', 'intestine', 'is', 'the', 'primary', 'site', 'of', 'nutrient', 'absorption', 'in', 'the', 'digestive', 'system.']\n",
            "[('The', 'small'), ('small', 'intestine'), ('intestine', 'is'), ('is', 'the'), ('the', 'primary'), ('primary', 'site'), ('site', 'of'), ('of', 'nutrient'), ('nutrient', 'absorption'), ('absorption', 'in'), ('in', 'the'), ('the', 'digestive'), ('digestive', 'system.'), ('The', 'small'), ('small', 'intestine'), ('intestine', 'is'), ('is', 'the'), ('the', 'primary'), ('primary', 'site'), ('site', 'of'), ('of', 'nutrient'), ('nutrient', 'absorption'), ('absorption', 'in'), ('in', 'the'), ('the', 'digestive'), ('digestive', 'system.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([   9.,  381.,  937., 1154.,  319.,    5., 2520.,    5.,  396.,    5.,\n",
            "         749., 2405.,    9.,  381.,  937., 1154.,  319.,    5., 2520.,    5.,\n",
            "         396.,    5.,  749., 2405.])\n",
            "['The', 'large', 'intestine', 'absorbs', 'water', 'and', 'electrolytes', 'and', 'forms', 'and', 'stores', 'feces.', 'The', 'large', 'intestine', 'absorbs', 'water', 'and', 'electrolytes', 'and', 'forms', 'and', 'stores', 'feces.']\n",
            "[('The', 'large'), ('large', 'intestine'), ('intestine', 'absorbs'), ('absorbs', 'water'), ('water', 'and'), ('and', 'electrolytes'), ('electrolytes', 'and'), ('and', 'forms'), ('forms', 'and'), ('and', 'stores'), ('stores', 'feces.'), ('The', 'large'), ('large', 'intestine'), ('intestine', 'absorbs'), ('absorbs', 'water'), ('water', 'and'), ('and', 'electrolytes'), ('electrolytes', 'and'), ('and', 'forms'), ('forms', 'and'), ('and', 'stores'), ('stores', 'feces.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([  9., 927., 992., 700., 815.,  24.,   1.,  77.,   6.,  94., 708.,   9.,\n",
            "        927., 992., 700., 815.,  24.,   1.,  77.,   6.,  94., 708.])\n",
            "['The', 'kidneys', 'filter', 'waste', 'products', 'from', 'the', 'blood', 'to', 'form', 'urine.', 'The', 'kidneys', 'filter', 'waste', 'products', 'from', 'the', 'blood', 'to', 'form', 'urine.']\n",
            "[('The', 'kidneys'), ('kidneys', 'filter'), ('filter', 'waste'), ('waste', 'products'), ('products', 'from'), ('from', 'the'), ('the', 'blood'), ('blood', 'to'), ('to', 'form'), ('form', 'urine.'), ('The', 'kidneys'), ('kidneys', 'filter'), ('filter', 'waste'), ('waste', 'products'), ('products', 'from'), ('from', 'the'), ('the', 'blood'), ('blood', 'to'), ('to', 'form'), ('form', 'urine.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.1990e+03, 1.3000e+01, 1.0000e+00, 9.8200e+02, 1.3230e+03, 2.0000e+00,\n",
            "        1.0000e+00, 9.2700e+02, 7.0000e+00, 9.9200e+02, 7.7000e+01, 5.0000e+00,\n",
            "        1.0100e+02, 7.0800e+02, 3.1990e+03, 1.3000e+01, 1.0000e+00, 9.8200e+02,\n",
            "        1.3230e+03, 2.0000e+00, 1.0000e+00, 9.2700e+02, 7.0000e+00, 9.9200e+02,\n",
            "        7.7000e+01, 5.0000e+00, 1.0100e+02, 7.0800e+02])\n",
            "['Nephrons', 'are', 'the', 'functional', 'units', 'of', 'the', 'kidneys', 'that', 'filter', 'blood', 'and', 'produce', 'urine.', 'Nephrons', 'are', 'the', 'functional', 'units', 'of', 'the', 'kidneys', 'that', 'filter', 'blood', 'and', 'produce', 'urine.']\n",
            "[('Nephrons', 'are'), ('are', 'the'), ('the', 'functional'), ('functional', 'units'), ('units', 'of'), ('of', 'the'), ('the', 'kidneys'), ('kidneys', 'that'), ('that', 'filter'), ('filter', 'blood'), ('blood', 'and'), ('and', 'produce'), ('produce', 'urine.'), ('Nephrons', 'are'), ('are', 'the'), ('the', 'functional'), ('functional', 'units'), ('units', 'of'), ('of', 'the'), ('the', 'kidneys'), ('kidneys', 'that'), ('that', 'filter'), ('filter', 'blood'), ('blood', 'and'), ('and', 'produce'), ('produce', 'urine.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([9.0000e+00, 1.1110e+03, 7.4900e+02, 1.3120e+03, 4.4700e+02, 4.4000e+01,\n",
            "        3.0000e+00, 2.4610e+03, 2.4000e+01, 1.0000e+00, 1.3400e+02, 9.0000e+00,\n",
            "        1.1110e+03, 7.4900e+02, 1.3120e+03, 4.4700e+02, 4.4000e+01, 3.0000e+00,\n",
            "        2.4610e+03, 2.4000e+01, 1.0000e+00, 1.3400e+02])\n",
            "['The', 'bladder', 'stores', 'urine', 'until', 'it', 'is', 'excreted', 'from', 'the', 'body.', 'The', 'bladder', 'stores', 'urine', 'until', 'it', 'is', 'excreted', 'from', 'the', 'body.']\n",
            "[('The', 'bladder'), ('bladder', 'stores'), ('stores', 'urine'), ('urine', 'until'), ('until', 'it'), ('it', 'is'), ('is', 'excreted'), ('excreted', 'from'), ('from', 'the'), ('the', 'body.'), ('The', 'bladder'), ('bladder', 'stores'), ('stores', 'urine'), ('urine', 'until'), ('until', 'it'), ('it', 'is'), ('is', 'excreted'), ('excreted', 'from'), ('from', 'the'), ('the', 'body.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3279.,   13.,   56., 2012.,  353.,   18., 1024.,  285.,    7.,  259.,\n",
            "         320.,  647.,  981., 3279.,   13.,   56., 2012.,  353.,   18., 1024.,\n",
            "         285.,    7.,  259.,  320.,  647.,  981.])\n",
            "['Hormones', 'are', 'chemical', 'messengers', 'produced', 'by', 'endocrine', 'glands', 'that', 'regulate', 'various', 'bodily', 'functions.', 'Hormones', 'are', 'chemical', 'messengers', 'produced', 'by', 'endocrine', 'glands', 'that', 'regulate', 'various', 'bodily', 'functions.']\n",
            "[('Hormones', 'are'), ('are', 'chemical'), ('chemical', 'messengers'), ('messengers', 'produced'), ('produced', 'by'), ('by', 'endocrine'), ('endocrine', 'glands'), ('glands', 'that'), ('that', 'regulate'), ('regulate', 'various'), ('various', 'bodily'), ('bodily', 'functions.'), ('Hormones', 'are'), ('are', 'chemical'), ('chemical', 'messengers'), ('messengers', 'produced'), ('produced', 'by'), ('by', 'endocrine'), ('endocrine', 'glands'), ('glands', 'that'), ('that', 'regulate'), ('regulate', 'various'), ('various', 'bodily'), ('bodily', 'functions.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([9.0000e+00, 7.2100e+02, 2.3250e+03, 7.9500e+02, 2.0110e+03, 2.3030e+03,\n",
            "        5.0000e+00, 1.5200e+02, 5.2000e+01, 1.0000e+00, 3.5200e+02, 2.0000e+00,\n",
            "        7.2100e+02, 2.2650e+03, 9.0000e+00, 7.2100e+02, 2.3250e+03, 7.9500e+02,\n",
            "        2.0110e+03, 2.3030e+03, 5.0000e+00, 1.5200e+02, 5.2000e+01, 1.0000e+00,\n",
            "        3.5200e+02, 2.0000e+00, 7.2100e+02, 2.2650e+03])\n",
            "['The', 'thyroid', 'gland', 'regulates', 'metabolism,', 'growth,', 'and', 'development', 'through', 'the', 'production', 'of', 'thyroid', 'hormones.', 'The', 'thyroid', 'gland', 'regulates', 'metabolism,', 'growth,', 'and', 'development', 'through', 'the', 'production', 'of', 'thyroid', 'hormones.']\n",
            "[('The', 'thyroid'), ('thyroid', 'gland'), ('gland', 'regulates'), ('regulates', 'metabolism,'), ('metabolism,', 'growth,'), ('growth,', 'and'), ('and', 'development'), ('development', 'through'), ('through', 'the'), ('the', 'production'), ('production', 'of'), ('of', 'thyroid'), ('thyroid', 'hormones.'), ('The', 'thyroid'), ('thyroid', 'gland'), ('gland', 'regulates'), ('regulates', 'metabolism,'), ('metabolism,', 'growth,'), ('growth,', 'and'), ('and', 'development'), ('development', 'through'), ('through', 'the'), ('the', 'production'), ('production', 'of'), ('of', 'thyroid'), ('thyroid', 'hormones.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([9.0000e+00, 1.1440e+03, 2.8500e+02, 1.0100e+02, 3.9000e+02, 4.0000e+01,\n",
            "        1.4000e+01, 2.6820e+03, 5.0000e+00, 2.9850e+03, 7.0000e+00, 2.8300e+02,\n",
            "        1.0000e+00, 5.0000e+01, 1.6070e+03, 6.0000e+00, 1.4660e+03, 9.0000e+00,\n",
            "        1.1440e+03, 2.8500e+02, 1.0100e+02, 3.9000e+02, 4.0000e+01, 1.4000e+01,\n",
            "        2.6820e+03, 5.0000e+00, 2.9850e+03, 7.0000e+00, 2.8300e+02, 1.0000e+00,\n",
            "        5.0000e+01, 1.6070e+03, 6.0000e+00, 1.4660e+03])\n",
            "['The', 'adrenal', 'glands', 'produce', 'hormones', 'such', 'as', 'cortisol', 'and', 'adrenaline', 'that', 'help', 'the', 'body', 'respond', 'to', 'stress.', 'The', 'adrenal', 'glands', 'produce', 'hormones', 'such', 'as', 'cortisol', 'and', 'adrenaline', 'that', 'help', 'the', 'body', 'respond', 'to', 'stress.']\n",
            "[('The', 'adrenal'), ('adrenal', 'glands'), ('glands', 'produce'), ('produce', 'hormones'), ('hormones', 'such'), ('such', 'as'), ('as', 'cortisol'), ('cortisol', 'and'), ('and', 'adrenaline'), ('adrenaline', 'that'), ('that', 'help'), ('help', 'the'), ('the', 'body'), ('body', 'respond'), ('respond', 'to'), ('to', 'stress.'), ('The', 'adrenal'), ('adrenal', 'glands'), ('glands', 'produce'), ('produce', 'hormones'), ('hormones', 'such'), ('such', 'as'), ('as', 'cortisol'), ('cortisol', 'and'), ('and', 'adrenaline'), ('adrenaline', 'that'), ('that', 'help'), ('help', 'the'), ('the', 'body'), ('body', 'respond'), ('respond', 'to'), ('to', 'stress.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([   9., 1868.,  101., 2527.,    5.,  390.,   40.,   14., 2481.,    5.,\n",
            "        1726.,    9., 1868.,  101., 2527.,    5.,  390.,   40.,   14., 2481.,\n",
            "           5., 1726.])\n",
            "['The', 'ovaries', 'produce', 'eggs', 'and', 'hormones', 'such', 'as', 'estrogen', 'and', 'progesterone.', 'The', 'ovaries', 'produce', 'eggs', 'and', 'hormones', 'such', 'as', 'estrogen', 'and', 'progesterone.']\n",
            "[('The', 'ovaries'), ('ovaries', 'produce'), ('produce', 'eggs'), ('eggs', 'and'), ('and', 'hormones'), ('hormones', 'such'), ('such', 'as'), ('as', 'estrogen'), ('estrogen', 'and'), ('and', 'progesterone.'), ('The', 'ovaries'), ('ovaries', 'produce'), ('produce', 'eggs'), ('eggs', 'and'), ('and', 'hormones'), ('hormones', 'such'), ('such', 'as'), ('as', 'estrogen'), ('estrogen', 'and'), ('and', 'progesterone.')]\n",
            "16\n",
            "14\n",
            "120\n",
            "30\n",
            "tensor([9.0000e+00, 1.4080e+03, 1.0100e+02, 1.4900e+03, 5.0000e+00, 1.0000e+00,\n",
            "        2.2660e+03, 1.4050e+03, 9.0000e+00, 1.4080e+03, 1.0100e+02, 1.4900e+03,\n",
            "        5.0000e+00, 1.0000e+00, 2.2660e+03, 1.4050e+03])\n",
            "['The', 'testes', 'produce', 'sperm', 'and', 'the', 'hormone', 'testosterone.', 'The', 'testes', 'produce', 'sperm', 'and', 'the', 'hormone', 'testosterone.']\n",
            "[('The', 'testes'), ('testes', 'produce'), ('produce', 'sperm'), ('sperm', 'and'), ('and', 'the'), ('the', 'hormone'), ('hormone', 'testosterone.'), ('The', 'testes'), ('testes', 'produce'), ('produce', 'sperm'), ('sperm', 'and'), ('and', 'the'), ('the', 'hormone'), ('hormone', 'testosterone.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([9.0000e+00, 7.6500e+02, 3.0000e+00, 1.0000e+00, 7.5000e+01, 3.6700e+02,\n",
            "        2.0000e+00, 1.0000e+00, 5.0000e+01, 5.0000e+00, 2.1100e+02, 1.4000e+01,\n",
            "        4.0000e+00, 6.5100e+02, 6.0000e+00, 3.5000e+02, 1.9500e+02, 4.0200e+02,\n",
            "        2.6440e+03, 9.0000e+00, 7.6500e+02, 3.0000e+00, 1.0000e+00, 7.5000e+01,\n",
            "        3.6700e+02, 2.0000e+00, 1.0000e+00, 5.0000e+01, 5.0000e+00, 2.1100e+02,\n",
            "        1.4000e+01, 4.0000e+00, 6.5100e+02, 6.0000e+00, 3.5000e+02, 1.9500e+02,\n",
            "        4.0200e+02, 2.6440e+03])\n",
            "['The', 'skin', 'is', 'the', 'largest', 'organ', 'of', 'the', 'body', 'and', 'serves', 'as', 'a', 'barrier', 'to', 'protect', 'against', 'environmental', 'damage.', 'The', 'skin', 'is', 'the', 'largest', 'organ', 'of', 'the', 'body', 'and', 'serves', 'as', 'a', 'barrier', 'to', 'protect', 'against', 'environmental', 'damage.']\n",
            "[('The', 'skin'), ('skin', 'is'), ('is', 'the'), ('the', 'largest'), ('largest', 'organ'), ('organ', 'of'), ('of', 'the'), ('the', 'body'), ('body', 'and'), ('and', 'serves'), ('serves', 'as'), ('as', 'a'), ('a', 'barrier'), ('barrier', 'to'), ('to', 'protect'), ('protect', 'against'), ('against', 'environmental'), ('environmental', 'damage.'), ('The', 'skin'), ('skin', 'is'), ('is', 'the'), ('the', 'largest'), ('largest', 'organ'), ('organ', 'of'), ('of', 'the'), ('the', 'body'), ('body', 'and'), ('and', 'serves'), ('serves', 'as'), ('as', 'a'), ('a', 'barrier'), ('barrier', 'to'), ('to', 'protect'), ('protect', 'against'), ('against', 'environmental'), ('environmental', 'damage.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([3081.,  285.,  283.,  259.,   50.,  331.,   18., 1732.,  467., 3081.,\n",
            "         285.,  283.,  259.,   50.,  331.,   18., 1732.,  467.])\n",
            "['Sweat', 'glands', 'help', 'regulate', 'body', 'temperature', 'by', 'producing', 'sweat.', 'Sweat', 'glands', 'help', 'regulate', 'body', 'temperature', 'by', 'producing', 'sweat.']\n",
            "[('Sweat', 'glands'), ('glands', 'help'), ('help', 'regulate'), ('regulate', 'body'), ('body', 'temperature'), ('temperature', 'by'), ('by', 'producing'), ('producing', 'sweat.'), ('Sweat', 'glands'), ('glands', 'help'), ('help', 'regulate'), ('regulate', 'body'), ('body', 'temperature'), ('temperature', 'by'), ('by', 'producing'), ('producing', 'sweat.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.1030e+03, 2.8500e+02, 1.0100e+02, 1.5620e+03, 2.1000e+01, 1.9040e+03,\n",
            "        1.4570e+03, 7.0000e+00, 2.0640e+03, 1.0000e+00, 7.6500e+02, 5.0000e+00,\n",
            "        2.2970e+03, 3.1030e+03, 2.8500e+02, 1.0100e+02, 1.5620e+03, 2.1000e+01,\n",
            "        1.9040e+03, 1.4570e+03, 7.0000e+00, 2.0640e+03, 1.0000e+00, 7.6500e+02,\n",
            "        5.0000e+00, 2.2970e+03])\n",
            "['Sebaceous', 'glands', 'produce', 'sebum,', 'an', 'oily', 'substance', 'that', 'lubricates', 'the', 'skin', 'and', 'hair.', 'Sebaceous', 'glands', 'produce', 'sebum,', 'an', 'oily', 'substance', 'that', 'lubricates', 'the', 'skin', 'and', 'hair.']\n",
            "[('Sebaceous', 'glands'), ('glands', 'produce'), ('produce', 'sebum,'), ('sebum,', 'an'), ('an', 'oily'), ('oily', 'substance'), ('substance', 'that'), ('that', 'lubricates'), ('lubricates', 'the'), ('the', 'skin'), ('skin', 'and'), ('and', 'hair.'), ('Sebaceous', 'glands'), ('glands', 'produce'), ('produce', 'sebum,'), ('sebum,', 'an'), ('an', 'oily'), ('oily', 'substance'), ('substance', 'that'), ('that', 'lubricates'), ('lubricates', 'the'), ('the', 'skin'), ('skin', 'and'), ('and', 'hair.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.0310e+03, 7.7000e+01, 4.1400e+02, 1.3000e+01, 2.6700e+02, 2.0000e+00,\n",
            "        1.0000e+00, 2.8000e+02, 2.6000e+01, 5.0000e+00, 2.8300e+02, 2.6330e+03,\n",
            "        1.0000e+00, 5.0000e+01, 1.9500e+02, 9.5000e+02, 3.0310e+03, 7.7000e+01,\n",
            "        4.1400e+02, 1.3000e+01, 2.6700e+02, 2.0000e+00, 1.0000e+00, 2.8000e+02,\n",
            "        2.6000e+01, 5.0000e+00, 2.8300e+02, 2.6330e+03, 1.0000e+00, 5.0000e+01,\n",
            "        1.9500e+02, 9.5000e+02])\n",
            "['White', 'blood', 'cells', 'are', 'part', 'of', 'the', 'immune', 'system', 'and', 'help', 'defend', 'the', 'body', 'against', 'infections.', 'White', 'blood', 'cells', 'are', 'part', 'of', 'the', 'immune', 'system', 'and', 'help', 'defend', 'the', 'body', 'against', 'infections.']\n",
            "[('White', 'blood'), ('blood', 'cells'), ('cells', 'are'), ('are', 'part'), ('part', 'of'), ('of', 'the'), ('the', 'immune'), ('immune', 'system'), ('system', 'and'), ('and', 'help'), ('help', 'defend'), ('defend', 'the'), ('the', 'body'), ('body', 'against'), ('against', 'infections.'), ('White', 'blood'), ('blood', 'cells'), ('cells', 'are'), ('are', 'part'), ('part', 'of'), ('of', 'the'), ('the', 'immune'), ('immune', 'system'), ('system', 'and'), ('and', 'help'), ('help', 'defend'), ('defend', 'the'), ('the', 'body'), ('body', 'against'), ('against', 'infections.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.4420e+03, 1.3000e+01, 5.0900e+02, 3.5300e+02, 1.8000e+01, 1.0000e+00,\n",
            "        2.8000e+02, 2.6000e+01, 7.0000e+00, 1.6620e+03, 5.0000e+00, 1.9460e+03,\n",
            "        2.3690e+03, 7.4400e+02, 3.4420e+03, 1.3000e+01, 5.0900e+02, 3.5300e+02,\n",
            "        1.8000e+01, 1.0000e+00, 2.8000e+02, 2.6000e+01, 7.0000e+00, 1.6620e+03,\n",
            "        5.0000e+00, 1.9460e+03, 2.3690e+03, 7.4400e+02])\n",
            "['Antibodies', 'are', 'proteins', 'produced', 'by', 'the', 'immune', 'system', 'that', 'recognize', 'and', 'neutralize', 'foreign', 'substances.', 'Antibodies', 'are', 'proteins', 'produced', 'by', 'the', 'immune', 'system', 'that', 'recognize', 'and', 'neutralize', 'foreign', 'substances.']\n",
            "[('Antibodies', 'are'), ('are', 'proteins'), ('proteins', 'produced'), ('produced', 'by'), ('by', 'the'), ('the', 'immune'), ('immune', 'system'), ('system', 'that'), ('that', 'recognize'), ('recognize', 'and'), ('and', 'neutralize'), ('neutralize', 'foreign'), ('foreign', 'substances.'), ('Antibodies', 'are'), ('are', 'proteins'), ('proteins', 'produced'), ('produced', 'by'), ('by', 'the'), ('the', 'immune'), ('immune', 'system'), ('system', 'that'), ('that', 'recognize'), ('recognize', 'and'), ('and', 'neutralize'), ('neutralize', 'foreign'), ('foreign', 'substances.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([  11., 1842.,    3.,    4., 2008.,    7.,  237., 2589.,   40.,   14.,\n",
            "        2887., 1282.,    5., 2351.,   11., 1842.,    3.,    4., 2008.,    7.,\n",
            "         237., 2589.,   40.,   14., 2887., 1282.,    5., 2351.])\n",
            "['A', 'pathogen', 'is', 'a', 'microorganism', 'that', 'causes', 'disease,', 'such', 'as', 'bacteria,', 'viruses,', 'and', 'fungi.', 'A', 'pathogen', 'is', 'a', 'microorganism', 'that', 'causes', 'disease,', 'such', 'as', 'bacteria,', 'viruses,', 'and', 'fungi.']\n",
            "[('A', 'pathogen'), ('pathogen', 'is'), ('is', 'a'), ('a', 'microorganism'), ('microorganism', 'that'), ('that', 'causes'), ('causes', 'disease,'), ('disease,', 'such'), ('such', 'as'), ('as', 'bacteria,'), ('bacteria,', 'viruses,'), ('viruses,', 'and'), ('and', 'fungi.'), ('A', 'pathogen'), ('pathogen', 'is'), ('is', 'a'), ('a', 'microorganism'), ('microorganism', 'that'), ('that', 'causes'), ('causes', 'disease,'), ('disease,', 'such'), ('such', 'as'), ('as', 'bacteria,'), ('bacteria,', 'viruses,'), ('viruses,', 'and'), ('and', 'fungi.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.2670e+03, 3.0000e+00, 1.0000e+00, 6.4600e+02, 1.6060e+03, 6.0000e+00,\n",
            "        9.4600e+02, 1.0000e+01, 2.2130e+03, 2.7850e+03, 1.8000e+01, 1.6480e+03,\n",
            "        1.4390e+03, 9.6000e+02, 5.0000e+00, 8.5400e+02, 3.2670e+03, 3.0000e+00,\n",
            "        1.0000e+00, 6.4600e+02, 1.6060e+03, 6.0000e+00, 9.4600e+02, 1.0000e+01,\n",
            "        2.2130e+03, 2.7850e+03, 1.8000e+01, 1.6480e+03, 1.4390e+03, 9.6000e+02,\n",
            "        5.0000e+00, 8.5400e+02])\n",
            "['Inflammation', 'is', 'the', \"body's\", 'response', 'to', 'injury', 'or', 'infection,', 'characterized', 'by', 'redness,', 'swelling,', 'heat,', 'and', 'pain.', 'Inflammation', 'is', 'the', \"body's\", 'response', 'to', 'injury', 'or', 'infection,', 'characterized', 'by', 'redness,', 'swelling,', 'heat,', 'and', 'pain.']\n",
            "[('Inflammation', 'is'), ('is', 'the'), ('the', \"body's\"), (\"body's\", 'response'), ('response', 'to'), ('to', 'injury'), ('injury', 'or'), ('or', 'infection,'), ('infection,', 'characterized'), ('characterized', 'by'), ('by', 'redness,'), ('redness,', 'swelling,'), ('swelling,', 'heat,'), ('heat,', 'and'), ('and', 'pain.'), ('Inflammation', 'is'), ('is', 'the'), ('the', \"body's\"), (\"body's\", 'response'), ('response', 'to'), ('to', 'injury'), ('injury', 'or'), ('or', 'infection,'), ('infection,', 'characterized'), ('characterized', 'by'), ('by', 'redness,'), ('redness,', 'swelling,'), ('swelling,', 'heat,'), ('heat,', 'and'), ('and', 'pain.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.0460e+03, 7.5000e+02, 1.0000e+00, 2.8000e+02, 2.6000e+01, 6.0000e+00,\n",
            "        1.0100e+02, 2.2430e+03, 1.9500e+02, 8.0000e+01, 2.3400e+02, 3.0460e+03,\n",
            "        7.5000e+02, 1.0000e+00, 2.8000e+02, 2.6000e+01, 6.0000e+00, 1.0100e+02,\n",
            "        2.2430e+03, 1.9500e+02, 8.0000e+01, 2.3400e+02])\n",
            "['Vaccines', 'stimulate', 'the', 'immune', 'system', 'to', 'produce', 'immunity', 'against', 'specific', 'diseases.', 'Vaccines', 'stimulate', 'the', 'immune', 'system', 'to', 'produce', 'immunity', 'against', 'specific', 'diseases.']\n",
            "[('Vaccines', 'stimulate'), ('stimulate', 'the'), ('the', 'immune'), ('immune', 'system'), ('system', 'to'), ('to', 'produce'), ('produce', 'immunity'), ('immunity', 'against'), ('against', 'specific'), ('specific', 'diseases.'), ('Vaccines', 'stimulate'), ('stimulate', 'the'), ('the', 'immune'), ('immune', 'system'), ('system', 'to'), ('to', 'produce'), ('produce', 'immunity'), ('immunity', 'against'), ('against', 'specific'), ('specific', 'diseases.')]\n",
            "16\n",
            "14\n",
            "120\n",
            "30\n",
            "tensor([3443.,   13.,  373.,   31.,    6.,  202., 2886.,  950., 3443.,   13.,\n",
            "         373.,   31.,    6.,  202., 2886.,  950.])\n",
            "['Antibiotics', 'are', 'medications', 'used', 'to', 'treat', 'bacterial', 'infections.', 'Antibiotics', 'are', 'medications', 'used', 'to', 'treat', 'bacterial', 'infections.']\n",
            "[('Antibiotics', 'are'), ('are', 'medications'), ('medications', 'used'), ('used', 'to'), ('to', 'treat'), ('treat', 'bacterial'), ('bacterial', 'infections.'), ('Antibiotics', 'are'), ('are', 'medications'), ('medications', 'used'), ('used', 'to'), ('to', 'treat'), ('treat', 'bacterial'), ('bacterial', 'infections.')]\n",
            "14\n",
            "12\n",
            "91\n",
            "26\n",
            "tensor([3447.,   13.,  373.,   31.,    6., 1629.,  854., 3447.,   13.,  373.,\n",
            "          31.,    6., 1629.,  854.])\n",
            "['Analgesics', 'are', 'medications', 'used', 'to', 'relieve', 'pain.', 'Analgesics', 'are', 'medications', 'used', 'to', 'relieve', 'pain.']\n",
            "[('Analgesics', 'are'), ('are', 'medications'), ('medications', 'used'), ('used', 'to'), ('to', 'relieve'), ('relieve', 'pain.'), ('Analgesics', 'are'), ('are', 'medications'), ('medications', 'used'), ('used', 'to'), ('to', 'relieve'), ('relieve', 'pain.')]\n",
            "14\n",
            "12\n",
            "91\n",
            "26\n",
            "tensor([3440.,   13.,  373.,   31.,    6., 1647., 2401., 3440.,   13.,  373.,\n",
            "          31.,    6., 1647., 2401.])\n",
            "['Antipyretics', 'are', 'medications', 'used', 'to', 'reduce', 'fever.', 'Antipyretics', 'are', 'medications', 'used', 'to', 'reduce', 'fever.']\n",
            "[('Antipyretics', 'are'), ('are', 'medications'), ('medications', 'used'), ('used', 'to'), ('to', 'reduce'), ('reduce', 'fever.'), ('Antipyretics', 'are'), ('are', 'medications'), ('medications', 'used'), ('used', 'to'), ('to', 'reduce'), ('reduce', 'fever.')]\n",
            "16\n",
            "14\n",
            "120\n",
            "30\n",
            "tensor([3441.,   13.,  373.,   31.,    6.,  202., 2966., 1672., 3441.,   13.,\n",
            "         373.,   31.,    6.,  202., 2966., 1672.])\n",
            "['Antihistamines', 'are', 'medications', 'used', 'to', 'treat', 'allergic', 'reactions.', 'Antihistamines', 'are', 'medications', 'used', 'to', 'treat', 'allergic', 'reactions.']\n",
            "[('Antihistamines', 'are'), ('are', 'medications'), ('medications', 'used'), ('used', 'to'), ('to', 'treat'), ('treat', 'allergic'), ('allergic', 'reactions.'), ('Antihistamines', 'are'), ('are', 'medications'), ('medications', 'used'), ('used', 'to'), ('to', 'treat'), ('treat', 'allergic'), ('allergic', 'reactions.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([  11., 1444.,    3.,    4.,   81.,  191.,   86.,  847.,  530.,    6.,\n",
            "         202.,  947.,   10.,  234.,   11., 1444.,    3.,    4.,   81.,  191.,\n",
            "          86.,  847.,  530.,    6.,  202.,  947.,   10.,  234.])\n",
            "['A', 'surgeon', 'is', 'a', 'medical', 'doctor', 'who', 'performs', 'operations', 'to', 'treat', 'injuries', 'or', 'diseases.', 'A', 'surgeon', 'is', 'a', 'medical', 'doctor', 'who', 'performs', 'operations', 'to', 'treat', 'injuries', 'or', 'diseases.']\n",
            "[('A', 'surgeon'), ('surgeon', 'is'), ('is', 'a'), ('a', 'medical'), ('medical', 'doctor'), ('doctor', 'who'), ('who', 'performs'), ('performs', 'operations'), ('operations', 'to'), ('to', 'treat'), ('treat', 'injuries'), ('injuries', 'or'), ('or', 'diseases.'), ('A', 'surgeon'), ('surgeon', 'is'), ('is', 'a'), ('a', 'medical'), ('medical', 'doctor'), ('doctor', 'who'), ('who', 'performs'), ('performs', 'operations'), ('operations', 'to'), ('to', 'treat'), ('treat', 'injuries'), ('injuries', 'or'), ('or', 'diseases.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([  11., 1797.,    3.,    4.,   81.,  191.,   86., 2606.,    5., 1348.,\n",
            "        2250.,    5., 2200.,   11., 1797.,    3.,    4.,   81.,  191.,   86.,\n",
            "        2606.,    5., 1348., 2250.,    5., 2200.])\n",
            "['A', 'physician', 'is', 'a', 'medical', 'doctor', 'who', 'diagnoses', 'and', 'treats', 'illnesses', 'and', 'injuries.', 'A', 'physician', 'is', 'a', 'medical', 'doctor', 'who', 'diagnoses', 'and', 'treats', 'illnesses', 'and', 'injuries.']\n",
            "[('A', 'physician'), ('physician', 'is'), ('is', 'a'), ('a', 'medical'), ('medical', 'doctor'), ('doctor', 'who'), ('who', 'diagnoses'), ('diagnoses', 'and'), ('and', 'treats'), ('treats', 'illnesses'), ('illnesses', 'and'), ('and', 'injuries.'), ('A', 'physician'), ('physician', 'is'), ('is', 'a'), ('a', 'medical'), ('medical', 'doctor'), ('doctor', 'who'), ('who', 'diagnoses'), ('diagnoses', 'and'), ('and', 'treats'), ('treats', 'illnesses'), ('illnesses', 'and'), ('and', 'injuries.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([  11., 1921.,  139.,  238.,    6.,  363.,    5., 2915., 2567.,    8.,\n",
            "          81., 1737.,   11., 1921.,  139.,  238.,    6.,  363.,    5., 2915.,\n",
            "        2567.,    8.,   81., 1737.])\n",
            "['A', 'nurse', 'provides', 'care', 'to', 'patients', 'and', 'assists', 'doctors', 'in', 'medical', 'procedures.', 'A', 'nurse', 'provides', 'care', 'to', 'patients', 'and', 'assists', 'doctors', 'in', 'medical', 'procedures.']\n",
            "[('A', 'nurse'), ('nurse', 'provides'), ('provides', 'care'), ('care', 'to'), ('to', 'patients'), ('patients', 'and'), ('and', 'assists'), ('assists', 'doctors'), ('doctors', 'in'), ('in', 'medical'), ('medical', 'procedures.'), ('A', 'nurse'), ('nurse', 'provides'), ('provides', 'care'), ('care', 'to'), ('to', 'patients'), ('patients', 'and'), ('and', 'assists'), ('assists', 'doctors'), ('doctors', 'in'), ('in', 'medical'), ('medical', 'procedures.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([  11.,   81., 1495.,    3.,    4.,  191.,   86.,   54., 1087.,  659.,\n",
            "        1040.,    5., 1367.,    8.,    4.,   80.,  426.,    2.,  892.,   11.,\n",
            "          81., 1495.,    3.,    4.,  191.,   86.,   54., 1087.,  659., 1040.,\n",
            "           5., 1367.,    8.,    4.,   80.,  426.,    2.,  892.])\n",
            "['A', 'medical', 'specialist', 'is', 'a', 'doctor', 'who', 'has', 'completed', 'advanced', 'education', 'and', 'training', 'in', 'a', 'specific', 'area', 'of', 'medicine.', 'A', 'medical', 'specialist', 'is', 'a', 'doctor', 'who', 'has', 'completed', 'advanced', 'education', 'and', 'training', 'in', 'a', 'specific', 'area', 'of', 'medicine.']\n",
            "[('A', 'medical'), ('medical', 'specialist'), ('specialist', 'is'), ('is', 'a'), ('a', 'doctor'), ('doctor', 'who'), ('who', 'has'), ('has', 'completed'), ('completed', 'advanced'), ('advanced', 'education'), ('education', 'and'), ('and', 'training'), ('training', 'in'), ('in', 'a'), ('a', 'specific'), ('specific', 'area'), ('area', 'of'), ('of', 'medicine.'), ('A', 'medical'), ('medical', 'specialist'), ('specialist', 'is'), ('is', 'a'), ('a', 'doctor'), ('doctor', 'who'), ('who', 'has'), ('has', 'completed'), ('completed', 'advanced'), ('advanced', 'education'), ('education', 'and'), ('and', 'training'), ('training', 'in'), ('in', 'a'), ('a', 'specific'), ('specific', 'area'), ('area', 'of'), ('of', 'medicine.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.1270e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02,\n",
            "        7.0000e+00, 1.2600e+02, 2.8100e+02, 4.6400e+02, 6.0000e+00, 6.1700e+02,\n",
            "        5.0000e+00, 2.0200e+02, 2.3400e+02, 3.1270e+03, 3.0000e+00, 1.0000e+00,\n",
            "        2.7000e+01, 2.0000e+00, 1.0400e+02, 7.0000e+00, 1.2600e+02, 2.8100e+02,\n",
            "        4.6400e+02, 6.0000e+00, 6.1700e+02, 5.0000e+00, 2.0200e+02, 2.3400e+02])\n",
            "['Radiology', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'uses', 'imaging', 'techniques', 'to', 'diagnose', 'and', 'treat', 'diseases.', 'Radiology', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'uses', 'imaging', 'techniques', 'to', 'diagnose', 'and', 'treat', 'diseases.']\n",
            "[('Radiology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'uses'), ('uses', 'imaging'), ('imaging', 'techniques'), ('techniques', 'to'), ('to', 'diagnose'), ('diagnose', 'and'), ('and', 'treat'), ('treat', 'diseases.'), ('Radiology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'uses'), ('uses', 'imaging'), ('imaging', 'techniques'), ('techniques', 'to'), ('to', 'diagnose'), ('diagnose', 'and'), ('and', 'treat'), ('treat', 'diseases.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.1820e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02,\n",
            "        7.0000e+00, 1.2200e+02, 1.9000e+01, 1.0000e+00, 8.2100e+02, 1.0550e+03,\n",
            "        5.0000e+00, 3.2500e+02, 2.0000e+00, 2.8210e+03, 3.1820e+03, 3.0000e+00,\n",
            "        1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02, 7.0000e+00, 1.2200e+02,\n",
            "        1.9000e+01, 1.0000e+00, 8.2100e+02, 1.0550e+03, 5.0000e+00, 3.2500e+02,\n",
            "        2.0000e+00, 2.8210e+03])\n",
            "['Oncology', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'deals', 'with', 'the', 'prevention,', 'diagnosis,', 'and', 'treatment', 'of', 'cancer.', 'Oncology', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'deals', 'with', 'the', 'prevention,', 'diagnosis,', 'and', 'treatment', 'of', 'cancer.']\n",
            "[('Oncology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'prevention,'), ('prevention,', 'diagnosis,'), ('diagnosis,', 'and'), ('and', 'treatment'), ('treatment', 'of'), ('of', 'cancer.'), ('Oncology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'prevention,'), ('prevention,', 'diagnosis,'), ('diagnosis,', 'and'), ('and', 'treatment'), ('treatment', 'of'), ('of', 'cancer.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.4060e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02,\n",
            "        7.0000e+00, 1.2200e+02, 1.9000e+01, 2.9400e+02, 2.0000e+00, 1.0000e+00,\n",
            "        2.8400e+02, 5.0000e+00, 7.7000e+01, 1.2920e+03, 3.4060e+03, 3.0000e+00,\n",
            "        1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02, 7.0000e+00, 1.2200e+02,\n",
            "        1.9000e+01, 2.9400e+02, 2.0000e+00, 1.0000e+00, 2.8400e+02, 5.0000e+00,\n",
            "        7.7000e+01, 1.2920e+03])\n",
            "['Cardiology', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'deals', 'with', 'disorders', 'of', 'the', 'heart', 'and', 'blood', 'vessels.', 'Cardiology', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'deals', 'with', 'disorders', 'of', 'the', 'heart', 'and', 'blood', 'vessels.']\n",
            "[('Cardiology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'disorders'), ('disorders', 'of'), ('of', 'the'), ('the', 'heart'), ('heart', 'and'), ('and', 'blood'), ('blood', 'vessels.'), ('Cardiology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'disorders'), ('disorders', 'of'), ('of', 'the'), ('the', 'heart'), ('heart', 'and'), ('and', 'blood'), ('blood', 'vessels.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.1980e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02,\n",
            "        7.0000e+00, 1.2200e+02, 1.9000e+01, 2.9400e+02, 2.0000e+00, 1.0000e+00,\n",
            "        3.7100e+02, 2.0600e+02, 3.1980e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01,\n",
            "        2.0000e+00, 1.0400e+02, 7.0000e+00, 1.2200e+02, 1.9000e+01, 2.9400e+02,\n",
            "        2.0000e+00, 1.0000e+00, 3.7100e+02, 2.0600e+02])\n",
            "['Neurology', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'deals', 'with', 'disorders', 'of', 'the', 'nervous', 'system.', 'Neurology', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'deals', 'with', 'disorders', 'of', 'the', 'nervous', 'system.']\n",
            "[('Neurology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'disorders'), ('disorders', 'of'), ('of', 'the'), ('the', 'nervous'), ('nervous', 'system.'), ('Neurology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'disorders'), ('disorders', 'of'), ('of', 'the'), ('the', 'nervous'), ('nervous', 'system.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.1670e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02,\n",
            "        7.0000e+00, 1.2200e+02, 1.9000e+01, 1.0000e+00, 8.1000e+01, 2.3800e+02,\n",
            "        2.0000e+00, 2.2150e+03, 2.7760e+03, 5.0000e+00, 2.9880e+03, 3.1670e+03,\n",
            "        3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02, 7.0000e+00,\n",
            "        1.2200e+02, 1.9000e+01, 1.0000e+00, 8.1000e+01, 2.3800e+02, 2.0000e+00,\n",
            "        2.2150e+03, 2.7760e+03, 5.0000e+00, 2.9880e+03])\n",
            "['Pediatrics', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'deals', 'with', 'the', 'medical', 'care', 'of', 'infants,', 'children,', 'and', 'adolescents.', 'Pediatrics', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'deals', 'with', 'the', 'medical', 'care', 'of', 'infants,', 'children,', 'and', 'adolescents.']\n",
            "[('Pediatrics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'medical'), ('medical', 'care'), ('care', 'of'), ('of', 'infants,'), ('infants,', 'children,'), ('children,', 'and'), ('and', 'adolescents.'), ('Pediatrics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'medical'), ('medical', 'care'), ('care', 'of'), ('of', 'infants,'), ('infants,', 'children,'), ('children,', 'and'), ('and', 'adolescents.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.2950e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02,\n",
            "        7.0000e+00, 2.2800e+02, 2.3000e+01, 2.2600e+02, 2.3800e+02, 1.2000e+01,\n",
            "        1.9030e+03, 2.9840e+03, 3.2950e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01,\n",
            "        2.0000e+00, 1.0400e+02, 7.0000e+00, 2.2800e+02, 2.3000e+01, 2.2600e+02,\n",
            "        2.3800e+02, 1.2000e+01, 1.9030e+03, 2.9840e+03])\n",
            "['Geriatrics', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'focuses', 'on', 'health', 'care', 'for', 'older', 'adults.', 'Geriatrics', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'focuses', 'on', 'health', 'care', 'for', 'older', 'adults.']\n",
            "[('Geriatrics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'focuses'), ('focuses', 'on'), ('on', 'health'), ('health', 'care'), ('care', 'for'), ('for', 'older'), ('older', 'adults.'), ('Geriatrics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'focuses'), ('focuses', 'on'), ('on', 'health'), ('health', 'care'), ('care', 'for'), ('for', 'older'), ('older', 'adults.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.1370e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02,\n",
            "        7.0000e+00, 1.2200e+02, 1.9000e+01, 1.0000e+00, 1.0560e+03, 5.0000e+00,\n",
            "        3.2500e+02, 2.0000e+00, 2.0160e+03, 2.5860e+03, 3.1370e+03, 3.0000e+00,\n",
            "        1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02, 7.0000e+00, 1.2200e+02,\n",
            "        1.9000e+01, 1.0000e+00, 1.0560e+03, 5.0000e+00, 3.2500e+02, 2.0000e+00,\n",
            "        2.0160e+03, 2.5860e+03])\n",
            "['Psychiatry', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'deals', 'with', 'the', 'diagnosis', 'and', 'treatment', 'of', 'mental', 'disorders.', 'Psychiatry', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'deals', 'with', 'the', 'diagnosis', 'and', 'treatment', 'of', 'mental', 'disorders.']\n",
            "[('Psychiatry', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'diagnosis'), ('diagnosis', 'and'), ('and', 'treatment'), ('treatment', 'of'), ('of', 'mental'), ('mental', 'disorders.'), ('Psychiatry', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'diagnosis'), ('diagnosis', 'and'), ('and', 'treatment'), ('treatment', 'of'), ('of', 'mental'), ('mental', 'disorders.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.4450e+03, 3.6400e+02, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        3.6400e+02, 7.0000e+00, 3.6000e+01, 1.0000e+00, 3.3400e+02, 1.3300e+02,\n",
            "        8.0000e+00, 7.1900e+02, 4.1500e+02, 1.8000e+01, 1.0480e+03, 3.4450e+03,\n",
            "        3.6400e+02, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 3.6400e+02,\n",
            "        7.0000e+00, 3.6000e+01, 1.0000e+00, 3.3400e+02, 1.3300e+02, 8.0000e+00,\n",
            "        7.1900e+02, 4.1500e+02, 1.8000e+01, 1.0480e+03])\n",
            "['Anatomical', 'pathology', 'is', 'the', 'branch', 'of', 'pathology', 'that', 'studies', 'the', 'structural', 'changes', 'in', 'tissues', 'caused', 'by', 'disease.', 'Anatomical', 'pathology', 'is', 'the', 'branch', 'of', 'pathology', 'that', 'studies', 'the', 'structural', 'changes', 'in', 'tissues', 'caused', 'by', 'disease.']\n",
            "[('Anatomical', 'pathology'), ('pathology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'pathology'), ('pathology', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'structural'), ('structural', 'changes'), ('changes', 'in'), ('in', 'tissues'), ('tissues', 'caused'), ('caused', 'by'), ('by', 'disease.'), ('Anatomical', 'pathology'), ('pathology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'pathology'), ('pathology', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'structural'), ('structural', 'changes'), ('changes', 'in'), ('in', 'tissues'), ('tissues', 'caused'), ('caused', 'by'), ('by', 'disease.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([1.2050e+03, 3.6400e+02, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        3.6400e+02, 7.0000e+00, 2.2800e+02, 2.3000e+01, 1.0000e+00, 1.0560e+03,\n",
            "        2.0000e+00, 6.1500e+02, 1.5700e+02, 2.3000e+01, 1.0000e+00, 9.2200e+02,\n",
            "        3.0400e+02, 2.0000e+00, 6.4700e+02, 2.3770e+03, 5.0000e+00, 7.1800e+02,\n",
            "        1.2050e+03, 3.6400e+02, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        3.6400e+02, 7.0000e+00, 2.2800e+02, 2.3000e+01, 1.0000e+00, 1.0560e+03,\n",
            "        2.0000e+00, 6.1500e+02, 1.5700e+02, 2.3000e+01, 1.0000e+00, 9.2200e+02,\n",
            "        3.0400e+02, 2.0000e+00, 6.4700e+02, 2.3770e+03, 5.0000e+00, 7.1800e+02])\n",
            "['Clinical', 'pathology', 'is', 'the', 'branch', 'of', 'pathology', 'that', 'focuses', 'on', 'the', 'diagnosis', 'of', 'disease', 'based', 'on', 'the', 'laboratory', 'analysis', 'of', 'bodily', 'fluids', 'and', 'tissues.', 'Clinical', 'pathology', 'is', 'the', 'branch', 'of', 'pathology', 'that', 'focuses', 'on', 'the', 'diagnosis', 'of', 'disease', 'based', 'on', 'the', 'laboratory', 'analysis', 'of', 'bodily', 'fluids', 'and', 'tissues.']\n",
            "[('Clinical', 'pathology'), ('pathology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'pathology'), ('pathology', 'that'), ('that', 'focuses'), ('focuses', 'on'), ('on', 'the'), ('the', 'diagnosis'), ('diagnosis', 'of'), ('of', 'disease'), ('disease', 'based'), ('based', 'on'), ('on', 'the'), ('the', 'laboratory'), ('laboratory', 'analysis'), ('analysis', 'of'), ('of', 'bodily'), ('bodily', 'fluids'), ('fluids', 'and'), ('and', 'tissues.'), ('Clinical', 'pathology'), ('pathology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'pathology'), ('pathology', 'that'), ('that', 'focuses'), ('focuses', 'on'), ('on', 'the'), ('the', 'diagnosis'), ('diagnosis', 'of'), ('of', 'disease'), ('disease', 'based'), ('based', 'on'), ('on', 'the'), ('the', 'laboratory'), ('laboratory', 'analysis'), ('analysis', 'of'), ('of', 'bodily'), ('bodily', 'fluids'), ('fluids', 'and'), ('and', 'tissues.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.1650e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02,\n",
            "        7.0000e+00, 3.6000e+01, 1.0000e+00, 2.9100e+02, 2.0000e+00, 2.5470e+03,\n",
            "        2.3000e+01, 1.0000e+00, 1.3400e+02, 3.1650e+03, 3.0000e+00, 1.0000e+00,\n",
            "        2.7000e+01, 2.0000e+00, 1.0400e+02, 7.0000e+00, 3.6000e+01, 1.0000e+00,\n",
            "        2.9100e+02, 2.0000e+00, 2.5470e+03, 2.3000e+01, 1.0000e+00, 1.3400e+02])\n",
            "['Pharmacology', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'studies', 'the', 'effects', 'of', 'drugs', 'on', 'the', 'body.', 'Pharmacology', 'is', 'the', 'branch', 'of', 'medicine', 'that', 'studies', 'the', 'effects', 'of', 'drugs', 'on', 'the', 'body.']\n",
            "[('Pharmacology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'effects'), ('effects', 'of'), ('of', 'drugs'), ('drugs', 'on'), ('on', 'the'), ('the', 'body.'), ('Pharmacology', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'effects'), ('effects', 'of'), ('of', 'drugs'), ('drugs', 'on'), ('on', 'the'), ('the', 'body.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([  45., 2947.,    3.,    4.,  191.,   86.,  337.,    8., 2990., 2948.,\n",
            "           6.,  363., 1330., 1443.,   45., 2947.,    3.,    4.,  191.,   86.,\n",
            "         337.,    8., 2990., 2948.,    6.,  363., 1330., 1443.])\n",
            "['An', 'anesthesiologist', 'is', 'a', 'doctor', 'who', 'specializes', 'in', 'administering', 'anesthesia', 'to', 'patients', 'undergoing', 'surgery.', 'An', 'anesthesiologist', 'is', 'a', 'doctor', 'who', 'specializes', 'in', 'administering', 'anesthesia', 'to', 'patients', 'undergoing', 'surgery.']\n",
            "[('An', 'anesthesiologist'), ('anesthesiologist', 'is'), ('is', 'a'), ('a', 'doctor'), ('doctor', 'who'), ('who', 'specializes'), ('specializes', 'in'), ('in', 'administering'), ('administering', 'anesthesia'), ('anesthesia', 'to'), ('to', 'patients'), ('patients', 'undergoing'), ('undergoing', 'surgery.'), ('An', 'anesthesiologist'), ('anesthesiologist', 'is'), ('is', 'a'), ('a', 'doctor'), ('doctor', 'who'), ('who', 'specializes'), ('specializes', 'in'), ('in', 'administering'), ('administering', 'anesthesia'), ('anesthesia', 'to'), ('to', 'patients'), ('patients', 'undergoing'), ('undergoing', 'surgery.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([4.5000e+01, 1.9100e+03, 3.0000e+00, 4.0000e+00, 1.9100e+02, 8.6000e+01,\n",
            "        3.3700e+02, 8.0000e+00, 1.7540e+03, 2.7770e+03, 5.0000e+00, 1.0000e+00,\n",
            "        1.7680e+03, 1.8260e+03, 4.5000e+01, 1.9100e+03, 3.0000e+00, 4.0000e+00,\n",
            "        1.9100e+02, 8.6000e+01, 3.3700e+02, 8.0000e+00, 1.7540e+03, 2.7770e+03,\n",
            "        5.0000e+00, 1.0000e+00, 1.7680e+03, 1.8260e+03])\n",
            "['An', 'obstetrician', 'is', 'a', 'doctor', 'who', 'specializes', 'in', 'pregnancy,', 'childbirth,', 'and', 'the', 'postpartum', 'period.', 'An', 'obstetrician', 'is', 'a', 'doctor', 'who', 'specializes', 'in', 'pregnancy,', 'childbirth,', 'and', 'the', 'postpartum', 'period.']\n",
            "[('An', 'obstetrician'), ('obstetrician', 'is'), ('is', 'a'), ('a', 'doctor'), ('doctor', 'who'), ('who', 'specializes'), ('specializes', 'in'), ('in', 'pregnancy,'), ('pregnancy,', 'childbirth,'), ('childbirth,', 'and'), ('and', 'the'), ('the', 'postpartum'), ('postpartum', 'period.'), ('An', 'obstetrician'), ('obstetrician', 'is'), ('is', 'a'), ('a', 'doctor'), ('doctor', 'who'), ('who', 'specializes'), ('specializes', 'in'), ('in', 'pregnancy,'), ('pregnancy,', 'childbirth,'), ('childbirth,', 'and'), ('and', 'the'), ('the', 'postpartum'), ('postpartum', 'period.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([1.1000e+01, 2.3020e+03, 3.0000e+00, 4.0000e+00, 1.9100e+02, 8.6000e+01,\n",
            "        3.3700e+02, 8.0000e+00, 1.0000e+00, 9.9600e+02, 4.9800e+02, 2.0600e+02,\n",
            "        1.1000e+01, 2.3020e+03, 3.0000e+00, 4.0000e+00, 1.9100e+02, 8.6000e+01,\n",
            "        3.3700e+02, 8.0000e+00, 1.0000e+00, 9.9600e+02, 4.9800e+02, 2.0600e+02])\n",
            "['A', 'gynecologist', 'is', 'a', 'doctor', 'who', 'specializes', 'in', 'the', 'female', 'reproductive', 'system.', 'A', 'gynecologist', 'is', 'a', 'doctor', 'who', 'specializes', 'in', 'the', 'female', 'reproductive', 'system.']\n",
            "[('A', 'gynecologist'), ('gynecologist', 'is'), ('is', 'a'), ('a', 'doctor'), ('doctor', 'who'), ('who', 'specializes'), ('specializes', 'in'), ('in', 'the'), ('the', 'female'), ('female', 'reproductive'), ('reproductive', 'system.'), ('A', 'gynecologist'), ('gynecologist', 'is'), ('is', 'a'), ('a', 'doctor'), ('doctor', 'who'), ('who', 'specializes'), ('specializes', 'in'), ('in', 'the'), ('the', 'female'), ('female', 'reproductive'), ('reproductive', 'system.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([1.1000e+01, 2.6240e+03, 3.0000e+00, 4.0000e+00, 1.9100e+02, 8.6000e+01,\n",
            "        3.3700e+02, 8.0000e+00, 1.0000e+00, 1.0550e+03, 8.2100e+02, 5.0000e+00,\n",
            "        3.2500e+02, 2.0000e+00, 6.1400e+02, 5.0000e+00, 6.3400e+02, 2.0000e+00,\n",
            "        1.0000e+00, 8.6100e+02, 1.1020e+03, 1.1000e+01, 2.6240e+03, 3.0000e+00,\n",
            "        4.0000e+00, 1.9100e+02, 8.6000e+01, 3.3700e+02, 8.0000e+00, 1.0000e+00,\n",
            "        1.0550e+03, 8.2100e+02, 5.0000e+00, 3.2500e+02, 2.0000e+00, 6.1400e+02,\n",
            "        5.0000e+00, 6.3400e+02, 2.0000e+00, 1.0000e+00, 8.6100e+02, 1.1020e+03])\n",
            "['A', 'dentist', 'is', 'a', 'doctor', 'who', 'specializes', 'in', 'the', 'diagnosis,', 'prevention,', 'and', 'treatment', 'of', 'diseases', 'and', 'conditions', 'of', 'the', 'oral', 'cavity.', 'A', 'dentist', 'is', 'a', 'doctor', 'who', 'specializes', 'in', 'the', 'diagnosis,', 'prevention,', 'and', 'treatment', 'of', 'diseases', 'and', 'conditions', 'of', 'the', 'oral', 'cavity.']\n",
            "[('A', 'dentist'), ('dentist', 'is'), ('is', 'a'), ('a', 'doctor'), ('doctor', 'who'), ('who', 'specializes'), ('specializes', 'in'), ('in', 'the'), ('the', 'diagnosis,'), ('diagnosis,', 'prevention,'), ('prevention,', 'and'), ('and', 'treatment'), ('treatment', 'of'), ('of', 'diseases'), ('diseases', 'and'), ('and', 'conditions'), ('conditions', 'of'), ('of', 'the'), ('the', 'oral'), ('oral', 'cavity.'), ('A', 'dentist'), ('dentist', 'is'), ('is', 'a'), ('a', 'doctor'), ('doctor', 'who'), ('who', 'specializes'), ('specializes', 'in'), ('in', 'the'), ('the', 'diagnosis,'), ('diagnosis,', 'prevention,'), ('prevention,', 'and'), ('and', 'treatment'), ('treatment', 'of'), ('of', 'diseases'), ('diseases', 'and'), ('and', 'conditions'), ('conditions', 'of'), ('of', 'the'), ('the', 'oral'), ('oral', 'cavity.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([3.1580e+03, 4.6000e+02, 3.0000e+00, 4.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.0400e+02, 7.0000e+00, 1.2600e+02, 2.4600e+03, 5.0000e+00, 5.8000e+01,\n",
            "        7.1400e+02, 6.0000e+00, 2.8300e+02, 3.6300e+02, 1.6560e+03, 2.4000e+01,\n",
            "        9.4700e+02, 5.0000e+00, 2.2490e+03, 3.1580e+03, 4.6000e+02, 3.0000e+00,\n",
            "        4.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02, 7.0000e+00, 1.2600e+02,\n",
            "        2.4600e+03, 5.0000e+00, 5.8000e+01, 7.1400e+02, 6.0000e+00, 2.8300e+02,\n",
            "        3.6300e+02, 1.6560e+03, 2.4000e+01, 9.4700e+02, 5.0000e+00, 2.2490e+03])\n",
            "['Physical', 'therapy', 'is', 'a', 'branch', 'of', 'medicine', 'that', 'uses', 'exercises', 'and', 'other', 'treatments', 'to', 'help', 'patients', 'recover', 'from', 'injuries', 'and', 'illnesses.', 'Physical', 'therapy', 'is', 'a', 'branch', 'of', 'medicine', 'that', 'uses', 'exercises', 'and', 'other', 'treatments', 'to', 'help', 'patients', 'recover', 'from', 'injuries', 'and', 'illnesses.']\n",
            "[('Physical', 'therapy'), ('therapy', 'is'), ('is', 'a'), ('a', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'uses'), ('uses', 'exercises'), ('exercises', 'and'), ('and', 'other'), ('other', 'treatments'), ('treatments', 'to'), ('to', 'help'), ('help', 'patients'), ('patients', 'recover'), ('recover', 'from'), ('from', 'injuries'), ('injuries', 'and'), ('and', 'illnesses.'), ('Physical', 'therapy'), ('therapy', 'is'), ('is', 'a'), ('a', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'uses'), ('uses', 'exercises'), ('exercises', 'and'), ('and', 'other'), ('other', 'treatments'), ('treatments', 'to'), ('to', 'help'), ('help', 'patients'), ('patients', 'recover'), ('recover', 'from'), ('from', 'injuries'), ('injuries', 'and'), ('and', 'illnesses.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([3.1840e+03, 4.6000e+02, 3.0000e+00, 4.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        1.0400e+02, 7.0000e+00, 3.9100e+02, 3.6300e+02, 2.6090e+03, 1.6550e+03,\n",
            "        1.0000e+01, 5.4300e+02, 1.0000e+00, 6.2500e+02, 2.1900e+02, 5.0000e+00,\n",
            "        1.6200e+02, 1.5220e+03, 1.9560e+03, 1.2000e+01, 2.2270e+03, 3.1840e+03,\n",
            "        4.6000e+02, 3.0000e+00, 4.0000e+00, 2.7000e+01, 2.0000e+00, 1.0400e+02,\n",
            "        7.0000e+00, 3.9100e+02, 3.6300e+02, 2.6090e+03, 1.6550e+03, 1.0000e+01,\n",
            "        5.4300e+02, 1.0000e+00, 6.2500e+02, 2.1900e+02, 5.0000e+00, 1.6200e+02,\n",
            "        1.5220e+03, 1.9560e+03, 1.2000e+01, 2.2270e+03])\n",
            "['Occupational', 'therapy', 'is', 'a', 'branch', 'of', 'medicine', 'that', 'helps', 'patients', 'develop,', 'recover,', 'or', 'maintain', 'the', 'daily', 'living', 'and', 'work', 'skills', 'needed', 'for', 'independence.', 'Occupational', 'therapy', 'is', 'a', 'branch', 'of', 'medicine', 'that', 'helps', 'patients', 'develop,', 'recover,', 'or', 'maintain', 'the', 'daily', 'living', 'and', 'work', 'skills', 'needed', 'for', 'independence.']\n",
            "[('Occupational', 'therapy'), ('therapy', 'is'), ('is', 'a'), ('a', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'helps'), ('helps', 'patients'), ('patients', 'develop,'), ('develop,', 'recover,'), ('recover,', 'or'), ('or', 'maintain'), ('maintain', 'the'), ('the', 'daily'), ('daily', 'living'), ('living', 'and'), ('and', 'work'), ('work', 'skills'), ('skills', 'needed'), ('needed', 'for'), ('for', 'independence.'), ('Occupational', 'therapy'), ('therapy', 'is'), ('is', 'a'), ('a', 'branch'), ('branch', 'of'), ('of', 'medicine'), ('medicine', 'that'), ('that', 'helps'), ('helps', 'patients'), ('patients', 'develop,'), ('develop,', 'recover,'), ('recover,', 'or'), ('or', 'maintain'), ('maintain', 'the'), ('the', 'daily'), ('daily', 'living'), ('living', 'and'), ('and', 'work'), ('work', 'skills'), ('skills', 'needed'), ('needed', 'for'), ('for', 'independence.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([1.1000e+01, 8.1000e+01, 1.6130e+03, 2.7180e+03, 3.6000e+01, 6.0000e+00,\n",
            "        2.9830e+03, 1.3100e+02, 8.0000e+00, 1.0000e+00, 1.1200e+02, 2.0000e+00,\n",
            "        8.9200e+02, 1.1000e+01, 8.1000e+01, 1.6130e+03, 2.7180e+03, 3.6000e+01,\n",
            "        6.0000e+00, 2.9830e+03, 1.3100e+02, 8.0000e+00, 1.0000e+00, 1.1200e+02,\n",
            "        2.0000e+00, 8.9200e+02])\n",
            "['A', 'medical', 'researcher', 'conducts', 'studies', 'to', 'advance', 'knowledge', 'in', 'the', 'field', 'of', 'medicine.', 'A', 'medical', 'researcher', 'conducts', 'studies', 'to', 'advance', 'knowledge', 'in', 'the', 'field', 'of', 'medicine.']\n",
            "[('A', 'medical'), ('medical', 'researcher'), ('researcher', 'conducts'), ('conducts', 'studies'), ('studies', 'to'), ('to', 'advance'), ('advance', 'knowledge'), ('knowledge', 'in'), ('in', 'the'), ('the', 'field'), ('field', 'of'), ('of', 'medicine.'), ('A', 'medical'), ('medical', 'researcher'), ('researcher', 'conducts'), ('conducts', 'studies'), ('studies', 'to'), ('to', 'advance'), ('advance', 'knowledge'), ('knowledge', 'in'), ('in', 'the'), ('the', 'field'), ('field', 'of'), ('of', 'medicine.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.2050e+03, 1.3460e+03, 1.3000e+01, 2.5600e+02, 3.6000e+01, 7.0000e+00,\n",
            "        7.3300e+02, 1.0000e+00, 1.5760e+03, 5.0000e+00, 2.5320e+03, 2.0000e+00,\n",
            "        1.1900e+02, 7.1400e+02, 1.0000e+01, 2.1630e+03, 1.2050e+03, 1.3460e+03,\n",
            "        1.3000e+01, 2.5600e+02, 3.6000e+01, 7.0000e+00, 7.3300e+02, 1.0000e+00,\n",
            "        1.5760e+03, 5.0000e+00, 2.5320e+03, 2.0000e+00, 1.1900e+02, 7.1400e+02,\n",
            "        1.0000e+01, 2.1630e+03])\n",
            "['Clinical', 'trials', 'are', 'research', 'studies', 'that', 'test', 'the', 'safety', 'and', 'effectiveness', 'of', 'new', 'treatments', 'or', 'interventions.', 'Clinical', 'trials', 'are', 'research', 'studies', 'that', 'test', 'the', 'safety', 'and', 'effectiveness', 'of', 'new', 'treatments', 'or', 'interventions.']\n",
            "[('Clinical', 'trials'), ('trials', 'are'), ('are', 'research'), ('research', 'studies'), ('studies', 'that'), ('that', 'test'), ('test', 'the'), ('the', 'safety'), ('safety', 'and'), ('and', 'effectiveness'), ('effectiveness', 'of'), ('of', 'new'), ('new', 'treatments'), ('treatments', 'or'), ('or', 'interventions.'), ('Clinical', 'trials'), ('trials', 'are'), ('are', 'research'), ('research', 'studies'), ('studies', 'that'), ('that', 'test'), ('test', 'the'), ('the', 'safety'), ('safety', 'and'), ('and', 'effectiveness'), ('effectiveness', 'of'), ('of', 'new'), ('new', 'treatments'), ('treatments', 'or'), ('or', 'interventions.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.1440e+03, 1.0400e+02, 2.2800e+02, 2.3000e+01, 1.0000e+00, 1.7460e+03,\n",
            "        2.0000e+00, 6.1400e+02, 5.0000e+00, 1.0000e+00, 1.7190e+03, 2.0000e+00,\n",
            "        2.2600e+02, 5.0000e+00, 6.9600e+02, 3.1440e+03, 1.0400e+02, 2.2800e+02,\n",
            "        2.3000e+01, 1.0000e+00, 1.7460e+03, 2.0000e+00, 6.1400e+02, 5.0000e+00,\n",
            "        1.0000e+00, 1.7190e+03, 2.0000e+00, 2.2600e+02, 5.0000e+00, 6.9600e+02])\n",
            "['Preventive', 'medicine', 'focuses', 'on', 'the', 'prevention', 'of', 'diseases', 'and', 'the', 'promotion', 'of', 'health', 'and', 'well-being.', 'Preventive', 'medicine', 'focuses', 'on', 'the', 'prevention', 'of', 'diseases', 'and', 'the', 'promotion', 'of', 'health', 'and', 'well-being.']\n",
            "[('Preventive', 'medicine'), ('medicine', 'focuses'), ('focuses', 'on'), ('on', 'the'), ('the', 'prevention'), ('prevention', 'of'), ('of', 'diseases'), ('diseases', 'and'), ('and', 'the'), ('the', 'promotion'), ('promotion', 'of'), ('of', 'health'), ('health', 'and'), ('and', 'well-being.'), ('Preventive', 'medicine'), ('medicine', 'focuses'), ('focuses', 'on'), ('on', 'the'), ('the', 'prevention'), ('prevention', 'of'), ('of', 'diseases'), ('diseases', 'and'), ('and', 'the'), ('the', 'promotion'), ('promotion', 'of'), ('of', 'health'), ('health', 'and'), ('and', 'well-being.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.3380e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 7.6000e+01,\n",
            "        6.1400e+02, 1.4820e+03, 5.0000e+00, 1.6000e+01, 2.5000e+01, 1.0730e+03,\n",
            "        8.0000e+00, 8.3000e+02, 3.3380e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01,\n",
            "        2.0000e+00, 7.6000e+01, 6.1400e+02, 1.4820e+03, 5.0000e+00, 1.6000e+01,\n",
            "        2.5000e+01, 1.0730e+03, 8.0000e+00, 8.3000e+02])\n",
            "['Epidemiology', 'is', 'the', 'study', 'of', 'how', 'diseases', 'spread', 'and', 'can', 'be', 'controlled', 'in', 'populations.', 'Epidemiology', 'is', 'the', 'study', 'of', 'how', 'diseases', 'spread', 'and', 'can', 'be', 'controlled', 'in', 'populations.']\n",
            "[('Epidemiology', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'how'), ('how', 'diseases'), ('diseases', 'spread'), ('spread', 'and'), ('and', 'can'), ('can', 'be'), ('be', 'controlled'), ('controlled', 'in'), ('in', 'populations.'), ('Epidemiology', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'how'), ('how', 'diseases'), ('diseases', 'spread'), ('spread', 'and'), ('and', 'can'), ('can', 'be'), ('be', 'controlled'), ('controlled', 'in'), ('in', 'populations.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([1.1770e+03, 2.2600e+02, 3.0000e+00, 1.0000e+00, 3.4500e+02, 2.0000e+00,\n",
            "        8.1200e+02, 5.0000e+00, 2.2330e+03, 1.0000e+00, 2.2600e+02, 2.0000e+00,\n",
            "        1.0890e+03, 5.2000e+01, 2.5350e+03, 1.7780e+03, 5.0000e+00, 2.5600e+02,\n",
            "        1.2000e+01, 6.1500e+02, 5.0000e+00, 9.4600e+02, 1.7450e+03, 1.1770e+03,\n",
            "        2.2600e+02, 3.0000e+00, 1.0000e+00, 3.4500e+02, 2.0000e+00, 8.1200e+02,\n",
            "        5.0000e+00, 2.2330e+03, 1.0000e+00, 2.2600e+02, 2.0000e+00, 1.0890e+03,\n",
            "        5.2000e+01, 2.5350e+03, 1.7780e+03, 5.0000e+00, 2.5600e+02, 1.2000e+01,\n",
            "        6.1500e+02, 5.0000e+00, 9.4600e+02, 1.7450e+03])\n",
            "['Public', 'health', 'is', 'the', 'science', 'of', 'protecting', 'and', 'improving', 'the', 'health', 'of', 'communities', 'through', 'education,', 'policy-making,', 'and', 'research', 'for', 'disease', 'and', 'injury', 'prevention.', 'Public', 'health', 'is', 'the', 'science', 'of', 'protecting', 'and', 'improving', 'the', 'health', 'of', 'communities', 'through', 'education,', 'policy-making,', 'and', 'research', 'for', 'disease', 'and', 'injury', 'prevention.']\n",
            "[('Public', 'health'), ('health', 'is'), ('is', 'the'), ('the', 'science'), ('science', 'of'), ('of', 'protecting'), ('protecting', 'and'), ('and', 'improving'), ('improving', 'the'), ('the', 'health'), ('health', 'of'), ('of', 'communities'), ('communities', 'through'), ('through', 'education,'), ('education,', 'policy-making,'), ('policy-making,', 'and'), ('and', 'research'), ('research', 'for'), ('for', 'disease'), ('disease', 'and'), ('and', 'injury'), ('injury', 'prevention.'), ('Public', 'health'), ('health', 'is'), ('is', 'the'), ('the', 'science'), ('science', 'of'), ('of', 'protecting'), ('protecting', 'and'), ('and', 'improving'), ('improving', 'the'), ('the', 'health'), ('health', 'of'), ('of', 'communities'), ('communities', 'through'), ('through', 'education,'), ('education,', 'policy-making,'), ('policy-making,', 'and'), ('and', 'research'), ('research', 'for'), ('for', 'disease'), ('disease', 'and'), ('and', 'injury'), ('injury', 'prevention.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.0750e+03, 3.0000e+00, 1.0000e+00, 1.1500e+02, 2.0000e+00, 1.4160e+03,\n",
            "        3.3200e+02, 6.0000e+00, 8.0800e+02, 8.1000e+01, 2.3800e+02, 5.0000e+00,\n",
            "        2.7060e+03, 1.6250e+03, 3.0750e+03, 3.0000e+00, 1.0000e+00, 1.1500e+02,\n",
            "        2.0000e+00, 1.4160e+03, 3.3200e+02, 6.0000e+00, 8.0800e+02, 8.1000e+01,\n",
            "        2.3800e+02, 5.0000e+00, 2.7060e+03, 1.6250e+03])\n",
            "['Telemedicine', 'is', 'the', 'use', 'of', 'telecommunication', 'technology', 'to', 'provide', 'medical', 'care', 'and', 'consultation', 'remotely.', 'Telemedicine', 'is', 'the', 'use', 'of', 'telecommunication', 'technology', 'to', 'provide', 'medical', 'care', 'and', 'consultation', 'remotely.']\n",
            "[('Telemedicine', 'is'), ('is', 'the'), ('the', 'use'), ('use', 'of'), ('of', 'telecommunication'), ('telecommunication', 'technology'), ('technology', 'to'), ('to', 'provide'), ('provide', 'medical'), ('medical', 'care'), ('care', 'and'), ('and', 'consultation'), ('consultation', 'remotely.'), ('Telemedicine', 'is'), ('is', 'the'), ('the', 'use'), ('use', 'of'), ('of', 'telecommunication'), ('telecommunication', 'technology'), ('technology', 'to'), ('to', 'provide'), ('provide', 'medical'), ('medical', 'care'), ('care', 'and'), ('and', 'consultation'), ('consultation', 'remotely.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 1.4730e+03, 3.0000e+00, 4.0000e+00, 8.1000e+01, 2.1890e+03,\n",
            "        3.1000e+01, 6.0000e+00, 2.0890e+03, 6.0000e+00, 1.0000e+00, 2.1000e+02,\n",
            "        3.5300e+02, 1.6400e+02, 1.0000e+00, 1.3400e+02, 1.1000e+01, 1.4730e+03,\n",
            "        3.0000e+00, 4.0000e+00, 8.1000e+01, 2.1890e+03, 3.1000e+01, 6.0000e+00,\n",
            "        2.0890e+03, 6.0000e+00, 1.0000e+00, 2.1000e+02, 3.5300e+02, 1.6400e+02,\n",
            "        1.0000e+00, 1.3400e+02])\n",
            "['A', 'stethoscope', 'is', 'a', 'medical', 'instrument', 'used', 'to', 'listen', 'to', 'the', 'sounds', 'produced', 'within', 'the', 'body.', 'A', 'stethoscope', 'is', 'a', 'medical', 'instrument', 'used', 'to', 'listen', 'to', 'the', 'sounds', 'produced', 'within', 'the', 'body.']\n",
            "[('A', 'stethoscope'), ('stethoscope', 'is'), ('is', 'a'), ('a', 'medical'), ('medical', 'instrument'), ('instrument', 'used'), ('used', 'to'), ('to', 'listen'), ('listen', 'to'), ('to', 'the'), ('the', 'sounds'), ('sounds', 'produced'), ('produced', 'within'), ('within', 'the'), ('the', 'body.'), ('A', 'stethoscope'), ('stethoscope', 'is'), ('is', 'a'), ('a', 'medical'), ('medical', 'instrument'), ('instrument', 'used'), ('used', 'to'), ('to', 'listen'), ('listen', 'to'), ('to', 'the'), ('the', 'sounds'), ('sounds', 'produced'), ('produced', 'within'), ('within', 'the'), ('the', 'body.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([4.5000e+01, 2.5220e+03, 3.4920e+03, 1.0000e+01, 3.3500e+03, 3.0000e+00,\n",
            "        4.0000e+00, 7.3300e+02, 7.0000e+00, 5.3800e+02, 1.0000e+00, 6.1100e+02,\n",
            "        2.9980e+03, 2.0000e+00, 1.0000e+00, 9.6100e+02, 4.5000e+01, 2.5220e+03,\n",
            "        3.4920e+03, 1.0000e+01, 3.3500e+03, 3.0000e+00, 4.0000e+00, 7.3300e+02,\n",
            "        7.0000e+00, 5.3800e+02, 1.0000e+00, 6.1100e+02, 2.9980e+03, 2.0000e+00,\n",
            "        1.0000e+00, 9.6100e+02])\n",
            "['An', 'electrocardiogram', '(ECG', 'or', 'EKG)', 'is', 'a', 'test', 'that', 'measures', 'the', 'electrical', 'activity', 'of', 'the', 'heart.', 'An', 'electrocardiogram', '(ECG', 'or', 'EKG)', 'is', 'a', 'test', 'that', 'measures', 'the', 'electrical', 'activity', 'of', 'the', 'heart.']\n",
            "[('An', 'electrocardiogram'), ('electrocardiogram', '(ECG'), ('(ECG', 'or'), ('or', 'EKG)'), ('EKG)', 'is'), ('is', 'a'), ('a', 'test'), ('test', 'that'), ('that', 'measures'), ('measures', 'the'), ('the', 'electrical'), ('electrical', 'activity'), ('activity', 'of'), ('of', 'the'), ('the', 'heart.'), ('An', 'electrocardiogram'), ('electrocardiogram', '(ECG'), ('(ECG', 'or'), ('or', 'EKG)'), ('EKG)', 'is'), ('is', 'a'), ('a', 'test'), ('test', 'that'), ('that', 'measures'), ('measures', 'the'), ('the', 'electrical'), ('electrical', 'activity'), ('activity', 'of'), ('of', 'the'), ('the', 'heart.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([3.2280e+03, 1.6100e+03, 2.8100e+02, 3.4900e+03, 3.0000e+00, 2.1000e+01,\n",
            "        2.8100e+02, 7.3500e+02, 7.0000e+00, 1.2600e+02, 1.4500e+02, 5.9500e+02,\n",
            "        5.0000e+00, 1.6840e+03, 3.1700e+02, 6.0000e+00, 1.0100e+02, 1.0590e+03,\n",
            "        5.6400e+02, 2.0000e+00, 1.0000e+00, 6.4600e+02, 3.8500e+02, 4.7200e+02,\n",
            "        3.2280e+03, 1.6100e+03, 2.8100e+02, 3.4900e+03, 3.0000e+00, 2.1000e+01,\n",
            "        2.8100e+02, 7.3500e+02, 7.0000e+00, 1.2600e+02, 1.4500e+02, 5.9500e+02,\n",
            "        5.0000e+00, 1.6840e+03, 3.1700e+02, 6.0000e+00, 1.0100e+02, 1.0590e+03,\n",
            "        5.6400e+02, 2.0000e+00, 1.0000e+00, 6.4600e+02, 3.8500e+02, 4.7200e+02])\n",
            "['Magnetic', 'resonance', 'imaging', '(MRI)', 'is', 'an', 'imaging', 'technique', 'that', 'uses', 'magnetic', 'fields', 'and', 'radio', 'waves', 'to', 'produce', 'detailed', 'images', 'of', 'the', \"body's\", 'internal', 'structures.', 'Magnetic', 'resonance', 'imaging', '(MRI)', 'is', 'an', 'imaging', 'technique', 'that', 'uses', 'magnetic', 'fields', 'and', 'radio', 'waves', 'to', 'produce', 'detailed', 'images', 'of', 'the', \"body's\", 'internal', 'structures.']\n",
            "[('Magnetic', 'resonance'), ('resonance', 'imaging'), ('imaging', '(MRI)'), ('(MRI)', 'is'), ('is', 'an'), ('an', 'imaging'), ('imaging', 'technique'), ('technique', 'that'), ('that', 'uses'), ('uses', 'magnetic'), ('magnetic', 'fields'), ('fields', 'and'), ('and', 'radio'), ('radio', 'waves'), ('waves', 'to'), ('to', 'produce'), ('produce', 'detailed'), ('detailed', 'images'), ('images', 'of'), ('of', 'the'), ('the', \"body's\"), (\"body's\", 'internal'), ('internal', 'structures.'), ('Magnetic', 'resonance'), ('resonance', 'imaging'), ('imaging', '(MRI)'), ('(MRI)', 'is'), ('is', 'an'), ('an', 'imaging'), ('imaging', 'technique'), ('technique', 'that'), ('that', 'uses'), ('uses', 'magnetic'), ('magnetic', 'fields'), ('fields', 'and'), ('and', 'radio'), ('radio', 'waves'), ('waves', 'to'), ('to', 'produce'), ('produce', 'detailed'), ('detailed', 'images'), ('images', 'of'), ('of', 'the'), ('the', \"body's\"), (\"body's\", 'internal'), ('internal', 'structures.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.3900e+03, 1.3770e+03, 3.4930e+03, 1.5670e+03, 1.1500e+02, 3.0250e+03,\n",
            "        6.0000e+00, 2.3500e+02, 1.0590e+03, 5.6400e+02, 2.0000e+00, 1.0000e+00,\n",
            "        6.4600e+02, 3.8500e+02, 4.7200e+02, 3.3900e+03, 1.3770e+03, 3.4930e+03,\n",
            "        1.5670e+03, 1.1500e+02, 3.0250e+03, 6.0000e+00, 2.3500e+02, 1.0590e+03,\n",
            "        5.6400e+02, 2.0000e+00, 1.0000e+00, 6.4600e+02, 3.8500e+02, 4.7200e+02])\n",
            "['Computed', 'tomography', '(CT)', 'scans', 'use', 'X-rays', 'to', 'create', 'detailed', 'images', 'of', 'the', \"body's\", 'internal', 'structures.', 'Computed', 'tomography', '(CT)', 'scans', 'use', 'X-rays', 'to', 'create', 'detailed', 'images', 'of', 'the', \"body's\", 'internal', 'structures.']\n",
            "[('Computed', 'tomography'), ('tomography', '(CT)'), ('(CT)', 'scans'), ('scans', 'use'), ('use', 'X-rays'), ('X-rays', 'to'), ('to', 'create'), ('create', 'detailed'), ('detailed', 'images'), ('images', 'of'), ('of', 'the'), ('the', \"body's\"), (\"body's\", 'internal'), ('internal', 'structures.'), ('Computed', 'tomography'), ('tomography', '(CT)'), ('(CT)', 'scans'), ('scans', 'use'), ('use', 'X-rays'), ('X-rays', 'to'), ('to', 'create'), ('create', 'detailed'), ('detailed', 'images'), ('images', 'of'), ('of', 'the'), ('the', \"body's\"), (\"body's\", 'internal'), ('internal', 'structures.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.0530e+03, 2.8100e+02, 1.2600e+02, 2.2770e+03, 1.7100e+02, 3.1700e+02,\n",
            "        6.0000e+00, 2.3500e+02, 5.6400e+02, 2.0000e+00, 1.0000e+00, 2.1940e+03,\n",
            "        2.0000e+00, 1.0000e+00, 1.3400e+02, 3.0530e+03, 2.8100e+02, 1.2600e+02,\n",
            "        2.2770e+03, 1.7100e+02, 3.1700e+02, 6.0000e+00, 2.3500e+02, 5.6400e+02,\n",
            "        2.0000e+00, 1.0000e+00, 2.1940e+03, 2.0000e+00, 1.0000e+00, 1.3400e+02])\n",
            "['Ultrasound', 'imaging', 'uses', 'high-frequency', 'sound', 'waves', 'to', 'create', 'images', 'of', 'the', 'inside', 'of', 'the', 'body.', 'Ultrasound', 'imaging', 'uses', 'high-frequency', 'sound', 'waves', 'to', 'create', 'images', 'of', 'the', 'inside', 'of', 'the', 'body.']\n",
            "[('Ultrasound', 'imaging'), ('imaging', 'uses'), ('uses', 'high-frequency'), ('high-frequency', 'sound'), ('sound', 'waves'), ('waves', 'to'), ('to', 'create'), ('create', 'images'), ('images', 'of'), ('of', 'the'), ('the', 'inside'), ('inside', 'of'), ('of', 'the'), ('the', 'body.'), ('Ultrasound', 'imaging'), ('imaging', 'uses'), ('uses', 'high-frequency'), ('high-frequency', 'sound'), ('sound', 'waves'), ('waves', 'to'), ('to', 'create'), ('create', 'images'), ('images', 'of'), ('of', 'the'), ('the', 'inside'), ('inside', 'of'), ('of', 'the'), ('the', 'body.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([1.1000e+01, 2.8590e+03, 3.0000e+00, 4.0000e+00, 8.1000e+01, 5.1200e+02,\n",
            "        7.0000e+00, 1.0800e+02, 1.4240e+03, 4.0000e+00, 4.8200e+02, 7.8400e+02,\n",
            "        2.0000e+00, 3.2900e+02, 1.2000e+01, 6.0300e+02, 3.2300e+02, 4.0000e+00,\n",
            "        2.0060e+03, 1.1000e+01, 2.8590e+03, 3.0000e+00, 4.0000e+00, 8.1000e+01,\n",
            "        5.1200e+02, 7.0000e+00, 1.0800e+02, 1.4240e+03, 4.0000e+00, 4.8200e+02,\n",
            "        7.8400e+02, 2.0000e+00, 3.2900e+02, 1.2000e+01, 6.0300e+02, 3.2300e+02,\n",
            "        4.0000e+00, 2.0060e+03])\n",
            "['A', 'biopsy', 'is', 'a', 'medical', 'procedure', 'that', 'involves', 'taking', 'a', 'small', 'sample', 'of', 'tissue', 'for', 'examination', 'under', 'a', 'microscope.', 'A', 'biopsy', 'is', 'a', 'medical', 'procedure', 'that', 'involves', 'taking', 'a', 'small', 'sample', 'of', 'tissue', 'for', 'examination', 'under', 'a', 'microscope.']\n",
            "[('A', 'biopsy'), ('biopsy', 'is'), ('is', 'a'), ('a', 'medical'), ('medical', 'procedure'), ('procedure', 'that'), ('that', 'involves'), ('involves', 'taking'), ('taking', 'a'), ('a', 'small'), ('small', 'sample'), ('sample', 'of'), ('of', 'tissue'), ('tissue', 'for'), ('for', 'examination'), ('examination', 'under'), ('under', 'a'), ('a', 'microscope.'), ('A', 'biopsy'), ('biopsy', 'is'), ('is', 'a'), ('a', 'medical'), ('medical', 'procedure'), ('procedure', 'that'), ('that', 'involves'), ('involves', 'taking'), ('taking', 'a'), ('a', 'small'), ('small', 'sample'), ('sample', 'of'), ('of', 'tissue'), ('tissue', 'for'), ('for', 'examination'), ('examination', 'under'), ('under', 'a'), ('a', 'microscope.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3419.,  732.,   13.,  922., 2953., 1828.,   23.,    4.,   77.,  784.,\n",
            "           6., 1126.,  226.,    5.,  617.,  234., 3419.,  732.,   13.,  922.,\n",
            "        2953., 1828.,   23.,    4.,   77.,  784.,    6., 1126.,  226.,    5.,\n",
            "         617.,  234.])\n",
            "['Blood', 'tests', 'are', 'laboratory', 'analyses', 'performed', 'on', 'a', 'blood', 'sample', 'to', 'assess', 'health', 'and', 'diagnose', 'diseases.', 'Blood', 'tests', 'are', 'laboratory', 'analyses', 'performed', 'on', 'a', 'blood', 'sample', 'to', 'assess', 'health', 'and', 'diagnose', 'diseases.']\n",
            "[('Blood', 'tests'), ('tests', 'are'), ('are', 'laboratory'), ('laboratory', 'analyses'), ('analyses', 'performed'), ('performed', 'on'), ('on', 'a'), ('a', 'blood'), ('blood', 'sample'), ('sample', 'to'), ('to', 'assess'), ('assess', 'health'), ('health', 'and'), ('and', 'diagnose'), ('diagnose', 'diseases.'), ('Blood', 'tests'), ('tests', 'are'), ('are', 'laboratory'), ('laboratory', 'analyses'), ('analyses', 'performed'), ('performed', 'on'), ('on', 'a'), ('a', 'blood'), ('blood', 'sample'), ('sample', 'to'), ('to', 'assess'), ('assess', 'health'), ('health', 'and'), ('and', 'diagnose'), ('diagnose', 'diseases.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([3.0470e+03, 3.0000e+00, 1.0000e+00, 2.9890e+03, 2.0000e+00, 4.0000e+00,\n",
            "        1.3090e+03, 6.0000e+00, 7.5000e+02, 1.0000e+00, 2.8000e+02, 2.6000e+01,\n",
            "        6.0000e+00, 3.5000e+02, 1.9500e+02, 8.0000e+01, 2.2110e+03, 2.3400e+02,\n",
            "        3.0470e+03, 3.0000e+00, 1.0000e+00, 2.9890e+03, 2.0000e+00, 4.0000e+00,\n",
            "        1.3090e+03, 6.0000e+00, 7.5000e+02, 1.0000e+00, 2.8000e+02, 2.6000e+01,\n",
            "        6.0000e+00, 3.5000e+02, 1.9500e+02, 8.0000e+01, 2.2110e+03, 2.3400e+02])\n",
            "['Vaccination', 'is', 'the', 'administration', 'of', 'a', 'vaccine', 'to', 'stimulate', 'the', 'immune', 'system', 'to', 'protect', 'against', 'specific', 'infectious', 'diseases.', 'Vaccination', 'is', 'the', 'administration', 'of', 'a', 'vaccine', 'to', 'stimulate', 'the', 'immune', 'system', 'to', 'protect', 'against', 'specific', 'infectious', 'diseases.']\n",
            "[('Vaccination', 'is'), ('is', 'the'), ('the', 'administration'), ('administration', 'of'), ('of', 'a'), ('a', 'vaccine'), ('vaccine', 'to'), ('to', 'stimulate'), ('stimulate', 'the'), ('the', 'immune'), ('immune', 'system'), ('system', 'to'), ('to', 'protect'), ('protect', 'against'), ('against', 'specific'), ('specific', 'infectious'), ('infectious', 'diseases.'), ('Vaccination', 'is'), ('is', 'the'), ('the', 'administration'), ('administration', 'of'), ('of', 'a'), ('a', 'vaccine'), ('vaccine', 'to'), ('to', 'stimulate'), ('stimulate', 'the'), ('the', 'immune'), ('immune', 'system'), ('system', 'to'), ('to', 'protect'), ('protect', 'against'), ('against', 'specific'), ('specific', 'infectious'), ('infectious', 'diseases.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.0890e+03, 3.0000e+00, 1.0000e+00, 5.7000e+01, 2.0000e+00, 5.4200e+02,\n",
            "        2.1000e+01, 1.1800e+02, 5.9100e+02, 2.4000e+01, 2.8880e+03, 1.0000e+01,\n",
            "        5.8000e+01, 2.1900e+02, 2.0070e+03, 3.0890e+03, 3.0000e+00, 1.0000e+00,\n",
            "        5.7000e+01, 2.0000e+00, 5.4200e+02, 2.1000e+01, 1.1800e+02, 5.9100e+02,\n",
            "        2.4000e+01, 2.8880e+03, 1.0000e+01, 5.8000e+01, 2.1900e+02, 2.0070e+03])\n",
            "['Sterilization', 'is', 'the', 'process', 'of', 'making', 'an', 'object', 'free', 'from', 'bacteria', 'or', 'other', 'living', 'microorganisms.', 'Sterilization', 'is', 'the', 'process', 'of', 'making', 'an', 'object', 'free', 'from', 'bacteria', 'or', 'other', 'living', 'microorganisms.']\n",
            "[('Sterilization', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'of'), ('of', 'making'), ('making', 'an'), ('an', 'object'), ('object', 'free'), ('free', 'from'), ('from', 'bacteria'), ('bacteria', 'or'), ('or', 'other'), ('other', 'living'), ('living', 'microorganisms.'), ('Sterilization', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'of'), ('of', 'making'), ('making', 'an'), ('an', 'object'), ('object', 'free'), ('free', 'from'), ('from', 'bacteria'), ('bacteria', 'or'), ('or', 'other'), ('other', 'living'), ('living', 'microorganisms.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([3.3270e+03, 1.1420e+03, 3.0000e+00, 1.0000e+00, 2.2450e+03, 2.3800e+02,\n",
            "        5.7800e+02, 6.0000e+00, 4.0000e+00, 8.4600e+02, 8.6000e+01, 5.4000e+01,\n",
            "        6.4900e+02, 2.2010e+03, 1.0000e+01, 3.0000e+00, 1.4530e+03, 7.3900e+02,\n",
            "        2.2510e+03, 3.3270e+03, 1.1420e+03, 3.0000e+00, 1.0000e+00, 2.2450e+03,\n",
            "        2.3800e+02, 5.7800e+02, 6.0000e+00, 4.0000e+00, 8.4600e+02, 8.6000e+01,\n",
            "        5.4000e+01, 6.4900e+02, 2.2010e+03, 1.0000e+01, 3.0000e+00, 1.4530e+03,\n",
            "        7.3900e+02, 2.2510e+03])\n",
            "['First', 'aid', 'is', 'the', 'immediate', 'care', 'given', 'to', 'a', 'person', 'who', 'has', 'been', 'injured', 'or', 'is', 'suddenly', 'taken', 'ill.', 'First', 'aid', 'is', 'the', 'immediate', 'care', 'given', 'to', 'a', 'person', 'who', 'has', 'been', 'injured', 'or', 'is', 'suddenly', 'taken', 'ill.']\n",
            "[('First', 'aid'), ('aid', 'is'), ('is', 'the'), ('the', 'immediate'), ('immediate', 'care'), ('care', 'given'), ('given', 'to'), ('to', 'a'), ('a', 'person'), ('person', 'who'), ('who', 'has'), ('has', 'been'), ('been', 'injured'), ('injured', 'or'), ('or', 'is'), ('is', 'suddenly'), ('suddenly', 'taken'), ('taken', 'ill.'), ('First', 'aid'), ('aid', 'is'), ('is', 'the'), ('the', 'immediate'), ('immediate', 'care'), ('care', 'given'), ('given', 'to'), ('to', 'a'), ('a', 'person'), ('person', 'who'), ('who', 'has'), ('has', 'been'), ('been', 'injured'), ('injured', 'or'), ('or', 'is'), ('is', 'suddenly'), ('suddenly', 'taken'), ('taken', 'ill.')]\n",
            "46\n",
            "44\n",
            "1035\n",
            "90\n",
            "tensor([3.4050e+03, 1.6000e+03, 3.4940e+03, 3.0000e+00, 2.1000e+01, 2.5140e+03,\n",
            "        5.1200e+02, 7.0000e+00, 2.7500e+03, 2.7780e+03, 2.7330e+03, 1.9000e+01,\n",
            "        6.5300e+02, 1.2990e+03, 6.0000e+00, 5.4300e+02, 2.7700e+03, 5.9300e+02,\n",
            "        5.0000e+00, 1.8610e+03, 4.0400e+02, 6.4100e+02, 1.1290e+03, 3.4050e+03,\n",
            "        1.6000e+03, 3.4940e+03, 3.0000e+00, 2.1000e+01, 2.5140e+03, 5.1200e+02,\n",
            "        7.0000e+00, 2.7500e+03, 2.7780e+03, 2.7330e+03, 1.9000e+01, 6.5300e+02,\n",
            "        1.2990e+03, 6.0000e+00, 5.4300e+02, 2.7700e+03, 5.9300e+02, 5.0000e+00,\n",
            "        1.8610e+03, 4.0400e+02, 6.4100e+02, 1.1290e+03])\n",
            "['Cardiopulmonary', 'resuscitation', '(CPR)', 'is', 'an', 'emergency', 'procedure', 'that', 'combines', 'chest', 'compressions', 'with', 'artificial', 'ventilation', 'to', 'maintain', 'circulatory', 'flow', 'and', 'oxygenation', 'during', 'cardiac', 'arrest.', 'Cardiopulmonary', 'resuscitation', '(CPR)', 'is', 'an', 'emergency', 'procedure', 'that', 'combines', 'chest', 'compressions', 'with', 'artificial', 'ventilation', 'to', 'maintain', 'circulatory', 'flow', 'and', 'oxygenation', 'during', 'cardiac', 'arrest.']\n",
            "[('Cardiopulmonary', 'resuscitation'), ('resuscitation', '(CPR)'), ('(CPR)', 'is'), ('is', 'an'), ('an', 'emergency'), ('emergency', 'procedure'), ('procedure', 'that'), ('that', 'combines'), ('combines', 'chest'), ('chest', 'compressions'), ('compressions', 'with'), ('with', 'artificial'), ('artificial', 'ventilation'), ('ventilation', 'to'), ('to', 'maintain'), ('maintain', 'circulatory'), ('circulatory', 'flow'), ('flow', 'and'), ('and', 'oxygenation'), ('oxygenation', 'during'), ('during', 'cardiac'), ('cardiac', 'arrest.'), ('Cardiopulmonary', 'resuscitation'), ('resuscitation', '(CPR)'), ('(CPR)', 'is'), ('is', 'an'), ('an', 'emergency'), ('emergency', 'procedure'), ('procedure', 'that'), ('that', 'combines'), ('combines', 'chest'), ('chest', 'compressions'), ('compressions', 'with'), ('with', 'artificial'), ('artificial', 'ventilation'), ('ventilation', 'to'), ('to', 'maintain'), ('maintain', 'circulatory'), ('circulatory', 'flow'), ('flow', 'and'), ('and', 'oxygenation'), ('oxygenation', 'during'), ('during', 'cardiac'), ('cardiac', 'arrest.')]\n",
            "54\n",
            "52\n",
            "1431\n",
            "106\n",
            "tensor([1.1000e+01, 2.6310e+03, 3.0000e+00, 4.0000e+00, 8.1000e+01, 6.1800e+02,\n",
            "        7.0000e+00, 2.6260e+03, 2.1000e+01, 2.3200e+02, 1.5330e+03, 6.0000e+00,\n",
            "        1.0000e+00, 2.8400e+02, 6.0000e+00, 1.6050e+03, 4.0000e+00, 2.6900e+02,\n",
            "        1.5930e+03, 8.0000e+00, 2.8100e+03, 2.0000e+00, 1.5400e+03, 2.9220e+03,\n",
            "        1.0000e+01, 6.4100e+02, 1.1290e+03, 1.1000e+01, 2.6310e+03, 3.0000e+00,\n",
            "        4.0000e+00, 8.1000e+01, 6.1800e+02, 7.0000e+00, 2.6260e+03, 2.1000e+01,\n",
            "        2.3200e+02, 1.5330e+03, 6.0000e+00, 1.0000e+00, 2.8400e+02, 6.0000e+00,\n",
            "        1.6050e+03, 4.0000e+00, 2.6900e+02, 1.5930e+03, 8.0000e+00, 2.8100e+03,\n",
            "        2.0000e+00, 1.5400e+03, 2.9220e+03, 1.0000e+01, 6.4100e+02, 1.1290e+03])\n",
            "['A', 'defibrillator', 'is', 'a', 'medical', 'device', 'that', 'delivers', 'an', 'electric', 'shock', 'to', 'the', 'heart', 'to', 'restore', 'a', 'normal', 'rhythm', 'in', 'cases', 'of', 'severe', 'arrhythmias', 'or', 'cardiac', 'arrest.', 'A', 'defibrillator', 'is', 'a', 'medical', 'device', 'that', 'delivers', 'an', 'electric', 'shock', 'to', 'the', 'heart', 'to', 'restore', 'a', 'normal', 'rhythm', 'in', 'cases', 'of', 'severe', 'arrhythmias', 'or', 'cardiac', 'arrest.']\n",
            "[('A', 'defibrillator'), ('defibrillator', 'is'), ('is', 'a'), ('a', 'medical'), ('medical', 'device'), ('device', 'that'), ('that', 'delivers'), ('delivers', 'an'), ('an', 'electric'), ('electric', 'shock'), ('shock', 'to'), ('to', 'the'), ('the', 'heart'), ('heart', 'to'), ('to', 'restore'), ('restore', 'a'), ('a', 'normal'), ('normal', 'rhythm'), ('rhythm', 'in'), ('in', 'cases'), ('cases', 'of'), ('of', 'severe'), ('severe', 'arrhythmias'), ('arrhythmias', 'or'), ('or', 'cardiac'), ('cardiac', 'arrest.'), ('A', 'defibrillator'), ('defibrillator', 'is'), ('is', 'a'), ('a', 'medical'), ('medical', 'device'), ('device', 'that'), ('that', 'delivers'), ('delivers', 'an'), ('an', 'electric'), ('electric', 'shock'), ('shock', 'to'), ('to', 'the'), ('the', 'heart'), ('heart', 'to'), ('to', 'restore'), ('restore', 'a'), ('a', 'normal'), ('normal', 'rhythm'), ('rhythm', 'in'), ('in', 'cases'), ('cases', 'of'), ('of', 'severe'), ('severe', 'arrhythmias'), ('arrhythmias', 'or'), ('or', 'cardiac'), ('cardiac', 'arrest.')]\n",
            "40\n",
            "38\n",
            "780\n",
            "78\n",
            "tensor([3.2190e+03, 4.0100e+02, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        4.0100e+02, 7.0000e+00, 1.2200e+02, 1.9000e+01, 1.0000e+00, 1.0300e+02,\n",
            "        2.6300e+02, 5.0000e+00, 1.9800e+02, 9.6600e+02, 8.1000e+01, 3.5500e+02,\n",
            "        5.0000e+00, 2.1200e+02, 3.2190e+03, 4.0100e+02, 3.0000e+00, 1.0000e+00,\n",
            "        2.7000e+01, 2.0000e+00, 4.0100e+02, 7.0000e+00, 1.2200e+02, 1.9000e+01,\n",
            "        1.0000e+00, 1.0300e+02, 2.6300e+02, 5.0000e+00, 1.9800e+02, 9.6600e+02,\n",
            "        8.1000e+01, 3.5500e+02, 5.0000e+00, 2.1200e+02])\n",
            "['Medical', 'ethics', 'is', 'the', 'branch', 'of', 'ethics', 'that', 'deals', 'with', 'the', 'moral', 'principles', 'and', 'values', 'guiding', 'medical', 'practice', 'and', 'research.', 'Medical', 'ethics', 'is', 'the', 'branch', 'of', 'ethics', 'that', 'deals', 'with', 'the', 'moral', 'principles', 'and', 'values', 'guiding', 'medical', 'practice', 'and', 'research.']\n",
            "[('Medical', 'ethics'), ('ethics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'ethics'), ('ethics', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'moral'), ('moral', 'principles'), ('principles', 'and'), ('and', 'values'), ('values', 'guiding'), ('guiding', 'medical'), ('medical', 'practice'), ('practice', 'and'), ('and', 'research.'), ('Medical', 'ethics'), ('ethics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'ethics'), ('ethics', 'that'), ('that', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'moral'), ('moral', 'principles'), ('principles', 'and'), ('and', 'values'), ('values', 'guiding'), ('guiding', 'medical'), ('medical', 'practice'), ('practice', 'and'), ('and', 'research.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3.2370e+03, 3.0000e+00, 1.0000e+00, 4.9200e+02, 3.4000e+01, 2.0000e+00,\n",
            "        3.3000e+01, 5.0000e+00, 4.3000e+01, 7.4800e+02, 3.2370e+03, 3.0000e+00,\n",
            "        1.0000e+00, 4.9200e+02, 3.4000e+01, 2.0000e+00, 3.3000e+01, 5.0000e+00,\n",
            "        4.3000e+01, 7.4800e+02])\n",
            "['Linguistics', 'is', 'the', 'scientific', 'study', 'of', 'language', 'and', 'its', 'structure.', 'Linguistics', 'is', 'the', 'scientific', 'study', 'of', 'language', 'and', 'its', 'structure.']\n",
            "[('Linguistics', 'is'), ('is', 'the'), ('the', 'scientific'), ('scientific', 'study'), ('study', 'of'), ('of', 'language'), ('language', 'and'), ('and', 'its'), ('its', 'structure.'), ('Linguistics', 'is'), ('is', 'the'), ('the', 'scientific'), ('scientific', 'study'), ('study', 'of'), ('of', 'language'), ('language', 'and'), ('and', 'its'), ('its', 'structure.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.1630e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 2.2000e+02,\n",
            "        7.0000e+00, 3.6000e+01, 1.0000e+00, 2.1000e+02, 2.0000e+00, 7.0000e+01,\n",
            "        4.7600e+02, 3.1630e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00,\n",
            "        2.2000e+02, 7.0000e+00, 3.6000e+01, 1.0000e+00, 2.1000e+02, 2.0000e+00,\n",
            "        7.0000e+01, 4.7600e+02])\n",
            "['Phonetics', 'is', 'the', 'branch', 'of', 'linguistics', 'that', 'studies', 'the', 'sounds', 'of', 'human', 'speech.', 'Phonetics', 'is', 'the', 'branch', 'of', 'linguistics', 'that', 'studies', 'the', 'sounds', 'of', 'human', 'speech.']\n",
            "[('Phonetics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'linguistics'), ('linguistics', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'sounds'), ('sounds', 'of'), ('of', 'human'), ('human', 'speech.'), ('Phonetics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'linguistics'), ('linguistics', 'that'), ('that', 'studies'), ('studies', 'the'), ('the', 'sounds'), ('sounds', 'of'), ('of', 'human'), ('human', 'speech.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3.1610e+03, 1.2200e+02, 1.9000e+01, 1.0000e+00, 1.4280e+03, 8.5900e+02,\n",
            "        2.0000e+00, 2.1000e+02, 8.0000e+00, 3.8200e+02, 3.1610e+03, 1.2200e+02,\n",
            "        1.9000e+01, 1.0000e+00, 1.4280e+03, 8.5900e+02, 2.0000e+00, 2.1000e+02,\n",
            "        8.0000e+00, 3.8200e+02])\n",
            "['Phonology', 'deals', 'with', 'the', 'systematic', 'organization', 'of', 'sounds', 'in', 'languages.', 'Phonology', 'deals', 'with', 'the', 'systematic', 'organization', 'of', 'sounds', 'in', 'languages.']\n",
            "[('Phonology', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'systematic'), ('systematic', 'organization'), ('organization', 'of'), ('of', 'sounds'), ('sounds', 'in'), ('in', 'languages.'), ('Phonology', 'deals'), ('deals', 'with'), ('with', 'the'), ('the', 'systematic'), ('systematic', 'organization'), ('organization', 'of'), ('of', 'sounds'), ('sounds', 'in'), ('in', 'languages.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.2090e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 1.0000e+00,\n",
            "        7.3000e+01, 5.0000e+00, 9.8700e+02, 2.0000e+00, 1.3600e+02, 3.2090e+03,\n",
            "        3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 1.0000e+00, 7.3000e+01,\n",
            "        5.0000e+00, 9.8700e+02, 2.0000e+00, 1.3600e+02])\n",
            "['Morphology', 'is', 'the', 'study', 'of', 'the', 'structure', 'and', 'formation', 'of', 'words.', 'Morphology', 'is', 'the', 'study', 'of', 'the', 'structure', 'and', 'formation', 'of', 'words.']\n",
            "[('Morphology', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'structure'), ('structure', 'and'), ('and', 'formation'), ('formation', 'of'), ('of', 'words.'), ('Morphology', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'structure'), ('structure', 'and'), ('and', 'formation'), ('formation', 'of'), ('of', 'words.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([1.1700e+03, 6.0200e+02, 1.0000e+00, 2.5500e+02, 7.0000e+00, 2.3180e+03,\n",
            "        1.0000e+00, 7.3000e+01, 2.0000e+00, 2.5400e+02, 1.1700e+03, 6.0200e+02,\n",
            "        1.0000e+00, 2.5500e+02, 7.0000e+00, 2.3180e+03, 1.0000e+00, 7.3000e+01,\n",
            "        2.0000e+00, 2.5400e+02])\n",
            "['Syntax', 'examines', 'the', 'rules', 'that', 'govern', 'the', 'structure', 'of', 'sentences.', 'Syntax', 'examines', 'the', 'rules', 'that', 'govern', 'the', 'structure', 'of', 'sentences.']\n",
            "[('Syntax', 'examines'), ('examines', 'the'), ('the', 'rules'), ('rules', 'that'), ('that', 'govern'), ('govern', 'the'), ('the', 'structure'), ('structure', 'of'), ('of', 'sentences.'), ('Syntax', 'examines'), ('examines', 'the'), ('the', 'rules'), ('rules', 'that'), ('that', 'govern'), ('govern', 'the'), ('the', 'structure'), ('structure', 'of'), ('of', 'sentences.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([3.1020e+03, 3.0000e+00, 1.0000e+00, 2.7000e+01, 2.0000e+00, 2.2000e+02,\n",
            "        2.9800e+02, 1.9000e+01, 1.3000e+02, 3.1020e+03, 3.0000e+00, 1.0000e+00,\n",
            "        2.7000e+01, 2.0000e+00, 2.2000e+02, 2.9800e+02, 1.9000e+01, 1.3000e+02])\n",
            "['Semantics', 'is', 'the', 'branch', 'of', 'linguistics', 'concerned', 'with', 'meaning.', 'Semantics', 'is', 'the', 'branch', 'of', 'linguistics', 'concerned', 'with', 'meaning.']\n",
            "[('Semantics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'linguistics'), ('linguistics', 'concerned'), ('concerned', 'with'), ('with', 'meaning.'), ('Semantics', 'is'), ('is', 'the'), ('the', 'branch'), ('branch', 'of'), ('of', 'linguistics'), ('linguistics', 'concerned'), ('concerned', 'with'), ('with', 'meaning.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([3.1470e+03, 3.6000e+01, 7.6000e+01, 2.7050e+03, 2.2090e+03, 1.0000e+00,\n",
            "        5.5700e+02, 2.0000e+00, 1.3000e+02, 3.1470e+03, 3.6000e+01, 7.6000e+01,\n",
            "        2.7050e+03, 2.2090e+03, 1.0000e+00, 5.5700e+02, 2.0000e+00, 1.3000e+02])\n",
            "['Pragmatics', 'studies', 'how', 'context', 'influences', 'the', 'interpretation', 'of', 'meaning.', 'Pragmatics', 'studies', 'how', 'context', 'influences', 'the', 'interpretation', 'of', 'meaning.']\n",
            "[('Pragmatics', 'studies'), ('studies', 'how'), ('how', 'context'), ('context', 'influences'), ('influences', 'the'), ('the', 'interpretation'), ('interpretation', 'of'), ('of', 'meaning.'), ('Pragmatics', 'studies'), ('studies', 'how'), ('how', 'context'), ('context', 'influences'), ('influences', 'the'), ('the', 'interpretation'), ('interpretation', 'of'), ('of', 'meaning.')]\n",
            "16\n",
            "14\n",
            "120\n",
            "30\n",
            "tensor([3.0970e+03, 6.0200e+02, 1.0000e+00, 3.4700e+02, 3.5000e+01, 3.3000e+01,\n",
            "        5.0000e+00, 4.8000e+02, 3.0970e+03, 6.0200e+02, 1.0000e+00, 3.4700e+02,\n",
            "        3.5000e+01, 3.3000e+01, 5.0000e+00, 4.8000e+02])\n",
            "['Sociolinguistics', 'examines', 'the', 'relationship', 'between', 'language', 'and', 'society.', 'Sociolinguistics', 'examines', 'the', 'relationship', 'between', 'language', 'and', 'society.']\n",
            "[('Sociolinguistics', 'examines'), ('examines', 'the'), ('the', 'relationship'), ('relationship', 'between'), ('between', 'language'), ('language', 'and'), ('and', 'society.'), ('Sociolinguistics', 'examines'), ('examines', 'the'), ('the', 'relationship'), ('relationship', 'between'), ('between', 'language'), ('language', 'and'), ('and', 'society.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([3.1360e+03, 2.4440e+03, 1.0000e+00, 1.7010e+03, 1.7350e+03, 9.3600e+02,\n",
            "        8.0000e+00, 3.3000e+01, 3.2100e+02, 3.1360e+03, 2.4440e+03, 1.0000e+00,\n",
            "        1.7010e+03, 1.7350e+03, 9.3600e+02, 8.0000e+00, 3.3000e+01, 3.2100e+02])\n",
            "['Psycholinguistics', 'explores', 'the', 'psychological', 'processes', 'involved', 'in', 'language', 'use.', 'Psycholinguistics', 'explores', 'the', 'psychological', 'processes', 'involved', 'in', 'language', 'use.']\n",
            "[('Psycholinguistics', 'explores'), ('explores', 'the'), ('the', 'psychological'), ('psychological', 'processes'), ('processes', 'involved'), ('involved', 'in'), ('in', 'language'), ('language', 'use.'), ('Psycholinguistics', 'explores'), ('explores', 'the'), ('the', 'psychological'), ('psychological', 'processes'), ('processes', 'involved'), ('involved', 'in'), ('in', 'language'), ('language', 'use.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.2830e+03, 2.2000e+02, 3.6000e+01, 1.0000e+00, 5.6900e+02, 5.0000e+00,\n",
            "        1.5200e+02, 2.0000e+00, 9.1000e+01, 7.4000e+01, 2.4900e+02, 3.2830e+03,\n",
            "        2.2000e+02, 3.6000e+01, 1.0000e+00, 5.6900e+02, 5.0000e+00, 1.5200e+02,\n",
            "        2.0000e+00, 9.1000e+01, 7.4000e+01, 2.4900e+02])\n",
            "['Historical', 'linguistics', 'studies', 'the', 'history', 'and', 'development', 'of', 'languages', 'over', 'time.', 'Historical', 'linguistics', 'studies', 'the', 'history', 'and', 'development', 'of', 'languages', 'over', 'time.']\n",
            "[('Historical', 'linguistics'), ('linguistics', 'studies'), ('studies', 'the'), ('the', 'history'), ('history', 'and'), ('and', 'development'), ('development', 'of'), ('of', 'languages'), ('languages', 'over'), ('over', 'time.'), ('Historical', 'linguistics'), ('linguistics', 'studies'), ('studies', 'the'), ('the', 'history'), ('history', 'and'), ('and', 'development'), ('development', 'of'), ('of', 'languages'), ('languages', 'over'), ('over', 'time.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([1203.,  220.,  636.,   91.,    6.,  991.,   96., 1878.,    5., 2597.,\n",
            "        1203.,  220.,  636.,   91.,    6.,  991.,   96., 1878.,    5., 2597.])\n",
            "['Comparative', 'linguistics', 'compares', 'languages', 'to', 'find', 'common', 'origins', 'and', 'differences.', 'Comparative', 'linguistics', 'compares', 'languages', 'to', 'find', 'common', 'origins', 'and', 'differences.']\n",
            "[('Comparative', 'linguistics'), ('linguistics', 'compares'), ('compares', 'languages'), ('languages', 'to'), ('to', 'find'), ('find', 'common'), ('common', 'origins'), ('origins', 'and'), ('and', 'differences.'), ('Comparative', 'linguistics'), ('linguistics', 'compares'), ('compares', 'languages'), ('languages', 'to'), ('to', 'find'), ('find', 'common'), ('common', 'origins'), ('origins', 'and'), ('and', 'differences.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3.3640e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 1.6390e+03,\n",
            "        4.4300e+02, 1.6400e+02, 4.0000e+00, 9.2000e+01, 3.3640e+03, 3.0000e+00,\n",
            "        1.0000e+00, 3.4000e+01, 2.0000e+00, 1.6390e+03, 4.4300e+02, 1.6400e+02,\n",
            "        4.0000e+00, 9.2000e+01])\n",
            "['Dialectology', 'is', 'the', 'study', 'of', 'regional', 'variations', 'within', 'a', 'language.', 'Dialectology', 'is', 'the', 'study', 'of', 'regional', 'variations', 'within', 'a', 'language.']\n",
            "[('Dialectology', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'regional'), ('regional', 'variations'), ('variations', 'within'), ('within', 'a'), ('a', 'language.'), ('Dialectology', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'regional'), ('regional', 'variations'), ('variations', 'within'), ('within', 'a'), ('a', 'language.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.3350e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 1.0000e+00,\n",
            "        1.8830e+03, 5.0000e+00, 5.6900e+02, 2.0000e+00, 1.3600e+02, 3.3350e+03,\n",
            "        3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 1.0000e+00, 1.8830e+03,\n",
            "        5.0000e+00, 5.6900e+02, 2.0000e+00, 1.3600e+02])\n",
            "['Etymology', 'is', 'the', 'study', 'of', 'the', 'origin', 'and', 'history', 'of', 'words.', 'Etymology', 'is', 'the', 'study', 'of', 'the', 'origin', 'and', 'history', 'of', 'words.']\n",
            "[('Etymology', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'origin'), ('origin', 'and'), ('and', 'history'), ('history', 'of'), ('of', 'words.'), ('Etymology', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'the'), ('the', 'origin'), ('origin', 'and'), ('and', 'history'), ('history', 'of'), ('of', 'words.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([2.4100e+02, 3.0060e+03, 3.0000e+00, 1.0000e+00, 5.7000e+01, 1.8000e+01,\n",
            "        2.2000e+01, 5.6800e+02, 9.1800e+02, 9.2000e+01, 2.4100e+02, 3.0060e+03,\n",
            "        3.0000e+00, 1.0000e+00, 5.7000e+01, 1.8000e+01, 2.2000e+01, 5.6800e+02,\n",
            "        9.1800e+02, 9.2000e+01])\n",
            "['Language', 'acquisition', 'is', 'the', 'process', 'by', 'which', 'humans', 'learn', 'language.', 'Language', 'acquisition', 'is', 'the', 'process', 'by', 'which', 'humans', 'learn', 'language.']\n",
            "[('Language', 'acquisition'), ('acquisition', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'humans'), ('humans', 'learn'), ('learn', 'language.'), ('Language', 'acquisition'), ('acquisition', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'humans'), ('humans', 'learn'), ('learn', 'language.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.4220e+03, 3.0000e+00, 1.0000e+00, 3.0800e+02, 6.0000e+00, 7.5700e+02,\n",
            "        5.0000e+00, 2.0000e+02, 3.9000e+01, 9.1000e+01, 2.3800e+03, 3.4220e+03,\n",
            "        3.0000e+00, 1.0000e+00, 3.0800e+02, 6.0000e+00, 7.5700e+02, 5.0000e+00,\n",
            "        2.0000e+02, 3.9000e+01, 9.1000e+01, 2.3800e+03])\n",
            "['Bilingualism', 'is', 'the', 'ability', 'to', 'speak', 'and', 'understand', 'two', 'languages', 'fluently.', 'Bilingualism', 'is', 'the', 'ability', 'to', 'speak', 'and', 'understand', 'two', 'languages', 'fluently.']\n",
            "[('Bilingualism', 'is'), ('is', 'the'), ('the', 'ability'), ('ability', 'to'), ('to', 'speak'), ('speak', 'and'), ('and', 'understand'), ('understand', 'two'), ('two', 'languages'), ('languages', 'fluently.'), ('Bilingualism', 'is'), ('is', 'the'), ('the', 'ability'), ('ability', 'to'), ('to', 'speak'), ('speak', 'and'), ('and', 'understand'), ('understand', 'two'), ('two', 'languages'), ('languages', 'fluently.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.3940e+03, 3.0000e+00, 1.0000e+00, 3.5500e+02, 2.0000e+00, 2.9610e+03,\n",
            "        3.5000e+01, 3.9000e+01, 1.0000e+01, 6.0000e+01, 9.1000e+01, 8.0000e+00,\n",
            "        4.0000e+00, 2.6930e+03, 3.3940e+03, 3.0000e+00, 1.0000e+00, 3.5500e+02,\n",
            "        2.0000e+00, 2.9610e+03, 3.5000e+01, 3.9000e+01, 1.0000e+01, 6.0000e+01,\n",
            "        9.1000e+01, 8.0000e+00, 4.0000e+00, 2.6930e+03])\n",
            "['Code-switching', 'is', 'the', 'practice', 'of', 'alternating', 'between', 'two', 'or', 'more', 'languages', 'in', 'a', 'conversation.', 'Code-switching', 'is', 'the', 'practice', 'of', 'alternating', 'between', 'two', 'or', 'more', 'languages', 'in', 'a', 'conversation.']\n",
            "[('Code-switching', 'is'), ('is', 'the'), ('the', 'practice'), ('practice', 'of'), ('of', 'alternating'), ('alternating', 'between'), ('between', 'two'), ('two', 'or'), ('or', 'more'), ('more', 'languages'), ('languages', 'in'), ('in', 'a'), ('a', 'conversation.'), ('Code-switching', 'is'), ('is', 'the'), ('the', 'practice'), ('practice', 'of'), ('of', 'alternating'), ('alternating', 'between'), ('between', 'two'), ('two', 'or'), ('or', 'more'), ('more', 'languages'), ('languages', 'in'), ('in', 'a'), ('a', 'conversation.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([1.1000e+01, 8.4200e+02, 3.0000e+00, 1.0000e+00, 3.4200e+02, 1.2700e+02,\n",
            "        2.0000e+00, 1.7100e+02, 7.0000e+00, 1.6000e+01, 1.0460e+03, 1.8300e+02,\n",
            "        8.0000e+00, 4.0000e+00, 9.2000e+01, 1.1000e+01, 8.4200e+02, 3.0000e+00,\n",
            "        1.0000e+00, 3.4200e+02, 1.2700e+02, 2.0000e+00, 1.7100e+02, 7.0000e+00,\n",
            "        1.6000e+01, 1.0460e+03, 1.8300e+02, 8.0000e+00, 4.0000e+00, 9.2000e+01])\n",
            "['A', 'phoneme', 'is', 'the', 'smallest', 'unit', 'of', 'sound', 'that', 'can', 'distinguish', 'meaning', 'in', 'a', 'language.', 'A', 'phoneme', 'is', 'the', 'smallest', 'unit', 'of', 'sound', 'that', 'can', 'distinguish', 'meaning', 'in', 'a', 'language.']\n",
            "[('A', 'phoneme'), ('phoneme', 'is'), ('is', 'the'), ('the', 'smallest'), ('smallest', 'unit'), ('unit', 'of'), ('of', 'sound'), ('sound', 'that'), ('that', 'can'), ('can', 'distinguish'), ('distinguish', 'meaning'), ('meaning', 'in'), ('in', 'a'), ('a', 'language.'), ('A', 'phoneme'), ('phoneme', 'is'), ('is', 'the'), ('the', 'smallest'), ('smallest', 'unit'), ('unit', 'of'), ('of', 'sound'), ('sound', 'that'), ('that', 'can'), ('can', 'distinguish'), ('distinguish', 'meaning'), ('meaning', 'in'), ('in', 'a'), ('a', 'language.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([1.1000e+01, 1.9830e+03, 3.0000e+00, 1.0000e+00, 3.4200e+02, 1.2700e+02,\n",
            "        2.0000e+00, 1.8300e+02, 8.0000e+00, 4.0000e+00, 9.2000e+01, 1.1000e+01,\n",
            "        1.9830e+03, 3.0000e+00, 1.0000e+00, 3.4200e+02, 1.2700e+02, 2.0000e+00,\n",
            "        1.8300e+02, 8.0000e+00, 4.0000e+00, 9.2000e+01])\n",
            "['A', 'morpheme', 'is', 'the', 'smallest', 'unit', 'of', 'meaning', 'in', 'a', 'language.', 'A', 'morpheme', 'is', 'the', 'smallest', 'unit', 'of', 'meaning', 'in', 'a', 'language.']\n",
            "[('A', 'morpheme'), ('morpheme', 'is'), ('is', 'the'), ('the', 'smallest'), ('smallest', 'unit'), ('unit', 'of'), ('of', 'meaning'), ('meaning', 'in'), ('in', 'a'), ('a', 'language.'), ('A', 'morpheme'), ('morpheme', 'is'), ('is', 'the'), ('the', 'smallest'), ('smallest', 'unit'), ('unit', 'of'), ('of', 'meaning'), ('meaning', 'in'), ('in', 'a'), ('a', 'language.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([1.1000e+01, 2.1070e+03, 3.0000e+00, 4.0000e+00, 1.2700e+02, 2.0000e+00,\n",
            "        2.1060e+03, 1.8300e+02, 7.0000e+00, 1.3290e+03, 4.0000e+00, 1.2800e+02,\n",
            "        2.0000e+00, 1.3600e+02, 1.1000e+01, 2.1070e+03, 3.0000e+00, 4.0000e+00,\n",
            "        1.2700e+02, 2.0000e+00, 2.1060e+03, 1.8300e+02, 7.0000e+00, 1.3290e+03,\n",
            "        4.0000e+00, 1.2800e+02, 2.0000e+00, 1.3600e+02])\n",
            "['A', 'lexeme', 'is', 'a', 'unit', 'of', 'lexical', 'meaning', 'that', 'underlies', 'a', 'set', 'of', 'words.', 'A', 'lexeme', 'is', 'a', 'unit', 'of', 'lexical', 'meaning', 'that', 'underlies', 'a', 'set', 'of', 'words.']\n",
            "[('A', 'lexeme'), ('lexeme', 'is'), ('is', 'a'), ('a', 'unit'), ('unit', 'of'), ('of', 'lexical'), ('lexical', 'meaning'), ('meaning', 'that'), ('that', 'underlies'), ('underlies', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'words.'), ('A', 'lexeme'), ('lexeme', 'is'), ('is', 'a'), ('a', 'unit'), ('unit', 'of'), ('of', 'lexical'), ('lexical', 'meaning'), ('meaning', 'that'), ('that', 'underlies'), ('underlies', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'words.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.2930e+03, 3.0000e+00, 1.0000e+00, 1.2800e+02, 2.0000e+00, 3.3400e+02,\n",
            "        2.5500e+02, 2.3170e+03, 1.0000e+00, 1.0860e+03, 2.0000e+00, 1.5480e+03,\n",
            "        1.7980e+03, 5.0000e+00, 1.3600e+02, 3.2930e+03, 3.0000e+00, 1.0000e+00,\n",
            "        1.2800e+02, 2.0000e+00, 3.3400e+02, 2.5500e+02, 2.3170e+03, 1.0000e+00,\n",
            "        1.0860e+03, 2.0000e+00, 1.5480e+03, 1.7980e+03, 5.0000e+00, 1.3600e+02])\n",
            "['Grammar', 'is', 'the', 'set', 'of', 'structural', 'rules', 'governing', 'the', 'composition', 'of', 'sentences,', 'phrases,', 'and', 'words.', 'Grammar', 'is', 'the', 'set', 'of', 'structural', 'rules', 'governing', 'the', 'composition', 'of', 'sentences,', 'phrases,', 'and', 'words.']\n",
            "[('Grammar', 'is'), ('is', 'the'), ('the', 'set'), ('set', 'of'), ('of', 'structural'), ('structural', 'rules'), ('rules', 'governing'), ('governing', 'the'), ('the', 'composition'), ('composition', 'of'), ('of', 'sentences,'), ('sentences,', 'phrases,'), ('phrases,', 'and'), ('and', 'words.'), ('Grammar', 'is'), ('is', 'the'), ('the', 'set'), ('set', 'of'), ('of', 'structural'), ('structural', 'rules'), ('rules', 'governing'), ('governing', 'the'), ('the', 'composition'), ('composition', 'of'), ('of', 'sentences,'), ('sentences,', 'phrases,'), ('phrases,', 'and'), ('and', 'words.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([1.1000e+01, 2.6840e+03, 3.0000e+00, 4.0000e+00, 3.8100e+02, 6.3800e+02,\n",
            "        2.0000e+00, 1.6100e+02, 1.0000e+01, 2.0900e+02, 7.3100e+02, 3.1000e+01,\n",
            "        1.2000e+01, 5.5000e+02, 2.1200e+02, 1.1000e+01, 2.6840e+03, 3.0000e+00,\n",
            "        4.0000e+00, 3.8100e+02, 6.3800e+02, 2.0000e+00, 1.6100e+02, 1.0000e+01,\n",
            "        2.0900e+02, 7.3100e+02, 3.1000e+01, 1.2000e+01, 5.5000e+02, 2.1200e+02])\n",
            "['A', 'corpus', 'is', 'a', 'large', 'collection', 'of', 'written', 'or', 'spoken', 'texts', 'used', 'for', 'linguistic', 'research.', 'A', 'corpus', 'is', 'a', 'large', 'collection', 'of', 'written', 'or', 'spoken', 'texts', 'used', 'for', 'linguistic', 'research.']\n",
            "[('A', 'corpus'), ('corpus', 'is'), ('is', 'a'), ('a', 'large'), ('large', 'collection'), ('collection', 'of'), ('of', 'written'), ('written', 'or'), ('or', 'spoken'), ('spoken', 'texts'), ('texts', 'used'), ('used', 'for'), ('for', 'linguistic'), ('linguistic', 'research.'), ('A', 'corpus'), ('corpus', 'is'), ('is', 'a'), ('a', 'large'), ('large', 'collection'), ('collection', 'of'), ('of', 'written'), ('written', 'or'), ('or', 'spoken'), ('spoken', 'texts'), ('texts', 'used'), ('used', 'for'), ('for', 'linguistic'), ('linguistic', 'research.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.3660e+03, 2.2000e+02, 4.2900e+02, 6.0000e+00, 1.5300e+02, 3.3000e+01,\n",
            "        1.4000e+01, 4.4000e+01, 3.0000e+00, 2.9950e+03, 7.0700e+02, 3.3660e+03,\n",
            "        2.2000e+02, 4.2900e+02, 6.0000e+00, 1.5300e+02, 3.3000e+01, 1.4000e+01,\n",
            "        4.4000e+01, 3.0000e+00, 2.9950e+03, 7.0700e+02])\n",
            "['Descriptive', 'linguistics', 'aims', 'to', 'describe', 'language', 'as', 'it', 'is', 'actually', 'used.', 'Descriptive', 'linguistics', 'aims', 'to', 'describe', 'language', 'as', 'it', 'is', 'actually', 'used.']\n",
            "[('Descriptive', 'linguistics'), ('linguistics', 'aims'), ('aims', 'to'), ('to', 'describe'), ('describe', 'language'), ('language', 'as'), ('as', 'it'), ('it', 'is'), ('is', 'actually'), ('actually', 'used.'), ('Descriptive', 'linguistics'), ('linguistics', 'aims'), ('aims', 'to'), ('to', 'describe'), ('describe', 'language'), ('language', 'as'), ('as', 'it'), ('it', 'is'), ('is', 'actually'), ('actually', 'used.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3145.,  220., 1753.,  255.,   12.,   76.,   33., 1532.,   25.,  707.,\n",
            "        3145.,  220., 1753.,  255.,   12.,   76.,   33., 1532.,   25.,  707.])\n",
            "['Prescriptive', 'linguistics', 'prescribes', 'rules', 'for', 'how', 'language', 'should', 'be', 'used.', 'Prescriptive', 'linguistics', 'prescribes', 'rules', 'for', 'how', 'language', 'should', 'be', 'used.']\n",
            "[('Prescriptive', 'linguistics'), ('linguistics', 'prescribes'), ('prescribes', 'rules'), ('rules', 'for'), ('for', 'how'), ('how', 'language'), ('language', 'should'), ('should', 'be'), ('be', 'used.'), ('Prescriptive', 'linguistics'), ('linguistics', 'prescribes'), ('prescribes', 'rules'), ('rules', 'for'), ('for', 'how'), ('how', 'language'), ('language', 'should'), ('should', 'be'), ('be', 'used.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([3.3000e+03, 3.9200e+02, 3.0000e+00, 4.0000e+00, 4.8000e+01, 7.0000e+00,\n",
            "        4.2900e+02, 6.0000e+00, 1.5300e+02, 1.0000e+00, 2.2370e+03, 1.3100e+02,\n",
            "        7.0000e+00, 3.3800e+02, 4.2000e+01, 2.8000e+01, 4.1000e+01, 9.2000e+01,\n",
            "        3.3000e+03, 3.9200e+02, 3.0000e+00, 4.0000e+00, 4.8000e+01, 7.0000e+00,\n",
            "        4.2900e+02, 6.0000e+00, 1.5300e+02, 1.0000e+00, 2.2370e+03, 1.3100e+02,\n",
            "        7.0000e+00, 3.3800e+02, 4.2000e+01, 2.8000e+01, 4.1000e+01, 9.2000e+01])\n",
            "['Generative', 'grammar', 'is', 'a', 'theory', 'that', 'aims', 'to', 'describe', 'the', 'implicit', 'knowledge', 'that', 'speakers', 'have', 'about', 'their', 'language.', 'Generative', 'grammar', 'is', 'a', 'theory', 'that', 'aims', 'to', 'describe', 'the', 'implicit', 'knowledge', 'that', 'speakers', 'have', 'about', 'their', 'language.']\n",
            "[('Generative', 'grammar'), ('grammar', 'is'), ('is', 'a'), ('a', 'theory'), ('theory', 'that'), ('that', 'aims'), ('aims', 'to'), ('to', 'describe'), ('describe', 'the'), ('the', 'implicit'), ('implicit', 'knowledge'), ('knowledge', 'that'), ('that', 'speakers'), ('speakers', 'have'), ('have', 'about'), ('about', 'their'), ('their', 'language.'), ('Generative', 'grammar'), ('grammar', 'is'), ('is', 'a'), ('a', 'theory'), ('theory', 'that'), ('that', 'aims'), ('aims', 'to'), ('to', 'describe'), ('describe', 'the'), ('the', 'implicit'), ('implicit', 'knowledge'), ('knowledge', 'that'), ('that', 'speakers'), ('speakers', 'have'), ('have', 'about'), ('about', 'their'), ('their', 'language.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([3.0590e+03, 3.9200e+02, 3.0000e+00, 4.0000e+00, 2.0100e+02, 2.0000e+00,\n",
            "        2.3360e+03, 3.9200e+02, 7.0000e+00, 2.7090e+03, 1.0000e+00, 1.3630e+03,\n",
            "        1.1330e+03, 6.0000e+00, 1.5490e+03, 6.0000e+00, 2.3380e+03, 1.1900e+02,\n",
            "        2.5400e+02, 3.0590e+03, 3.9200e+02, 3.0000e+00, 4.0000e+00, 2.0100e+02,\n",
            "        2.0000e+00, 2.3360e+03, 3.9200e+02, 7.0000e+00, 2.7090e+03, 1.0000e+00,\n",
            "        1.3630e+03, 1.1330e+03, 6.0000e+00, 1.5490e+03, 6.0000e+00, 2.3380e+03,\n",
            "        1.1900e+02, 2.5400e+02])\n",
            "['Transformational', 'grammar', 'is', 'a', 'type', 'of', 'generative', 'grammar', 'that', 'considers', 'the', 'transformations', 'applied', 'to', 'sentences', 'to', 'generate', 'new', 'sentences.', 'Transformational', 'grammar', 'is', 'a', 'type', 'of', 'generative', 'grammar', 'that', 'considers', 'the', 'transformations', 'applied', 'to', 'sentences', 'to', 'generate', 'new', 'sentences.']\n",
            "[('Transformational', 'grammar'), ('grammar', 'is'), ('is', 'a'), ('a', 'type'), ('type', 'of'), ('of', 'generative'), ('generative', 'grammar'), ('grammar', 'that'), ('that', 'considers'), ('considers', 'the'), ('the', 'transformations'), ('transformations', 'applied'), ('applied', 'to'), ('to', 'sentences'), ('sentences', 'to'), ('to', 'generate'), ('generate', 'new'), ('new', 'sentences.'), ('Transformational', 'grammar'), ('grammar', 'is'), ('is', 'a'), ('a', 'type'), ('type', 'of'), ('of', 'generative'), ('generative', 'grammar'), ('grammar', 'that'), ('that', 'considers'), ('considers', 'the'), ('the', 'transformations'), ('transformations', 'applied'), ('applied', 'to'), ('to', 'sentences'), ('sentences', 'to'), ('to', 'generate'), ('generate', 'new'), ('new', 'sentences.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 2.6050e+03, 3.0000e+00, 4.0000e+00, 1.1700e+02, 9.4000e+01,\n",
            "        2.0000e+00, 4.0000e+00, 3.3000e+01, 8.0000e+01, 6.0000e+00, 4.0000e+00,\n",
            "        5.0300e+02, 1.0000e+01, 4.8100e+02, 5.7400e+02, 1.1000e+01, 2.6050e+03,\n",
            "        3.0000e+00, 4.0000e+00, 1.1700e+02, 9.4000e+01, 2.0000e+00, 4.0000e+00,\n",
            "        3.3000e+01, 8.0000e+01, 6.0000e+00, 4.0000e+00, 5.0300e+02, 1.0000e+01,\n",
            "        4.8100e+02, 5.7400e+02])\n",
            "['A', 'dialect', 'is', 'a', 'particular', 'form', 'of', 'a', 'language', 'specific', 'to', 'a', 'region', 'or', 'social', 'group.', 'A', 'dialect', 'is', 'a', 'particular', 'form', 'of', 'a', 'language', 'specific', 'to', 'a', 'region', 'or', 'social', 'group.']\n",
            "[('A', 'dialect'), ('dialect', 'is'), ('is', 'a'), ('a', 'particular'), ('particular', 'form'), ('form', 'of'), ('of', 'a'), ('a', 'language'), ('language', 'specific'), ('specific', 'to'), ('to', 'a'), ('a', 'region'), ('region', 'or'), ('or', 'social'), ('social', 'group.'), ('A', 'dialect'), ('dialect', 'is'), ('is', 'a'), ('a', 'particular'), ('particular', 'form'), ('form', 'of'), ('of', 'a'), ('a', 'language'), ('language', 'specific'), ('specific', 'to'), ('to', 'a'), ('a', 'region'), ('region', 'or'), ('or', 'social'), ('social', 'group.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([4.5000e+01, 2.2540e+03, 3.0000e+00, 1.0000e+00, 8.7000e+01, 2.3000e+03,\n",
            "        1.8350e+03, 6.0000e+00, 4.0000e+00, 1.1700e+02, 8.4500e+02, 4.5000e+01,\n",
            "        2.2540e+03, 3.0000e+00, 1.0000e+00, 8.7000e+01, 2.3000e+03, 1.8350e+03,\n",
            "        6.0000e+00, 4.0000e+00, 1.1700e+02, 8.4500e+02])\n",
            "['An', 'idiolect', 'is', 'the', 'speech', 'habits', 'peculiar', 'to', 'a', 'particular', 'person.', 'An', 'idiolect', 'is', 'the', 'speech', 'habits', 'peculiar', 'to', 'a', 'particular', 'person.']\n",
            "[('An', 'idiolect'), ('idiolect', 'is'), ('is', 'the'), ('the', 'speech'), ('speech', 'habits'), ('habits', 'peculiar'), ('peculiar', 'to'), ('to', 'a'), ('a', 'particular'), ('particular', 'person.'), ('An', 'idiolect'), ('idiolect', 'is'), ('is', 'the'), ('the', 'speech'), ('speech', 'habits'), ('habits', 'peculiar'), ('peculiar', 'to'), ('to', 'a'), ('a', 'particular'), ('particular', 'person.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([1.1000e+01, 2.6650e+03, 3.0000e+00, 4.0000e+00, 7.5400e+02, 1.8100e+02,\n",
            "        3.3000e+01, 6.1900e+02, 2.4000e+01, 1.0000e+00, 1.9960e+03, 2.0000e+00,\n",
            "        1.8570e+03, 3.8200e+02, 1.1000e+01, 2.6650e+03, 3.0000e+00, 4.0000e+00,\n",
            "        7.5400e+02, 1.8100e+02, 3.3000e+01, 6.1900e+02, 2.4000e+01, 1.0000e+00,\n",
            "        1.9960e+03, 2.0000e+00, 1.8570e+03, 3.8200e+02])\n",
            "['A', 'creole', 'is', 'a', 'stable', 'natural', 'language', 'developed', 'from', 'the', 'mixing', 'of', 'parent', 'languages.', 'A', 'creole', 'is', 'a', 'stable', 'natural', 'language', 'developed', 'from', 'the', 'mixing', 'of', 'parent', 'languages.']\n",
            "[('A', 'creole'), ('creole', 'is'), ('is', 'a'), ('a', 'stable'), ('stable', 'natural'), ('natural', 'language'), ('language', 'developed'), ('developed', 'from'), ('from', 'the'), ('the', 'mixing'), ('mixing', 'of'), ('of', 'parent'), ('parent', 'languages.'), ('A', 'creole'), ('creole', 'is'), ('is', 'a'), ('a', 'stable'), ('stable', 'natural'), ('natural', 'language'), ('language', 'developed'), ('developed', 'from'), ('from', 'the'), ('the', 'mixing'), ('mixing', 'of'), ('of', 'parent'), ('parent', 'languages.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([1.1000e+01, 1.7950e+03, 3.0000e+00, 4.0000e+00, 1.5260e+03, 9.4000e+01,\n",
            "        2.0000e+00, 8.7000e+01, 2.3670e+03, 2.4000e+01, 3.9000e+01, 1.0000e+01,\n",
            "        6.0000e+01, 9.2100e+02, 3.1000e+01, 1.8000e+01, 8.4800e+02, 8.6000e+01,\n",
            "        2.3300e+02, 6.7000e+01, 1.5350e+03, 4.0000e+00, 9.6000e+01, 9.2000e+01,\n",
            "        1.1000e+01, 1.7950e+03, 3.0000e+00, 4.0000e+00, 1.5260e+03, 9.4000e+01,\n",
            "        2.0000e+00, 8.7000e+01, 2.3670e+03, 2.4000e+01, 3.9000e+01, 1.0000e+01,\n",
            "        6.0000e+01, 9.2100e+02, 3.1000e+01, 1.8000e+01, 8.4800e+02, 8.6000e+01,\n",
            "        2.3300e+02, 6.7000e+01, 1.5350e+03, 4.0000e+00, 9.6000e+01, 9.2000e+01])\n",
            "['A', 'pidgin', 'is', 'a', 'simplified', 'form', 'of', 'speech', 'formed', 'from', 'two', 'or', 'more', 'languages,', 'used', 'by', 'people', 'who', 'do', 'not', 'share', 'a', 'common', 'language.', 'A', 'pidgin', 'is', 'a', 'simplified', 'form', 'of', 'speech', 'formed', 'from', 'two', 'or', 'more', 'languages,', 'used', 'by', 'people', 'who', 'do', 'not', 'share', 'a', 'common', 'language.']\n",
            "[('A', 'pidgin'), ('pidgin', 'is'), ('is', 'a'), ('a', 'simplified'), ('simplified', 'form'), ('form', 'of'), ('of', 'speech'), ('speech', 'formed'), ('formed', 'from'), ('from', 'two'), ('two', 'or'), ('or', 'more'), ('more', 'languages,'), ('languages,', 'used'), ('used', 'by'), ('by', 'people'), ('people', 'who'), ('who', 'do'), ('do', 'not'), ('not', 'share'), ('share', 'a'), ('a', 'common'), ('common', 'language.'), ('A', 'pidgin'), ('pidgin', 'is'), ('is', 'a'), ('a', 'simplified'), ('simplified', 'form'), ('form', 'of'), ('of', 'speech'), ('speech', 'formed'), ('formed', 'from'), ('from', 'two'), ('two', 'or'), ('or', 'more'), ('more', 'languages,'), ('languages,', 'used'), ('used', 'by'), ('by', 'people'), ('people', 'who'), ('who', 'do'), ('do', 'not'), ('not', 'share'), ('share', 'a'), ('a', 'common'), ('common', 'language.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([3.1750e+03, 3.0000e+00, 1.0000e+00, 2.6940e+03, 1.4920e+03, 2.6000e+01,\n",
            "        2.0000e+00, 4.0000e+00, 9.2000e+01, 3.1750e+03, 3.0000e+00, 1.0000e+00,\n",
            "        2.6940e+03, 1.4920e+03, 2.6000e+01, 2.0000e+00, 4.0000e+00, 9.2000e+01])\n",
            "['Orthography', 'is', 'the', 'conventional', 'spelling', 'system', 'of', 'a', 'language.', 'Orthography', 'is', 'the', 'conventional', 'spelling', 'system', 'of', 'a', 'language.']\n",
            "[('Orthography', 'is'), ('is', 'the'), ('the', 'conventional'), ('conventional', 'spelling'), ('spelling', 'system'), ('system', 'of'), ('of', 'a'), ('a', 'language.'), ('Orthography', 'is'), ('is', 'the'), ('the', 'conventional'), ('conventional', 'spelling'), ('spelling', 'system'), ('system', 'of'), ('of', 'a'), ('a', 'language.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([1.1000e+01, 2.3130e+03, 3.0000e+00, 1.0000e+00, 3.4200e+02, 1.2700e+02,\n",
            "        2.0000e+00, 4.4000e+02, 7.0000e+00, 2.5700e+02, 4.0000e+00, 1.8040e+03,\n",
            "        1.1000e+01, 2.3130e+03, 3.0000e+00, 1.0000e+00, 3.4200e+02, 1.2700e+02,\n",
            "        2.0000e+00, 4.4000e+02, 7.0000e+00, 2.5700e+02, 4.0000e+00, 1.8040e+03])\n",
            "['A', 'grapheme', 'is', 'the', 'smallest', 'unit', 'of', 'writing', 'that', 'represents', 'a', 'phoneme.', 'A', 'grapheme', 'is', 'the', 'smallest', 'unit', 'of', 'writing', 'that', 'represents', 'a', 'phoneme.']\n",
            "[('A', 'grapheme'), ('grapheme', 'is'), ('is', 'the'), ('the', 'smallest'), ('smallest', 'unit'), ('unit', 'of'), ('of', 'writing'), ('writing', 'that'), ('that', 'represents'), ('represents', 'a'), ('a', 'phoneme.'), ('A', 'grapheme'), ('grapheme', 'is'), ('is', 'the'), ('the', 'smallest'), ('smallest', 'unit'), ('unit', 'of'), ('of', 'writing'), ('writing', 'that'), ('that', 'represents'), ('represents', 'a'), ('a', 'phoneme.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([  11., 1436.,    3.,    4.,  127.,    2.,  859.,   12.,    4.,  172.,\n",
            "           2.,   87., 1508.,   11., 1436.,    3.,    4.,  127.,    2.,  859.,\n",
            "          12.,    4.,  172.,    2.,   87., 1508.])\n",
            "['A', 'syllable', 'is', 'a', 'unit', 'of', 'organization', 'for', 'a', 'sequence', 'of', 'speech', 'sounds.', 'A', 'syllable', 'is', 'a', 'unit', 'of', 'organization', 'for', 'a', 'sequence', 'of', 'speech', 'sounds.']\n",
            "[('A', 'syllable'), ('syllable', 'is'), ('is', 'a'), ('a', 'unit'), ('unit', 'of'), ('of', 'organization'), ('organization', 'for'), ('for', 'a'), ('a', 'sequence'), ('sequence', 'of'), ('of', 'speech'), ('speech', 'sounds.'), ('A', 'syllable'), ('syllable', 'is'), ('is', 'a'), ('a', 'unit'), ('unit', 'of'), ('of', 'organization'), ('organization', 'for'), ('for', 'a'), ('a', 'sequence'), ('sequence', 'of'), ('of', 'speech'), ('speech', 'sounds.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([3.1400e+03, 3.0000e+00, 1.0000e+00, 1.5920e+03, 1.4670e+03, 5.0000e+00,\n",
            "        2.1600e+03, 2.0000e+00, 4.7600e+02, 3.1400e+03, 3.0000e+00, 1.0000e+00,\n",
            "        1.5920e+03, 1.4670e+03, 5.0000e+00, 2.1600e+03, 2.0000e+00, 4.7600e+02])\n",
            "['Prosody', 'is', 'the', 'rhythm,', 'stress,', 'and', 'intonation', 'of', 'speech.', 'Prosody', 'is', 'the', 'rhythm,', 'stress,', 'and', 'intonation', 'of', 'speech.']\n",
            "[('Prosody', 'is'), ('is', 'the'), ('the', 'rhythm,'), ('rhythm,', 'stress,'), ('stress,', 'and'), ('and', 'intonation'), ('intonation', 'of'), ('of', 'speech.'), ('Prosody', 'is'), ('is', 'the'), ('the', 'rhythm,'), ('rhythm,', 'stress,'), ('stress,', 'and'), ('and', 'intonation'), ('intonation', 'of'), ('of', 'speech.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([3.3570e+03, 3.0400e+02, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00,\n",
            "        3.3000e+01, 1.1500e+02, 1.1470e+03, 7.3100e+02, 5.0000e+00, 6.2900e+02,\n",
            "        3.3570e+03, 3.0400e+02, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00,\n",
            "        3.3000e+01, 1.1500e+02, 1.1470e+03, 7.3100e+02, 5.0000e+00, 6.2900e+02])\n",
            "['Discourse', 'analysis', 'is', 'the', 'study', 'of', 'language', 'use', 'across', 'texts', 'and', 'contexts.', 'Discourse', 'analysis', 'is', 'the', 'study', 'of', 'language', 'use', 'across', 'texts', 'and', 'contexts.']\n",
            "[('Discourse', 'analysis'), ('analysis', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'language'), ('language', 'use'), ('use', 'across'), ('across', 'texts'), ('texts', 'and'), ('and', 'contexts.'), ('Discourse', 'analysis'), ('analysis', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'language'), ('language', 'use'), ('use', 'across'), ('across', 'texts'), ('texts', 'and'), ('and', 'contexts.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.0840e+03, 3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 5.5000e+02,\n",
            "        1.4610e+03, 8.5100e+02, 8.0000e+00, 5.4800e+02, 1.2400e+03, 3.0840e+03,\n",
            "        3.0000e+00, 1.0000e+00, 3.4000e+01, 2.0000e+00, 5.5000e+02, 1.4610e+03,\n",
            "        8.5100e+02, 8.0000e+00, 5.4800e+02, 1.2400e+03])\n",
            "['Stylistics', 'is', 'the', 'study', 'of', 'linguistic', 'style,', 'particularly', 'in', 'literary', 'works.', 'Stylistics', 'is', 'the', 'study', 'of', 'linguistic', 'style,', 'particularly', 'in', 'literary', 'works.']\n",
            "[('Stylistics', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'linguistic'), ('linguistic', 'style,'), ('style,', 'particularly'), ('particularly', 'in'), ('in', 'literary'), ('literary', 'works.'), ('Stylistics', 'is'), ('is', 'the'), ('the', 'study'), ('study', 'of'), ('of', 'linguistic'), ('linguistic', 'style,'), ('style,', 'particularly'), ('particularly', 'in'), ('in', 'literary'), ('literary', 'works.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([1.1650e+03, 3.0000e+00, 1.0000e+00, 5.7000e+01, 2.0000e+00, 1.6220e+03,\n",
            "        1.4040e+03, 2.4000e+01, 3.7000e+01, 3.3000e+01, 6.9000e+01, 3.0300e+02,\n",
            "        1.1650e+03, 3.0000e+00, 1.0000e+00, 5.7000e+01, 2.0000e+00, 1.6220e+03,\n",
            "        1.4040e+03, 2.4000e+01, 3.7000e+01, 3.3000e+01, 6.9000e+01, 3.0300e+02])\n",
            "['Translation', 'is', 'the', 'process', 'of', 'rendering', 'text', 'from', 'one', 'language', 'into', 'another.', 'Translation', 'is', 'the', 'process', 'of', 'rendering', 'text', 'from', 'one', 'language', 'into', 'another.']\n",
            "[('Translation', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'of'), ('of', 'rendering'), ('rendering', 'text'), ('text', 'from'), ('from', 'one'), ('one', 'language'), ('language', 'into'), ('into', 'another.'), ('Translation', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'of'), ('of', 'rendering'), ('rendering', 'text'), ('text', 'from'), ('from', 'one'), ('one', 'language'), ('language', 'into'), ('into', 'another.')]\n",
            "16\n",
            "14\n",
            "120\n",
            "30\n",
            "tensor([1.1860e+03, 3.0000e+00, 1.0000e+00, 8.6100e+02, 1.3580e+03, 2.0000e+00,\n",
            "        2.0900e+02, 9.2000e+01, 1.1860e+03, 3.0000e+00, 1.0000e+00, 8.6100e+02,\n",
            "        1.3580e+03, 2.0000e+00, 2.0900e+02, 9.2000e+01])\n",
            "['Interpretation', 'is', 'the', 'oral', 'translation', 'of', 'spoken', 'language.', 'Interpretation', 'is', 'the', 'oral', 'translation', 'of', 'spoken', 'language.']\n",
            "[('Interpretation', 'is'), ('is', 'the'), ('the', 'oral'), ('oral', 'translation'), ('translation', 'of'), ('of', 'spoken'), ('spoken', 'language.'), ('Interpretation', 'is'), ('is', 'the'), ('the', 'oral'), ('oral', 'translation'), ('translation', 'of'), ('of', 'spoken'), ('spoken', 'language.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([2.4100e+02, 2.4210e+03, 1.3000e+01, 5.7300e+02, 2.0000e+00, 3.4800e+02,\n",
            "        9.1000e+01, 7.0000e+00, 4.2000e+01, 4.0000e+00, 9.6000e+01, 2.8200e+02,\n",
            "        1.8810e+03, 2.4100e+02, 2.4210e+03, 1.3000e+01, 5.7300e+02, 2.0000e+00,\n",
            "        3.4800e+02, 9.1000e+01, 7.0000e+00, 4.2000e+01, 4.0000e+00, 9.6000e+01,\n",
            "        2.8200e+02, 1.8810e+03])\n",
            "['Language', 'families', 'are', 'groups', 'of', 'related', 'languages', 'that', 'have', 'a', 'common', 'historical', 'origin.', 'Language', 'families', 'are', 'groups', 'of', 'related', 'languages', 'that', 'have', 'a', 'common', 'historical', 'origin.']\n",
            "[('Language', 'families'), ('families', 'are'), ('are', 'groups'), ('groups', 'of'), ('of', 'related'), ('related', 'languages'), ('languages', 'that'), ('that', 'have'), ('have', 'a'), ('a', 'common'), ('common', 'historical'), ('historical', 'origin.'), ('Language', 'families'), ('families', 'are'), ('are', 'groups'), ('groups', 'of'), ('of', 'related'), ('related', 'languages'), ('languages', 'that'), ('that', 'have'), ('have', 'a'), ('a', 'common'), ('common', 'historical'), ('historical', 'origin.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.2690e+03, 3.0000e+00, 1.0000e+00, 7.5000e+01, 3.3000e+01, 2.4200e+03,\n",
            "        1.4700e+02, 9.1000e+01, 4.0000e+01, 1.4000e+01, 3.3410e+03, 3.0940e+03,\n",
            "        5.0000e+00, 3.2840e+03, 3.2690e+03, 3.0000e+00, 1.0000e+00, 7.5000e+01,\n",
            "        3.3000e+01, 2.4200e+03, 1.4700e+02, 9.1000e+01, 4.0000e+01, 1.4000e+01,\n",
            "        3.3410e+03, 3.0940e+03, 5.0000e+00, 3.2840e+03])\n",
            "['Indo-European', 'is', 'the', 'largest', 'language', 'family,', 'including', 'languages', 'such', 'as', 'English,', 'Spanish,', 'and', 'Hindi.', 'Indo-European', 'is', 'the', 'largest', 'language', 'family,', 'including', 'languages', 'such', 'as', 'English,', 'Spanish,', 'and', 'Hindi.']\n",
            "[('Indo-European', 'is'), ('is', 'the'), ('the', 'largest'), ('largest', 'language'), ('language', 'family,'), ('family,', 'including'), ('including', 'languages'), ('languages', 'such'), ('such', 'as'), ('as', 'English,'), ('English,', 'Spanish,'), ('Spanish,', 'and'), ('and', 'Hindi.'), ('Indo-European', 'is'), ('is', 'the'), ('the', 'largest'), ('largest', 'language'), ('language', 'family,'), ('family,', 'including'), ('including', 'languages'), ('languages', 'such'), ('such', 'as'), ('as', 'English,'), ('English,', 'Spanish,'), ('Spanish,', 'and'), ('and', 'Hindi.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([9.0000e+00, 3.1080e+03, 9.5500e+02, 2.5300e+02, 7.0000e+00, 1.0000e+00,\n",
            "        7.3000e+01, 2.0000e+00, 4.0000e+00, 3.3000e+01, 1.1430e+03, 4.3000e+01,\n",
            "        1.4980e+03, 1.2380e+03, 5.0000e+00, 2.7600e+03, 9.0000e+00, 3.1080e+03,\n",
            "        9.5500e+02, 2.5300e+02, 7.0000e+00, 1.0000e+00, 7.3000e+01, 2.0000e+00,\n",
            "        4.0000e+00, 3.3000e+01, 1.1430e+03, 4.3000e+01, 1.4980e+03, 1.2380e+03,\n",
            "        5.0000e+00, 2.7600e+03])\n",
            "['The', 'Sapir-Whorf', 'hypothesis', 'suggests', 'that', 'the', 'structure', 'of', 'a', 'language', 'affects', 'its', \"speakers'\", 'worldview', 'and', 'cognition.', 'The', 'Sapir-Whorf', 'hypothesis', 'suggests', 'that', 'the', 'structure', 'of', 'a', 'language', 'affects', 'its', \"speakers'\", 'worldview', 'and', 'cognition.']\n",
            "[('The', 'Sapir-Whorf'), ('Sapir-Whorf', 'hypothesis'), ('hypothesis', 'suggests'), ('suggests', 'that'), ('that', 'the'), ('the', 'structure'), ('structure', 'of'), ('of', 'a'), ('a', 'language'), ('language', 'affects'), ('affects', 'its'), ('its', \"speakers'\"), (\"speakers'\", 'worldview'), ('worldview', 'and'), ('and', 'cognition.'), ('The', 'Sapir-Whorf'), ('Sapir-Whorf', 'hypothesis'), ('hypothesis', 'suggests'), ('suggests', 'that'), ('that', 'the'), ('the', 'structure'), ('structure', 'of'), ('of', 'a'), ('a', 'language'), ('language', 'affects'), ('affects', 'its'), ('its', \"speakers'\"), (\"speakers'\", 'worldview'), ('worldview', 'and'), ('and', 'cognition.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([ 241.,  712., 1093.,   91.,  661.,    6.,   41.,   96.,  334., 2407.,\n",
            "         241.,  712., 1093.,   91.,  661.,    6.,   41.,   96.,  334., 2407.])\n",
            "['Language', 'typology', 'classifies', 'languages', 'according', 'to', 'their', 'common', 'structural', 'features.', 'Language', 'typology', 'classifies', 'languages', 'according', 'to', 'their', 'common', 'structural', 'features.']\n",
            "[('Language', 'typology'), ('typology', 'classifies'), ('classifies', 'languages'), ('languages', 'according'), ('according', 'to'), ('to', 'their'), ('their', 'common'), ('common', 'structural'), ('structural', 'features.'), ('Language', 'typology'), ('typology', 'classifies'), ('classifies', 'languages'), ('languages', 'according'), ('according', 'to'), ('to', 'their'), ('their', 'common'), ('common', 'structural'), ('structural', 'features.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([  11.,  550.,  322.,    3.,    4., 2409.,   10., 2788.,    7.,    3.,\n",
            "          96.,    6.,   51.,  382.,   11.,  550.,  322.,    3.,    4., 2409.,\n",
            "          10., 2788.,    7.,    3.,   96.,    6.,   51.,  382.])\n",
            "['A', 'linguistic', 'universal', 'is', 'a', 'feature', 'or', 'characteristic', 'that', 'is', 'common', 'to', 'all', 'languages.', 'A', 'linguistic', 'universal', 'is', 'a', 'feature', 'or', 'characteristic', 'that', 'is', 'common', 'to', 'all', 'languages.']\n",
            "[('A', 'linguistic'), ('linguistic', 'universal'), ('universal', 'is'), ('is', 'a'), ('a', 'feature'), ('feature', 'or'), ('or', 'characteristic'), ('characteristic', 'that'), ('that', 'is'), ('is', 'common'), ('common', 'to'), ('to', 'all'), ('all', 'languages.'), ('A', 'linguistic'), ('linguistic', 'universal'), ('universal', 'is'), ('is', 'a'), ('a', 'feature'), ('feature', 'or'), ('or', 'characteristic'), ('characteristic', 'that'), ('that', 'is'), ('is', 'common'), ('common', 'to'), ('to', 'all'), ('all', 'languages.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([  11., 2078.,    3.,    4.,   98., 2987.,   24.,   37.,   33.,    5.,\n",
            "        2230.,   69.,  135.,  163.,  715.,   11., 2078.,    3.,    4.,   98.,\n",
            "        2987.,   24.,   37.,   33.,    5., 2230.,   69.,  135.,  163.,  715.])\n",
            "['A', 'loanword', 'is', 'a', 'word', 'adopted', 'from', 'one', 'language', 'and', 'incorporated', 'into', 'another', 'without', 'translation.', 'A', 'loanword', 'is', 'a', 'word', 'adopted', 'from', 'one', 'language', 'and', 'incorporated', 'into', 'another', 'without', 'translation.']\n",
            "[('A', 'loanword'), ('loanword', 'is'), ('is', 'a'), ('a', 'word'), ('word', 'adopted'), ('adopted', 'from'), ('from', 'one'), ('one', 'language'), ('language', 'and'), ('and', 'incorporated'), ('incorporated', 'into'), ('into', 'another'), ('another', 'without'), ('without', 'translation.'), ('A', 'loanword'), ('loanword', 'is'), ('is', 'a'), ('a', 'word'), ('word', 'adopted'), ('adopted', 'from'), ('from', 'one'), ('one', 'language'), ('language', 'and'), ('and', 'incorporated'), ('incorporated', 'into'), ('into', 'another'), ('another', 'without'), ('without', 'translation.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([  11., 2822.,    3.,    4.,   98.,   10.,  840., 2848.,   24.,  135.,\n",
            "          33.,   18.,  549.,  715.,   11., 2822.,    3.,    4.,   98.,   10.,\n",
            "         840., 2848.,   24.,  135.,   33.,   18.,  549.,  715.])\n",
            "['A', 'calque', 'is', 'a', 'word', 'or', 'phrase', 'borrowed', 'from', 'another', 'language', 'by', 'literal', 'translation.', 'A', 'calque', 'is', 'a', 'word', 'or', 'phrase', 'borrowed', 'from', 'another', 'language', 'by', 'literal', 'translation.']\n",
            "[('A', 'calque'), ('calque', 'is'), ('is', 'a'), ('a', 'word'), ('word', 'or'), ('or', 'phrase'), ('phrase', 'borrowed'), ('borrowed', 'from'), ('from', 'another'), ('another', 'language'), ('language', 'by'), ('by', 'literal'), ('literal', 'translation.'), ('A', 'calque'), ('calque', 'is'), ('is', 'a'), ('a', 'word'), ('word', 'or'), ('or', 'phrase'), ('phrase', 'borrowed'), ('borrowed', 'from'), ('from', 'another'), ('another', 'language'), ('language', 'by'), ('by', 'literal'), ('literal', 'translation.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([3.3600e+03, 1.7500e+02, 6.0000e+00, 4.0000e+00, 7.6700e+02, 9.9000e+01,\n",
            "        3.9000e+01, 9.1000e+01, 1.0000e+01, 2.6040e+03, 1.3000e+01, 3.1000e+01,\n",
            "        1.8000e+01, 1.0000e+00, 1.7300e+02, 2.7410e+03, 8.0000e+00, 8.4000e+01,\n",
            "        6.2900e+02, 3.3600e+03, 1.7500e+02, 6.0000e+00, 4.0000e+00, 7.6700e+02,\n",
            "        9.9000e+01, 3.9000e+01, 9.1000e+01, 1.0000e+01, 2.6040e+03, 1.3000e+01,\n",
            "        3.1000e+01, 1.8000e+01, 1.0000e+00, 1.7300e+02, 2.7410e+03, 8.0000e+00,\n",
            "        8.4000e+01, 6.2900e+02])\n",
            "['Diglossia', 'refers', 'to', 'a', 'situation', 'where', 'two', 'languages', 'or', 'dialects', 'are', 'used', 'by', 'the', 'same', 'community', 'in', 'different', 'contexts.', 'Diglossia', 'refers', 'to', 'a', 'situation', 'where', 'two', 'languages', 'or', 'dialects', 'are', 'used', 'by', 'the', 'same', 'community', 'in', 'different', 'contexts.']\n",
            "[('Diglossia', 'refers'), ('refers', 'to'), ('to', 'a'), ('a', 'situation'), ('situation', 'where'), ('where', 'two'), ('two', 'languages'), ('languages', 'or'), ('or', 'dialects'), ('dialects', 'are'), ('are', 'used'), ('used', 'by'), ('by', 'the'), ('the', 'same'), ('same', 'community'), ('community', 'in'), ('in', 'different'), ('different', 'contexts.'), ('Diglossia', 'refers'), ('refers', 'to'), ('to', 'a'), ('a', 'situation'), ('situation', 'where'), ('where', 'two'), ('two', 'languages'), ('languages', 'or'), ('or', 'dialects'), ('dialects', 'are'), ('are', 'used'), ('used', 'by'), ('by', 'the'), ('the', 'same'), ('same', 'community'), ('community', 'in'), ('in', 'different'), ('different', 'contexts.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([1.1000e+01, 2.0950e+03, 2.3580e+03, 3.0000e+00, 4.0000e+00, 3.3000e+01,\n",
            "        7.0000e+00, 3.0000e+00, 3.1000e+01, 1.4000e+01, 4.0000e+00, 9.6000e+01,\n",
            "        3.3000e+01, 3.5000e+01, 3.3800e+02, 2.0000e+00, 8.4000e+01, 8.7900e+02,\n",
            "        3.8200e+02, 1.1000e+01, 2.0950e+03, 2.3580e+03, 3.0000e+00, 4.0000e+00,\n",
            "        3.3000e+01, 7.0000e+00, 3.0000e+00, 3.1000e+01, 1.4000e+01, 4.0000e+00,\n",
            "        9.6000e+01, 3.3000e+01, 3.5000e+01, 3.3800e+02, 2.0000e+00, 8.4000e+01,\n",
            "        8.7900e+02, 3.8200e+02])\n",
            "['A', 'lingua', 'franca', 'is', 'a', 'language', 'that', 'is', 'used', 'as', 'a', 'common', 'language', 'between', 'speakers', 'of', 'different', 'native', 'languages.', 'A', 'lingua', 'franca', 'is', 'a', 'language', 'that', 'is', 'used', 'as', 'a', 'common', 'language', 'between', 'speakers', 'of', 'different', 'native', 'languages.']\n",
            "[('A', 'lingua'), ('lingua', 'franca'), ('franca', 'is'), ('is', 'a'), ('a', 'language'), ('language', 'that'), ('that', 'is'), ('is', 'used'), ('used', 'as'), ('as', 'a'), ('a', 'common'), ('common', 'language'), ('language', 'between'), ('between', 'speakers'), ('speakers', 'of'), ('of', 'different'), ('different', 'native'), ('native', 'languages.'), ('A', 'lingua'), ('lingua', 'franca'), ('franca', 'is'), ('is', 'a'), ('a', 'language'), ('language', 'that'), ('that', 'is'), ('is', 'used'), ('used', 'as'), ('as', 'a'), ('a', 'common'), ('common', 'language'), ('language', 'between'), ('between', 'speakers'), ('speakers', 'of'), ('of', 'different'), ('different', 'native'), ('native', 'languages.')]\n",
            "50\n",
            "48\n",
            "1225\n",
            "98\n",
            "tensor([4.5000e+01, 1.0250e+03, 3.3000e+01, 3.0000e+00, 3.7000e+01, 7.0000e+00,\n",
            "        3.0000e+00, 7.1000e+01, 4.9400e+02, 2.0000e+00, 2.4230e+03, 3.6600e+02,\n",
            "        2.0000e+00, 1.1500e+02, 1.4000e+01, 4.3000e+01, 3.3800e+02, 2.5990e+03,\n",
            "        3.6600e+02, 1.0000e+01, 1.5340e+03, 6.0000e+00, 7.5600e+02, 1.3500e+02,\n",
            "        9.2000e+01, 4.5000e+01, 1.0250e+03, 3.3000e+01, 3.0000e+00, 3.7000e+01,\n",
            "        7.0000e+00, 3.0000e+00, 7.1000e+01, 4.9400e+02, 2.0000e+00, 2.4230e+03,\n",
            "        3.6600e+02, 2.0000e+00, 1.1500e+02, 1.4000e+01, 4.3000e+01, 3.3800e+02,\n",
            "        2.5990e+03, 3.6600e+02, 1.0000e+01, 1.5340e+03, 6.0000e+00, 7.5600e+02,\n",
            "        1.3500e+02, 9.2000e+01])\n",
            "['An', 'endangered', 'language', 'is', 'one', 'that', 'is', 'at', 'risk', 'of', 'falling', 'out', 'of', 'use', 'as', 'its', 'speakers', 'die', 'out', 'or', 'shift', 'to', 'speaking', 'another', 'language.', 'An', 'endangered', 'language', 'is', 'one', 'that', 'is', 'at', 'risk', 'of', 'falling', 'out', 'of', 'use', 'as', 'its', 'speakers', 'die', 'out', 'or', 'shift', 'to', 'speaking', 'another', 'language.']\n",
            "[('An', 'endangered'), ('endangered', 'language'), ('language', 'is'), ('is', 'one'), ('one', 'that'), ('that', 'is'), ('is', 'at'), ('at', 'risk'), ('risk', 'of'), ('of', 'falling'), ('falling', 'out'), ('out', 'of'), ('of', 'use'), ('use', 'as'), ('as', 'its'), ('its', 'speakers'), ('speakers', 'die'), ('die', 'out'), ('out', 'or'), ('or', 'shift'), ('shift', 'to'), ('to', 'speaking'), ('speaking', 'another'), ('another', 'language.'), ('An', 'endangered'), ('endangered', 'language'), ('language', 'is'), ('is', 'one'), ('one', 'that'), ('that', 'is'), ('is', 'at'), ('at', 'risk'), ('risk', 'of'), ('of', 'falling'), ('falling', 'out'), ('out', 'of'), ('of', 'use'), ('use', 'as'), ('as', 'its'), ('its', 'speakers'), ('speakers', 'die'), ('die', 'out'), ('out', 'or'), ('or', 'shift'), ('shift', 'to'), ('to', 'speaking'), ('speaking', 'another'), ('another', 'language.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([  11., 1068.,   33.,    3.,   37.,    7.,  179., 2071.,   54.,  194.,\n",
            "         879., 1497.,   11., 1068.,   33.,    3.,   37.,    7.,  179., 2071.,\n",
            "          54.,  194.,  879., 1497.])\n",
            "['A', 'dead', 'language', 'is', 'one', 'that', 'no', 'longer', 'has', 'any', 'native', 'speakers.', 'A', 'dead', 'language', 'is', 'one', 'that', 'no', 'longer', 'has', 'any', 'native', 'speakers.']\n",
            "[('A', 'dead'), ('dead', 'language'), ('language', 'is'), ('is', 'one'), ('one', 'that'), ('that', 'no'), ('no', 'longer'), ('longer', 'has'), ('has', 'any'), ('any', 'native'), ('native', 'speakers.'), ('A', 'dead'), ('dead', 'language'), ('language', 'is'), ('is', 'one'), ('one', 'that'), ('that', 'no'), ('no', 'longer'), ('longer', 'has'), ('has', 'any'), ('any', 'native'), ('native', 'speakers.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3119., 2528.,  658.,    6., 2835., 1025.,   10., 1068.,   91.,  652.,\n",
            "          69.,   96.,  321., 3119., 2528.,  658.,    6., 2835., 1025.,   10.,\n",
            "        1068.,   91.,  652.,   69.,   96.,  321.])\n",
            "['Revitalization', 'efforts', 'aim', 'to', 'bring', 'endangered', 'or', 'dead', 'languages', 'back', 'into', 'common', 'use.', 'Revitalization', 'efforts', 'aim', 'to', 'bring', 'endangered', 'or', 'dead', 'languages', 'back', 'into', 'common', 'use.']\n",
            "[('Revitalization', 'efforts'), ('efforts', 'aim'), ('aim', 'to'), ('to', 'bring'), ('bring', 'endangered'), ('endangered', 'or'), ('or', 'dead'), ('dead', 'languages'), ('languages', 'back'), ('back', 'into'), ('into', 'common'), ('common', 'use.'), ('Revitalization', 'efforts'), ('efforts', 'aim'), ('aim', 'to'), ('to', 'bring'), ('bring', 'endangered'), ('endangered', 'or'), ('or', 'dead'), ('dead', 'languages'), ('languages', 'back'), ('back', 'into'), ('into', 'common'), ('common', 'use.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([2.4100e+02, 8.2300e+02, 1.0800e+02, 9.0200e+02, 5.0000e+00, 8.1200e+02,\n",
            "        9.2100e+02, 6.0600e+02, 4.5600e+02, 7.0000e+00, 1.3000e+01, 7.1000e+01,\n",
            "        4.9400e+02, 2.0000e+00, 2.4360e+03, 2.4100e+02, 8.2300e+02, 1.0800e+02,\n",
            "        9.0200e+02, 5.0000e+00, 8.1200e+02, 9.2100e+02, 6.0600e+02, 4.5600e+02,\n",
            "        7.0000e+00, 1.3000e+01, 7.1000e+01, 4.9400e+02, 2.0000e+00, 2.4360e+03])\n",
            "['Language', 'preservation', 'involves', 'maintaining', 'and', 'protecting', 'languages,', 'especially', 'those', 'that', 'are', 'at', 'risk', 'of', 'extinction.', 'Language', 'preservation', 'involves', 'maintaining', 'and', 'protecting', 'languages,', 'especially', 'those', 'that', 'are', 'at', 'risk', 'of', 'extinction.']\n",
            "[('Language', 'preservation'), ('preservation', 'involves'), ('involves', 'maintaining'), ('maintaining', 'and'), ('and', 'protecting'), ('protecting', 'languages,'), ('languages,', 'especially'), ('especially', 'those'), ('those', 'that'), ('that', 'are'), ('are', 'at'), ('at', 'risk'), ('risk', 'of'), ('of', 'extinction.'), ('Language', 'preservation'), ('preservation', 'involves'), ('involves', 'maintaining'), ('maintaining', 'and'), ('and', 'protecting'), ('protecting', 'languages,'), ('languages,', 'especially'), ('especially', 'those'), ('those', 'that'), ('that', 'are'), ('are', 'at'), ('at', 'risk'), ('risk', 'of'), ('of', 'extinction.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3162.,  255.,  153.,   76., 1803.,   13., 1667.,   14.,   87.,  210.,\n",
            "           8.,   84.,  629., 3162.,  255.,  153.,   76., 1803.,   13., 1667.,\n",
            "          14.,   87.,  210.,    8.,   84.,  629.])\n",
            "['Phonological', 'rules', 'describe', 'how', 'phonemes', 'are', 'realized', 'as', 'speech', 'sounds', 'in', 'different', 'contexts.', 'Phonological', 'rules', 'describe', 'how', 'phonemes', 'are', 'realized', 'as', 'speech', 'sounds', 'in', 'different', 'contexts.']\n",
            "[('Phonological', 'rules'), ('rules', 'describe'), ('describe', 'how'), ('how', 'phonemes'), ('phonemes', 'are'), ('are', 'realized'), ('realized', 'as'), ('as', 'speech'), ('speech', 'sounds'), ('sounds', 'in'), ('in', 'different'), ('different', 'contexts.'), ('Phonological', 'rules'), ('rules', 'describe'), ('describe', 'how'), ('how', 'phonemes'), ('phonemes', 'are'), ('are', 'realized'), ('realized', 'as'), ('as', 'speech'), ('speech', 'sounds'), ('sounds', 'in'), ('in', 'different'), ('different', 'contexts.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.4490e+03, 1.3000e+01, 4.4300e+02, 2.0000e+00, 4.0000e+00, 8.4200e+02,\n",
            "        7.0000e+00, 8.6700e+02, 8.0000e+00, 8.4000e+01, 2.7040e+03, 1.6300e+02,\n",
            "        1.0980e+03, 1.3000e+02, 3.4490e+03, 1.3000e+01, 4.4300e+02, 2.0000e+00,\n",
            "        4.0000e+00, 8.4200e+02, 7.0000e+00, 8.6700e+02, 8.0000e+00, 8.4000e+01,\n",
            "        2.7040e+03, 1.6300e+02, 1.0980e+03, 1.3000e+02])\n",
            "['Allophones', 'are', 'variations', 'of', 'a', 'phoneme', 'that', 'occur', 'in', 'different', 'contexts', 'without', 'changing', 'meaning.', 'Allophones', 'are', 'variations', 'of', 'a', 'phoneme', 'that', 'occur', 'in', 'different', 'contexts', 'without', 'changing', 'meaning.']\n",
            "[('Allophones', 'are'), ('are', 'variations'), ('variations', 'of'), ('of', 'a'), ('a', 'phoneme'), ('phoneme', 'that'), ('that', 'occur'), ('occur', 'in'), ('in', 'different'), ('different', 'contexts'), ('contexts', 'without'), ('without', 'changing'), ('changing', 'meaning.'), ('Allophones', 'are'), ('are', 'variations'), ('variations', 'of'), ('of', 'a'), ('a', 'phoneme'), ('phoneme', 'that'), ('that', 'occur'), ('occur', 'in'), ('in', 'different'), ('different', 'contexts'), ('contexts', 'without'), ('without', 'changing'), ('changing', 'meaning.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([1.1000e+01, 1.9990e+03, 5.2300e+02, 3.0000e+00, 4.0000e+00, 5.2300e+02,\n",
            "        2.0000e+00, 1.1400e+02, 7.0000e+00, 2.5980e+03, 1.8000e+01, 1.4100e+02,\n",
            "        3.7000e+01, 1.8050e+03, 2.2480e+03, 1.0000e+00, 1.8020e+03, 2.6990e+03,\n",
            "        1.1000e+01, 1.9990e+03, 5.2300e+02, 3.0000e+00, 4.0000e+00, 5.2300e+02,\n",
            "        2.0000e+00, 1.1400e+02, 7.0000e+00, 2.5980e+03, 1.8000e+01, 1.4100e+02,\n",
            "        3.7000e+01, 1.8050e+03, 2.2480e+03, 1.0000e+00, 1.8020e+03, 2.6990e+03])\n",
            "['A', 'minimal', 'pair', 'is', 'a', 'pair', 'of', 'words', 'that', 'differ', 'by', 'only', 'one', 'phoneme,', 'illustrating', 'the', 'phonemic', 'contrast.', 'A', 'minimal', 'pair', 'is', 'a', 'pair', 'of', 'words', 'that', 'differ', 'by', 'only', 'one', 'phoneme,', 'illustrating', 'the', 'phonemic', 'contrast.']\n",
            "[('A', 'minimal'), ('minimal', 'pair'), ('pair', 'is'), ('is', 'a'), ('a', 'pair'), ('pair', 'of'), ('of', 'words'), ('words', 'that'), ('that', 'differ'), ('differ', 'by'), ('by', 'only'), ('only', 'one'), ('one', 'phoneme,'), ('phoneme,', 'illustrating'), ('illustrating', 'the'), ('the', 'phonemic'), ('phonemic', 'contrast.'), ('A', 'minimal'), ('minimal', 'pair'), ('pair', 'is'), ('is', 'a'), ('a', 'pair'), ('pair', 'of'), ('of', 'words'), ('words', 'that'), ('that', 'differ'), ('differ', 'by'), ('by', 'only'), ('only', 'one'), ('one', 'phoneme,'), ('phoneme,', 'illustrating'), ('illustrating', 'the'), ('the', 'phonemic'), ('phonemic', 'contrast.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([3.0870e+03, 3.0000e+00, 1.0000e+00, 2.5100e+03, 8.3500e+02, 2.3000e+01,\n",
            "        4.1300e+02, 1.4350e+03, 1.0000e+01, 1.1400e+02, 8.0000e+00, 4.7600e+02,\n",
            "        3.0870e+03, 3.0000e+00, 1.0000e+00, 2.5100e+03, 8.3500e+02, 2.3000e+01,\n",
            "        4.1300e+02, 1.4350e+03, 1.0000e+01, 1.1400e+02, 8.0000e+00, 4.7600e+02])\n",
            "['Stress', 'is', 'the', 'emphasis', 'placed', 'on', 'certain', 'syllables', 'or', 'words', 'in', 'speech.', 'Stress', 'is', 'the', 'emphasis', 'placed', 'on', 'certain', 'syllables', 'or', 'words', 'in', 'speech.']\n",
            "[('Stress', 'is'), ('is', 'the'), ('the', 'emphasis'), ('emphasis', 'placed'), ('placed', 'on'), ('on', 'certain'), ('certain', 'syllables'), ('syllables', 'or'), ('or', 'words'), ('words', 'in'), ('in', 'speech.'), ('Stress', 'is'), ('is', 'the'), ('the', 'emphasis'), ('emphasis', 'placed'), ('placed', 'on'), ('on', 'certain'), ('certain', 'syllables'), ('syllables', 'or'), ('or', 'words'), ('words', 'in'), ('in', 'speech.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.2630e+03, 1.7500e+02, 6.0000e+00, 1.0000e+00, 4.4400e+02, 2.0000e+00,\n",
            "        8.3700e+02, 1.9600e+02, 4.7800e+02, 2.2000e+01, 1.6000e+01, 8.5000e+01,\n",
            "        1.0000e+00, 1.8300e+02, 2.0000e+00, 2.5400e+02, 3.2630e+03, 1.7500e+02,\n",
            "        6.0000e+00, 1.0000e+00, 4.4400e+02, 2.0000e+00, 8.3700e+02, 1.9600e+02,\n",
            "        4.7800e+02, 2.2000e+01, 1.6000e+01, 8.5000e+01, 1.0000e+00, 1.8300e+02,\n",
            "        2.0000e+00, 2.5400e+02])\n",
            "['Intonation', 'refers', 'to', 'the', 'variation', 'of', 'pitch', 'while', 'speaking,', 'which', 'can', 'change', 'the', 'meaning', 'of', 'sentences.', 'Intonation', 'refers', 'to', 'the', 'variation', 'of', 'pitch', 'while', 'speaking,', 'which', 'can', 'change', 'the', 'meaning', 'of', 'sentences.']\n",
            "[('Intonation', 'refers'), ('refers', 'to'), ('to', 'the'), ('the', 'variation'), ('variation', 'of'), ('of', 'pitch'), ('pitch', 'while'), ('while', 'speaking,'), ('speaking,', 'which'), ('which', 'can'), ('can', 'change'), ('change', 'the'), ('the', 'meaning'), ('meaning', 'of'), ('of', 'sentences.'), ('Intonation', 'refers'), ('refers', 'to'), ('to', 'the'), ('the', 'variation'), ('variation', 'of'), ('of', 'pitch'), ('pitch', 'while'), ('while', 'speaking,'), ('speaking,', 'which'), ('which', 'can'), ('can', 'change'), ('change', 'the'), ('the', 'meaning'), ('meaning', 'of'), ('of', 'sentences.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([3063.,   91.,  115.,  837.,  443.,    6., 1046.,   98.,  272., 3063.,\n",
            "          91.,  115.,  837.,  443.,    6., 1046.,   98.,  272.])\n",
            "['Tone', 'languages', 'use', 'pitch', 'variations', 'to', 'distinguish', 'word', 'meanings.', 'Tone', 'languages', 'use', 'pitch', 'variations', 'to', 'distinguish', 'word', 'meanings.']\n",
            "[('Tone', 'languages'), ('languages', 'use'), ('use', 'pitch'), ('pitch', 'variations'), ('variations', 'to'), ('to', 'distinguish'), ('distinguish', 'word'), ('word', 'meanings.'), ('Tone', 'languages'), ('languages', 'use'), ('use', 'pitch'), ('pitch', 'variations'), ('variations', 'to'), ('to', 'distinguish'), ('distinguish', 'word'), ('word', 'meanings.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([1.1000e+01, 1.4310e+03, 1.3470e+03, 3.0000e+00, 4.0000e+00, 1.0540e+03,\n",
            "        1.6190e+03, 1.0000e+00, 1.4320e+03, 7.3000e+01, 2.0000e+00, 4.0000e+00,\n",
            "        4.8700e+02, 6.6100e+02, 6.0000e+00, 4.0000e+00, 3.9700e+02, 2.3160e+03,\n",
            "        1.1000e+01, 1.4310e+03, 1.3470e+03, 3.0000e+00, 4.0000e+00, 1.0540e+03,\n",
            "        1.6190e+03, 1.0000e+00, 1.4320e+03, 7.3000e+01, 2.0000e+00, 4.0000e+00,\n",
            "        4.8700e+02, 6.6100e+02, 6.0000e+00, 4.0000e+00, 3.9700e+02, 2.3160e+03])\n",
            "['A', 'syntax', 'tree', 'is', 'a', 'diagram', 'representing', 'the', 'syntactic', 'structure', 'of', 'a', 'sentence', 'according', 'to', 'a', 'formal', 'grammar.', 'A', 'syntax', 'tree', 'is', 'a', 'diagram', 'representing', 'the', 'syntactic', 'structure', 'of', 'a', 'sentence', 'according', 'to', 'a', 'formal', 'grammar.']\n",
            "[('A', 'syntax'), ('syntax', 'tree'), ('tree', 'is'), ('is', 'a'), ('a', 'diagram'), ('diagram', 'representing'), ('representing', 'the'), ('the', 'syntactic'), ('syntactic', 'structure'), ('structure', 'of'), ('of', 'a'), ('a', 'sentence'), ('sentence', 'according'), ('according', 'to'), ('to', 'a'), ('a', 'formal'), ('formal', 'grammar.'), ('A', 'syntax'), ('syntax', 'tree'), ('tree', 'is'), ('is', 'a'), ('a', 'diagram'), ('diagram', 'representing'), ('representing', 'the'), ('the', 'syntactic'), ('syntactic', 'structure'), ('structure', 'of'), ('of', 'a'), ('a', 'sentence'), ('sentence', 'according'), ('according', 'to'), ('to', 'a'), ('a', 'formal'), ('formal', 'grammar.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.4020e+03, 3.9200e+02, 3.0000e+00, 4.0000e+00, 2.6000e+01, 1.2000e+01,\n",
            "        2.9500e+03, 4.8700e+02, 7.3000e+01, 1.5700e+02, 2.3000e+01, 1.0000e+00,\n",
            "        7.7800e+02, 7.8500e+02, 2.0000e+00, 1.3600e+02, 3.4020e+03, 3.9200e+02,\n",
            "        3.0000e+00, 4.0000e+00, 2.6000e+01, 1.2000e+01, 2.9500e+03, 4.8700e+02,\n",
            "        7.3000e+01, 1.5700e+02, 2.3000e+01, 1.0000e+00, 7.7800e+02, 7.8500e+02,\n",
            "        2.0000e+00, 1.3600e+02])\n",
            "['Case', 'grammar', 'is', 'a', 'system', 'for', 'analyzing', 'sentence', 'structure', 'based', 'on', 'the', 'semantic', 'roles', 'of', 'words.', 'Case', 'grammar', 'is', 'a', 'system', 'for', 'analyzing', 'sentence', 'structure', 'based', 'on', 'the', 'semantic', 'roles', 'of', 'words.']\n",
            "[('Case', 'grammar'), ('grammar', 'is'), ('is', 'a'), ('a', 'system'), ('system', 'for'), ('for', 'analyzing'), ('analyzing', 'sentence'), ('sentence', 'structure'), ('structure', 'based'), ('based', 'on'), ('on', 'the'), ('the', 'semantic'), ('semantic', 'roles'), ('roles', 'of'), ('of', 'words.'), ('Case', 'grammar'), ('grammar', 'is'), ('is', 'a'), ('a', 'system'), ('system', 'for'), ('for', 'analyzing'), ('analyzing', 'sentence'), ('sentence', 'structure'), ('structure', 'based'), ('based', 'on'), ('on', 'the'), ('the', 'semantic'), ('semantic', 'roles'), ('roles', 'of'), ('of', 'words.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.0280e+03, 5.2800e+02, 7.1200e+02, 1.0930e+03, 9.1000e+01, 1.5700e+02,\n",
            "        2.3000e+01, 1.0000e+00, 5.2800e+02, 2.0000e+00, 7.4500e+02, 1.2980e+03,\n",
            "        5.0000e+00, 1.1800e+02, 8.0000e+00, 2.5400e+02, 3.0280e+03, 5.2800e+02,\n",
            "        7.1200e+02, 1.0930e+03, 9.1000e+01, 1.5700e+02, 2.3000e+01, 1.0000e+00,\n",
            "        5.2800e+02, 2.0000e+00, 7.4500e+02, 1.2980e+03, 5.0000e+00, 1.1800e+02,\n",
            "        8.0000e+00, 2.5400e+02])\n",
            "['Word', 'order', 'typology', 'classifies', 'languages', 'based', 'on', 'the', 'order', 'of', 'subject,', 'verb,', 'and', 'object', 'in', 'sentences.', 'Word', 'order', 'typology', 'classifies', 'languages', 'based', 'on', 'the', 'order', 'of', 'subject,', 'verb,', 'and', 'object', 'in', 'sentences.']\n",
            "[('Word', 'order'), ('order', 'typology'), ('typology', 'classifies'), ('classifies', 'languages'), ('languages', 'based'), ('based', 'on'), ('on', 'the'), ('the', 'order'), ('order', 'of'), ('of', 'subject,'), ('subject,', 'verb,'), ('verb,', 'and'), ('and', 'object'), ('object', 'in'), ('in', 'sentences.'), ('Word', 'order'), ('order', 'typology'), ('typology', 'classifies'), ('classifies', 'languages'), ('languages', 'based'), ('based', 'on'), ('on', 'the'), ('the', 'order'), ('order', 'of'), ('of', 'subject,'), ('subject,', 'verb,'), ('verb,', 'and'), ('and', 'object'), ('object', 'in'), ('in', 'sentences.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.4460e+03, 3.0000e+00, 1.0000e+00, 1.1500e+02, 2.0000e+00, 1.1400e+02,\n",
            "        4.0000e+01, 1.4000e+01, 1.7170e+03, 6.0000e+00, 1.6450e+03, 6.5200e+02,\n",
            "        6.0000e+00, 8.2000e+02, 2.0150e+03, 1.0220e+03, 3.4460e+03, 3.0000e+00,\n",
            "        1.0000e+00, 1.1500e+02, 2.0000e+00, 1.1400e+02, 4.0000e+01, 1.4000e+01,\n",
            "        1.7170e+03, 6.0000e+00, 1.6450e+03, 6.5200e+02, 6.0000e+00, 8.2000e+02,\n",
            "        2.0150e+03, 1.0220e+03])\n",
            "['Anaphora', 'is', 'the', 'use', 'of', 'words', 'such', 'as', 'pronouns', 'to', 'refer', 'back', 'to', 'previously', 'mentioned', 'entities.', 'Anaphora', 'is', 'the', 'use', 'of', 'words', 'such', 'as', 'pronouns', 'to', 'refer', 'back', 'to', 'previously', 'mentioned', 'entities.']\n",
            "[('Anaphora', 'is'), ('is', 'the'), ('the', 'use'), ('use', 'of'), ('of', 'words'), ('words', 'such'), ('such', 'as'), ('as', 'pronouns'), ('pronouns', 'to'), ('to', 'refer'), ('refer', 'back'), ('back', 'to'), ('to', 'previously'), ('previously', 'mentioned'), ('mentioned', 'entities.'), ('Anaphora', 'is'), ('is', 'the'), ('the', 'use'), ('use', 'of'), ('of', 'words'), ('words', 'such'), ('such', 'as'), ('as', 'pronouns'), ('pronouns', 'to'), ('to', 'refer'), ('refer', 'back'), ('back', 'to'), ('to', 'previously'), ('previously', 'mentioned'), ('mentioned', 'entities.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3368.,  175.,    6.,  114.,    5.,  839.,    7.,  643.,   25.,  983.,\n",
            "        1327.,  163., 2994., 2703.,  949., 3368.,  175.,    6.,  114.,    5.,\n",
            "         839.,    7.,  643.,   25.,  983., 1327.,  163., 2994., 2703.,  949.])\n",
            "['Deixis', 'refers', 'to', 'words', 'and', 'phrases', 'that', 'cannot', 'be', 'fully', 'understood', 'without', 'additional', 'contextual', 'information.', 'Deixis', 'refers', 'to', 'words', 'and', 'phrases', 'that', 'cannot', 'be', 'fully', 'understood', 'without', 'additional', 'contextual', 'information.']\n",
            "[('Deixis', 'refers'), ('refers', 'to'), ('to', 'words'), ('words', 'and'), ('and', 'phrases'), ('phrases', 'that'), ('that', 'cannot'), ('cannot', 'be'), ('be', 'fully'), ('fully', 'understood'), ('understood', 'without'), ('without', 'additional'), ('additional', 'contextual'), ('contextual', 'information.'), ('Deixis', 'refers'), ('refers', 'to'), ('to', 'words'), ('words', 'and'), ('and', 'phrases'), ('phrases', 'that'), ('that', 'cannot'), ('cannot', 'be'), ('be', 'fully'), ('fully', 'understood'), ('understood', 'without'), ('without', 'additional'), ('additional', 'contextual'), ('contextual', 'information.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3448.,  142.,  125.,    4.,   98.,   10.,  487.,   54.,   60.,   66.,\n",
            "          37.,  357.,  130., 3448.,  142.,  125.,    4.,   98.,   10.,  487.,\n",
            "          54.,   60.,   66.,   37.,  357.,  130.])\n",
            "['Ambiguity', 'occurs', 'when', 'a', 'word', 'or', 'sentence', 'has', 'more', 'than', 'one', 'possible', 'meaning.', 'Ambiguity', 'occurs', 'when', 'a', 'word', 'or', 'sentence', 'has', 'more', 'than', 'one', 'possible', 'meaning.']\n",
            "[('Ambiguity', 'occurs'), ('occurs', 'when'), ('when', 'a'), ('a', 'word'), ('word', 'or'), ('or', 'sentence'), ('sentence', 'has'), ('has', 'more'), ('more', 'than'), ('than', 'one'), ('one', 'possible'), ('possible', 'meaning.'), ('Ambiguity', 'occurs'), ('occurs', 'when'), ('when', 'a'), ('a', 'word'), ('word', 'or'), ('or', 'sentence'), ('sentence', 'has'), ('has', 'more'), ('more', 'than'), ('than', 'one'), ('one', 'possible'), ('possible', 'meaning.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.1490e+03, 3.0000e+00, 1.0000e+00, 2.7620e+03, 2.0000e+00, 2.1800e+02,\n",
            "        3.5700e+02, 8.9300e+02, 1.2000e+01, 4.0000e+00, 9.8000e+01, 1.0000e+01,\n",
            "        1.7990e+03, 3.1490e+03, 3.0000e+00, 1.0000e+00, 2.7620e+03, 2.0000e+00,\n",
            "        2.1800e+02, 3.5700e+02, 8.9300e+02, 1.2000e+01, 4.0000e+00, 9.8000e+01,\n",
            "        1.0000e+01, 1.7990e+03])\n",
            "['Polysemy', 'is', 'the', 'coexistence', 'of', 'many', 'possible', 'meanings', 'for', 'a', 'word', 'or', 'phrase.', 'Polysemy', 'is', 'the', 'coexistence', 'of', 'many', 'possible', 'meanings', 'for', 'a', 'word', 'or', 'phrase.']\n",
            "[('Polysemy', 'is'), ('is', 'the'), ('the', 'coexistence'), ('coexistence', 'of'), ('of', 'many'), ('many', 'possible'), ('possible', 'meanings'), ('meanings', 'for'), ('for', 'a'), ('a', 'word'), ('word', 'or'), ('or', 'phrase.'), ('Polysemy', 'is'), ('is', 'the'), ('the', 'coexistence'), ('coexistence', 'of'), ('of', 'many'), ('many', 'possible'), ('possible', 'meanings'), ('meanings', 'for'), ('for', 'a'), ('a', 'word'), ('word', 'or'), ('or', 'phrase.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.2810e+03, 1.3000e+01, 1.1400e+02, 7.0000e+00, 1.7100e+02, 1.0000e+00,\n",
            "        1.7300e+02, 3.8000e+01, 4.2000e+01, 8.4000e+01, 2.7200e+02, 3.2810e+03,\n",
            "        1.3000e+01, 1.1400e+02, 7.0000e+00, 1.7100e+02, 1.0000e+00, 1.7300e+02,\n",
            "        3.8000e+01, 4.2000e+01, 8.4000e+01, 2.7200e+02])\n",
            "['Homophones', 'are', 'words', 'that', 'sound', 'the', 'same', 'but', 'have', 'different', 'meanings.', 'Homophones', 'are', 'words', 'that', 'sound', 'the', 'same', 'but', 'have', 'different', 'meanings.']\n",
            "[('Homophones', 'are'), ('are', 'words'), ('words', 'that'), ('that', 'sound'), ('sound', 'the'), ('the', 'same'), ('same', 'but'), ('but', 'have'), ('have', 'different'), ('different', 'meanings.'), ('Homophones', 'are'), ('are', 'words'), ('words', 'that'), ('that', 'sound'), ('sound', 'the'), ('the', 'same'), ('same', 'but'), ('but', 'have'), ('have', 'different'), ('different', 'meanings.')]\n",
            "12\n",
            "10\n",
            "66\n",
            "22\n",
            "tensor([3080.,   13.,  114.,   19.,  770.,  272., 3080.,   13.,  114.,   19.,\n",
            "         770.,  272.])\n",
            "['Synonyms', 'are', 'words', 'with', 'similar', 'meanings.', 'Synonyms', 'are', 'words', 'with', 'similar', 'meanings.']\n",
            "[('Synonyms', 'are'), ('are', 'words'), ('words', 'with'), ('with', 'similar'), ('similar', 'meanings.'), ('Synonyms', 'are'), ('are', 'words'), ('words', 'with'), ('with', 'similar'), ('similar', 'meanings.')]\n",
            "12\n",
            "10\n",
            "66\n",
            "22\n",
            "tensor([3439.,   13.,  114.,   19.,  529.,  272., 3439.,   13.,  114.,   19.,\n",
            "         529.,  272.])\n",
            "['Antonyms', 'are', 'words', 'with', 'opposite', 'meanings.', 'Antonyms', 'are', 'words', 'with', 'opposite', 'meanings.']\n",
            "[('Antonyms', 'are'), ('are', 'words'), ('words', 'with'), ('with', 'opposite'), ('opposite', 'meanings.'), ('Antonyms', 'are'), ('are', 'words'), ('words', 'with'), ('with', 'opposite'), ('opposite', 'meanings.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 1.3960e+03, 3.0000e+00, 4.0000e+00, 1.6440e+03, 1.6200e+02,\n",
            "        7.0000e+00, 2.0870e+03, 1.1400e+02, 2.3060e+03, 2.0300e+02, 6.6100e+02,\n",
            "        6.0000e+00, 1.5280e+03, 2.0000e+00, 1.3000e+02, 1.1000e+01, 1.3960e+03,\n",
            "        3.0000e+00, 4.0000e+00, 1.6440e+03, 1.6200e+02, 7.0000e+00, 2.0870e+03,\n",
            "        1.1400e+02, 2.3060e+03, 2.0300e+02, 6.6100e+02, 6.0000e+00, 1.5280e+03,\n",
            "        2.0000e+00, 1.3000e+02])\n",
            "['A', 'thesaurus', 'is', 'a', 'reference', 'work', 'that', 'lists', 'words', 'grouped', 'together', 'according', 'to', 'similarity', 'of', 'meaning.', 'A', 'thesaurus', 'is', 'a', 'reference', 'work', 'that', 'lists', 'words', 'grouped', 'together', 'according', 'to', 'similarity', 'of', 'meaning.']\n",
            "[('A', 'thesaurus'), ('thesaurus', 'is'), ('is', 'a'), ('a', 'reference'), ('reference', 'work'), ('work', 'that'), ('that', 'lists'), ('lists', 'words'), ('words', 'grouped'), ('grouped', 'together'), ('together', 'according'), ('according', 'to'), ('to', 'similarity'), ('similarity', 'of'), ('of', 'meaning.'), ('A', 'thesaurus'), ('thesaurus', 'is'), ('is', 'a'), ('a', 'reference'), ('reference', 'work'), ('work', 'that'), ('that', 'lists'), ('lists', 'words'), ('words', 'grouped'), ('grouped', 'together'), ('together', 'according'), ('according', 'to'), ('to', 'similarity'), ('similarity', 'of'), ('of', 'meaning.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([1.1000e+01, 2.1050e+03, 3.0000e+00, 1.0000e+00, 1.2780e+03, 2.0000e+00,\n",
            "        4.0000e+00, 3.3000e+01, 1.0000e+01, 4.0000e+00, 8.0000e+01, 1.1200e+02,\n",
            "        2.0000e+00, 7.4700e+02, 1.1000e+01, 2.1050e+03, 3.0000e+00, 1.0000e+00,\n",
            "        1.2780e+03, 2.0000e+00, 4.0000e+00, 3.3000e+01, 1.0000e+01, 4.0000e+00,\n",
            "        8.0000e+01, 1.1200e+02, 2.0000e+00, 7.4700e+02])\n",
            "['A', 'lexicon', 'is', 'the', 'vocabulary', 'of', 'a', 'language', 'or', 'a', 'specific', 'field', 'of', 'study.', 'A', 'lexicon', 'is', 'the', 'vocabulary', 'of', 'a', 'language', 'or', 'a', 'specific', 'field', 'of', 'study.']\n",
            "[('A', 'lexicon'), ('lexicon', 'is'), ('is', 'the'), ('the', 'vocabulary'), ('vocabulary', 'of'), ('of', 'a'), ('a', 'language'), ('language', 'or'), ('or', 'a'), ('a', 'specific'), ('specific', 'field'), ('field', 'of'), ('of', 'study.'), ('A', 'lexicon'), ('lexicon', 'is'), ('is', 'the'), ('the', 'vocabulary'), ('vocabulary', 'of'), ('of', 'a'), ('a', 'language'), ('language', 'or'), ('or', 'a'), ('a', 'specific'), ('specific', 'field'), ('field', 'of'), ('of', 'study.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([3.3930e+03, 1.7500e+02, 6.0000e+00, 1.0000e+00, 2.2990e+03, 2.1330e+03,\n",
            "        2.0000e+00, 4.0000e+00, 1.1700e+02, 9.8000e+01, 1.9000e+01, 1.3500e+02,\n",
            "        9.8000e+01, 1.0000e+01, 1.1400e+02, 1.9000e+01, 4.0000e+00, 3.9400e+02,\n",
            "        5.7500e+02, 6.6000e+01, 2.7930e+03, 3.3930e+03, 1.7500e+02, 6.0000e+00,\n",
            "        1.0000e+00, 2.2990e+03, 2.1330e+03, 2.0000e+00, 4.0000e+00, 1.1700e+02,\n",
            "        9.8000e+01, 1.9000e+01, 1.3500e+02, 9.8000e+01, 1.0000e+01, 1.1400e+02,\n",
            "        1.9000e+01, 4.0000e+00, 3.9400e+02, 5.7500e+02, 6.6000e+01, 2.7930e+03])\n",
            "['Collocation', 'refers', 'to', 'the', 'habitual', 'juxtaposition', 'of', 'a', 'particular', 'word', 'with', 'another', 'word', 'or', 'words', 'with', 'a', 'frequency', 'greater', 'than', 'chance.', 'Collocation', 'refers', 'to', 'the', 'habitual', 'juxtaposition', 'of', 'a', 'particular', 'word', 'with', 'another', 'word', 'or', 'words', 'with', 'a', 'frequency', 'greater', 'than', 'chance.']\n",
            "[('Collocation', 'refers'), ('refers', 'to'), ('to', 'the'), ('the', 'habitual'), ('habitual', 'juxtaposition'), ('juxtaposition', 'of'), ('of', 'a'), ('a', 'particular'), ('particular', 'word'), ('word', 'with'), ('with', 'another'), ('another', 'word'), ('word', 'or'), ('or', 'words'), ('words', 'with'), ('with', 'a'), ('a', 'frequency'), ('frequency', 'greater'), ('greater', 'than'), ('than', 'chance.'), ('Collocation', 'refers'), ('refers', 'to'), ('to', 'the'), ('the', 'habitual'), ('habitual', 'juxtaposition'), ('juxtaposition', 'of'), ('of', 'a'), ('a', 'particular'), ('particular', 'word'), ('word', 'with'), ('with', 'another'), ('another', 'word'), ('word', 'or'), ('or', 'words'), ('words', 'with'), ('with', 'a'), ('a', 'frequency'), ('frequency', 'greater'), ('greater', 'than'), ('than', 'chance.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([  11., 1638.,    3.,    4., 1303.,    2.,    4.,   33.,   31.,   12.,\n",
            "           4.,  117., 1698.,   10.,    8.,    4.,  117.,  481., 1542.,   11.,\n",
            "        1638.,    3.,    4., 1303.,    2.,    4.,   33.,   31.,   12.,    4.,\n",
            "         117., 1698.,   10.,    8.,    4.,  117.,  481., 1542.])\n",
            "['A', 'register', 'is', 'a', 'variety', 'of', 'a', 'language', 'used', 'for', 'a', 'particular', 'purpose', 'or', 'in', 'a', 'particular', 'social', 'setting.', 'A', 'register', 'is', 'a', 'variety', 'of', 'a', 'language', 'used', 'for', 'a', 'particular', 'purpose', 'or', 'in', 'a', 'particular', 'social', 'setting.']\n",
            "[('A', 'register'), ('register', 'is'), ('is', 'a'), ('a', 'variety'), ('variety', 'of'), ('of', 'a'), ('a', 'language'), ('language', 'used'), ('used', 'for'), ('for', 'a'), ('a', 'particular'), ('particular', 'purpose'), ('purpose', 'or'), ('or', 'in'), ('in', 'a'), ('a', 'particular'), ('particular', 'social'), ('social', 'setting.'), ('A', 'register'), ('register', 'is'), ('is', 'a'), ('a', 'variety'), ('variety', 'of'), ('of', 'a'), ('a', 'language'), ('language', 'used'), ('used', 'for'), ('for', 'a'), ('a', 'particular'), ('particular', 'purpose'), ('purpose', 'or'), ('or', 'in'), ('in', 'a'), ('a', 'particular'), ('particular', 'social'), ('social', 'setting.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([  11.,   87.,  306.,    3.,   21., 1311.,    7.,  847.,    4.,  149.,\n",
            "           8., 2743.,   40.,   14.,  542.,    4., 1615.,   10.,  974.,    4.,\n",
            "        2746.,   11.,   87.,  306.,    3.,   21., 1311.,    7.,  847.,    4.,\n",
            "         149.,    8., 2743.,   40.,   14.,  542.,    4., 1615.,   10.,  974.,\n",
            "           4., 2746.])\n",
            "['A', 'speech', 'act', 'is', 'an', 'utterance', 'that', 'performs', 'a', 'function', 'in', 'communication,', 'such', 'as', 'making', 'a', 'request', 'or', 'giving', 'a', 'command.', 'A', 'speech', 'act', 'is', 'an', 'utterance', 'that', 'performs', 'a', 'function', 'in', 'communication,', 'such', 'as', 'making', 'a', 'request', 'or', 'giving', 'a', 'command.']\n",
            "[('A', 'speech'), ('speech', 'act'), ('act', 'is'), ('is', 'an'), ('an', 'utterance'), ('utterance', 'that'), ('that', 'performs'), ('performs', 'a'), ('a', 'function'), ('function', 'in'), ('in', 'communication,'), ('communication,', 'such'), ('such', 'as'), ('as', 'making'), ('making', 'a'), ('a', 'request'), ('request', 'or'), ('or', 'giving'), ('giving', 'a'), ('a', 'command.'), ('A', 'speech'), ('speech', 'act'), ('act', 'is'), ('is', 'an'), ('an', 'utterance'), ('utterance', 'that'), ('that', 'performs'), ('performs', 'a'), ('a', 'function'), ('function', 'in'), ('in', 'communication,'), ('communication,', 'such'), ('such', 'as'), ('as', 'making'), ('making', 'a'), ('a', 'request'), ('request', 'or'), ('or', 'giving'), ('giving', 'a'), ('a', 'command.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.3840e+03, 2.2380e+03, 1.7500e+02, 6.0000e+00, 1.0000e+00, 2.2360e+03,\n",
            "        8.9300e+02, 7.0000e+00, 1.3000e+01, 6.7000e+01, 4.0700e+02, 4.0000e+02,\n",
            "        8.0000e+00, 2.0900e+02, 9.2000e+01, 3.3840e+03, 2.2380e+03, 1.7500e+02,\n",
            "        6.0000e+00, 1.0000e+00, 2.2360e+03, 8.9300e+02, 7.0000e+00, 1.3000e+01,\n",
            "        6.7000e+01, 4.0700e+02, 4.0000e+02, 8.0000e+00, 2.0900e+02, 9.2000e+01])\n",
            "['Conversational', 'implicature', 'refers', 'to', 'the', 'implied', 'meanings', 'that', 'are', 'not', 'directly', 'expressed', 'in', 'spoken', 'language.', 'Conversational', 'implicature', 'refers', 'to', 'the', 'implied', 'meanings', 'that', 'are', 'not', 'directly', 'expressed', 'in', 'spoken', 'language.']\n",
            "[('Conversational', 'implicature'), ('implicature', 'refers'), ('refers', 'to'), ('to', 'the'), ('the', 'implied'), ('implied', 'meanings'), ('meanings', 'that'), ('that', 'are'), ('are', 'not'), ('not', 'directly'), ('directly', 'expressed'), ('expressed', 'in'), ('in', 'spoken'), ('spoken', 'language.'), ('Conversational', 'implicature'), ('implicature', 'refers'), ('refers', 'to'), ('to', 'the'), ('the', 'implied'), ('implied', 'meanings'), ('meanings', 'that'), ('that', 'are'), ('are', 'not'), ('not', 'directly'), ('directly', 'expressed'), ('expressed', 'in'), ('in', 'spoken'), ('spoken', 'language.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([  11., 1953.,    3.,    4., 1943., 2758.,   98.,   10., 1000.,   11.,\n",
            "        1953.,    3.,    4., 1943., 2758.,   98.,   10., 1000.])\n",
            "['A', 'neologism', 'is', 'a', 'newly', 'coined', 'word', 'or', 'expression.', 'A', 'neologism', 'is', 'a', 'newly', 'coined', 'word', 'or', 'expression.']\n",
            "[('A', 'neologism'), ('neologism', 'is'), ('is', 'a'), ('a', 'newly'), ('newly', 'coined'), ('coined', 'word'), ('word', 'or'), ('or', 'expression.'), ('A', 'neologism'), ('neologism', 'is'), ('is', 'a'), ('a', 'newly'), ('newly', 'coined'), ('coined', 'word'), ('word', 'or'), ('or', 'expression.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([  11., 2478.,    3.,    4., 2003.,   10., 2223.,   98.,   10.,  187.,\n",
            "        1455.,   12.,   37.,  630., 1375., 2290.,   10., 2853.,   11., 2478.,\n",
            "           3.,    4., 2003.,   10., 2223.,   98.,   10.,  187., 1455.,   12.,\n",
            "          37.,  630., 1375., 2290.,   10., 2853.])\n",
            "['A', 'euphemism', 'is', 'a', 'mild', 'or', 'indirect', 'word', 'or', 'expression', 'substituted', 'for', 'one', 'considered', 'too', 'harsh', 'or', 'blunt.', 'A', 'euphemism', 'is', 'a', 'mild', 'or', 'indirect', 'word', 'or', 'expression', 'substituted', 'for', 'one', 'considered', 'too', 'harsh', 'or', 'blunt.']\n",
            "[('A', 'euphemism'), ('euphemism', 'is'), ('is', 'a'), ('a', 'mild'), ('mild', 'or'), ('or', 'indirect'), ('indirect', 'word'), ('word', 'or'), ('or', 'expression'), ('expression', 'substituted'), ('substituted', 'for'), ('for', 'one'), ('one', 'considered'), ('considered', 'too'), ('too', 'harsh'), ('harsh', 'or'), ('or', 'blunt.'), ('A', 'euphemism'), ('euphemism', 'is'), ('is', 'a'), ('a', 'mild'), ('mild', 'or'), ('or', 'indirect'), ('indirect', 'word'), ('word', 'or'), ('or', 'expression'), ('expression', 'substituted'), ('substituted', 'for'), ('for', 'one'), ('one', 'considered'), ('considered', 'too'), ('too', 'harsh'), ('harsh', 'or'), ('or', 'blunt.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 2.5430e+03, 3.0000e+00, 4.0000e+00, 2.6180e+03, 1.0000e+01,\n",
            "        1.3210e+03, 7.3400e+02, 3.1000e+01, 2.1910e+03, 2.0000e+00, 4.0000e+00,\n",
            "        1.7830e+03, 1.0000e+01, 1.9470e+03, 1.9000e+03, 1.1000e+01, 2.5430e+03,\n",
            "        3.0000e+00, 4.0000e+00, 2.6180e+03, 1.0000e+01, 1.3210e+03, 7.3400e+02,\n",
            "        3.1000e+01, 2.1910e+03, 2.0000e+00, 4.0000e+00, 1.7830e+03, 1.0000e+01,\n",
            "        1.9470e+03, 1.9000e+03])\n",
            "['A', 'dysphemism', 'is', 'a', 'derogatory', 'or', 'unpleasant', 'term', 'used', 'instead', 'of', 'a', 'pleasant', 'or', 'neutral', 'one.', 'A', 'dysphemism', 'is', 'a', 'derogatory', 'or', 'unpleasant', 'term', 'used', 'instead', 'of', 'a', 'pleasant', 'or', 'neutral', 'one.']\n",
            "[('A', 'dysphemism'), ('dysphemism', 'is'), ('is', 'a'), ('a', 'derogatory'), ('derogatory', 'or'), ('or', 'unpleasant'), ('unpleasant', 'term'), ('term', 'used'), ('used', 'instead'), ('instead', 'of'), ('of', 'a'), ('a', 'pleasant'), ('pleasant', 'or'), ('or', 'neutral'), ('neutral', 'one.'), ('A', 'dysphemism'), ('dysphemism', 'is'), ('is', 'a'), ('a', 'derogatory'), ('derogatory', 'or'), ('or', 'unpleasant'), ('unpleasant', 'term'), ('term', 'used'), ('used', 'instead'), ('instead', 'of'), ('of', 'a'), ('a', 'pleasant'), ('pleasant', 'or'), ('or', 'neutral'), ('neutral', 'one.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.2570e+03, 3.0000e+00, 4.7700e+02, 3.3000e+01, 3.1000e+01, 1.8000e+01,\n",
            "        4.0000e+00, 1.1700e+02, 1.7290e+03, 1.0000e+01, 5.7400e+02, 3.2570e+03,\n",
            "        3.0000e+00, 4.7700e+02, 3.3000e+01, 3.1000e+01, 1.8000e+01, 4.0000e+00,\n",
            "        1.1700e+02, 1.7290e+03, 1.0000e+01, 5.7400e+02])\n",
            "['Jargon', 'is', 'specialized', 'language', 'used', 'by', 'a', 'particular', 'profession', 'or', 'group.', 'Jargon', 'is', 'specialized', 'language', 'used', 'by', 'a', 'particular', 'profession', 'or', 'group.']\n",
            "[('Jargon', 'is'), ('is', 'specialized'), ('specialized', 'language'), ('language', 'used'), ('used', 'by'), ('by', 'a'), ('a', 'particular'), ('particular', 'profession'), ('profession', 'or'), ('or', 'group.'), ('Jargon', 'is'), ('is', 'specialized'), ('specialized', 'language'), ('language', 'used'), ('used', 'by'), ('by', 'a'), ('a', 'particular'), ('particular', 'profession'), ('profession', 'or'), ('or', 'group.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.0990e+03, 3.0000e+00, 2.2060e+03, 3.3000e+01, 3.1000e+01, 1.8000e+01,\n",
            "        4.0000e+00, 1.1700e+02, 2.3070e+03, 2.0000e+00, 1.8310e+03, 3.0990e+03,\n",
            "        3.0000e+00, 2.2060e+03, 3.3000e+01, 3.1000e+01, 1.8000e+01, 4.0000e+00,\n",
            "        1.1700e+02, 2.3070e+03, 2.0000e+00, 1.8310e+03])\n",
            "['Slang', 'is', 'informal', 'language', 'used', 'by', 'a', 'particular', 'group', 'of', 'people.', 'Slang', 'is', 'informal', 'language', 'used', 'by', 'a', 'particular', 'group', 'of', 'people.']\n",
            "[('Slang', 'is'), ('is', 'informal'), ('informal', 'language'), ('language', 'used'), ('used', 'by'), ('by', 'a'), ('a', 'particular'), ('particular', 'group'), ('group', 'of'), ('of', 'people.'), ('Slang', 'is'), ('is', 'informal'), ('informal', 'language'), ('language', 'used'), ('used', 'by'), ('by', 'a'), ('a', 'particular'), ('particular', 'group'), ('group', 'of'), ('of', 'people.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([4.5000e+01, 3.0150e+03, 3.0000e+00, 4.0000e+00, 2.5770e+03, 1.9700e+02,\n",
            "        2.0000e+00, 1.7180e+03, 4.0000e+00, 2.1240e+03, 5.3000e+01, 4.2200e+02,\n",
            "        1.9000e+01, 4.0000e+00, 1.1700e+02, 5.0300e+02, 1.0000e+01, 4.8100e+02,\n",
            "        5.7400e+02, 4.5000e+01, 3.0150e+03, 3.0000e+00, 4.0000e+00, 2.5770e+03,\n",
            "        1.9700e+02, 2.0000e+00, 1.7180e+03, 4.0000e+00, 2.1240e+03, 5.3000e+01,\n",
            "        4.2200e+02, 1.9000e+01, 4.0000e+00, 1.1700e+02, 5.0300e+02, 1.0000e+01,\n",
            "        4.8100e+02, 5.7400e+02])\n",
            "['An', 'accent', 'is', 'a', 'distinctive', 'way', 'of', 'pronouncing', 'a', 'language,', 'often', 'associated', 'with', 'a', 'particular', 'region', 'or', 'social', 'group.', 'An', 'accent', 'is', 'a', 'distinctive', 'way', 'of', 'pronouncing', 'a', 'language,', 'often', 'associated', 'with', 'a', 'particular', 'region', 'or', 'social', 'group.']\n",
            "[('An', 'accent'), ('accent', 'is'), ('is', 'a'), ('a', 'distinctive'), ('distinctive', 'way'), ('way', 'of'), ('of', 'pronouncing'), ('pronouncing', 'a'), ('a', 'language,'), ('language,', 'often'), ('often', 'associated'), ('associated', 'with'), ('with', 'a'), ('a', 'particular'), ('particular', 'region'), ('region', 'or'), ('or', 'social'), ('social', 'group.'), ('An', 'accent'), ('accent', 'is'), ('is', 'a'), ('a', 'distinctive'), ('distinctive', 'way'), ('way', 'of'), ('of', 'pronouncing'), ('pronouncing', 'a'), ('a', 'language,'), ('language,', 'often'), ('often', 'associated'), ('associated', 'with'), ('with', 'a'), ('a', 'particular'), ('particular', 'region'), ('region', 'or'), ('or', 'social'), ('social', 'group.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([  45., 2253.,    3.,    4.,  840.,   10.,  187.,    7.,   54.,    4.,\n",
            "        2397.,  183.,   84.,   24.,   43.,  549.,  130.,   45., 2253.,    3.,\n",
            "           4.,  840.,   10.,  187.,    7.,   54.,    4., 2397.,  183.,   84.,\n",
            "          24.,   43.,  549.,  130.])\n",
            "['An', 'idiom', 'is', 'a', 'phrase', 'or', 'expression', 'that', 'has', 'a', 'figurative', 'meaning', 'different', 'from', 'its', 'literal', 'meaning.', 'An', 'idiom', 'is', 'a', 'phrase', 'or', 'expression', 'that', 'has', 'a', 'figurative', 'meaning', 'different', 'from', 'its', 'literal', 'meaning.']\n",
            "[('An', 'idiom'), ('idiom', 'is'), ('is', 'a'), ('a', 'phrase'), ('phrase', 'or'), ('or', 'expression'), ('expression', 'that'), ('that', 'has'), ('has', 'a'), ('a', 'figurative'), ('figurative', 'meaning'), ('meaning', 'different'), ('different', 'from'), ('from', 'its'), ('its', 'literal'), ('literal', 'meaning.'), ('An', 'idiom'), ('idiom', 'is'), ('is', 'a'), ('a', 'phrase'), ('phrase', 'or'), ('or', 'expression'), ('expression', 'that'), ('that', 'has'), ('has', 'a'), ('a', 'figurative'), ('figurative', 'meaning'), ('meaning', 'different'), ('different', 'from'), ('from', 'its'), ('its', 'literal'), ('literal', 'meaning.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 1.7050e+03, 3.0000e+00, 4.0000e+00, 7.7400e+02, 1.2600e+03,\n",
            "        1.5720e+03, 7.0000e+00, 1.0020e+03, 4.0000e+00, 3.9300e+02, 2.4800e+02,\n",
            "        1.0000e+01, 8.3800e+02, 2.0000e+00, 2.9800e+03, 1.1000e+01, 1.7050e+03,\n",
            "        3.0000e+00, 4.0000e+00, 7.7400e+02, 1.2600e+03, 1.5720e+03, 7.0000e+00,\n",
            "        1.0020e+03, 4.0000e+00, 3.9300e+02, 2.4800e+02, 1.0000e+01, 8.3800e+02,\n",
            "        2.0000e+00, 2.9800e+03])\n",
            "['A', 'proverb', 'is', 'a', 'short,', 'well-known', 'saying', 'that', 'expresses', 'a', 'general', 'truth', 'or', 'piece', 'of', 'advice.', 'A', 'proverb', 'is', 'a', 'short,', 'well-known', 'saying', 'that', 'expresses', 'a', 'general', 'truth', 'or', 'piece', 'of', 'advice.']\n",
            "[('A', 'proverb'), ('proverb', 'is'), ('is', 'a'), ('a', 'short,'), ('short,', 'well-known'), ('well-known', 'saying'), ('saying', 'that'), ('that', 'expresses'), ('expresses', 'a'), ('a', 'general'), ('general', 'truth'), ('truth', 'or'), ('or', 'piece'), ('piece', 'of'), ('of', 'advice.'), ('A', 'proverb'), ('proverb', 'is'), ('is', 'a'), ('a', 'short,'), ('short,', 'well-known'), ('well-known', 'saying'), ('saying', 'that'), ('that', 'expresses'), ('expresses', 'a'), ('a', 'general'), ('general', 'truth'), ('truth', 'or'), ('or', 'piece'), ('piece', 'of'), ('of', 'advice.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.1180e+03, 3.0000e+00, 1.0000e+00, 4.2400e+02, 2.0000e+00, 2.5330e+03,\n",
            "        1.0000e+01, 1.8130e+03, 7.5600e+02, 1.0000e+01, 1.2310e+03, 3.1180e+03,\n",
            "        3.0000e+00, 1.0000e+00, 4.2400e+02, 2.0000e+00, 2.5330e+03, 1.0000e+01,\n",
            "        1.8130e+03, 7.5600e+02, 1.0000e+01, 1.2310e+03])\n",
            "['Rhetoric', 'is', 'the', 'art', 'of', 'effective', 'or', 'persuasive', 'speaking', 'or', 'writing.', 'Rhetoric', 'is', 'the', 'art', 'of', 'effective', 'or', 'persuasive', 'speaking', 'or', 'writing.']\n",
            "[('Rhetoric', 'is'), ('is', 'the'), ('the', 'art'), ('art', 'of'), ('of', 'effective'), ('effective', 'or'), ('or', 'persuasive'), ('persuasive', 'speaking'), ('speaking', 'or'), ('or', 'writing.'), ('Rhetoric', 'is'), ('is', 'the'), ('the', 'art'), ('art', 'of'), ('of', 'effective'), ('effective', 'or'), ('or', 'persuasive'), ('persuasive', 'speaking'), ('speaking', 'or'), ('or', 'writing.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([ 11., 890.,   3.,   4., 399.,   2.,  87.,   7.,  49.,  21., 118.,  10.,\n",
            "        431.,  14., 479.,  58.,  66., 243.,  44., 934.,  53.,  12., 466., 403.,\n",
            "         11., 890.,   3.,   4., 399.,   2.,  87.,   7.,  49.,  21., 118.,  10.,\n",
            "        431.,  14., 479.,  58.,  66., 243.,  44., 934.,  53.,  12., 466., 403.])\n",
            "['A', 'metaphor', 'is', 'a', 'figure', 'of', 'speech', 'that', 'describes', 'an', 'object', 'or', 'action', 'as', 'something', 'other', 'than', 'what', 'it', 'is,', 'often', 'for', 'symbolic', 'effect.', 'A', 'metaphor', 'is', 'a', 'figure', 'of', 'speech', 'that', 'describes', 'an', 'object', 'or', 'action', 'as', 'something', 'other', 'than', 'what', 'it', 'is,', 'often', 'for', 'symbolic', 'effect.']\n",
            "[('A', 'metaphor'), ('metaphor', 'is'), ('is', 'a'), ('a', 'figure'), ('figure', 'of'), ('of', 'speech'), ('speech', 'that'), ('that', 'describes'), ('describes', 'an'), ('an', 'object'), ('object', 'or'), ('or', 'action'), ('action', 'as'), ('as', 'something'), ('something', 'other'), ('other', 'than'), ('than', 'what'), ('what', 'it'), ('it', 'is,'), ('is,', 'often'), ('often', 'for'), ('for', 'symbolic'), ('symbolic', 'effect.'), ('A', 'metaphor'), ('metaphor', 'is'), ('is', 'a'), ('a', 'figure'), ('figure', 'of'), ('of', 'speech'), ('speech', 'that'), ('that', 'describes'), ('describes', 'an'), ('an', 'object'), ('object', 'or'), ('or', 'action'), ('action', 'as'), ('as', 'something'), ('something', 'other'), ('other', 'than'), ('than', 'what'), ('what', 'it'), ('it', 'is,'), ('is,', 'often'), ('often', 'for'), ('for', 'symbolic'), ('symbolic', 'effect.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([1.1000e+01, 1.5270e+03, 3.0000e+00, 4.0000e+00, 3.9900e+02, 2.0000e+00,\n",
            "        8.7000e+01, 7.0000e+00, 6.3600e+02, 3.9000e+01, 8.4000e+01, 1.3930e+03,\n",
            "        1.9900e+02, 3.5000e+03, 1.0000e+01, 3.5020e+03, 1.1000e+01, 1.5270e+03,\n",
            "        3.0000e+00, 4.0000e+00, 3.9900e+02, 2.0000e+00, 8.7000e+01, 7.0000e+00,\n",
            "        6.3600e+02, 3.9000e+01, 8.4000e+01, 1.3930e+03, 1.9900e+02, 3.5000e+03,\n",
            "        1.0000e+01, 3.5020e+03])\n",
            "['A', 'simile', 'is', 'a', 'figure', 'of', 'speech', 'that', 'compares', 'two', 'different', 'things', 'using', \"'like'\", 'or', \"'as'.\", 'A', 'simile', 'is', 'a', 'figure', 'of', 'speech', 'that', 'compares', 'two', 'different', 'things', 'using', \"'like'\", 'or', \"'as'.\"]\n",
            "[('A', 'simile'), ('simile', 'is'), ('is', 'a'), ('a', 'figure'), ('figure', 'of'), ('of', 'speech'), ('speech', 'that'), ('that', 'compares'), ('compares', 'two'), ('two', 'different'), ('different', 'things'), ('things', 'using'), ('using', \"'like'\"), (\"'like'\", 'or'), ('or', \"'as'.\"), ('A', 'simile'), ('simile', 'is'), ('is', 'a'), ('a', 'figure'), ('figure', 'of'), ('of', 'speech'), ('speech', 'that'), ('that', 'compares'), ('compares', 'two'), ('two', 'different'), ('different', 'things'), ('things', 'using'), ('using', \"'like'\"), (\"'like'\", 'or'), ('or', \"'as'.\")]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3.1660e+03, 3.0000e+00, 1.0000e+00, 2.9040e+03, 2.0000e+00, 7.0000e+01,\n",
            "        2.7870e+03, 6.0000e+00, 1.9360e+03, 1.0220e+03, 3.1660e+03, 3.0000e+00,\n",
            "        1.0000e+00, 2.9040e+03, 2.0000e+00, 7.0000e+01, 2.7870e+03, 6.0000e+00,\n",
            "        1.9360e+03, 1.0220e+03])\n",
            "['Personification', 'is', 'the', 'attribution', 'of', 'human', 'characteristics', 'to', 'non-human', 'entities.', 'Personification', 'is', 'the', 'attribution', 'of', 'human', 'characteristics', 'to', 'non-human', 'entities.']\n",
            "[('Personification', 'is'), ('is', 'the'), ('the', 'attribution'), ('attribution', 'of'), ('of', 'human'), ('human', 'characteristics'), ('characteristics', 'to'), ('to', 'non-human'), ('non-human', 'entities.'), ('Personification', 'is'), ('is', 'the'), ('the', 'attribution'), ('attribution', 'of'), ('of', 'human'), ('human', 'characteristics'), ('characteristics', 'to'), ('to', 'non-human'), ('non-human', 'entities.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([3.2760e+03, 3.0000e+00, 2.1000e+01, 2.4660e+03, 1.3800e+02, 6.7000e+01,\n",
            "        2.0290e+03, 6.0000e+00, 2.5000e+01, 7.3900e+02, 2.0860e+03, 3.2760e+03,\n",
            "        3.0000e+00, 2.1000e+01, 2.4660e+03, 1.3800e+02, 6.7000e+01, 2.0290e+03,\n",
            "        6.0000e+00, 2.5000e+01, 7.3900e+02, 2.0860e+03])\n",
            "['Hyperbole', 'is', 'an', 'exaggerated', 'statement', 'not', 'meant', 'to', 'be', 'taken', 'literally.', 'Hyperbole', 'is', 'an', 'exaggerated', 'statement', 'not', 'meant', 'to', 'be', 'taken', 'literally.']\n",
            "[('Hyperbole', 'is'), ('is', 'an'), ('an', 'exaggerated'), ('exaggerated', 'statement'), ('statement', 'not'), ('not', 'meant'), ('meant', 'to'), ('to', 'be'), ('be', 'taken'), ('taken', 'literally.'), ('Hyperbole', 'is'), ('is', 'an'), ('an', 'exaggerated'), ('exaggerated', 'statement'), ('statement', 'not'), ('not', 'meant'), ('meant', 'to'), ('to', 'be'), ('be', 'taken'), ('taken', 'literally.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.4500e+03, 3.0000e+00, 1.0000e+00, 4.9900e+02, 2.0000e+00, 1.0000e+00,\n",
            "        1.7300e+02, 5.5900e+02, 1.0770e+03, 2.1000e+02, 8.0000e+00, 4.0000e+00,\n",
            "        1.7200e+02, 2.0000e+00, 1.3600e+02, 3.4500e+03, 3.0000e+00, 1.0000e+00,\n",
            "        4.9900e+02, 2.0000e+00, 1.0000e+00, 1.7300e+02, 5.5900e+02, 1.0770e+03,\n",
            "        2.1000e+02, 8.0000e+00, 4.0000e+00, 1.7200e+02, 2.0000e+00, 1.3600e+02])\n",
            "['Alliteration', 'is', 'the', 'repetition', 'of', 'the', 'same', 'initial', 'consonant', 'sounds', 'in', 'a', 'sequence', 'of', 'words.', 'Alliteration', 'is', 'the', 'repetition', 'of', 'the', 'same', 'initial', 'consonant', 'sounds', 'in', 'a', 'sequence', 'of', 'words.']\n",
            "[('Alliteration', 'is'), ('is', 'the'), ('the', 'repetition'), ('repetition', 'of'), ('of', 'the'), ('the', 'same'), ('same', 'initial'), ('initial', 'consonant'), ('consonant', 'sounds'), ('sounds', 'in'), ('in', 'a'), ('a', 'sequence'), ('sequence', 'of'), ('of', 'words.'), ('Alliteration', 'is'), ('is', 'the'), ('the', 'repetition'), ('repetition', 'of'), ('of', 'the'), ('the', 'same'), ('same', 'initial'), ('initial', 'consonant'), ('consonant', 'sounds'), ('sounds', 'in'), ('in', 'a'), ('a', 'sequence'), ('sequence', 'of'), ('of', 'words.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3.4330e+03, 3.0000e+00, 1.0000e+00, 4.9900e+02, 2.0000e+00, 1.2750e+03,\n",
            "        2.1000e+02, 8.0000e+00, 1.9570e+03, 1.3600e+02, 3.4330e+03, 3.0000e+00,\n",
            "        1.0000e+00, 4.9900e+02, 2.0000e+00, 1.2750e+03, 2.1000e+02, 8.0000e+00,\n",
            "        1.9570e+03, 1.3600e+02])\n",
            "['Assonance', 'is', 'the', 'repetition', 'of', 'vowel', 'sounds', 'in', 'nearby', 'words.', 'Assonance', 'is', 'the', 'repetition', 'of', 'vowel', 'sounds', 'in', 'nearby', 'words.']\n",
            "[('Assonance', 'is'), ('is', 'the'), ('the', 'repetition'), ('repetition', 'of'), ('of', 'vowel'), ('vowel', 'sounds'), ('sounds', 'in'), ('in', 'nearby'), ('nearby', 'words.'), ('Assonance', 'is'), ('is', 'the'), ('the', 'repetition'), ('repetition', 'of'), ('of', 'vowel'), ('vowel', 'sounds'), ('sounds', 'in'), ('in', 'nearby'), ('nearby', 'words.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.3860e+03, 3.0000e+00, 1.0000e+00, 4.9900e+02, 2.0000e+00, 1.0770e+03,\n",
            "        1.5090e+03, 3.2400e+02, 7.1000e+01, 1.0000e+00, 2.5030e+03, 2.0000e+00,\n",
            "        1.3600e+02, 3.3860e+03, 3.0000e+00, 1.0000e+00, 4.9900e+02, 2.0000e+00,\n",
            "        1.0770e+03, 1.5090e+03, 3.2400e+02, 7.1000e+01, 1.0000e+00, 2.5030e+03,\n",
            "        2.0000e+00, 1.3600e+02])\n",
            "['Consonance', 'is', 'the', 'repetition', 'of', 'consonant', 'sounds,', 'typically', 'at', 'the', 'end', 'of', 'words.', 'Consonance', 'is', 'the', 'repetition', 'of', 'consonant', 'sounds,', 'typically', 'at', 'the', 'end', 'of', 'words.']\n",
            "[('Consonance', 'is'), ('is', 'the'), ('the', 'repetition'), ('repetition', 'of'), ('of', 'consonant'), ('consonant', 'sounds,'), ('sounds,', 'typically'), ('typically', 'at'), ('at', 'the'), ('the', 'end'), ('end', 'of'), ('of', 'words.'), ('Consonance', 'is'), ('is', 'the'), ('the', 'repetition'), ('repetition', 'of'), ('of', 'consonant'), ('consonant', 'sounds,'), ('sounds,', 'typically'), ('typically', 'at'), ('at', 'the'), ('the', 'end'), ('end', 'of'), ('of', 'words.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([3.1810e+03, 3.0000e+00, 1.0000e+00, 9.8700e+02, 2.0000e+00, 4.0000e+00,\n",
            "        9.8000e+01, 2.4000e+01, 4.0000e+00, 1.7100e+02, 4.2200e+02, 1.9000e+01,\n",
            "        2.4300e+02, 3.0000e+00, 1.9610e+03, 3.1810e+03, 3.0000e+00, 1.0000e+00,\n",
            "        9.8700e+02, 2.0000e+00, 4.0000e+00, 9.8000e+01, 2.4000e+01, 4.0000e+00,\n",
            "        1.7100e+02, 4.2200e+02, 1.9000e+01, 2.4300e+02, 3.0000e+00, 1.9610e+03])\n",
            "['Onomatopoeia', 'is', 'the', 'formation', 'of', 'a', 'word', 'from', 'a', 'sound', 'associated', 'with', 'what', 'is', 'named.', 'Onomatopoeia', 'is', 'the', 'formation', 'of', 'a', 'word', 'from', 'a', 'sound', 'associated', 'with', 'what', 'is', 'named.']\n",
            "[('Onomatopoeia', 'is'), ('is', 'the'), ('the', 'formation'), ('formation', 'of'), ('of', 'a'), ('a', 'word'), ('word', 'from'), ('from', 'a'), ('a', 'sound'), ('sound', 'associated'), ('associated', 'with'), ('with', 'what'), ('what', 'is'), ('is', 'named.'), ('Onomatopoeia', 'is'), ('is', 'the'), ('the', 'formation'), ('formation', 'of'), ('of', 'a'), ('a', 'word'), ('word', 'from'), ('from', 'a'), ('a', 'sound'), ('sound', 'associated'), ('associated', 'with'), ('with', 'what'), ('what', 'is'), ('is', 'named.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([1.1700e+03, 3.0000e+00, 1.0000e+00, 1.1300e+03, 2.0000e+00, 1.1400e+02,\n",
            "        5.0000e+00, 8.3900e+02, 6.0000e+00, 2.3500e+02, 1.2610e+03, 2.5400e+02,\n",
            "        1.1700e+03, 3.0000e+00, 1.0000e+00, 1.1300e+03, 2.0000e+00, 1.1400e+02,\n",
            "        5.0000e+00, 8.3900e+02, 6.0000e+00, 2.3500e+02, 1.2610e+03, 2.5400e+02])\n",
            "['Syntax', 'is', 'the', 'arrangement', 'of', 'words', 'and', 'phrases', 'to', 'create', 'well-formed', 'sentences.', 'Syntax', 'is', 'the', 'arrangement', 'of', 'words', 'and', 'phrases', 'to', 'create', 'well-formed', 'sentences.']\n",
            "[('Syntax', 'is'), ('is', 'the'), ('the', 'arrangement'), ('arrangement', 'of'), ('of', 'words'), ('words', 'and'), ('and', 'phrases'), ('phrases', 'to'), ('to', 'create'), ('create', 'well-formed'), ('well-formed', 'sentences.'), ('Syntax', 'is'), ('is', 'the'), ('the', 'arrangement'), ('arrangement', 'of'), ('of', 'words'), ('words', 'and'), ('and', 'phrases'), ('phrases', 'to'), ('to', 'create'), ('create', 'well-formed'), ('well-formed', 'sentences.')]\n",
            "14\n",
            "12\n",
            "91\n",
            "26\n",
            "tensor([3.2410e+03, 3.0000e+00, 1.0000e+00, 3.5500e+02, 2.0000e+00, 2.7360e+03,\n",
            "        2.6010e+03, 3.2410e+03, 3.0000e+00, 1.0000e+00, 3.5500e+02, 2.0000e+00,\n",
            "        2.7360e+03, 2.6010e+03])\n",
            "['Lexicography', 'is', 'the', 'practice', 'of', 'compiling', 'dictionaries.', 'Lexicography', 'is', 'the', 'practice', 'of', 'compiling', 'dictionaries.']\n",
            "[('Lexicography', 'is'), ('is', 'the'), ('the', 'practice'), ('practice', 'of'), ('of', 'compiling'), ('compiling', 'dictionaries.'), ('Lexicography', 'is'), ('is', 'the'), ('the', 'practice'), ('practice', 'of'), ('of', 'compiling'), ('compiling', 'dictionaries.')]\n",
            "16\n",
            "14\n",
            "120\n",
            "30\n",
            "tensor([  11., 2094.,    3.,    4.,  846.,   86.,   36., 2093.,   11., 2094.,\n",
            "           3.,    4.,  846.,   86.,   36., 2093.])\n",
            "['A', 'linguist', 'is', 'a', 'person', 'who', 'studies', 'linguistics.', 'A', 'linguist', 'is', 'a', 'person', 'who', 'studies', 'linguistics.']\n",
            "[('A', 'linguist'), ('linguist', 'is'), ('is', 'a'), ('a', 'person'), ('person', 'who'), ('who', 'studies'), ('studies', 'linguistics.'), ('A', 'linguist'), ('linguist', 'is'), ('is', 'a'), ('a', 'person'), ('person', 'who'), ('who', 'studies'), ('studies', 'linguistics.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([ 241., 2916.,  224., 1671., 1232.,  478.,    5., 2088., 1521.,  241.,\n",
            "        2916.,  224., 1671., 1232.,  478.,    5., 2088., 1521.])\n",
            "['Language', 'arts', 'include', 'reading,', 'writing,', 'speaking,', 'and', 'listening', 'skills.', 'Language', 'arts', 'include', 'reading,', 'writing,', 'speaking,', 'and', 'listening', 'skills.']\n",
            "[('Language', 'arts'), ('arts', 'include'), ('include', 'reading,'), ('reading,', 'writing,'), ('writing,', 'speaking,'), ('speaking,', 'and'), ('and', 'listening'), ('listening', 'skills.'), ('Language', 'arts'), ('arts', 'include'), ('include', 'reading,'), ('reading,', 'writing,'), ('writing,', 'speaking,'), ('speaking,', 'and'), ('and', 'listening'), ('listening', 'skills.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([3.3790e+03, 4.4000e+02, 1.0800e+02, 1.0000e+00, 1.8700e+02, 2.0000e+00,\n",
            "        3.8700e+02, 5.0000e+00, 2.5120e+03, 5.2000e+01, 2.2470e+03, 1.4700e+03,\n",
            "        3.3790e+03, 4.4000e+02, 1.0800e+02, 1.0000e+00, 1.8700e+02, 2.0000e+00,\n",
            "        3.8700e+02, 5.0000e+00, 2.5120e+03, 5.2000e+01, 2.2470e+03, 1.4700e+03])\n",
            "['Creative', 'writing', 'involves', 'the', 'expression', 'of', 'ideas', 'and', 'emotions', 'through', 'imaginative', 'storytelling.', 'Creative', 'writing', 'involves', 'the', 'expression', 'of', 'ideas', 'and', 'emotions', 'through', 'imaginative', 'storytelling.']\n",
            "[('Creative', 'writing'), ('writing', 'involves'), ('involves', 'the'), ('the', 'expression'), ('expression', 'of'), ('of', 'ideas'), ('ideas', 'and'), ('and', 'emotions'), ('emotions', 'through'), ('through', 'imaginative'), ('imaginative', 'storytelling.'), ('Creative', 'writing'), ('writing', 'involves'), ('involves', 'the'), ('the', 'expression'), ('expression', 'of'), ('of', 'ideas'), ('ideas', 'and'), ('and', 'emotions'), ('emotions', 'through'), ('through', 'imaginative'), ('imaginative', 'storytelling.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3.2330e+03, 3.0400e+02, 3.0000e+00, 1.0000e+00, 6.0300e+02, 5.0000e+00,\n",
            "        5.5700e+02, 2.0000e+00, 5.4800e+02, 1.4030e+03, 3.2330e+03, 3.0400e+02,\n",
            "        3.0000e+00, 1.0000e+00, 6.0300e+02, 5.0000e+00, 5.5700e+02, 2.0000e+00,\n",
            "        5.4800e+02, 1.4030e+03])\n",
            "['Literary', 'analysis', 'is', 'the', 'examination', 'and', 'interpretation', 'of', 'literary', 'texts.', 'Literary', 'analysis', 'is', 'the', 'examination', 'and', 'interpretation', 'of', 'literary', 'texts.']\n",
            "[('Literary', 'analysis'), ('analysis', 'is'), ('is', 'the'), ('the', 'examination'), ('examination', 'and'), ('and', 'interpretation'), ('interpretation', 'of'), ('of', 'literary'), ('literary', 'texts.'), ('Literary', 'analysis'), ('analysis', 'is'), ('is', 'the'), ('the', 'examination'), ('examination', 'and'), ('and', 'interpretation'), ('interpretation', 'of'), ('of', 'literary'), ('literary', 'texts.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([3.1520e+03, 3.0000e+00, 4.0000e+00, 9.4000e+01, 2.0000e+00, 5.4700e+02,\n",
            "        7.0000e+00, 1.2600e+02, 2.9770e+03, 5.0000e+00, 1.5910e+03, 8.0400e+02,\n",
            "        2.0000e+00, 3.3000e+01, 6.0000e+00, 2.4700e+03, 2.7200e+02, 3.1520e+03,\n",
            "        3.0000e+00, 4.0000e+00, 9.4000e+01, 2.0000e+00, 5.4700e+02, 7.0000e+00,\n",
            "        1.2600e+02, 2.9770e+03, 5.0000e+00, 1.5910e+03, 8.0400e+02, 2.0000e+00,\n",
            "        3.3000e+01, 6.0000e+00, 2.4700e+03, 2.7200e+02])\n",
            "['Poetry', 'is', 'a', 'form', 'of', 'literature', 'that', 'uses', 'aesthetic', 'and', 'rhythmic', 'qualities', 'of', 'language', 'to', 'evoke', 'meanings.', 'Poetry', 'is', 'a', 'form', 'of', 'literature', 'that', 'uses', 'aesthetic', 'and', 'rhythmic', 'qualities', 'of', 'language', 'to', 'evoke', 'meanings.']\n",
            "[('Poetry', 'is'), ('is', 'a'), ('a', 'form'), ('form', 'of'), ('of', 'literature'), ('literature', 'that'), ('that', 'uses'), ('uses', 'aesthetic'), ('aesthetic', 'and'), ('and', 'rhythmic'), ('rhythmic', 'qualities'), ('qualities', 'of'), ('of', 'language'), ('language', 'to'), ('to', 'evoke'), ('evoke', 'meanings.'), ('Poetry', 'is'), ('is', 'a'), ('a', 'form'), ('form', 'of'), ('of', 'literature'), ('literature', 'that'), ('that', 'uses'), ('uses', 'aesthetic'), ('aesthetic', 'and'), ('and', 'rhythmic'), ('rhythmic', 'qualities'), ('qualities', 'of'), ('of', 'language'), ('language', 'to'), ('to', 'evoke'), ('evoke', 'meanings.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.3520e+03, 3.0000e+00, 4.0000e+00, 5.8100e+02, 2.0000e+00, 5.4700e+02,\n",
            "        9.4000e+02, 1.2000e+01, 5.2100e+02, 1.8000e+01, 2.9970e+03, 2.3000e+01,\n",
            "        4.0000e+00, 7.5300e+02, 3.3520e+03, 3.0000e+00, 4.0000e+00, 5.8100e+02,\n",
            "        2.0000e+00, 5.4700e+02, 9.4000e+02, 1.2000e+01, 5.2100e+02, 1.8000e+01,\n",
            "        2.9970e+03, 2.3000e+01, 4.0000e+00, 7.5300e+02])\n",
            "['Drama', 'is', 'a', 'genre', 'of', 'literature', 'intended', 'for', 'performance', 'by', 'actors', 'on', 'a', 'stage.', 'Drama', 'is', 'a', 'genre', 'of', 'literature', 'intended', 'for', 'performance', 'by', 'actors', 'on', 'a', 'stage.']\n",
            "[('Drama', 'is'), ('is', 'a'), ('a', 'genre'), ('genre', 'of'), ('of', 'literature'), ('literature', 'intended'), ('intended', 'for'), ('for', 'performance'), ('performance', 'by'), ('by', 'actors'), ('actors', 'on'), ('on', 'a'), ('a', 'stage.'), ('Drama', 'is'), ('is', 'a'), ('a', 'genre'), ('genre', 'of'), ('of', 'literature'), ('literature', 'intended'), ('intended', 'for'), ('for', 'performance'), ('performance', 'by'), ('by', 'actors'), ('actors', 'on'), ('on', 'a'), ('a', 'stage.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([3.1410e+03, 3.0000e+00, 1.6100e+02, 1.0000e+01, 2.0900e+02, 3.3000e+01,\n",
            "        8.0000e+00, 4.3000e+01, 1.8890e+03, 2.3680e+03, 1.6300e+02, 2.0100e+03,\n",
            "        7.4800e+02, 3.1410e+03, 3.0000e+00, 1.6100e+02, 1.0000e+01, 2.0900e+02,\n",
            "        3.3000e+01, 8.0000e+00, 4.3000e+01, 1.8890e+03, 2.3680e+03, 1.6300e+02,\n",
            "        2.0100e+03, 7.4800e+02])\n",
            "['Prose', 'is', 'written', 'or', 'spoken', 'language', 'in', 'its', 'ordinary', 'form,', 'without', 'metrical', 'structure.', 'Prose', 'is', 'written', 'or', 'spoken', 'language', 'in', 'its', 'ordinary', 'form,', 'without', 'metrical', 'structure.']\n",
            "[('Prose', 'is'), ('is', 'written'), ('written', 'or'), ('or', 'spoken'), ('spoken', 'language'), ('language', 'in'), ('in', 'its'), ('its', 'ordinary'), ('ordinary', 'form,'), ('form,', 'without'), ('without', 'metrical'), ('metrical', 'structure.'), ('Prose', 'is'), ('is', 'written'), ('written', 'or'), ('or', 'spoken'), ('spoken', 'language'), ('language', 'in'), ('in', 'its'), ('its', 'ordinary'), ('ordinary', 'form,'), ('form,', 'without'), ('without', 'metrical'), ('metrical', 'structure.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([1.1000e+01, 3.7200e+02, 3.0000e+00, 4.0000e+00, 2.0900e+02, 1.0000e+01,\n",
            "        1.6100e+02, 3.0700e+02, 2.0000e+00, 1.0820e+03, 2.4750e+03, 4.0000e+00,\n",
            "        2.0800e+02, 1.1000e+01, 3.7200e+02, 3.0000e+00, 4.0000e+00, 2.0900e+02,\n",
            "        1.0000e+01, 1.6100e+02, 3.0700e+02, 2.0000e+00, 1.0820e+03, 2.4750e+03,\n",
            "        4.0000e+00, 2.0800e+02])\n",
            "['A', 'narrative', 'is', 'a', 'spoken', 'or', 'written', 'account', 'of', 'connected', 'events;', 'a', 'story.', 'A', 'narrative', 'is', 'a', 'spoken', 'or', 'written', 'account', 'of', 'connected', 'events;', 'a', 'story.']\n",
            "[('A', 'narrative'), ('narrative', 'is'), ('is', 'a'), ('a', 'spoken'), ('spoken', 'or'), ('or', 'written'), ('written', 'account'), ('account', 'of'), ('of', 'connected'), ('connected', 'events;'), ('events;', 'a'), ('a', 'story.'), ('A', 'narrative'), ('narrative', 'is'), ('is', 'a'), ('a', 'spoken'), ('spoken', 'or'), ('or', 'written'), ('written', 'account'), ('account', 'of'), ('of', 'connected'), ('connected', 'events;'), ('events;', 'a'), ('a', 'story.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([1.1000e+01, 1.7820e+03, 3.0000e+00, 1.0000e+00, 1.7200e+02, 2.0000e+00,\n",
            "        1.0160e+03, 8.0000e+00, 4.0000e+00, 2.0800e+02, 1.1000e+01, 1.7820e+03,\n",
            "        3.0000e+00, 1.0000e+00, 1.7200e+02, 2.0000e+00, 1.0160e+03, 8.0000e+00,\n",
            "        4.0000e+00, 2.0800e+02])\n",
            "['A', 'plot', 'is', 'the', 'sequence', 'of', 'events', 'in', 'a', 'story.', 'A', 'plot', 'is', 'the', 'sequence', 'of', 'events', 'in', 'a', 'story.']\n",
            "[('A', 'plot'), ('plot', 'is'), ('is', 'the'), ('the', 'sequence'), ('sequence', 'of'), ('of', 'events'), ('events', 'in'), ('in', 'a'), ('a', 'story.'), ('A', 'plot'), ('plot', 'is'), ('is', 'the'), ('the', 'sequence'), ('sequence', 'of'), ('of', 'events'), ('events', 'in'), ('in', 'a'), ('a', 'story.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.4000e+03, 3.0000e+00, 1.0000e+00, 5.7000e+01, 1.8000e+01, 2.2000e+01,\n",
            "        2.1000e+01, 2.9030e+03, 1.5970e+03, 1.0000e+00, 1.8180e+03, 2.0000e+00,\n",
            "        4.0000e+00, 1.0970e+03, 3.4000e+03, 3.0000e+00, 1.0000e+00, 5.7000e+01,\n",
            "        1.8000e+01, 2.2000e+01, 2.1000e+01, 2.9030e+03, 1.5970e+03, 1.0000e+00,\n",
            "        1.8180e+03, 2.0000e+00, 4.0000e+00, 1.0970e+03])\n",
            "['Characterization', 'is', 'the', 'process', 'by', 'which', 'an', 'author', 'reveals', 'the', 'personality', 'of', 'a', 'character.', 'Characterization', 'is', 'the', 'process', 'by', 'which', 'an', 'author', 'reveals', 'the', 'personality', 'of', 'a', 'character.']\n",
            "[('Characterization', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'an'), ('an', 'author'), ('author', 'reveals'), ('reveals', 'the'), ('the', 'personality'), ('personality', 'of'), ('of', 'a'), ('a', 'character.'), ('Characterization', 'is'), ('is', 'the'), ('the', 'process'), ('process', 'by'), ('by', 'which'), ('which', 'an'), ('an', 'author'), ('author', 'reveals'), ('reveals', 'the'), ('the', 'personality'), ('personality', 'of'), ('of', 'a'), ('a', 'character.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([1.1000e+01, 7.2900e+02, 3.0000e+00, 1.0000e+00, 1.0990e+03, 4.5300e+02,\n",
            "        1.0000e+01, 3.8800e+02, 5.9700e+02, 8.0000e+00, 4.0000e+00, 4.6300e+02,\n",
            "        1.1000e+01, 7.2900e+02, 3.0000e+00, 1.0000e+00, 1.0990e+03, 4.5300e+02,\n",
            "        1.0000e+01, 3.8800e+02, 5.9700e+02, 8.0000e+00, 4.0000e+00, 4.6300e+02])\n",
            "['A', 'theme', 'is', 'the', 'central', 'topic', 'or', 'idea', 'explored', 'in', 'a', 'text.', 'A', 'theme', 'is', 'the', 'central', 'topic', 'or', 'idea', 'explored', 'in', 'a', 'text.']\n",
            "[('A', 'theme'), ('theme', 'is'), ('is', 'the'), ('the', 'central'), ('central', 'topic'), ('topic', 'or'), ('or', 'idea'), ('idea', 'explored'), ('explored', 'in'), ('in', 'a'), ('a', 'text.'), ('A', 'theme'), ('theme', 'is'), ('is', 'the'), ('the', 'central'), ('central', 'topic'), ('topic', 'or'), ('or', 'idea'), ('idea', 'explored'), ('explored', 'in'), ('in', 'a'), ('a', 'text.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([  11., 1981.,    3.,    4., 1652.,  289.,    7.,   54.,  466., 1529.,\n",
            "           8.,    4.,  208.,   11., 1981.,    3.,    4., 1652.,  289.,    7.,\n",
            "          54.,  466., 1529.,    8.,    4.,  208.])\n",
            "['A', 'motif', 'is', 'a', 'recurring', 'element', 'that', 'has', 'symbolic', 'significance', 'in', 'a', 'story.', 'A', 'motif', 'is', 'a', 'recurring', 'element', 'that', 'has', 'symbolic', 'significance', 'in', 'a', 'story.']\n",
            "[('A', 'motif'), ('motif', 'is'), ('is', 'a'), ('a', 'recurring'), ('recurring', 'element'), ('element', 'that'), ('that', 'has'), ('has', 'symbolic'), ('symbolic', 'significance'), ('significance', 'in'), ('in', 'a'), ('a', 'story.'), ('A', 'motif'), ('motif', 'is'), ('is', 'a'), ('a', 'recurring'), ('recurring', 'element'), ('element', 'that'), ('that', 'has'), ('has', 'symbolic'), ('symbolic', 'significance'), ('significance', 'in'), ('in', 'a'), ('a', 'story.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([  11.,  251.,    3.,   21., 1916., 2789.,   10.,  604.,    7.,  257.,\n",
            "           4., 1064.,  130.,   11.,  251.,    3.,   21., 1916., 2789.,   10.,\n",
            "         604.,    7.,  257.,    4., 1064.,  130.])\n",
            "['A', 'symbol', 'is', 'an', 'object,', 'character,', 'or', 'event', 'that', 'represents', 'a', 'deeper', 'meaning.', 'A', 'symbol', 'is', 'an', 'object,', 'character,', 'or', 'event', 'that', 'represents', 'a', 'deeper', 'meaning.']\n",
            "[('A', 'symbol'), ('symbol', 'is'), ('is', 'an'), ('an', 'object,'), ('object,', 'character,'), ('character,', 'or'), ('or', 'event'), ('event', 'that'), ('that', 'represents'), ('represents', 'a'), ('a', 'deeper'), ('deeper', 'meaning.'), ('A', 'symbol'), ('symbol', 'is'), ('is', 'an'), ('an', 'object,'), ('object,', 'character,'), ('character,', 'or'), ('or', 'event'), ('event', 'that'), ('that', 'represents'), ('represents', 'a'), ('a', 'deeper'), ('deeper', 'meaning.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([1.1000e+01, 1.7120e+03, 3.0000e+00, 1.0000e+00, 2.0500e+03, 1.5600e+02,\n",
            "        8.0000e+00, 4.0000e+00, 2.0800e+02, 1.1000e+01, 1.7120e+03, 3.0000e+00,\n",
            "        1.0000e+00, 2.0500e+03, 1.5600e+02, 8.0000e+00, 4.0000e+00, 2.0800e+02])\n",
            "['A', 'protagonist', 'is', 'the', 'main', 'character', 'in', 'a', 'story.', 'A', 'protagonist', 'is', 'the', 'main', 'character', 'in', 'a', 'story.']\n",
            "[('A', 'protagonist'), ('protagonist', 'is'), ('is', 'the'), ('the', 'main'), ('main', 'character'), ('character', 'in'), ('in', 'a'), ('a', 'story.'), ('A', 'protagonist'), ('protagonist', 'is'), ('is', 'the'), ('the', 'main'), ('main', 'character'), ('character', 'in'), ('in', 'a'), ('a', 'story.')]\n",
            "18\n",
            "16\n",
            "153\n",
            "34\n",
            "tensor([4.5000e+01, 2.9430e+03, 3.0000e+00, 4.0000e+00, 1.5600e+02, 8.6000e+01,\n",
            "        8.6200e+02, 1.0000e+00, 1.7110e+03, 4.5000e+01, 2.9430e+03, 3.0000e+00,\n",
            "        4.0000e+00, 1.5600e+02, 8.6000e+01, 8.6200e+02, 1.0000e+00, 1.7110e+03])\n",
            "['An', 'antagonist', 'is', 'a', 'character', 'who', 'opposes', 'the', 'protagonist.', 'An', 'antagonist', 'is', 'a', 'character', 'who', 'opposes', 'the', 'protagonist.']\n",
            "[('An', 'antagonist'), ('antagonist', 'is'), ('is', 'a'), ('a', 'character'), ('character', 'who'), ('who', 'opposes'), ('opposes', 'the'), ('the', 'protagonist.'), ('An', 'antagonist'), ('antagonist', 'is'), ('is', 'a'), ('a', 'character'), ('character', 'who'), ('who', 'opposes'), ('opposes', 'the'), ('the', 'protagonist.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([3.3630e+03, 3.0000e+00, 1.0000e+00, 1.6100e+02, 1.0000e+01, 2.0900e+02,\n",
            "        2.6920e+03, 6.0100e+02, 3.5000e+01, 2.7830e+03, 3.3630e+03, 3.0000e+00,\n",
            "        1.0000e+00, 1.6100e+02, 1.0000e+01, 2.0900e+02, 2.6920e+03, 6.0100e+02,\n",
            "        3.5000e+01, 2.7830e+03])\n",
            "['Dialogue', 'is', 'the', 'written', 'or', 'spoken', 'conversational', 'exchange', 'between', 'characters.', 'Dialogue', 'is', 'the', 'written', 'or', 'spoken', 'conversational', 'exchange', 'between', 'characters.']\n",
            "[('Dialogue', 'is'), ('is', 'the'), ('the', 'written'), ('written', 'or'), ('or', 'spoken'), ('spoken', 'conversational'), ('conversational', 'exchange'), ('exchange', 'between'), ('between', 'characters.'), ('Dialogue', 'is'), ('is', 'the'), ('the', 'written'), ('written', 'or'), ('or', 'spoken'), ('spoken', 'conversational'), ('conversational', 'exchange'), ('exchange', 'between'), ('between', 'characters.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([  11., 1986.,    3.,    4.,  545.,   87.,   18.,   37.,  156.,    8.,\n",
            "           4., 1785.,   10.,  208.,   11., 1986.,    3.,    4.,  545.,   87.,\n",
            "          18.,   37.,  156.,    8.,    4., 1785.,   10.,  208.])\n",
            "['A', 'monologue', 'is', 'a', 'long', 'speech', 'by', 'one', 'character', 'in', 'a', 'play', 'or', 'story.', 'A', 'monologue', 'is', 'a', 'long', 'speech', 'by', 'one', 'character', 'in', 'a', 'play', 'or', 'story.']\n",
            "[('A', 'monologue'), ('monologue', 'is'), ('is', 'a'), ('a', 'long'), ('long', 'speech'), ('speech', 'by'), ('by', 'one'), ('one', 'character'), ('character', 'in'), ('in', 'a'), ('a', 'play'), ('play', 'or'), ('or', 'story.'), ('A', 'monologue'), ('monologue', 'is'), ('is', 'a'), ('a', 'long'), ('long', 'speech'), ('speech', 'by'), ('by', 'one'), ('one', 'character'), ('character', 'in'), ('in', 'a'), ('a', 'play'), ('play', 'or'), ('or', 'story.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([  11., 1515.,    3.,    4.,   87.,    8.,   22.,    4.,  156., 1496.,\n",
            "          41.,  722., 2963.,   53.,  196., 2964.,   23.,  753.,   11., 1515.,\n",
            "           3.,    4.,   87.,    8.,   22.,    4.,  156., 1496.,   41.,  722.,\n",
            "        2963.,   53.,  196., 2964.,   23.,  753.])\n",
            "['A', 'soliloquy', 'is', 'a', 'speech', 'in', 'which', 'a', 'character', 'speaks', 'their', 'thoughts', 'aloud,', 'often', 'while', 'alone', 'on', 'stage.', 'A', 'soliloquy', 'is', 'a', 'speech', 'in', 'which', 'a', 'character', 'speaks', 'their', 'thoughts', 'aloud,', 'often', 'while', 'alone', 'on', 'stage.']\n",
            "[('A', 'soliloquy'), ('soliloquy', 'is'), ('is', 'a'), ('a', 'speech'), ('speech', 'in'), ('in', 'which'), ('which', 'a'), ('a', 'character'), ('character', 'speaks'), ('speaks', 'their'), ('their', 'thoughts'), ('thoughts', 'aloud,'), ('aloud,', 'often'), ('often', 'while'), ('while', 'alone'), ('alone', 'on'), ('on', 'stage.'), ('A', 'soliloquy'), ('soliloquy', 'is'), ('is', 'a'), ('a', 'speech'), ('speech', 'in'), ('in', 'which'), ('which', 'a'), ('a', 'character'), ('character', 'speaks'), ('speaks', 'their'), ('their', 'thoughts'), ('thoughts', 'aloud,'), ('aloud,', 'often'), ('often', 'while'), ('while', 'alone'), ('alone', 'on'), ('on', 'stage.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([ 11., 890.,   3.,   4., 399.,   2.,  87.,   7.,  49.,  21., 118.,  10.,\n",
            "        431.,  14., 479.,  58.,  66., 243.,  44., 934.,  53.,  12., 466., 403.,\n",
            "         11., 890.,   3.,   4., 399.,   2.,  87.,   7.,  49.,  21., 118.,  10.,\n",
            "        431.,  14., 479.,  58.,  66., 243.,  44., 934.,  53.,  12., 466., 403.])\n",
            "['A', 'metaphor', 'is', 'a', 'figure', 'of', 'speech', 'that', 'describes', 'an', 'object', 'or', 'action', 'as', 'something', 'other', 'than', 'what', 'it', 'is,', 'often', 'for', 'symbolic', 'effect.', 'A', 'metaphor', 'is', 'a', 'figure', 'of', 'speech', 'that', 'describes', 'an', 'object', 'or', 'action', 'as', 'something', 'other', 'than', 'what', 'it', 'is,', 'often', 'for', 'symbolic', 'effect.']\n",
            "[('A', 'metaphor'), ('metaphor', 'is'), ('is', 'a'), ('a', 'figure'), ('figure', 'of'), ('of', 'speech'), ('speech', 'that'), ('that', 'describes'), ('describes', 'an'), ('an', 'object'), ('object', 'or'), ('or', 'action'), ('action', 'as'), ('as', 'something'), ('something', 'other'), ('other', 'than'), ('than', 'what'), ('what', 'it'), ('it', 'is,'), ('is,', 'often'), ('often', 'for'), ('for', 'symbolic'), ('symbolic', 'effect.'), ('A', 'metaphor'), ('metaphor', 'is'), ('is', 'a'), ('a', 'figure'), ('figure', 'of'), ('of', 'speech'), ('speech', 'that'), ('that', 'describes'), ('describes', 'an'), ('an', 'object'), ('object', 'or'), ('or', 'action'), ('action', 'as'), ('as', 'something'), ('something', 'other'), ('other', 'than'), ('than', 'what'), ('what', 'it'), ('it', 'is,'), ('is,', 'often'), ('often', 'for'), ('for', 'symbolic'), ('symbolic', 'effect.')]\n",
            "42\n",
            "40\n",
            "861\n",
            "82\n",
            "tensor([3.3220e+03, 3.0000e+00, 4.0000e+00, 5.4800e+02, 6.1800e+02, 3.1000e+01,\n",
            "        6.0000e+00, 9.7500e+02, 2.1000e+01, 2.2240e+03, 1.0000e+01, 2.2730e+03,\n",
            "        2.0000e+00, 2.4300e+02, 3.0000e+00, 6.0000e+00, 2.7490e+03, 2.1210e+03,\n",
            "        8.0000e+00, 1.0000e+00, 2.0800e+02, 3.3220e+03, 3.0000e+00, 4.0000e+00,\n",
            "        5.4800e+02, 6.1800e+02, 3.1000e+01, 6.0000e+00, 9.7500e+02, 2.1000e+01,\n",
            "        2.2240e+03, 1.0000e+01, 2.2730e+03, 2.0000e+00, 2.4300e+02, 3.0000e+00,\n",
            "        6.0000e+00, 2.7490e+03, 2.1210e+03, 8.0000e+00, 1.0000e+00, 2.0800e+02])\n",
            "['Foreshadowing', 'is', 'a', 'literary', 'device', 'used', 'to', 'give', 'an', 'indication', 'or', 'hint', 'of', 'what', 'is', 'to', 'come', 'later', 'in', 'the', 'story.', 'Foreshadowing', 'is', 'a', 'literary', 'device', 'used', 'to', 'give', 'an', 'indication', 'or', 'hint', 'of', 'what', 'is', 'to', 'come', 'later', 'in', 'the', 'story.']\n",
            "[('Foreshadowing', 'is'), ('is', 'a'), ('a', 'literary'), ('literary', 'device'), ('device', 'used'), ('used', 'to'), ('to', 'give'), ('give', 'an'), ('an', 'indication'), ('indication', 'or'), ('or', 'hint'), ('hint', 'of'), ('of', 'what'), ('what', 'is'), ('is', 'to'), ('to', 'come'), ('come', 'later'), ('later', 'in'), ('in', 'the'), ('the', 'story.'), ('Foreshadowing', 'is'), ('is', 'a'), ('a', 'literary'), ('literary', 'device'), ('device', 'used'), ('used', 'to'), ('to', 'give'), ('give', 'an'), ('an', 'indication'), ('indication', 'or'), ('or', 'hint'), ('hint', 'of'), ('of', 'what'), ('what', 'is'), ('is', 'to'), ('to', 'come'), ('come', 'later'), ('later', 'in'), ('in', 'the'), ('the', 'story.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.2620e+03, 3.0000e+00, 4.0000e+00, 3.9900e+02, 2.0000e+00, 8.7000e+01,\n",
            "        9.9000e+01, 1.0000e+00, 9.4000e+02, 1.8300e+02, 3.0000e+00, 5.2900e+02,\n",
            "        6.0000e+00, 1.0000e+00, 5.4900e+02, 1.3000e+02, 3.2620e+03, 3.0000e+00,\n",
            "        4.0000e+00, 3.9900e+02, 2.0000e+00, 8.7000e+01, 9.9000e+01, 1.0000e+00,\n",
            "        9.4000e+02, 1.8300e+02, 3.0000e+00, 5.2900e+02, 6.0000e+00, 1.0000e+00,\n",
            "        5.4900e+02, 1.3000e+02])\n",
            "['Irony', 'is', 'a', 'figure', 'of', 'speech', 'where', 'the', 'intended', 'meaning', 'is', 'opposite', 'to', 'the', 'literal', 'meaning.', 'Irony', 'is', 'a', 'figure', 'of', 'speech', 'where', 'the', 'intended', 'meaning', 'is', 'opposite', 'to', 'the', 'literal', 'meaning.']\n",
            "[('Irony', 'is'), ('is', 'a'), ('a', 'figure'), ('figure', 'of'), ('of', 'speech'), ('speech', 'where'), ('where', 'the'), ('the', 'intended'), ('intended', 'meaning'), ('meaning', 'is'), ('is', 'opposite'), ('opposite', 'to'), ('to', 'the'), ('the', 'literal'), ('literal', 'meaning.'), ('Irony', 'is'), ('is', 'a'), ('a', 'figure'), ('figure', 'of'), ('of', 'speech'), ('speech', 'where'), ('where', 'the'), ('the', 'intended'), ('intended', 'meaning'), ('meaning', 'is'), ('is', 'opposite'), ('opposite', 'to'), ('to', 'the'), ('the', 'literal'), ('literal', 'meaning.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([3.1060e+03, 3.0000e+00, 4.0000e+00, 5.8100e+02, 2.0000e+00, 5.4700e+02,\n",
            "        7.0000e+00, 1.2600e+02, 2.2620e+03, 2.1500e+03, 1.0000e+01, 1.5870e+03,\n",
            "        6.0000e+00, 2.6620e+03, 1.0000e+01, 2.4400e+03, 2.3860e+03, 8.0000e+00,\n",
            "        4.8000e+02, 3.1060e+03, 3.0000e+00, 4.0000e+00, 5.8100e+02, 2.0000e+00,\n",
            "        5.4700e+02, 7.0000e+00, 1.2600e+02, 2.2620e+03, 2.1500e+03, 1.0000e+01,\n",
            "        1.5870e+03, 6.0000e+00, 2.6620e+03, 1.0000e+01, 2.4400e+03, 2.3860e+03,\n",
            "        8.0000e+00, 4.8000e+02])\n",
            "['Satire', 'is', 'a', 'genre', 'of', 'literature', 'that', 'uses', 'humor,', 'irony,', 'or', 'ridicule', 'to', 'criticize', 'or', 'expose', 'flaws', 'in', 'society.', 'Satire', 'is', 'a', 'genre', 'of', 'literature', 'that', 'uses', 'humor,', 'irony,', 'or', 'ridicule', 'to', 'criticize', 'or', 'expose', 'flaws', 'in', 'society.']\n",
            "[('Satire', 'is'), ('is', 'a'), ('a', 'genre'), ('genre', 'of'), ('of', 'literature'), ('literature', 'that'), ('that', 'uses'), ('uses', 'humor,'), ('humor,', 'irony,'), ('irony,', 'or'), ('or', 'ridicule'), ('ridicule', 'to'), ('to', 'criticize'), ('criticize', 'or'), ('or', 'expose'), ('expose', 'flaws'), ('flaws', 'in'), ('in', 'society.'), ('Satire', 'is'), ('is', 'a'), ('a', 'genre'), ('genre', 'of'), ('of', 'literature'), ('literature', 'that'), ('that', 'uses'), ('uses', 'humor,'), ('humor,', 'irony,'), ('irony,', 'or'), ('or', 'ridicule'), ('ridicule', 'to'), ('to', 'criticize'), ('criticize', 'or'), ('or', 'expose'), ('expose', 'flaws'), ('flaws', 'in'), ('in', 'society.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([1.1000e+01, 1.8550e+03, 3.0000e+00, 2.1000e+01, 2.2460e+03, 2.0000e+00,\n",
            "        4.0000e+00, 1.1700e+02, 1.2340e+03, 2.9170e+03, 1.0000e+01, 5.8100e+02,\n",
            "        1.9000e+01, 2.6290e+03, 2.4650e+03, 1.2000e+01, 2.7470e+03, 4.0300e+02,\n",
            "        1.1000e+01, 1.8550e+03, 3.0000e+00, 2.1000e+01, 2.2460e+03, 2.0000e+00,\n",
            "        4.0000e+00, 1.1700e+02, 1.2340e+03, 2.9170e+03, 1.0000e+01, 5.8100e+02,\n",
            "        1.9000e+01, 2.6290e+03, 2.4650e+03, 1.2000e+01, 2.7470e+03, 4.0300e+02])\n",
            "['A', 'parody', 'is', 'an', 'imitation', 'of', 'a', 'particular', 'writer,', 'artist,', 'or', 'genre', 'with', 'deliberate', 'exaggeration', 'for', 'comic', 'effect.', 'A', 'parody', 'is', 'an', 'imitation', 'of', 'a', 'particular', 'writer,', 'artist,', 'or', 'genre', 'with', 'deliberate', 'exaggeration', 'for', 'comic', 'effect.']\n",
            "[('A', 'parody'), ('parody', 'is'), ('is', 'an'), ('an', 'imitation'), ('imitation', 'of'), ('of', 'a'), ('a', 'particular'), ('particular', 'writer,'), ('writer,', 'artist,'), ('artist,', 'or'), ('or', 'genre'), ('genre', 'with'), ('with', 'deliberate'), ('deliberate', 'exaggeration'), ('exaggeration', 'for'), ('for', 'comic'), ('comic', 'effect.'), ('A', 'parody'), ('parody', 'is'), ('is', 'an'), ('an', 'imitation'), ('imitation', 'of'), ('of', 'a'), ('a', 'particular'), ('particular', 'writer,'), ('writer,', 'artist,'), ('artist,', 'or'), ('or', 'genre'), ('genre', 'with'), ('with', 'deliberate'), ('deliberate', 'exaggeration'), ('exaggeration', 'for'), ('for', 'comic'), ('comic', 'effect.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([  45., 2968.,    3.,    4.,  170.,    8.,   22.,  411.,    5., 1016.,\n",
            "         258., 1152.,  387.,   10.,  103., 1696.,   45., 2968.,    3.,    4.,\n",
            "         170.,    8.,   22.,  411.,    5., 1016.,  258., 1152.,  387.,   10.,\n",
            "         103., 1696.])\n",
            "['An', 'allegory', 'is', 'a', 'story', 'in', 'which', 'characters', 'and', 'events', 'represent', 'abstract', 'ideas', 'or', 'moral', 'qualities.', 'An', 'allegory', 'is', 'a', 'story', 'in', 'which', 'characters', 'and', 'events', 'represent', 'abstract', 'ideas', 'or', 'moral', 'qualities.']\n",
            "[('An', 'allegory'), ('allegory', 'is'), ('is', 'a'), ('a', 'story'), ('story', 'in'), ('in', 'which'), ('which', 'characters'), ('characters', 'and'), ('and', 'events'), ('events', 'represent'), ('represent', 'abstract'), ('abstract', 'ideas'), ('ideas', 'or'), ('or', 'moral'), ('moral', 'qualities.'), ('An', 'allegory'), ('allegory', 'is'), ('is', 'a'), ('a', 'story'), ('story', 'in'), ('in', 'which'), ('which', 'characters'), ('characters', 'and'), ('and', 'events'), ('events', 'represent'), ('represent', 'abstract'), ('abstract', 'ideas'), ('ideas', 'or'), ('or', 'moral'), ('moral', 'qualities.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([  11., 2434.,    3.,    4.,  344.,  170.,    7.,  324., 2408., 2946.,\n",
            "           5., 2690.,    4.,  103.,  916.,   11., 2434.,    3.,    4.,  344.,\n",
            "         170.,    7.,  324., 2408., 2946.,    5., 2690.,    4.,  103.,  916.])\n",
            "['A', 'fable', 'is', 'a', 'short', 'story', 'that', 'typically', 'features', 'animals', 'and', 'conveys', 'a', 'moral', 'lesson.', 'A', 'fable', 'is', 'a', 'short', 'story', 'that', 'typically', 'features', 'animals', 'and', 'conveys', 'a', 'moral', 'lesson.']\n",
            "[('A', 'fable'), ('fable', 'is'), ('is', 'a'), ('a', 'short'), ('short', 'story'), ('story', 'that'), ('that', 'typically'), ('typically', 'features'), ('features', 'animals'), ('animals', 'and'), ('and', 'conveys'), ('conveys', 'a'), ('a', 'moral'), ('moral', 'lesson.'), ('A', 'fable'), ('fable', 'is'), ('is', 'a'), ('a', 'short'), ('short', 'story'), ('story', 'that'), ('that', 'typically'), ('typically', 'features'), ('features', 'animals'), ('animals', 'and'), ('and', 'conveys'), ('conveys', 'a'), ('a', 'moral'), ('moral', 'lesson.')]\n",
            "48\n",
            "46\n",
            "1128\n",
            "94\n",
            "tensor([1.1000e+01, 1.9640e+03, 3.0000e+00, 4.0000e+00, 1.6600e+02, 1.7000e+02,\n",
            "        7.0000e+00, 1.0030e+03, 1.0000e+00, 6.1200e+02, 5.6900e+02, 2.0000e+00,\n",
            "        4.0000e+00, 8.4800e+02, 1.0000e+01, 4.0000e+00, 1.8100e+02, 1.8100e+03,\n",
            "        5.3000e+01, 5.5600e+02, 2.3210e+03, 1.0000e+01, 1.4490e+03, 1.1180e+03,\n",
            "        1.1000e+01, 1.9640e+03, 3.0000e+00, 4.0000e+00, 1.6600e+02, 1.7000e+02,\n",
            "        7.0000e+00, 1.0030e+03, 1.0000e+00, 6.1200e+02, 5.6900e+02, 2.0000e+00,\n",
            "        4.0000e+00, 8.4800e+02, 1.0000e+01, 4.0000e+00, 1.8100e+02, 1.8100e+03,\n",
            "        5.3000e+01, 5.5600e+02, 2.3210e+03, 1.0000e+01, 1.4490e+03, 1.1180e+03])\n",
            "['A', 'myth', 'is', 'a', 'traditional', 'story', 'that', 'explains', 'the', 'early', 'history', 'of', 'a', 'people', 'or', 'a', 'natural', 'phenomenon,', 'often', 'involving', 'gods', 'or', 'supernatural', 'beings.', 'A', 'myth', 'is', 'a', 'traditional', 'story', 'that', 'explains', 'the', 'early', 'history', 'of', 'a', 'people', 'or', 'a', 'natural', 'phenomenon,', 'often', 'involving', 'gods', 'or', 'supernatural', 'beings.']\n",
            "[('A', 'myth'), ('myth', 'is'), ('is', 'a'), ('a', 'traditional'), ('traditional', 'story'), ('story', 'that'), ('that', 'explains'), ('explains', 'the'), ('the', 'early'), ('early', 'history'), ('history', 'of'), ('of', 'a'), ('a', 'people'), ('people', 'or'), ('or', 'a'), ('a', 'natural'), ('natural', 'phenomenon,'), ('phenomenon,', 'often'), ('often', 'involving'), ('involving', 'gods'), ('gods', 'or'), ('or', 'supernatural'), ('supernatural', 'beings.'), ('A', 'myth'), ('myth', 'is'), ('is', 'a'), ('a', 'traditional'), ('traditional', 'story'), ('story', 'that'), ('that', 'explains'), ('explains', 'the'), ('the', 'early'), ('early', 'history'), ('history', 'of'), ('of', 'a'), ('a', 'people'), ('people', 'or'), ('or', 'a'), ('a', 'natural'), ('natural', 'phenomenon,'), ('phenomenon,', 'often'), ('often', 'involving'), ('involving', 'gods'), ('gods', 'or'), ('or', 'supernatural'), ('supernatural', 'beings.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([  11.,  917.,    3.,    4.,  166.,  170.,  340., 1774.,  504.,   14.,\n",
            "         282.,   38., 1334.,   11.,  917.,    3.,    4.,  166.,  170.,  340.,\n",
            "        1774.,  504.,   14.,  282.,   38., 1334.])\n",
            "['A', 'legend', 'is', 'a', 'traditional', 'story', 'sometimes', 'popularly', 'regarded', 'as', 'historical', 'but', 'unauthenticated.', 'A', 'legend', 'is', 'a', 'traditional', 'story', 'sometimes', 'popularly', 'regarded', 'as', 'historical', 'but', 'unauthenticated.']\n",
            "[('A', 'legend'), ('legend', 'is'), ('is', 'a'), ('a', 'traditional'), ('traditional', 'story'), ('story', 'sometimes'), ('sometimes', 'popularly'), ('popularly', 'regarded'), ('regarded', 'as'), ('as', 'historical'), ('historical', 'but'), ('but', 'unauthenticated.'), ('A', 'legend'), ('legend', 'is'), ('is', 'a'), ('a', 'traditional'), ('traditional', 'story'), ('story', 'sometimes'), ('sometimes', 'popularly'), ('popularly', 'regarded'), ('regarded', 'as'), ('as', 'historical'), ('historical', 'but'), ('but', 'unauthenticated.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([3.3230e+03, 3.0000e+00, 1.0000e+00, 1.6600e+02, 2.8720e+03, 2.6510e+03,\n",
            "        1.4710e+03, 5.0000e+00, 5.1500e+02, 2.0000e+00, 4.0000e+00, 2.7400e+03,\n",
            "        1.8460e+03, 5.2000e+01, 5.8200e+02, 1.8000e+01, 9.8000e+01, 2.0000e+00,\n",
            "        1.9780e+03, 3.3230e+03, 3.0000e+00, 1.0000e+00, 1.6600e+02, 2.8720e+03,\n",
            "        2.6510e+03, 1.4710e+03, 5.0000e+00, 5.1500e+02, 2.0000e+00, 4.0000e+00,\n",
            "        2.7400e+03, 1.8460e+03, 5.2000e+01, 5.8200e+02, 1.8000e+01, 9.8000e+01,\n",
            "        2.0000e+00, 1.9780e+03])\n",
            "['Folklore', 'is', 'the', 'traditional', 'beliefs,', 'customs,', 'stories,', 'and', 'practices', 'of', 'a', 'community,', 'passed', 'through', 'generations', 'by', 'word', 'of', 'mouth.', 'Folklore', 'is', 'the', 'traditional', 'beliefs,', 'customs,', 'stories,', 'and', 'practices', 'of', 'a', 'community,', 'passed', 'through', 'generations', 'by', 'word', 'of', 'mouth.']\n",
            "[('Folklore', 'is'), ('is', 'the'), ('the', 'traditional'), ('traditional', 'beliefs,'), ('beliefs,', 'customs,'), ('customs,', 'stories,'), ('stories,', 'and'), ('and', 'practices'), ('practices', 'of'), ('of', 'a'), ('a', 'community,'), ('community,', 'passed'), ('passed', 'through'), ('through', 'generations'), ('generations', 'by'), ('by', 'word'), ('word', 'of'), ('of', 'mouth.'), ('Folklore', 'is'), ('is', 'the'), ('the', 'traditional'), ('traditional', 'beliefs,'), ('beliefs,', 'customs,'), ('customs,', 'stories,'), ('stories,', 'and'), ('and', 'practices'), ('practices', 'of'), ('of', 'a'), ('a', 'community,'), ('community,', 'passed'), ('passed', 'through'), ('through', 'generations'), ('generations', 'by'), ('by', 'word'), ('word', 'of'), ('of', 'mouth.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([  11., 2424., 1423.,    3.,    4.,  170., 2406., 2417.,  411.,    5.,\n",
            "        2053., 1015.,   53.,   19.,    4.,  103.,  916.,   11., 2424., 1423.,\n",
            "           3.,    4.,  170., 2406., 2417.,  411.,    5., 2053., 1015.,   53.,\n",
            "          19.,    4.,  103.,  916.])\n",
            "['A', 'fairy', 'tale', 'is', 'a', 'story', 'featuring', 'fantastical', 'characters', 'and', 'magical', 'events,', 'often', 'with', 'a', 'moral', 'lesson.', 'A', 'fairy', 'tale', 'is', 'a', 'story', 'featuring', 'fantastical', 'characters', 'and', 'magical', 'events,', 'often', 'with', 'a', 'moral', 'lesson.']\n",
            "[('A', 'fairy'), ('fairy', 'tale'), ('tale', 'is'), ('is', 'a'), ('a', 'story'), ('story', 'featuring'), ('featuring', 'fantastical'), ('fantastical', 'characters'), ('characters', 'and'), ('and', 'magical'), ('magical', 'events,'), ('events,', 'often'), ('often', 'with'), ('with', 'a'), ('a', 'moral'), ('moral', 'lesson.'), ('A', 'fairy'), ('fairy', 'tale'), ('tale', 'is'), ('is', 'a'), ('a', 'story'), ('story', 'featuring'), ('featuring', 'fantastical'), ('fantastical', 'characters'), ('characters', 'and'), ('and', 'magical'), ('magical', 'events,'), ('events,', 'often'), ('often', 'with'), ('with', 'a'), ('a', 'moral'), ('moral', 'lesson.')]\n",
            "38\n",
            "36\n",
            "703\n",
            "74\n",
            "tensor([4.5000e+01, 2.4920e+03, 3.0000e+00, 4.0000e+00, 5.4500e+02, 3.7200e+02,\n",
            "        1.7810e+03, 2.6120e+03, 1.0000e+00, 9.5900e+02, 2.6340e+03, 5.0000e+00,\n",
            "        2.9810e+03, 2.0000e+00, 4.0000e+00, 2.1130e+03, 1.0000e+01, 2.8200e+02,\n",
            "        2.3960e+03, 4.5000e+01, 2.4920e+03, 3.0000e+00, 4.0000e+00, 5.4500e+02,\n",
            "        3.7200e+02, 1.7810e+03, 2.6120e+03, 1.0000e+00, 9.5900e+02, 2.6340e+03,\n",
            "        5.0000e+00, 2.9810e+03, 2.0000e+00, 4.0000e+00, 2.1130e+03, 1.0000e+01,\n",
            "        2.8200e+02, 2.3960e+03])\n",
            "['An', 'epic', 'is', 'a', 'long', 'narrative', 'poem', 'detailing', 'the', 'heroic', 'deeds', 'and', 'adventures', 'of', 'a', 'legendary', 'or', 'historical', 'figure.', 'An', 'epic', 'is', 'a', 'long', 'narrative', 'poem', 'detailing', 'the', 'heroic', 'deeds', 'and', 'adventures', 'of', 'a', 'legendary', 'or', 'historical', 'figure.']\n",
            "[('An', 'epic'), ('epic', 'is'), ('is', 'a'), ('a', 'long'), ('long', 'narrative'), ('narrative', 'poem'), ('poem', 'detailing'), ('detailing', 'the'), ('the', 'heroic'), ('heroic', 'deeds'), ('deeds', 'and'), ('and', 'adventures'), ('adventures', 'of'), ('of', 'a'), ('a', 'legendary'), ('legendary', 'or'), ('or', 'historical'), ('historical', 'figure.'), ('An', 'epic'), ('epic', 'is'), ('is', 'a'), ('a', 'long'), ('long', 'narrative'), ('narrative', 'poem'), ('poem', 'detailing'), ('detailing', 'the'), ('the', 'heroic'), ('heroic', 'deeds'), ('deeds', 'and'), ('and', 'adventures'), ('adventures', 'of'), ('of', 'a'), ('a', 'legendary'), ('legendary', 'or'), ('or', 'historical'), ('historical', 'figure.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([  11.,  874.,    3.,    4.,  907.,  288.,  372.,    7.,   49., 2161.,\n",
            "          70., 2449.,   11.,  874.,    3.,    4.,  907.,  288.,  372.,    7.,\n",
            "          49., 2161.,   70., 2449.])\n",
            "['A', 'novel', 'is', 'a', 'long,', 'fictional', 'narrative', 'that', 'describes', 'intimate', 'human', 'experiences.', 'A', 'novel', 'is', 'a', 'long,', 'fictional', 'narrative', 'that', 'describes', 'intimate', 'human', 'experiences.']\n",
            "[('A', 'novel'), ('novel', 'is'), ('is', 'a'), ('a', 'long,'), ('long,', 'fictional'), ('fictional', 'narrative'), ('narrative', 'that'), ('that', 'describes'), ('describes', 'intimate'), ('intimate', 'human'), ('human', 'experiences.'), ('A', 'novel'), ('novel', 'is'), ('is', 'a'), ('a', 'long,'), ('long,', 'fictional'), ('fictional', 'narrative'), ('narrative', 'that'), ('that', 'describes'), ('describes', 'intimate'), ('intimate', 'human'), ('human', 'experiences.')]\n",
            "34\n",
            "32\n",
            "561\n",
            "66\n",
            "tensor([  11.,  344.,  170.,    3.,    4., 2836.,  288.,  372.,    7.,  324.,\n",
            "         228.,   23.,    4.,  768., 2231.,   10., 1097.,   11.,  344.,  170.,\n",
            "           3.,    4., 2836.,  288.,  372.,    7.,  324.,  228.,   23.,    4.,\n",
            "         768., 2231.,   10., 1097.])\n",
            "['A', 'short', 'story', 'is', 'a', 'brief', 'fictional', 'narrative', 'that', 'typically', 'focuses', 'on', 'a', 'single', 'incident', 'or', 'character.', 'A', 'short', 'story', 'is', 'a', 'brief', 'fictional', 'narrative', 'that', 'typically', 'focuses', 'on', 'a', 'single', 'incident', 'or', 'character.']\n",
            "[('A', 'short'), ('short', 'story'), ('story', 'is'), ('is', 'a'), ('a', 'brief'), ('brief', 'fictional'), ('fictional', 'narrative'), ('narrative', 'that'), ('that', 'typically'), ('typically', 'focuses'), ('focuses', 'on'), ('on', 'a'), ('a', 'single'), ('single', 'incident'), ('incident', 'or'), ('or', 'character.'), ('A', 'short'), ('short', 'story'), ('story', 'is'), ('is', 'a'), ('a', 'brief'), ('brief', 'fictional'), ('fictional', 'narrative'), ('narrative', 'that'), ('that', 'typically'), ('typically', 'focuses'), ('focuses', 'on'), ('on', 'a'), ('a', 'single'), ('single', 'incident'), ('incident', 'or'), ('or', 'character.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([  11., 2017.,    3.,    4.,  282.,  307.,   10., 1114.,  161.,   24.,\n",
            "         361.,  131.,   10.,  755., 1505.,   11., 2017.,    3.,    4.,  282.,\n",
            "         307.,   10., 1114.,  161.,   24.,  361.,  131.,   10.,  755., 1505.])\n",
            "['A', 'memoir', 'is', 'a', 'historical', 'account', 'or', 'biography', 'written', 'from', 'personal', 'knowledge', 'or', 'special', 'sources.', 'A', 'memoir', 'is', 'a', 'historical', 'account', 'or', 'biography', 'written', 'from', 'personal', 'knowledge', 'or', 'special', 'sources.']\n",
            "[('A', 'memoir'), ('memoir', 'is'), ('is', 'a'), ('a', 'historical'), ('historical', 'account'), ('account', 'or'), ('or', 'biography'), ('biography', 'written'), ('written', 'from'), ('from', 'personal'), ('personal', 'knowledge'), ('knowledge', 'or'), ('or', 'special'), ('special', 'sources.'), ('A', 'memoir'), ('memoir', 'is'), ('is', 'a'), ('a', 'historical'), ('historical', 'account'), ('account', 'or'), ('or', 'biography'), ('biography', 'written'), ('written', 'from'), ('from', 'personal'), ('personal', 'knowledge'), ('knowledge', 'or'), ('or', 'special'), ('special', 'sources.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([4.5000e+01, 2.9010e+03, 3.0000e+00, 4.0000e+00, 1.5550e+03, 3.0700e+02,\n",
            "        2.0000e+00, 1.0000e+00, 2.9020e+03, 3.7900e+02, 4.5000e+01, 2.9010e+03,\n",
            "        3.0000e+00, 4.0000e+00, 1.5550e+03, 3.0700e+02, 2.0000e+00, 1.0000e+00,\n",
            "        2.9020e+03, 3.7900e+02])\n",
            "['An', 'autobiography', 'is', 'a', 'self-written', 'account', 'of', 'the', \"author's\", 'life.', 'An', 'autobiography', 'is', 'a', 'self-written', 'account', 'of', 'the', \"author's\", 'life.']\n",
            "[('An', 'autobiography'), ('autobiography', 'is'), ('is', 'a'), ('a', 'self-written'), ('self-written', 'account'), ('account', 'of'), ('of', 'the'), ('the', \"author's\"), (\"author's\", 'life.'), ('An', 'autobiography'), ('autobiography', 'is'), ('is', 'a'), ('a', 'self-written'), ('self-written', 'account'), ('account', 'of'), ('of', 'the'), ('the', \"author's\"), (\"author's\", 'life.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([  11., 1114.,    3.,   21.,  307.,    2., 1511.,  146.,  161.,   18.,\n",
            "         135.,  845.,   11., 1114.,    3.,   21.,  307.,    2., 1511.,  146.,\n",
            "         161.,   18.,  135.,  845.])\n",
            "['A', 'biography', 'is', 'an', 'account', 'of', \"someone's\", 'life', 'written', 'by', 'another', 'person.', 'A', 'biography', 'is', 'an', 'account', 'of', \"someone's\", 'life', 'written', 'by', 'another', 'person.']\n",
            "[('A', 'biography'), ('biography', 'is'), ('is', 'an'), ('an', 'account'), ('account', 'of'), ('of', \"someone's\"), (\"someone's\", 'life'), ('life', 'written'), ('written', 'by'), ('by', 'another'), ('another', 'person.'), ('A', 'biography'), ('biography', 'is'), ('is', 'an'), ('an', 'account'), ('account', 'of'), ('of', \"someone's\"), (\"someone's\", 'life'), ('life', 'written'), ('written', 'by'), ('by', 'another'), ('another', 'person.')]\n",
            "22\n",
            "20\n",
            "231\n",
            "42\n",
            "tensor([1.1000e+01, 2.6020e+03, 3.0000e+00, 4.0000e+00, 6.2500e+02, 1.6570e+03,\n",
            "        2.0000e+00, 3.6100e+02, 1.0050e+03, 5.0000e+00, 1.3900e+03, 1.1000e+01,\n",
            "        2.6020e+03, 3.0000e+00, 4.0000e+00, 6.2500e+02, 1.6570e+03, 2.0000e+00,\n",
            "        3.6100e+02, 1.0050e+03, 5.0000e+00, 1.3900e+03])\n",
            "['A', 'diary', 'is', 'a', 'daily', 'record', 'of', 'personal', 'experiences', 'and', 'thoughts.', 'A', 'diary', 'is', 'a', 'daily', 'record', 'of', 'personal', 'experiences', 'and', 'thoughts.']\n",
            "[('A', 'diary'), ('diary', 'is'), ('is', 'a'), ('a', 'daily'), ('daily', 'record'), ('record', 'of'), ('of', 'personal'), ('personal', 'experiences'), ('experiences', 'and'), ('and', 'thoughts.'), ('A', 'diary'), ('diary', 'is'), ('is', 'a'), ('a', 'daily'), ('daily', 'record'), ('record', 'of'), ('of', 'personal'), ('personal', 'experiences'), ('experiences', 'and'), ('and', 'thoughts.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([1.1000e+01, 2.1410e+03, 3.0000e+00, 4.0000e+00, 6.2500e+02, 1.0000e+01,\n",
            "        5.2000e+02, 3.0700e+02, 2.0000e+00, 1.0150e+03, 2.4500e+03, 1.0000e+01,\n",
            "        1.9140e+03, 1.1000e+01, 2.1410e+03, 3.0000e+00, 4.0000e+00, 6.2500e+02,\n",
            "        1.0000e+01, 5.2000e+02, 3.0700e+02, 2.0000e+00, 1.0150e+03, 2.4500e+03,\n",
            "        1.0000e+01, 1.9140e+03])\n",
            "['A', 'journal', 'is', 'a', 'daily', 'or', 'periodic', 'account', 'of', 'events,', 'experiences,', 'or', 'observations.', 'A', 'journal', 'is', 'a', 'daily', 'or', 'periodic', 'account', 'of', 'events,', 'experiences,', 'or', 'observations.']\n",
            "[('A', 'journal'), ('journal', 'is'), ('is', 'a'), ('a', 'daily'), ('daily', 'or'), ('or', 'periodic'), ('periodic', 'account'), ('account', 'of'), ('of', 'events,'), ('events,', 'experiences,'), ('experiences,', 'or'), ('or', 'observations.'), ('A', 'journal'), ('journal', 'is'), ('is', 'a'), ('a', 'daily'), ('daily', 'or'), ('or', 'periodic'), ('periodic', 'account'), ('account', 'of'), ('of', 'events,'), ('events,', 'experiences,'), ('experiences,', 'or'), ('or', 'observations.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([4.5000e+01, 2.4840e+03, 3.0000e+00, 4.0000e+00, 3.4400e+02, 8.3800e+02,\n",
            "        2.0000e+00, 4.4000e+02, 2.3000e+01, 4.0000e+00, 1.1700e+02, 7.4500e+02,\n",
            "        5.3000e+01, 1.0010e+03, 3.6100e+02, 1.2850e+03, 4.5000e+01, 2.4840e+03,\n",
            "        3.0000e+00, 4.0000e+00, 3.4400e+02, 8.3800e+02, 2.0000e+00, 4.4000e+02,\n",
            "        2.3000e+01, 4.0000e+00, 1.1700e+02, 7.4500e+02, 5.3000e+01, 1.0010e+03,\n",
            "        3.6100e+02, 1.2850e+03])\n",
            "['An', 'essay', 'is', 'a', 'short', 'piece', 'of', 'writing', 'on', 'a', 'particular', 'subject,', 'often', 'expressing', 'personal', 'views.', 'An', 'essay', 'is', 'a', 'short', 'piece', 'of', 'writing', 'on', 'a', 'particular', 'subject,', 'often', 'expressing', 'personal', 'views.']\n",
            "[('An', 'essay'), ('essay', 'is'), ('is', 'a'), ('a', 'short'), ('short', 'piece'), ('piece', 'of'), ('of', 'writing'), ('writing', 'on'), ('on', 'a'), ('a', 'particular'), ('particular', 'subject,'), ('subject,', 'often'), ('often', 'expressing'), ('expressing', 'personal'), ('personal', 'views.'), ('An', 'essay'), ('essay', 'is'), ('is', 'a'), ('a', 'short'), ('short', 'piece'), ('piece', 'of'), ('of', 'writing'), ('writing', 'on'), ('on', 'a'), ('a', 'particular'), ('particular', 'subject,'), ('subject,', 'often'), ('often', 'expressing'), ('expressing', 'personal'), ('personal', 'views.')]\n",
            "36\n",
            "34\n",
            "630\n",
            "70\n",
            "tensor([  45., 2919.,    3.,    4.,  161., 1086.,   23.,    4.,   80., 1372.,\n",
            "          53.,  508.,    8.,    4., 1942., 2054.,   10., 2140.,   45., 2919.,\n",
            "           3.,    4.,  161., 1086.,   23.,    4.,   80., 1372.,   53.,  508.,\n",
            "           8.,    4., 1942., 2054.,   10., 2140.])\n",
            "['An', 'article', 'is', 'a', 'written', 'composition', 'on', 'a', 'specific', 'topic,', 'often', 'published', 'in', 'a', 'newspaper,', 'magazine,', 'or', 'journal.', 'An', 'article', 'is', 'a', 'written', 'composition', 'on', 'a', 'specific', 'topic,', 'often', 'published', 'in', 'a', 'newspaper,', 'magazine,', 'or', 'journal.']\n",
            "[('An', 'article'), ('article', 'is'), ('is', 'a'), ('a', 'written'), ('written', 'composition'), ('composition', 'on'), ('on', 'a'), ('a', 'specific'), ('specific', 'topic,'), ('topic,', 'often'), ('often', 'published'), ('published', 'in'), ('in', 'a'), ('a', 'newspaper,'), ('newspaper,', 'magazine,'), ('magazine,', 'or'), ('or', 'journal.'), ('An', 'article'), ('article', 'is'), ('is', 'a'), ('a', 'written'), ('written', 'composition'), ('composition', 'on'), ('on', 'a'), ('a', 'specific'), ('specific', 'topic,'), ('topic,', 'often'), ('often', 'published'), ('published', 'in'), ('in', 'a'), ('a', 'newspaper,'), ('newspaper,', 'magazine,'), ('magazine,', 'or'), ('or', 'journal.')]\n",
            "20\n",
            "18\n",
            "190\n",
            "38\n",
            "tensor([  11.,   87.,    3.,    4.,  397., 2993., 2627.,    6.,   21., 1125.,\n",
            "          11.,   87.,    3.,    4.,  397., 2993., 2627.,    6.,   21., 1125.])\n",
            "['A', 'speech', 'is', 'a', 'formal', 'address', 'delivered', 'to', 'an', 'audience.', 'A', 'speech', 'is', 'a', 'formal', 'address', 'delivered', 'to', 'an', 'audience.']\n",
            "[('A', 'speech'), ('speech', 'is'), ('is', 'a'), ('a', 'formal'), ('formal', 'address'), ('address', 'delivered'), ('delivered', 'to'), ('to', 'an'), ('an', 'audience.'), ('A', 'speech'), ('speech', 'is'), ('is', 'a'), ('a', 'formal'), ('formal', 'address'), ('address', 'delivered'), ('delivered', 'to'), ('to', 'an'), ('an', 'audience.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.1780e+03, 3.0000e+00, 1.0000e+00, 4.2400e+02, 2.0000e+00, 8.0600e+02,\n",
            "        4.7800e+02, 6.0600e+02, 8.0000e+00, 4.0000e+00, 3.9700e+02, 5.0000e+00,\n",
            "        2.5160e+03, 8.9700e+02, 3.1780e+03, 3.0000e+00, 1.0000e+00, 4.2400e+02,\n",
            "        2.0000e+00, 8.0600e+02, 4.7800e+02, 6.0600e+02, 8.0000e+00, 4.0000e+00,\n",
            "        3.9700e+02, 5.0000e+00, 2.5160e+03, 8.9700e+02])\n",
            "['Oratory', 'is', 'the', 'art', 'of', 'public', 'speaking,', 'especially', 'in', 'a', 'formal', 'and', 'eloquent', 'manner.', 'Oratory', 'is', 'the', 'art', 'of', 'public', 'speaking,', 'especially', 'in', 'a', 'formal', 'and', 'eloquent', 'manner.']\n",
            "[('Oratory', 'is'), ('is', 'the'), ('the', 'art'), ('art', 'of'), ('of', 'public'), ('public', 'speaking,'), ('speaking,', 'especially'), ('especially', 'in'), ('in', 'a'), ('a', 'formal'), ('formal', 'and'), ('and', 'eloquent'), ('eloquent', 'manner.'), ('Oratory', 'is'), ('is', 'the'), ('the', 'art'), ('art', 'of'), ('of', 'public'), ('public', 'speaking,'), ('speaking,', 'especially'), ('especially', 'in'), ('in', 'a'), ('a', 'formal'), ('formal', 'and'), ('and', 'eloquent'), ('eloquent', 'manner.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.1170e+03, 2.6080e+03, 1.3000e+01, 4.6400e+02, 3.1000e+01, 1.8000e+01,\n",
            "        3.3800e+02, 5.0000e+00, 1.2330e+03, 6.0000e+00, 1.8140e+03, 2.2070e+03,\n",
            "        1.0000e+01, 2.4990e+03, 1.0000e+00, 1.1250e+03, 3.1170e+03, 2.6080e+03,\n",
            "        1.3000e+01, 4.6400e+02, 3.1000e+01, 1.8000e+01, 3.3800e+02, 5.0000e+00,\n",
            "        1.2330e+03, 6.0000e+00, 1.8140e+03, 2.2070e+03, 1.0000e+01, 2.4990e+03,\n",
            "        1.0000e+00, 1.1250e+03])\n",
            "['Rhetorical', 'devices', 'are', 'techniques', 'used', 'by', 'speakers', 'and', 'writers', 'to', 'persuade,', 'inform,', 'or', 'entertain', 'the', 'audience.', 'Rhetorical', 'devices', 'are', 'techniques', 'used', 'by', 'speakers', 'and', 'writers', 'to', 'persuade,', 'inform,', 'or', 'entertain', 'the', 'audience.']\n",
            "[('Rhetorical', 'devices'), ('devices', 'are'), ('are', 'techniques'), ('techniques', 'used'), ('used', 'by'), ('by', 'speakers'), ('speakers', 'and'), ('and', 'writers'), ('writers', 'to'), ('to', 'persuade,'), ('persuade,', 'inform,'), ('inform,', 'or'), ('or', 'entertain'), ('entertain', 'the'), ('the', 'audience.'), ('Rhetorical', 'devices'), ('devices', 'are'), ('are', 'techniques'), ('techniques', 'used'), ('used', 'by'), ('by', 'speakers'), ('speakers', 'and'), ('and', 'writers'), ('writers', 'to'), ('to', 'persuade,'), ('persuade,', 'inform,'), ('inform,', 'or'), ('or', 'entertain'), ('entertain', 'the'), ('the', 'audience.')]\n",
            "26\n",
            "24\n",
            "325\n",
            "50\n",
            "tensor([  45., 2939.,    3.,    4., 2725.,  138.,    7., 1002.,    4.,  393.,\n",
            "         248.,   10., 1744.,   45., 2939.,    3.,    4., 2725.,  138.,    7.,\n",
            "        1002.,    4.,  393.,  248.,   10., 1744.])\n",
            "['An', 'aphorism', 'is', 'a', 'concise', 'statement', 'that', 'expresses', 'a', 'general', 'truth', 'or', 'principle.', 'An', 'aphorism', 'is', 'a', 'concise', 'statement', 'that', 'expresses', 'a', 'general', 'truth', 'or', 'principle.']\n",
            "[('An', 'aphorism'), ('aphorism', 'is'), ('is', 'a'), ('a', 'concise'), ('concise', 'statement'), ('statement', 'that'), ('that', 'expresses'), ('expresses', 'a'), ('a', 'general'), ('general', 'truth'), ('truth', 'or'), ('or', 'principle.'), ('An', 'aphorism'), ('aphorism', 'is'), ('is', 'a'), ('a', 'concise'), ('concise', 'statement'), ('statement', 'that'), ('that', 'expresses'), ('expresses', 'a'), ('a', 'general'), ('general', 'truth'), ('truth', 'or'), ('or', 'principle.')]\n",
            "30\n",
            "28\n",
            "435\n",
            "58\n",
            "tensor([1.1000e+01, 2.0340e+03, 3.0000e+00, 4.0000e+00, 7.7400e+02, 1.7940e+03,\n",
            "        1.3800e+02, 1.0010e+03, 4.0000e+00, 3.9300e+02, 2.4800e+02, 1.0000e+01,\n",
            "        1.5780e+03, 2.0000e+00, 2.7220e+03, 1.1000e+01, 2.0340e+03, 3.0000e+00,\n",
            "        4.0000e+00, 7.7400e+02, 1.7940e+03, 1.3800e+02, 1.0010e+03, 4.0000e+00,\n",
            "        3.9300e+02, 2.4800e+02, 1.0000e+01, 1.5780e+03, 2.0000e+00, 2.7220e+03])\n",
            "['A', 'maxim', 'is', 'a', 'short,', 'pithy', 'statement', 'expressing', 'a', 'general', 'truth', 'or', 'rule', 'of', 'conduct.', 'A', 'maxim', 'is', 'a', 'short,', 'pithy', 'statement', 'expressing', 'a', 'general', 'truth', 'or', 'rule', 'of', 'conduct.']\n",
            "[('A', 'maxim'), ('maxim', 'is'), ('is', 'a'), ('a', 'short,'), ('short,', 'pithy'), ('pithy', 'statement'), ('statement', 'expressing'), ('expressing', 'a'), ('a', 'general'), ('general', 'truth'), ('truth', 'or'), ('or', 'rule'), ('rule', 'of'), ('of', 'conduct.'), ('A', 'maxim'), ('maxim', 'is'), ('is', 'a'), ('a', 'short,'), ('short,', 'pithy'), ('pithy', 'statement'), ('statement', 'expressing'), ('expressing', 'a'), ('a', 'general'), ('general', 'truth'), ('truth', 'or'), ('or', 'rule'), ('rule', 'of'), ('of', 'conduct.')]\n",
            "32\n",
            "30\n",
            "496\n",
            "62\n",
            "tensor([3.4310e+03, 3.0000e+00, 4.0000e+00, 1.3800e+02, 1.0000e+01, 8.1300e+02,\n",
            "        7.0000e+00, 3.0000e+00, 5.0400e+02, 1.4000e+01, 1.9200e+02, 1.0180e+03,\n",
            "        1.1500e+03, 1.0000e+01, 7.8000e+02, 4.4900e+02, 3.4310e+03, 3.0000e+00,\n",
            "        4.0000e+00, 1.3800e+02, 1.0000e+01, 8.1300e+02, 7.0000e+00, 3.0000e+00,\n",
            "        5.0400e+02, 1.4000e+01, 1.9200e+02, 1.0180e+03, 1.1500e+03, 1.0000e+01,\n",
            "        7.8000e+02, 4.4900e+02])\n",
            "['Axiom', 'is', 'a', 'statement', 'or', 'proposition', 'that', 'is', 'regarded', 'as', 'being', 'established,', 'accepted,', 'or', 'self-evidently', 'true.', 'Axiom', 'is', 'a', 'statement', 'or', 'proposition', 'that', 'is', 'regarded', 'as', 'being', 'established,', 'accepted,', 'or', 'self-evidently', 'true.']\n",
            "[('Axiom', 'is'), ('is', 'a'), ('a', 'statement'), ('statement', 'or'), ('or', 'proposition'), ('proposition', 'that'), ('that', 'is'), ('is', 'regarded'), ('regarded', 'as'), ('as', 'being'), ('being', 'established,'), ('established,', 'accepted,'), ('accepted,', 'or'), ('or', 'self-evidently'), ('self-evidently', 'true.'), ('Axiom', 'is'), ('is', 'a'), ('a', 'statement'), ('statement', 'or'), ('or', 'proposition'), ('proposition', 'that'), ('that', 'is'), ('is', 'regarded'), ('regarded', 'as'), ('as', 'being'), ('being', 'established,'), ('established,', 'accepted,'), ('accepted,', 'or'), ('or', 'self-evidently'), ('self-evidently', 'true.')]\n",
            "28\n",
            "26\n",
            "378\n",
            "54\n",
            "tensor([3.3960e+03, 3.0000e+00, 2.1000e+01, 8.5500e+02, 1.8700e+02, 1.0000e+01,\n",
            "        3.8800e+02, 7.0000e+00, 5.4000e+01, 2.0690e+03, 4.3000e+01, 1.8800e+03,\n",
            "        5.0000e+00, 2.2410e+03, 3.3960e+03, 3.0000e+00, 2.1000e+01, 8.5500e+02,\n",
            "        1.8700e+02, 1.0000e+01, 3.8800e+02, 7.0000e+00, 5.4000e+01, 2.0690e+03,\n",
            "        4.3000e+01, 1.8800e+03, 5.0000e+00, 2.2410e+03])\n",
            "['Cliché', 'is', 'an', 'overused', 'expression', 'or', 'idea', 'that', 'has', 'lost', 'its', 'originality', 'and', 'impact.', 'Cliché', 'is', 'an', 'overused', 'expression', 'or', 'idea', 'that', 'has', 'lost', 'its', 'originality', 'and', 'impact.']\n",
            "[('Cliché', 'is'), ('is', 'an'), ('an', 'overused'), ('overused', 'expression'), ('expression', 'or'), ('or', 'idea'), ('idea', 'that'), ('that', 'has'), ('has', 'lost'), ('lost', 'its'), ('its', 'originality'), ('originality', 'and'), ('and', 'impact.'), ('Cliché', 'is'), ('is', 'an'), ('an', 'overused'), ('overused', 'expression'), ('expression', 'or'), ('or', 'idea'), ('idea', 'that'), ('that', 'has'), ('has', 'lost'), ('lost', 'its'), ('its', 'originality'), ('originality', 'and'), ('and', 'impact.')]\n",
            "24\n",
            "22\n",
            "276\n",
            "46\n",
            "tensor([  11., 1344.,    3.,    4.,   96.,   10.,  855.,  729.,   10.,  618.,\n",
            "           8., 2084.,   11., 1344.,    3.,    4.,   96.,   10.,  855.,  729.,\n",
            "          10.,  618.,    8., 2084.])\n",
            "['A', 'trope', 'is', 'a', 'common', 'or', 'overused', 'theme', 'or', 'device', 'in', 'literature.', 'A', 'trope', 'is', 'a', 'common', 'or', 'overused', 'theme', 'or', 'device', 'in', 'literature.']\n",
            "[('A', 'trope'), ('trope', 'is'), ('is', 'a'), ('a', 'common'), ('common', 'or'), ('or', 'overused'), ('overused', 'theme'), ('theme', 'or'), ('or', 'device'), ('device', 'in'), ('in', 'literature.'), ('A', 'trope'), ('trope', 'is'), ('is', 'a'), ('a', 'common'), ('common', 'or'), ('or', 'overused'), ('overused', 'theme'), ('theme', 'or'), ('or', 'device'), ('device', 'in'), ('in', 'literature.')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "words = vocab\n",
        "\n",
        "word_to_index = {word: i for i, word in enumerate(words)}\n",
        "\n",
        "nodes = vocab\n",
        "hyperedges = [(nodes[i], nodes[i + 1]) for i in range(len(nodes) - 1)]\n",
        "\n",
        "class Hypergraph:\n",
        "    def __init__(self, nodes, hyperedges):\n",
        "        self.nodes = nodes\n",
        "        self.hyperedges = hyperedges\n",
        "        self.addnodes = self.nodes.extend(nodes)\n",
        "        self.addedges = self.hyperedges.extend(hyperedges)\n",
        "        self.num_nodes = len(nodes)\n",
        "        self.num_hyperedges = len(hyperedges)\n",
        "        self.num_edges = self.num_nodes * (self.num_nodes - 1) // 2\n",
        "        self.num_vertices = self.num_nodes + self.num_hyperedges\n",
        "        self.node_features = Hypergraph.create_node_features(nodes)\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_nodes + self.num_hyperedges\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < self.num_nodes:\n",
        "            return self.nodes[idx]\n",
        "        else:\n",
        "            return self.hyperedges[idx - self.num_nodes]\n",
        "\n",
        "    @staticmethod\n",
        "    def create_node_features(nodes):\n",
        "        node_features = torch.zeros(len(nodes))\n",
        "        for i, node in enumerate(nodes):\n",
        "            node_features[i] = word_to_index[node]\n",
        "            if node not in word_to_index:\n",
        "              node_features[i] = len(word_to_index)\n",
        "        return node_features\n",
        "\n",
        "    def set_adjacency_matrix(self, adjacency_matrix):\n",
        "        self.adjacency_matrix = adjacency_matrix\n",
        "        self.num_edges = adjacency_matrix.sum()\n",
        "        self.num_vertices = self.num_nodes + self.num_hyperedges\n",
        "        self.node_features = Hypergraph.create_node_features(self.nodes)\n",
        "        self.adjacency_matrix = adjacency_matrix\n",
        "\n",
        "class HypergraphDataset:\n",
        "    def __init__(self, texts):\n",
        "        self.texts = texts\n",
        "        self.hypergraphs = self.create_hypergraphs(texts)\n",
        "        hypergraph = self.text_to_hypergraph(texts[0])\n",
        "        self.node_features = hypergraph.node_features\n",
        "        self.adjacency_matrix = hypergraph.set_adjacency_matrix\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.hypergraphs[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def text_to_hypergraph(self, text):\n",
        "            # Build the word_to_index dictionary dynamically\n",
        "            words = text.split()\n",
        "            sentences = text.split('.')\n",
        "            word_to_index = {word: i for i, word in enumerate(set(words))}\n",
        "\n",
        "            # Convert words to indices\n",
        "            node_features = [word_to_index[word] for word in words]\n",
        "\n",
        "            # Create the adjacency matrix\n",
        "            num_nodes = len(words)\n",
        "            adjacency_matrix = torch.zeros((num_nodes, num_nodes))\n",
        "            for i in range(num_nodes):\n",
        "                for j in range(i+1, num_nodes):\n",
        "                    adjacency_matrix[i, j] = adjacency_matrix[j, i] = 1\n",
        "# Create the hypergraph\n",
        "            hypergraph = Hypergraph(nodes, [(words[i], words[j]) for i in range(num_nodes) for j in range(i+1, num_nodes)])\n",
        "\n",
        "            # Set the node features\n",
        "            hypergraph.node_features = torch.tensor(node_features)\n",
        "\n",
        "            return hypergraph\n",
        "\n",
        "    def create_hypergraphs(self, texts):\n",
        "        hypergraphs = []\n",
        "        for text in texts:\n",
        "            nodes = text.split()\n",
        "            hyperedges = self.create_hyperedges(nodes)\n",
        "            hypergraphs.append(Hypergraph(nodes, hyperedges))\n",
        "        return hypergraphs\n",
        "\n",
        "    def create_hyperedges(self, nodes):\n",
        "        hyperedges = []\n",
        "        for i in range(len(nodes) - 1):\n",
        "            hyperedges.append((nodes[i], nodes[i + 1]))\n",
        "        return hyperedges\n",
        "    def get_relationships(self):\n",
        "        relationships = []\n",
        "        for hypergraph in self.hypergraphs:\n",
        "            for node in hypergraph.nodes:\n",
        "                for hyperedge in hypergraph.hyperedges:\n",
        "                    relationships.append((node, hyperedge[0], hyperedge[1]))\n",
        "            return relationships\n",
        "\n",
        "\n",
        "texts = [\n",
        "    \"This is a simple example.\",\n",
        "    \"Creating a hypergraph-based model.\",\n",
        "    \"Hypergraphs can represent complex relationships.\",\n",
        "    \"Each node in a hypergraph can connect to multiple nodes.\",\n",
        "    \"Hypergraph-based models are powerful tools for NLP.\",\n",
        "    \"These models can capture intricate dependencies.\",\n",
        "    \"A hypergraph structure is more flexible than a simple graph.\",\n",
        "    \"In NLP, hypergraphs can enhance the representation of text.\",\n",
        "    \"They can improve the performance of language models.\",\n",
        "    \"Advanced hypergraph models can capture higher-order relationships.\",\n",
        "    \"Natural language processing benefits from complex models.\",\n",
        "    \"Graph structures are essential for many machine learning tasks.\",\n",
        "    \"Text data can be represented as graphs or hypergraphs.\",\n",
        "    \"Hypergraphs offer a more expressive representation for text.\",\n",
        "    \"Understanding hypergraphs is key to leveraging their power.\",\n",
        "    \"Complex models can better capture the nuances of language.\",\n",
        "    \"Language models require robust and flexible architectures.\",\n",
        "    \"Hypergraph-based models can handle complex data scenarios.\",\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Add more texts as needed\n",
        "\n",
        "dataset = HypergraphDataset(corpus)\n",
        "hypergraphs = dataset.hypergraphs\n",
        "hyper_vocab = []\n",
        "\n",
        "for hypergraph in hypergraphs:\n",
        "    print(hypergraph.num_nodes)\n",
        "    print(hypergraph.num_hyperedges)\n",
        "    print(hypergraph.num_edges)\n",
        "    print(hypergraph.num_vertices)\n",
        "    print(hypergraph.node_features)\n",
        " #   print(hypergraph.adjacency_matrix)\n",
        "    print(hypergraph.nodes)\n",
        "    print(hypergraph.hyperedges)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for node in hypergraph.nodes:\n",
        "        hyper_vocab.append(node)\n",
        "        for hyperedge in hypergraph.hyperedges:\n",
        "            hyper_vocab.append(hyperedge)\n",
        "           #ltm += hyper_vocab\n",
        "\n",
        "print(hyper_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2lAAUlWBA1o",
        "outputId": "5727aceb-dd42-4688-b09c-c6a5c984d26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch-nn (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch-nn\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install torch-nn --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMb2l6dADQjm"
      },
      "outputs": [],
      "source": [
        "save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ah51oqdHq_3"
      },
      "source": [
        "sets up natural language processing from nodes of hypergraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nFfaxQfMYrx",
        "outputId": "42e94891-d6d7-4cdc-fbab-cbe86ca75d8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLP Model Summary:\n",
            "Input Dimension: 4096\n",
            "Hidden Dimension: 4096\n",
            "Output Dimension: 4096\n",
            "Vocabulary Size: 14020\n",
            "Embedding Size: 4096\n",
            "Mamba Network Input Dimension: 4096\n",
            "Mamba Network Hidden Dimension: 4096\n",
            "Mamba Network Output Dimension: 4096\n",
            "Params: 577650688\n",
            "Device: cpu\n",
            "LSTM Input Dimension: 4096\n",
            "LSTM Hidden Dimension: 4096\n",
            "LSTM Batch First: False\n",
            "LSTM Bidirectional: False\n",
            "LSTM Num Layers: 1\n",
            "KANSKP Input Dimension: 4096\n",
            "KANSKP Hidden Dimension: 4096\n",
            "KANSKP Output Dimension: 4096\n",
            "KANSKP Params: 167813120\n"
          ]
        }
      ],
      "source": [
        "input_text = \"test\"\n",
        "\n",
        "class HypergraphLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1, bidirectional=False, dropout=0.):\n",
        "        super(HypergraphLSTM, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.normalize = nn.SyncBatchNorm(input_dim)\n",
        "        self.dropout = dropout\n",
        "        self.params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), output_dim)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        # Embed the input\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # Pack the input sequence\n",
        "        packed_input = pack_padded_sequence(x, lengths, batch_first=True)\n",
        "\n",
        "        # Run the input through the LSTM\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_input)\n",
        "\n",
        "        # Unpack the output sequence\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "        # normalize output\n",
        "        output = self.normalize(output)\n",
        "\n",
        "        # Apply dropout\n",
        "        output = F.dropout(output, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Apply the linear layer\n",
        "        output = self.fc(output)\n",
        "\n",
        "        # Reshape the output to match the expected shape\n",
        "        output = output.view(-1, self.output_dim)\n",
        "\n",
        "        return output\n",
        "\n",
        "class MambaNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MambaNetwork, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "        self.hypergraph_lstm = HypergraphLSTM(input_dim, hidden_dim, hidden_dim)\n",
        "        self.mamba_layer = MambaLayer(hidden_dim, hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, hypergraph, lengths):\n",
        "        # Run the hypergraph through the Hypergraph LSTM\n",
        "        output = self.hypergraph_lstm(hypergraph, lengths)\n",
        "\n",
        "        # Run the output through the Mamba layer\n",
        "        output = self.mamba_layer(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class MambaLayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MambaLayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply the first linear layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Apply the second linear layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class KANSpikingNeuron(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(KANSpikingNeuron, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim)\n",
        "        self.params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply the first linear layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Apply the second linear layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Convert the output to spikes using the KAN model\n",
        "        spikes = torch.zeros_like(x)\n",
        "        for t in range(x.shape[1]):\n",
        "            spikes[:, t] = (x[:, t] > 0).float()\n",
        "\n",
        "        return spikes\n",
        "\n",
        "class NLPModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(NLPModel, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.hypergraph = hyper_vocab\n",
        "        self.mamba_network = MambaNetwork(input_dim, hidden_dim, output_dim)\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.lookup_layer = lookup.create_lookup_layer\n",
        "        self.vocab = vocab\n",
        "        #self.selfattention = nn.MultiHeadAttention(hidden_dim)\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.conversation_history = []\n",
        "        self.input_dim = input_dim\n",
        "        self.text_to_hypergraph = dataset.text_to_hypergraph(text=input_text)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "       # self.predict_next_statement = predict_next_statement\n",
        "     #   self.get_sequences_from_dataset = get_sequences_from_dataset\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.kanskp = KANSpikingNeuron(input_dim, hidden_dim, output_dim)\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.hidden_dim)\n",
        "        self.ltm = ltm\n",
        "        self.params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "        self.summary()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.lookup_layer is None:\n",
        "            raise ValueError(\"Lookup layer not created. Call create_lookup_layer first.\")\n",
        "        return self.lookup_layer(inputs)\n",
        "\n",
        "    def params(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "    def summary(self):\n",
        "        print(\"NLP Model Summary:\")\n",
        "        print(f\"Input Dimension: {self.input_dim}\")\n",
        "        print(f\"Hidden Dimension: {self.hidden_dim}\")\n",
        "        print(f\"Output Dimension: {self.output_dim}\")\n",
        "        print(f\"Vocabulary Size: {self.vocab_size}\")\n",
        "        print(f\"Embedding Size: {self.embedding.embedding_dim}\")\n",
        "        print(f\"Mamba Network Input Dimension: {self.mamba_network.input_dim}\")\n",
        "        print(f\"Mamba Network Hidden Dimension: {self.mamba_network.hidden_dim}\")\n",
        "        print(f\"Mamba Network Output Dimension: {self.mamba_network.output_dim}\")\n",
        "        print(f\"Params: {self.params}\")\n",
        "        print(f\"Device: {self.device}\")\n",
        "        print(f\"LSTM Input Dimension: {self.lstm.input_size}\")\n",
        "        print(f\"LSTM Hidden Dimension: {self.lstm.hidden_size}\")\n",
        "        #print(f\"LSTM Output Dimension: {self.lstm.output_dim}\")\n",
        "        print(f\"LSTM Batch First: {self.lstm.batch_first}\")\n",
        "        print(f\"LSTM Bidirectional: {self.lstm.bidirectional}\")\n",
        "        print(f\"LSTM Num Layers: {self.lstm.num_layers}\")\n",
        "        print(f\"KANSKP Input Dimension: {self.kanskp.input_dim}\")\n",
        "        print(f\"KANSKP Hidden Dimension: {self.kanskp.hidden_dim}\")\n",
        "        print(f\"KANSKP Output Dimension: {self.kanskp.output_dim}\")\n",
        "        print(f\"KANSKP Params: {self.kanskp.params}\")\n",
        "\n",
        "    def forward(self, hypergraph, lengths):\n",
        "        # Convert the hypergraph to a text\n",
        "        for hypergraphs in dataset.hypergraphs:\n",
        "            text = ''\n",
        "            hypergraph = hypergraphs[0] + ' ' + hypergraphs[1] + ' '\n",
        "            for node in hypergraphs.nodes:\n",
        "                text += node + ' '\n",
        "                for hyperedge in hypergraphs.hyperedges:\n",
        "                      text += hyperedge[0] + ' ' + hyperedge[1] + ' '\n",
        "                      x = self.text_to_hypergraph(text)\n",
        "                      node_features = hypergraphs.create_node_features(nodes)\n",
        "                      adjacency_matrix = hypergraphs.set_adjacency_matrix(hypergraphs.adjacency_matrix)\n",
        "                      x = torch.cat((node_features, adjacency_matrix), dim=1)\n",
        "                      x = x.view(1, -1)\n",
        "                      h0 = torch.zeros(1, self.hidden_dim).to(self.device)\n",
        "                      c0 = torch.zeros(1, self.hidden_dim).to(self.device)\n",
        "                      output = self.mamba_network(x, lengths)\n",
        "                      return output\n",
        "\n",
        "    def get_hypergraph(self, text):\n",
        "        return dataset.text_to_hypergraph(text)\n",
        "\n",
        "    def get_sequences_from_dataset(self, dataset, batch_size):\n",
        "        sequences = []\n",
        "        for i in range(0, len(dataset), batch_size):\n",
        "            batch = dataset[i:i+batch_size]\n",
        "            sequences.append(batch)\n",
        "        return sequences\n",
        "\n",
        "    def predict_next_statement(sequences):\n",
        "        # Initialize the LSTM model\n",
        "        sequences = text.split(\".\")\n",
        "\n",
        "        lstm = self.lstm(input_dim=len(sequences[0]), hidden_dim=128, num_layers=1)\n",
        "\n",
        "        # Convert the sequences to tensors\n",
        "        sequences_tensor = torch.tensor(sequences)\n",
        "\n",
        "        # Initialize the hidden and cell states\n",
        "        h0 = torch.zeros(1, 1, 128)\n",
        "        c0 = torch.zeros(1, 1, 128)\n",
        "\n",
        "        # Run the sequences through the LSTM\n",
        "        out, _ = lstm(sequences_tensor, (h0, c0))\n",
        "\n",
        "        # Get the output for the last time step\n",
        "        last_output = out[-1, :, :]\n",
        "\n",
        "        # Apply a linear layer to the output\n",
        "        fc = nn.Linear(128, len(vocab))\n",
        "        next_statement_logits = fc(last_output)\n",
        "\n",
        "        # Predict the next statement using the softmax function\n",
        "        next_statement_probs = torch.softmax(next_statement_logits, dim=1)\n",
        "        next_statement_idx = torch.argmax(next_statement_probs, dim=1).item()\n",
        "\n",
        "    # Return the predicted next statement\n",
        "        return vocab[next_statement_idx]\n",
        "\n",
        "    def memorize(self, text):\n",
        "        self.conversation_history.append(text)\n",
        "        self.ltm.append(self.conversation_history)\n",
        "        print(self.ltm)\n",
        "\n",
        "    def respond(self, input_text):\n",
        "        # Ensure input_text is a string\n",
        "        if not isinstance(input_text, str):\n",
        "            input_text = str(input_text)\n",
        "\n",
        "        # Ensure dataset has a text_to_hypergraph attribute\n",
        "        if not hasattr(dataset, 'text_to_hypergraph'):\n",
        "            raise AttributeError(\"Dataset object does not have a text_to_hypergraph attribute.\")\n",
        "\n",
        "        # Convert input text to a hypergraph\n",
        "        input_hypergraph = dataset.text_to_hypergraph(input_text)\n",
        "\n",
        "        # Initialize the hidden state and cell state for the LSTM\n",
        "        h0 = torch.zeros(1, 1, self.hidden_dim).to(self.device)\n",
        "        c0 = torch.zeros(1, 1, self.hidden_dim).to(self.device)\n",
        "\n",
        "        # Initialize the output sequence\n",
        "        outputs = []\n",
        "\n",
        "        # Run the input hypergraph through the model\n",
        "        x = self.embedding(torch.tensor([self.vocab_size - 1]).to(self.device))  # Start with a special \"start\" token\n",
        "        x = x.view(1, 1, -1)\n",
        "\n",
        "        for i in range(20):  # Generate a sequence of 20 words\n",
        "            out, (h0, c0) = self.lstm(x, (h0, c0))\n",
        "            out = self.fc(out.squeeze(0))\n",
        "            out = self.softmax(out)\n",
        "            word_idx = torch.argmax(out, dim=1).item()\n",
        "            if word_idx == self.vocab_size - 1:  # End with a special \"end\" token\n",
        "                break\n",
        "            outputs.append(self.vocab[word_idx])\n",
        "            x = self.embedding(torch.tensor([word_idx]).to(self.device)).view(1, 1, -1)\n",
        "\n",
        "        sequences = []\n",
        "        for word in hyper_vocab:\n",
        "            sequences.append(word)\n",
        "            for hyperedge in hyper_vocab:\n",
        "                sequences = self.get_sequences_from_dataset(dataset, batch_size=1)\n",
        "\n",
        "\n",
        "                next_statement = self.predict_next_statement(sequences)\n",
        "\n",
        "              # Generate a response based on the output sequence and the predicted next statement\n",
        "                response = ' '.join(outputs) + ' ' + next_statement\n",
        "        return response\n",
        "\n",
        "    def train(rank, world_size, dataset, input_dim, hidden_dim, output_dim):\n",
        "        rank = int(rank)\n",
        "        world_size = int(world_size)\n",
        "\n",
        "        torch.distributed.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
        "        torch.cuda.set_device(rank)\n",
        "        model = nlp_model.to(rank)\n",
        "        init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
        "\n",
        "        torch.cuda.set_device(rank)\n",
        "        ddp_model = DDP(model, device_ids=[rank])\n",
        "\n",
        "        dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = Adam(ddp_model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "        for epoch in range(128):  # Dummy epoch count\n",
        "            for node_features, adjacency_matrix in dataloader:\n",
        "                node_features = node_features[0].to(rank)\n",
        "                adjacency_matrix = adjacency_matrix[0].to(rank)\n",
        "input_dim = 4096\n",
        "hidden_dim = 4096\n",
        "input_hidden_dim = 1024\n",
        "output_dim = 4096\n",
        "nlp_model = NLPModel(input_dim, hidden_dim, output_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEbqbeJAzVfE",
        "outputId": "3236b4d0-b59e-4698-a4cd-54e1df750142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pygsp\n",
            "  Downloading PyGSP-0.5.1-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pygsp) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pygsp) (1.11.4)\n",
            "Installing collected packages: pygsp\n",
            "Successfully installed pygsp-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install pygsp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "E0joeMyaywxf",
        "outputId": "9987b1f2-44e5-40f2-ec06-a37306a6ed1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-03 20:32:47,352:[WARNING](pygsp.graphs.graph.compute_fourier_basis): Computing the full eigendecomposition of a large matrix (3517 x 3517) may take some time.\n",
            "WARNING:pygsp.graphs.graph:Computing the full eigendecomposition of a large matrix (3517 x 3517) may take some time.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import pygsp as pg\n",
        "\n",
        "G = nx.Graph()\n",
        "for hyperedge in nlp_model.hypergraph:\n",
        "    for node in hyperedge:\n",
        "        for other_node in hyperedge:\n",
        "            if node != other_node:\n",
        "                G.add_edge(node, other_node)\n",
        "\n",
        "# Create a PyGSP graph\n",
        "G = pg.graphs.Graph(nx.adjacency_matrix(G))\n",
        "\n",
        "# Compute the wavelets\n",
        "G.compute_fourier_basis()\n",
        "wavelets = pg.filters.Heat(G, tau=10)\n",
        "\n",
        "# Visualize or analyze the wavelets\n",
        "import matplotlib.pyplot as plt\n",
        "wavelets.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "u2IpRMpWEGd8",
        "outputId": "3639621a-efa5-4280-9d52-ac0e1d060b0d"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NLPModel' object has no attribute 'spawn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-61a9a7d76714>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         nlp_model.spawn(train,\n\u001b[0m\u001b[1;32m      7\u001b[0m              \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m              \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NLPModel' object has no attribute 'spawn'"
          ]
        }
      ],
      "source": [
        "\n",
        "rank = 1\n",
        "world_size = 2\n",
        "\n",
        "\n",
        "while True:\n",
        "        nlp_model.spawn(train,\n",
        "             args=(world_size, dataset, input_dim, hidden_dim),\n",
        "             nprocs=world_size,\n",
        "             join=True)\n",
        "        nlp_model.train(rank, world_size , dataset, input_dim, hidden_dim)\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5FLg-XFD2I3"
      },
      "outputs": [],
      "source": [
        "save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ooFDZUMsOysf"
      },
      "outputs": [],
      "source": [
        "class hyperchat():\n",
        "  #define chat with nlp hypergraph model\n",
        "  def __init__(self):\n",
        "      self.name = \"hyperchat\"\n",
        "      self.model = nlp_model\n",
        "      self.conversation_history = []\n",
        "\n",
        "      while self.name == \"hyperchat\":\n",
        "          user_input = input(\"You: \")\n",
        "          if user_input.lower() == \"exit\":\n",
        "              break\n",
        "          for text in user_input:\n",
        "            text = dataset.text_to_hypergraph(text)\n",
        "            self.model.respond(text)\n",
        "            print(self.model.conversation_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "zq8P3bHINHo7",
        "outputId": "812c84a9-f0c4-45a7-a3e1-e3eb6bb3e7f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hi\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "NLPModel.predict_next_statement() takes 1 positional argument but 2 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-abbe80351179>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhyperchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-2691bf28511c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_to_hypergraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrespond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconversation_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-e051280ba91d>\u001b[0m in \u001b[0;36mrespond\u001b[0;34m(self, input_text)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0mnext_statement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_next_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m               \u001b[0;31m# Generate a response based on the output sequence and the predicted next statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: NLPModel.predict_next_statement() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "hyperchat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpL3a3QXHxS_"
      },
      "source": [
        "sees stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6SR5swhcneb"
      },
      "outputs": [],
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VisionTransformer, self).__init__()\n",
        "        self.vit = torchvision.models.vit_b_16(pretrained=True)\n",
        "\n",
        "    def forward(self, image):\n",
        "        return self.vit(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7M0A3lVHzH3"
      },
      "source": [
        "cnn rnn combo network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZCazgnIYlMU"
      },
      "outputs": [],
      "source": [
        "# Define the MultiCNNRNNCombo class\n",
        "class MultiCNNRNNCombo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiCNNRNNCombo, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.rnn = nn.LSTM(64, 128, num_layers=2)\n",
        "\n",
        "    def forward(self, image):\n",
        "        cnn_output = self.cnn(image)\n",
        "        rnn_output, _ = self.rnn(cnn_output)\n",
        "        return rnn_output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TqxI1hOH7g6"
      },
      "source": [
        "py auto gui ambiguous actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCyh0COmV0AH"
      },
      "outputs": [],
      "source": [
        "class KeyboardMouseController(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(KeyboardMouseController, self).__init__()\n",
        "        self.pyautogui = pyautogui\n",
        "\n",
        "    def forward(self, action):\n",
        "        self.pyautogui.press(action)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ys4y3OTThbTe"
      },
      "outputs": [],
      "source": [
        "def text_to_speech(text):\n",
        "    tts = gtts.gTTS(text)\n",
        "    tts.save(\"response.mp3\")\n",
        "    os.system(\"mpg321 response.mp3\")\n",
        "\n",
        "# Error handling example\n",
        "try:\n",
        "        sentences_or_file_folder = texts\n",
        "        #hypergraph.addnodes(sentences_or_file_folder)\n",
        "        #ypergraph.addedges(similar_sentences_or_files)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: File folder not found. Please provide a valid file folder.\")\n",
        "\n",
        "# Training function\n",
        "def train(rank, world_size, dataset, input_dim, hidden_dim, output_dim):\n",
        "    torch.distributed.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
        "    torch.cuda.set_device(rank)\n",
        "    model = NLPModel(input_dim, hidden_dim, output_dim).to(rank)\n",
        "    ddp_model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[rank])\n",
        "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(ddp_model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(5):  # Dummy epoch count\n",
        "        for hypergraph in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = ddp_model(hypergraph)\n",
        "            target = torch.zeros_like(outputs).to(rank)  # Dummy target\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if rank == 0:\n",
        "            print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "    torch.distributed.destroy_process_group()\n",
        "\n",
        "# Example usage\n",
        "input_dim, hidden_dim, output_dim = 10, 20, 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfcH-chEH-PJ"
      },
      "source": [
        "integrated model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhdNplAHhXG8"
      },
      "outputs": [],
      "source": [
        "class MultimodalModel(nn.Module):\n",
        "    def __init__(self, chat_component, vision_transformer, multi_cnn_rnn_combo, keyboard_mouse_controller):\n",
        "        super(MultimodalModel, self).__init__()\n",
        "        self.nlp_model = nlp_model\n",
        "        self.chat_component = hyperchat\n",
        "        self.vision_transformer = vision_transformer\n",
        "        self.multi_cnn_rnn_combo = multi_cnn_rnn_combo\n",
        "        self.keyboard_mouse_controller = keyboard_mouse_controller\n",
        "        self.speech_component = text_to_speech\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def forward(self, user_input, image):\n",
        "        language_output = self.chat_component(user_input)\n",
        "        vision_output = self.vision_transformer(image)\n",
        "        action = self.multi_cnn_rnn_combo(vision_output)\n",
        "        self.keyboard_mouse_controller(action)\n",
        "        return language_output, action\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nZWyxKDIBXM"
      },
      "source": [
        "text to speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpfxsHyhhqD1"
      },
      "source": [
        "# Diffusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC8VeoDhIDmg"
      },
      "source": [
        "sets up image directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujsgEC4ZpSg0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "image_dir = 'C:/users/jonny/Documents/ONI/PATH/knowledge_base/picturememory'\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.img_names = os.listdir(img_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # Resize images to 64x64 (or any desired size)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "  # Update this with the path to your folder\n",
        "dataset = CustomImageDataset(img_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBZkJd5kIHKs"
      },
      "source": [
        "sets up diffusion model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "LmOXD1-cYE2I",
        "outputId": "489362e8-668f-4772-a903-fd237c191358"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "linspace() received an invalid combination of arguments - got (float, float, CustomImageDataset), but expected one of:\n * (Tensor start, Tensor end, int steps, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Number start, Tensor end, int steps, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Tensor start, Number end, int steps, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Number start, Number end, int steps, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-408a3173aba1>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-408a3173aba1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, timesteps, beta_start, beta_end)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDDPM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas_cumprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: linspace() received an invalid combination of arguments - got (float, float, CustomImageDataset), but expected one of:\n * (Tensor start, Tensor end, int steps, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Number start, Tensor end, int steps, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Tensor start, Number end, int steps, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Number start, Number end, int steps, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "class DDPM(nn.Module):\n",
        "    def __init__(self, timesteps=1000, beta_start=0.0001, beta_end=0.02):\n",
        "        super(DDPM, self).__init__()\n",
        "        self.timesteps = timesteps\n",
        "        self.betas = torch.linspace(beta_start, beta_end, timesteps)\n",
        "        self.alphas = 1 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # Forward process: add noise to x at time t\n",
        "        noise = torch.randn_like(x)\n",
        "        return (self.alphas_cumprod[t] ** 0.5) * x + (1 - self.alphas_cumprod[t]) ** 0.5 * noise\n",
        "\n",
        "    def reverse(self, x, t):\n",
        "        # Reverse process: denoise x at time t (simplified for illustration)\n",
        "        return x  # In practice, use a neural network to predict the denoised image\n",
        "\n",
        "    def sample(self, shape):\n",
        "        x = torch.randn(shape)\n",
        "        for t in reversed(range(self.timesteps)):\n",
        "            x = self.reverse(x, t)\n",
        "        return x\n",
        "\n",
        "    def params(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "model = DDPM(dataset)\n",
        "\n",
        "# Example usage\n",
        "transform = transforms.Compose([transforms.ToTensor(dataset), transforms.Normalize((0.5,), (0.5,))])\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "model_parameters = list(model.parameters())\n",
        "\n",
        "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "print(f'Model parameters: {model.params()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esMq7lxCpG6W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2T4AtlKILB8"
      },
      "source": [
        "optimizes diffuser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "udJmlU0MpHuf",
        "outputId": "e4426ab0-2d46-4d0a-e1c9-6eeb47d8a2ec"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c16c9acdd140>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in dataloader:\n",
        "        batch = batch.cuda()  # Move data to GPU if available\n",
        "        t = torch.randint(0, model.timesteps, (batch.size(0),)).cuda()\n",
        "        noisy_data = model.forward(batch, t)\n",
        "        optimizer.zero_grad()\n",
        "        loss = ((noisy_data - batch) ** 2).mean()  # Simplified loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}: Loss {loss.item()}')\n",
        "\n",
        "# Sampling\n",
        "sampled_images = model.sample((64, 3, 64, 64)).cpu().detach()  # Adjust shape as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvQzSapJtMO-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "jfE_tJJ0cQ1q",
        "outputId": "093e3b0a-a53b-42e7-daf5-1a2ebaaf23e0"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "invalid argument to reset_peak_memory_stats",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7ad5c6f1678c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Clear the session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_peak_memory_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_peak_allocations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_max_memory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mreset_peak_memory_stats\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \"\"\"\n\u001b[1;32m    308\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_resetPeakMemoryStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: invalid argument to reset_peak_memory_stats"
          ]
        }
      ],
      "source": [
        "''' clear '''\n",
        "\n",
        "\n",
        "# Clear the session\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.reset_peak_allocations()\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "torch.cuda.reset_max_memory_reserved()\n",
        "torch.cuda.reset_reserved_memory()\n",
        "\n",
        "\n",
        "# Free up GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Delete all variables\n",
        "#del vocab\n",
        "#del word_to_index\n",
        "#del nodes\n",
        "#del hyperedges\n",
        "#del hypergraph\n",
        "#del hyper_vocab\n",
        "#del dataset\n",
        "#del hypergraphs\n",
        "#del node_features\n",
        "#del adjacency_matrix\n",
        "#del nlp_model\n",
        "#del working_data\n",
        "\n",
        "\n",
        "# Free up GPU memory\n",
        "#tf.config.experimental.reset_memory_stats(device=\"GPU:1\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
